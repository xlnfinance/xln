# XLN Context - Core System Files (~111k tokens)
## Cross-Local Network: Off-chain settlement with on-chain anchoring

xln/
  jurisdictions/contracts/
    Depository.sol             1652 lines - enforceDebts() FIFO, collateral + credit (INVARIANT: L+R+C=0)
    EntityProvider.sol         1119 lines - Hanko sigs, Control/Dividend, governance
    SubcontractProvider.sol    155 lines - HTLCs, swaps, limit orders

  runtime/
    types.ts                     566 lines - All TypeScript interfaces (START HERE)
    runtime.ts                   1175 lines - Main coordinator, 100ms ticks, R->E->A routing
    entity-consensus.ts          954 lines - BFT consensus (ADD_TX -> PROPOSE -> SIGN -> COMMIT)
    account-consensus.ts         675 lines - Bilateral consensus, left/right perspective

    entity-tx/
      index.ts                   7 lines - Entity transaction types
      apply.ts                   483 lines - Entity tx dispatcher
      validation.ts              37 lines - Transaction validation
      financial.ts               33 lines - Financial accounting
      proposals.ts               35 lines - Proposal logic
      j-events.ts                218 lines - Jurisdiction events

    account-tx/
      index.ts                   10 lines - Account transaction types
      apply.ts                   72 lines - Account tx dispatcher

    routing/
      graph.ts                   117 lines - Network graph
      pathfinding.ts             227 lines - Dijkstra routing

    state-helpers.ts             314 lines - Pure state management
    snapshot-coder.ts            240 lines - Deterministic RLP serialization
    evm.ts                       940 lines - Blockchain integration

  vibepaper/
    emc2.md                      33 lines - Energy-Mass-Credit equivalence
    priorart.md                  62 lines - * WHY LIGHTNING/ROLLUPS DON'T WORK
    docs/00_QA.md                132 lines - Value prop FAQs
    docs/12_invariant.md         80 lines - * RCPE innovation (core primitive)
    docs/jea.md                  134 lines - Jurisdiction-Entity-Account model
    docs/summary.md              151 lines - Executive summary
    docs/consensus/transaction-flow-specification.md  280 lines
    docs/11_Jurisdiction_Machine.md  43 lines - Architecture

  worlds/
    architecture.md              143 lines - Scenario architecture, EntityInput primitives

Reading Guide: 1) types.ts (data structures), 2) docs/12_invariant.md (RCPE), 3) Depository.sol (enforceDebts), 4) entity-consensus.ts + account-consensus.ts, 5) entity-tx/apply.ts + account-tx/apply.ts, 6) runtime.ts


//jurisdictions/contracts/Depository.sol (1652 lines)
// SPDX-License-Identifier: unknown
pragma solidity ^0.8.24;


import "./ECDSA.sol";
import "./console.sol";
import "hardhat/console.sol";

import "./EntityProvider.sol";

import "./SubcontractProvider.sol";

// Add necessary interfaces
interface IERC20 {
  function transfer(address to, uint256 value) external returns (bool);
  function transferFrom(address from, address to, uint256 value) external returns (bool);
}
interface IERC721 {
  function transferFrom(address from, address to, uint256 tokenId) external;
}
//interface IERC1155 {
//  function safeTransferFrom(address from, address to, uint256 id, uint256 amount, bytes calldata data) external;
//}
// IERC1155 already imported from EntityProvider.sol

/* The mechanism:
  - Collateral bounds max exposure (like Lightning)
  - But credit can extend beyond (unlike Lightning)
  - Debt enforcement is mechanical (FIFO queue + liquidity trap)
  - No "please pay me back" - enforceDebts() is called on every reserve withdrawal

  First in history: No system combines escrowed collateral + credit extension + mechanical enforcement. Traditional finance has credit but it's
  social/legal enforcement. Crypto has collateral but no credit extension. You have both.
*/
contract Depository is Console {

  // Multi-provider support  
  mapping(address => bool) public approvedEntityProviders;
  address[] public entityProvidersList;
  
  mapping (bytes32 => mapping (uint => uint)) public _reserves;

  mapping (bytes => ChannelInfo) public _channels;
  mapping (bytes => mapping(uint => ChannelCollateral)) public _collaterals; 
  

  mapping (bytes32 => mapping (uint => Debt[])) public _debts;
  // the current debt index to pay
  mapping (bytes32 => mapping (uint => uint)) public _debtIndex;
  // total number of debts of an entity  
  mapping (bytes32 => uint) public _activeDebts;


  // === REPUTATION SCORES ===

  struct EntityScore {
    // Total gas used by the entity in `processBatch` calls. Tracks overall activity.
    uint64 totalGasUsed;
    // Timestamp when the entity first acquired an active debt. Resets to 0 when all debts are cleared.
    uint48 inDebtSince;
    // The total number of outstanding debts across all tokens.
    uint32 totalActiveDebts;
    // Counter for how many times the entity has been involved in a dispute.
    uint32 totalDisputes;
    // A counter for successfully paid-off debts. A measure of reliability.
    uint32 successfulRepayments;
    // A counter for successful cooperative settlements. A measure of good-faith participation.
    uint32 cooperativeActions;
  }

  mapping(bytes32 => EntityScore) public entityScores;


  struct Settled {
      bytes32 left;
      bytes32 right;
      uint tokenId;
      uint leftReserve;
      uint rightReserve;
      uint collateral;
      int ondelta;
  }
  event ChannelSettled(Settled[]);

  struct Hub {
    bytes32 entityId;
    uint gasused;
    string uri;
  }
  Hub[] public _hubs;
  
  event TransferReserveToCollateral(bytes32 indexed receivingEntity, bytes32 indexed counterentity, uint collateral, int ondelta, uint tokenId);
  event DisputeStarted(bytes32 indexed sender, bytes32 indexed counterentity, uint indexed disputeNonce, bytes initialArguments);
  event CooperativeClose(bytes32 indexed sender, bytes32 indexed counterentity, uint indexed cooperativeNonce);
  
  event ReserveTransferred(bytes32 indexed from, bytes32 indexed to, uint indexed tokenId, uint amount);

  /**
   * @notice Emitted whenever an entity's reserve balance for a specific token changes.
   * @dev This is the primary event for j-watchers to sync entity state.
   * @param entity The entity whose reserve was updated.
   * @param tokenId The internal ID of the token.
   * @param newBalance The absolute new balance of the token for the entity.
   */
  event ReserveUpdated(bytes32 indexed entity, uint indexed tokenId, uint newBalance);

  /**
   * @notice Emitted when entities settle off-chain account differences
   * @dev This event contains final absolute values after settlement processing
   * @param leftEntity The first entity in the settlement
   * @param rightEntity The second entity in the settlement
   * @param tokenId The token being settled
   * @param leftReserve Final absolute reserve balance for left entity
   * @param rightReserve Final absolute reserve balance for right entity
   * @param collateral Final absolute collateral amount
   * @param ondelta Final ondelta value
   */
  event SettlementProcessed(
    bytes32 indexed leftEntity,
    bytes32 indexed rightEntity,
    uint indexed tokenId,
    uint leftReserve,
    uint rightReserve,
    uint collateral,
    int ondelta
  );

  //event ChannelUpdated(address indexed receiver, address indexed addr, uint tokenId);


  // Token type identifiers
  uint8 constant TypeERC20 = 0;
  uint8 constant TypeERC721 = 1;
  uint8 constant TypeERC1155 = 2;   




  bytes32[] public _tokens;
  
  // Efficient token lookup: packedToken -> internalTokenId
  mapping(bytes32 => uint256) public tokenToId;

  // === MULTI-PROVIDER MANAGEMENT ===
  
  event EntityProviderAdded(address indexed provider);
  event EntityProviderRemoved(address indexed provider);
  
  modifier onlyApprovedProvider(address provider) {
    require(approvedEntityProviders[provider], "Provider not approved");
    _;
  }
  
  /**
   * @notice Add an EntityProvider to approved list
   * @param provider EntityProvider contract address
   */
  function addEntityProvider(address provider) external {
    require(!approvedEntityProviders[provider], "Already approved");
    approvedEntityProviders[provider] = true;
    entityProvidersList.push(provider);
    emit EntityProviderAdded(provider);
  }
  
  /**
   * @notice Remove an EntityProvider from approved list  
   * @param provider EntityProvider contract address
   */
  function removeEntityProvider(address provider) external {
    require(approvedEntityProviders[provider], "Not approved");
    approvedEntityProviders[provider] = false;
    
    // Remove from list
    for (uint i = 0; i < entityProvidersList.length; i++) {
      if (entityProvidersList[i] == provider) {
        entityProvidersList[i] = entityProvidersList[entityProvidersList.length - 1];
        entityProvidersList.pop();
        break;
      }
    }
    emit EntityProviderRemoved(provider);
  }
  
  /**
   * @notice Get all approved EntityProviders
   */
  function getApprovedProviders() external view returns (address[] memory) {
    return entityProvidersList;
  }

  constructor() {
    _tokens.push(bytes32(0));
    
    // empty record, hub_id==0 means not a hub
    _hubs.push(Hub({
      entityId: bytes32(0),
      uri: '',
      gasused: 0
    }));
    
    // DEBUG: Prefund top 1000 entities for testing
    debugBulkFundEntities();
  }
  
  function getTokensLength() public view returns (uint) {
    return _tokens.length;
  }





  struct Batch {
    // tokens move Token <=> Reserve <=> Collateral
    // but never Token <=> Collateral. 'reserve' acts as an intermediary balance
    ReserveToExternalToken[] reserveToExternalToken;
    ExternalTokenToReserve[] externalTokenToReserve;

    // don't require a signature
    ReserveToReserve[] reserveToReserve;
    ReserveToCollateral[] reserveToCollateral;

    // NEW: Simple settlements between entities (no signature verification for now)
    Settlement[] settlements;
    
    // DEPRECATED: Keep for backwards compatibility but will be replaced
    CooperativeUpdate[] cooperativeUpdate;
    CooperativeDisputeProof[] cooperativeDisputeProof;

    // initialDisputeProof is signed by the peer, but could be outdated
    // another peer has time to respond with a newer proof
    InitialDisputeProof[] initialDisputeProof;
    FinalDisputeProof[] finalDisputeProof;


    TokenAmountPair[] flashloans;

    //bytes32[] revealSecret;
    //bytes32[] cleanSecret;
    uint hub_id;
  }


  /* === HANKO INTEGRATION ===
  
  /* Nonce tracking for replay protection (since Hanko signatures are stateless)
  /* EVM-style sequential nonces: each entity must use nonce = lastNonce + 1
  mapping(address => uint256) public entityNonces;
  
  /* Domain separation for EIP-712 compatibility
  bytes32 public constant DOMAIN_SEPARATOR = keccak256("XLN_DEPOSITORY_HANKO_V1");
  
  event HankoBatchProcessed(bytes32 indexed entityId, bytes32 indexed hankoHash, uint256 nonce, bool success);
  
  /**
   * @notice Process batch with Hanko signature authorization using on-chain cryptographic verification
   * @dev SECURITY: All signatures are verified on-chain using ecrecover - no off-chain trust
   * @param encodedBatch The batch data
   * @param entityProvider EntityProvider contract address  
   * @param hankoData ABI-encoded Hanko bytes (placeholders, packedSignatures, claims)
   * @param nonce EVM-style sequential nonce for replay protection
   */
  /* DISABLED: Hanko processing
  function processBatchWithHanko(
    bytes calldata encodedBatch,
    address entityProvider,
    bytes calldata hankoData,
    uint256 nonce
  ) external onlyApprovedProvider(entityProvider) returns (bool completeSuccess) {
    
    // üõ°Ô∏è Domain separation: Hash batch with contract-specific context
    bytes32 domainSeparatedHash = keccak256(abi.encodePacked(
      DOMAIN_SEPARATOR,
      block.chainid,
      address(this),
      encodedBatch,
      nonce
    ));
    
    // üî• Verify Hanko with flashloan governance
    (bytes32 entityId, bool hankoValid) = EntityProvider(entityProvider).verifyHankoSignature(
      hankoData,
      domainSeparatedHash
    );
    
    require(hankoValid, "Invalid Hanko signature");
    require(entityId != bytes32(0), "No entity recovered from Hanko");
    
    // üöÄ Nonce management: Prevent replay attacks
    bytes32 entityIdBytes32 = entityId; // Already bytes32
    bytes32 hankoHash = keccak256(hankoData);
    
    require(nonce == entityNonces[address(uint160(uint256(entityIdBytes32)))] + 1, "Invalid nonce (must be sequential)");
    entityNonces[address(uint160(uint256(entityIdBytes32)))] = nonce;
    
    // ‚ö° Process the actual batch
    completeSuccess = _processBatch(entityIdBytes32, abi.decode(encodedBatch, (Batch)));
    
    emit HankoBatchProcessed(entityId, hankoHash, nonce, completeSuccess);
    
    return completeSuccess;
  }
  */
  




  // DEBUG: Simple function to fund entity reserves for testing
  function debugFundReserves(bytes32 entity, uint tokenId, uint amount) public {
    console.log("debugFundReserves: funding entity");
    console.logBytes32(entity);
    console.log("debugFundReserves: tokenId");
    console.logUint(tokenId);
    console.log("debugFundReserves: amount");
    console.logUint(amount);
    
    _reserves[entity][tokenId] += amount;
    emit ReserveUpdated(entity, tokenId, _reserves[entity][tokenId]);
    
    console.log("debugFundReserves: new balance");
    console.logUint(_reserves[entity][tokenId]);
  }

  // DEBUG: Bulk fund top 1000 entities with test reserves
  function debugBulkFundEntities() public {
    console.log("debugBulkFundEntities: funding entities 1-200 with USDC and ETH");

    uint256 fundAmount = 100000000000000000000; // 100 units (100e18)

    for (uint256 entityNum = 1; entityNum <= 500; entityNum++) {
      bytes32 entity = bytes32(entityNum); // Entity ID is just the number padded

      // Fund with tokens 1 (USDC), 2 (ETH) only
      for (uint256 tokenId = 1; tokenId <= 2; tokenId++) {
        _reserves[entity][tokenId] += fundAmount;
        emit ReserveUpdated(entity, tokenId, _reserves[entity][tokenId]);
      }
    }

    console.log("debugBulkFundEntities: funding complete");
  }

  function processBatch(bytes32 entity, Batch calldata batch) public returns (bool completeSuccess) {
    console.log("=== processBatch ENTRY ===");
    console.log("=== processBatch ENTRY ===");
    console.log("=== processBatch ENTRY ===");
    console.log("processBatch called with entity");
    console.logBytes32(entity);
    console.log("batch.reserveToReserve.length");
    console.logUint(batch.reserveToReserve.length);
    console.log("msg.sender:");
    console.logAddress(msg.sender);
    
    if (batch.reserveToReserve.length > 0) {
      console.log("First transfer details:");
      console.log("  to entity:");
      console.logBytes32(batch.reserveToReserve[0].receivingEntity);
      console.log("  tokenId:");
      console.logUint(batch.reserveToReserve[0].tokenId);
      console.log("  amount:");
      console.logUint(batch.reserveToReserve[0].amount);
      
      console.log("Sender current balance:");
      console.logUint(_reserves[entity][batch.reserveToReserve[0].tokenId]);
    }
    
    console.log("=== CALLING _processBatch ===");
    return _processBatch(entity, batch);
  }


  // ========== ACCOUNT PREFUNDING FUNCTION ==========
  // Allows an entity to fund an account's collateral from their reserves
  function prefundAccount(bytes32 counterpartyEntity, uint tokenId, uint amount) public returns (bool) {
    bytes32 fundingEntity = bytes32(uint256(uint160(msg.sender)));
    require(fundingEntity != counterpartyEntity, "Cannot prefund account with self");
    
    // Ensure entities are in canonical order (left < right)
    bytes32 leftEntity = fundingEntity < counterpartyEntity ? fundingEntity : counterpartyEntity;
    bytes32 rightEntity = fundingEntity < counterpartyEntity ? counterpartyEntity : fundingEntity;
    
    // Simple channel key: hash of left and right entities converted to bytes
    bytes memory ch_key = abi.encodePacked(keccak256(abi.encodePacked(leftEntity, rightEntity)));
    
    // Check funding entity has sufficient reserves
    require(_reserves[fundingEntity][tokenId] >= amount, "Insufficient reserves for prefunding");
    
    // Move funds from reserves to account collateral
    _reserves[fundingEntity][tokenId] -= amount;
    
    ChannelCollateral storage col = _collaterals[ch_key][tokenId];
    col.collateral += amount;
    
    // Emit SettlementProcessed event to notify both entities
    emit SettlementProcessed(
      leftEntity,
      rightEntity,
      tokenId,
      _reserves[leftEntity][tokenId],
      _reserves[rightEntity][tokenId],
      col.collateral,
      col.ondelta
    );
    
    console.log("Account prefunded:");
    console.logBytes32(fundingEntity);
    console.log("funded account with:");
    console.logBytes32(counterpartyEntity);
    console.log("amount:");
    console.logUint(amount);
    
    return true;
  }

  // ========== DIRECT R2R FUNCTION ==========
  // Simple reserve-to-reserve transfer (simpler than batch)
  function reserveToReserve(bytes32 fromEntity, bytes32 toEntity, uint tokenId, uint amount) public returns (bool) {
    require(fromEntity != toEntity, "Cannot transfer to self");
    require(_reserves[fromEntity][tokenId] >= amount, "Insufficient reserves");

    console.log("=== DIRECT R2R TRANSFER ===");
    console.logBytes32(fromEntity);
    console.log("to");
    console.logBytes32(toEntity);
    console.log("amount:");
    console.logUint(amount);

    // Simple transfer: subtract from sender, add to receiver
    _reserves[fromEntity][tokenId] -= amount;
    _reserves[toEntity][tokenId] += amount;

    // Emit events for j-watcher
    emit ReserveUpdated(fromEntity, tokenId, _reserves[fromEntity][tokenId]);
    emit ReserveUpdated(toEntity, tokenId, _reserves[toEntity][tokenId]);
    emit ReserveTransferred(fromEntity, toEntity, tokenId, amount);

    console.log("=== R2R TRANSFER COMPLETE ===");
    return true;
  }

  // ========== NEW SIMPLIFIED SETTLE FUNCTION ==========
  // Simple settlement between two entities without signature verification
  // Can be called independently or as part of processBatch
  function settle(bytes32 leftEntity, bytes32 rightEntity, SettlementDiff[] memory diffs) public returns (bool) {
    require(leftEntity != rightEntity, "Cannot settle with self");
    require(leftEntity < rightEntity, "Entities must be in order (left < right)");
    
    // Simple channel key: hash of left and right entities converted to bytes
    bytes memory ch_key = abi.encodePacked(keccak256(abi.encodePacked(leftEntity, rightEntity)));
    
    // Comment out signature verification for development
    // TODO: Re-enable signature verification in production
    
    for (uint j = 0; j < diffs.length; j++) {
      SettlementDiff memory diff = diffs[j];
      uint tokenId = diff.tokenId;
      
      // ‚úÖ INVARIANT CHECK: Total value change must be zero
      // leftDiff + rightDiff + collateralDiff == 0
      require(diff.leftDiff + diff.rightDiff + diff.collateralDiff == 0, "Settlement must balance");
      
      // Update left entity reserves
      if (diff.leftDiff < 0) {
        require(_reserves[leftEntity][tokenId] >= uint(-diff.leftDiff), "Left entity insufficient reserves");
        _reserves[leftEntity][tokenId] -= uint(-diff.leftDiff);
      } else if (diff.leftDiff > 0) {
        _reserves[leftEntity][tokenId] += uint(diff.leftDiff);
      }
      
      // Update right entity reserves  
      if (diff.rightDiff < 0) {
        require(_reserves[rightEntity][tokenId] >= uint(-diff.rightDiff), "Right entity insufficient reserves");
        _reserves[rightEntity][tokenId] -= uint(-diff.rightDiff);
      } else if (diff.rightDiff > 0) {
        _reserves[rightEntity][tokenId] += uint(diff.rightDiff);
      }
      
      // Update collateral
      ChannelCollateral storage col = _collaterals[ch_key][tokenId];
      if (diff.collateralDiff < 0) {
        require(col.collateral >= uint(-diff.collateralDiff), "Insufficient collateral");
        col.collateral -= uint(-diff.collateralDiff);
      } else if (diff.collateralDiff > 0) {
        col.collateral += uint(diff.collateralDiff);
      }
      
      // Update ondelta
      col.ondelta += diff.ondeltaDiff;
      
      // Emit SettlementProcessed event with final values for j-watcher consumption
      emit SettlementProcessed(
        leftEntity,
        rightEntity,
        tokenId,
        _reserves[leftEntity][tokenId],
        _reserves[rightEntity][tokenId],
        col.collateral,
        col.ondelta
      );
    }
    
    // TODO: Add cooperative nonce tracking if needed for settlement ordering
    return true;
  }

  function _processBatch(bytes32 entityId, Batch memory batch) private returns (bool completeSuccess) {
    console.log("_processBatch starting for entity");
    console.logBytes32(entityId);
    uint startGas = gasleft();

    // the order is important: first go methods that increase entity's balance
    // then methods that deduct from it

    completeSuccess = true; 

    // Process reserveToReserve transfers (the core functionality we need)
    console.log("Processing reserveToReserve transfers count:");
    console.logUint(batch.reserveToReserve.length);
    for (uint i = 0; i < batch.reserveToReserve.length; i++) {
      console.log("Transfer index:");
      console.logUint(i);
      console.log("From entity:");
      console.logBytes32(entityId);
      console.log("To entity:");
      console.logBytes32(batch.reserveToReserve[i].receivingEntity);
      console.log("Token ID:");
      console.logUint(batch.reserveToReserve[i].tokenId);
      console.log("Amount:");
      console.logUint(batch.reserveToReserve[i].amount);
      reserveToReserve(entityId, batch.reserveToReserve[i]);
    }

    // NEW: Process settlements (simplified account settlements between entities)
    console.log("Processing settlements count:");
    console.logUint(batch.settlements.length);
    for (uint i = 0; i < batch.settlements.length; i++) {
      Settlement memory settlement = batch.settlements[i];
      console.log("Settlement between:");
      console.logBytes32(settlement.leftEntity);
      console.log("and:");
      console.logBytes32(settlement.rightEntity);
      
      if (!settle(settlement.leftEntity, settlement.rightEntity, settlement.diffs)) {
        completeSuccess = false;
      }
    }

    /*
    // flashloans allow to settle batch of cooperativeUpdate
    for (uint i = 0; i < batch.flashloans.length; i++) {
      _reserves[msg.sender][batch.flashloans[i].tokenId] += batch.flashloans[i].amount;
    }

    for (uint i = 0; i < batch.flashloans.length; i++) {
      // fails if not enough _reserves 
      _reserves[entityAddress][batch.flashloans[i].tokenId] -= batch.flashloans[i].amount;
    }
    */
    
    /* DISABLED: dispute functions
    for (uint i = 0; i < batch.cooperativeUpdate.length; i++) {
      if(!(cooperativeUpdate(entityId, batch.cooperativeUpdate[i]))){
        completeSuccess = false;
      }
    }
    for (uint i = 0; i < batch.cooperativeDisputeProof.length; i++) {
      if(!(cooperativeDisputeProof(batch.cooperativeDisputeProof[i]))){
        completeSuccess = false;
      }
    }

    //submitProof (Header / proofbody)

    for (uint i = 0; i < batch.initialDisputeProof.length; i++) {
      if(!(initialDisputeProof(batch.initialDisputeProof[i]))){
        completeSuccess = false;
      }
    }

    for (uint i = 0; i < batch.finalDisputeProof.length; i++) {
      if(!(finalDisputeProof(batch.finalDisputeProof[i]))){
        completeSuccess = false;
      }
    }
    */

    
    /* DISABLED: collateral functions
    for (uint i = 0; i < batch.reserveToCollateral.length; i++) {
      if(!(reserveToCollateral(entityId, batch.reserveToCollateral[i]))){
        completeSuccess = false;
      }
    }
    */
    
    /*
    for (uint i = 0; i < batch.revealSecret.length; i++) {
      revealSecret(batch.revealSecret[i]);
    }

    for (uint i = 0; i < batch.cleanSecret.length; i++) {
      cleanSecret(batch.cleanSecret[i]);
    }*/

    // increase gasused for hubs
    // this is hardest to fake metric of real usage
    if (batch.hub_id != 0 && entityId == _hubs[batch.hub_id].entityId){
      _hubs[batch.hub_id].gasused += startGas - gasleft();
    }

    // Update entity's gas usage score
    entityScores[entityId].totalGasUsed += uint64(startGas - gasleft());

    return completeSuccess;
    
  }

  
  enum MessageType {
    CooperativeUpdate,
    CooperativeDisputeProof,
    DisputeProof
  }

  struct TokenAmountPair {
    uint tokenId;
    uint amount;
  }

  struct AddrAmountPair {
    bytes32 entity;
    uint amount;
  }

  struct ReserveToCollateral {
    uint tokenId;
    bytes32 receivingEntity;
    // put in _channels with who (addr) and how much (amount)
    AddrAmountPair[] pairs;
  }

  struct Diff {
    uint tokenId;
    int peerReserveDiff;
    int collateralDiff;
    int ondeltaDiff;
  }

  // Simplified settlement diff structure
  struct SettlementDiff {
    uint tokenId;
    int leftDiff;        // Change for left entity
    int rightDiff;       // Change for right entity  
    int collateralDiff;  // Change in collateral
    int ondeltaDiff;     // Change in ondelta
  }

  // Settlement batch between two entities
  struct Settlement {
    bytes32 leftEntity;
    bytes32 rightEntity;
    SettlementDiff[] diffs;
    // No signature field - signatures commented out for development
  }
  //Enforces the invariant: Its main job is to run the check you described: require(leftReserveDiff + rightReserveDiff + collateralDiff == 0). This guarantees no value is created or lost, only moved.
  struct CooperativeUpdate {
    bytes32 counterentity;
    Diff[] diffs;
    uint[] forgiveDebtsInTokenIds;
    bytes sig; 
  }





  struct Allowence {
    uint deltaIndex;
    uint rightAllowence;
    uint leftAllowence;
  }
  struct SubcontractClause {
    address subcontractProviderAddress;
    bytes encodedBatch;
    Allowence[] allowences;
  }

  struct ProofBody{
    int[] offdeltas;
    uint[] tokenIds;
    SubcontractClause[] subcontracts;
  }

  struct CooperativeDisputeProof {
    bytes32 counterentity;
    ProofBody proofbody;
    bytes initialArguments;
    bytes finalArguments;
    bytes sig;
  }

  struct InitialDisputeProof {
    bytes32 counterentity;
    uint cooperativeNonce;
    uint disputeNonce;
    bytes32 proofbodyHash; 
    bytes sig;

    bytes initialArguments;
  }

  struct FinalDisputeProof {
    bytes32 counterentity;
    uint initialCooperativeNonce;
    uint initialDisputeNonce;
    uint disputeUntilBlock;
    bytes32 initialProofbodyHash;
    bytes initialArguments;
    bool startedByLeft;

    uint finalCooperativeNonce;
    uint finalDisputeNonce;
    ProofBody finalProofbody;
    bytes finalArguments;

    bytes sig;
  }

  struct Debt {
    uint amount;
    bytes32 creditor;
  }
  
  struct ChannelCollateral {
    // total amount of collateral locked in the channel for this token
    uint collateral;
    // when Left +=/-= .collateral, do the same operation to .ondelta
    int ondelta;   
  }

  struct ChannelInfo{
    // TODO: we could possibly store all channel state as a single hash
    // and provide it with every request as CALLDATA to save gas
    // but unilateral reserveToCollateral would become tricky

    // used for cooperativeUpdate and cooperative close, stored forever
    uint cooperativeNonce;

    // dispute state is stored after dispute is started
    bytes32 disputeHash;
  }
  

  function packTokenReference(uint8 tokenType, address contractAddress, uint96 externalTokenId) public pure returns (bytes32) {
    require(tokenType <= 255);

    // Pack the contractAddress into the most significant 160 bits
    bytes32 packed = bytes32(uint256(uint160(contractAddress)) << 96);

    // Pack the tokenId into the next 96 bits
    packed |= bytes32(uint256(externalTokenId) << 8);

    // Pack the tokenType into the least significant 8 bits
    packed |= bytes32(uint256(tokenType));

    return packed;
  }

  function unpackTokenReference(bytes32 packed) public pure returns (address contractAddress, uint96 externalTokenId, uint8 tokenType) {
    // Unpack the contractAddress from the most significant 160 bits
    contractAddress = address(uint160(uint256(packed) >> 96));

    // Unpack the externalTokenId from the next 96 bits
    externalTokenId = uint96((uint256(packed) >> 8) & 0xFFFFFFFFFFFFFFFFFFFFFF);

    // Unpack the tokenType from the least significant 8 bits
    tokenType = uint8(uint256(packed) & 0xFF);

    return (contractAddress, externalTokenId, tokenType);
  }





  function registerHub(uint hub_id, string memory new_uri) public returns (uint) {
    if (hub_id == 0) {
      _hubs.push(Hub({
        entityId: bytes32(uint256(uint160(msg.sender))),
        uri: new_uri,
        gasused: 0
      }));
      return _hubs.length - 1;
    } else {
      require(bytes32(uint256(uint160(msg.sender))) == _hubs[hub_id].entityId, "Sender is not hub owner");
      _hubs[hub_id].uri = new_uri;
      return hub_id;
    }
  }

  struct ExternalTokenToReserve{
    bytes32 entity; // The entity to credit. If bytes32(0), defaults to msg.sender
    bytes32 packedToken;
    uint internalTokenId;
    uint amount;
  }
  function externalTokenToReserve(ExternalTokenToReserve memory params) public {
    bytes32 targetEntity = params.entity == bytes32(0) ? bytes32(uint256(uint160(msg.sender))) : params.entity;
    
    if (params.internalTokenId == 0) {
      // Check if token already exists using efficient lookup
      params.internalTokenId = tokenToId[params.packedToken];
      
      if (params.internalTokenId == 0) {
        // Create new token
        _tokens.push(params.packedToken);
        params.internalTokenId = _tokens.length - 1;
        tokenToId[params.packedToken] = params.internalTokenId;
        
        //console.log("Saved new token:", params.internalTokenId);
      }
    } else {
      params.packedToken = _tokens[params.internalTokenId];
      //require(_tokens[params.internalTokenId] == params.packedToken, "Token data mismatch");
    }


    (address contractAddress, uint96 tokenId, uint8 tokenType) = unpackTokenReference(params.packedToken);
    //console.log('unpackedToken ', contractAddress,tokenId,  tokenType);

    // todo: allow longer uint256 tokenId for ERC721 and ERC1155 
    // e.g. Rarible has format of 0xCreatorAddress..00000TokenId
    if (tokenType == TypeERC20) {
      require(IERC20(contractAddress).transferFrom(msg.sender, address(this), params.amount), "ERC20 transferFrom failed");
    } else if (tokenType == TypeERC721) {
      // 721 does not return bool on transfer
      IERC721(contractAddress).transferFrom(msg.sender, address(this), uint(tokenId));
      params.amount = 1; // For 721, amount is always 1
    } else if (tokenType == TypeERC1155) {
      IERC1155(contractAddress).safeTransferFrom(msg.sender, address(this), uint(tokenId), params.amount, "");
    }

    _reserves[targetEntity][params.internalTokenId] += params.amount;
    emit ReserveUpdated(targetEntity, params.internalTokenId, _reserves[targetEntity][params.internalTokenId]);
  }


  struct ReserveToExternalToken{
    bytes32 receivingEntity;
    uint tokenId;
    uint amount;
  }
  function reserveToExternalToken(bytes32 entity, ReserveToExternalToken memory params) internal {
    // enforceDebts(entity, params.tokenId); // DISABLED

    (address contractAddress, uint96 tokenId, uint8 tokenType) = unpackTokenReference(_tokens[params.tokenId]);
    //console.log('unpackedToken ', contractAddress,tokenId,  tokenType);

    require(_reserves[entity][params.tokenId] >= params.amount, "Not enough reserve");

    _reserves[entity][params.tokenId] -= params.amount;
    emit ReserveUpdated(entity, params.tokenId, _reserves[entity][params.tokenId]);

    if (tokenType == TypeERC20) {
      require(IERC20(contractAddress).transfer(address(uint160(uint256(params.receivingEntity))), params.amount));
    } else if (tokenType == TypeERC721) {
      IERC721(contractAddress).transferFrom(address(this), address(uint160(uint256(params.receivingEntity))), uint(tokenId));
    } else if (tokenType == TypeERC1155) {
      IERC1155(contractAddress).safeTransferFrom(address(this), address(uint160(uint256(params.receivingEntity))), uint(tokenId), params.amount, "");
    }

  }
  struct ReserveToReserve{
    bytes32 receivingEntity;
    uint tokenId;
    uint amount;
  }
  function reserveToReserve(bytes32 entity, ReserveToReserve memory params) internal {
    console.log("=== reserveToReserve ENTRY ===");
    console.log("reserveToReserve: from entity");
    console.logBytes32(entity);
    console.log("reserveToReserve: to entity");
    console.logBytes32(params.receivingEntity);
    console.log("reserveToReserve: tokenId");
    console.logUint(params.tokenId);
    console.log("reserveToReserve: amount");
    console.logUint(params.amount);
    console.log("reserveToReserve: sender balance");
    console.logUint(_reserves[entity][params.tokenId]);
    
    // enforceDebts(entity, params.tokenId); // DISABLED

    console.log("=== BALANCE CHECK ===");
    if (_reserves[entity][params.tokenId] >= params.amount) {
      console.log("SUCCESS: Balance check passed");
    } else {
      console.log("FAIL: Balance check failed - insufficient funds");
      console.log("Required:");
      console.logUint(params.amount);
      console.log("Available:");
      console.logUint(_reserves[entity][params.tokenId]);
    }

    require(_reserves[entity][params.tokenId] >= params.amount, "Insufficient balance for transfer");
    
    console.log("=== EXECUTING TRANSFER ===");
    _reserves[entity][params.tokenId] -= params.amount;
    _reserves[params.receivingEntity][params.tokenId] += params.amount;
    
    console.log("reserveToReserve: transfer complete");
    console.log("reserveToReserve: new sender balance");
    console.logUint(_reserves[entity][params.tokenId]);
    console.log("reserveToReserve: new recipient balance");
    console.logUint(_reserves[params.receivingEntity][params.tokenId]);
    
    emit ReserveUpdated(entity, params.tokenId, _reserves[entity][params.tokenId]);
    emit ReserveUpdated(params.receivingEntity, params.tokenId, _reserves[params.receivingEntity][params.tokenId]);
    emit ReserveTransferred(entity, params.receivingEntity, params.tokenId, params.amount);
    console.log("=== reserveToReserve COMPLETE ===");
  }

  /**
   * @notice Transfer control/dividend shares between entity reserves
   * @dev Wrapper around reserveToReserve with better semantics for control shares
   * @param to Recipient entity address
   * @param internalTokenId Internal token ID (use getControlShareTokenId helper)
   * @param amount Amount of shares to transfer
   */
  function transferControlShares(
    bytes32 entity,
    bytes32 to,
    uint256 internalTokenId,
    uint256 amount,
    string calldata /* purpose */
  ) internal {
    // enforceDebts(entity, internalTokenId); // DISABLED

    require(_reserves[entity][internalTokenId] >= amount, "Insufficient control shares");
    require(to != bytes32(0), "Invalid recipient");
    require(to != entity, "Cannot transfer to self");

    _reserves[entity][internalTokenId] -= amount;
    _reserves[to][internalTokenId] += amount;

    // emit ControlSharesTransferred(entity, to, internalTokenId, amount, purpose); // DISABLED
    emit ReserveUpdated(entity, internalTokenId, _reserves[entity][internalTokenId]);
    emit ReserveUpdated(to, internalTokenId, _reserves[to][internalTokenId]);
  }

  /**
   * @notice Get internal token ID for EntityProvider control/dividend tokens
   * @param entityProvider EntityProvider contract address
   * @param externalTokenId External token ID (entity number for control, entity number | 0x8000... for dividend)
   * @return internalTokenId Internal token ID for use with reserves
   */
  function getControlShareTokenId(address entityProvider, uint256 externalTokenId) external view returns (uint256 internalTokenId) {
    bytes32 packedToken = packTokenReference(TypeERC1155, entityProvider, uint96(externalTokenId));
    return tokenToId[packedToken];
  }




  
  function getDebts(bytes32 entity, uint tokenId) public view returns (Debt[] memory allDebts, uint currentDebtIndex) {
    currentDebtIndex = _debtIndex[entity][tokenId];
    allDebts = _debts[entity][tokenId];
  }


  /* triggered automatically before every reserveTo{Reserve/ChannelCollateral/PackedToken}
  /* can be called manually
  /* iterates over _debts starting from current _debtIndex, first-in-first-out 
  /* max _debts?
  /* Calling enforceDebts at the exit points is
  sound: it guarantees nobody can move funds while they owe. What you get is a single choke point that‚Äôs trivial to audit: ‚Äúany reserve decrease first clears
  debts.‚Äù
  The elegance is that it does ONE thing perfectly: ensures reserves can't exit while debts exist. That's the minimum viable enforcement needed to make bilateral credit work.

  It transforms the complex social problem of "who gets paid first when there isn't enough?" into a deterministic mechanical process. FIFO is the only fair queue because chronological priority is the only objective ordering that can't be gamed ex-post.
  */

  //The FIFO queue is the ONLY safe approach. Any deviation creates attack vectors
/* enforceDebts(): The Immutable Law of Chronological Justice
 *
 * This function is 100% OPTIMAL - any deviation breaks fairness invariants.
 * 
 * WHY FIFO IS THE ONLY SOLUTION:
 * In traditional finance, bankruptcy courts enforce "absolute priority rule" -
 * first creditor gets paid first. This prevents late-coming creditors from
 * jumping the queue through side deals, political influence, or sybil attacks.
 *
 * THE BEAUTY:
 * 1. SIMPLICITY: One queue, one order, no exceptions. O(n) complexity.
 * 2. UNGAMEABLE: Timestamp of debt creation is immutable history.
 * 3. DETERMINISTIC: No subjective judgments about "senior" vs "junior" debt.
 * 4. ATOMIC: Either you have reserves to pay next debt in full, or you don't.
 * 
 * THE MECHANISM:
 * - Every reserve withdrawal must first satisfy debts in order
 * - Creates a "liquidity trap" - entity can receive but not send until debts clear
 * - Transforms social reputation ("this hub owes me") into mechanical enforcement
 *
 * WHY NOT PARTIAL PAYMENTS?
 * Partial payments enable gaming: pay 1 wei to each creditor, keep queue forever.
 * Full payment requirement forces entity to accumulate enough for meaningful settlement.
 *
 * WHY NOT NETTING/PRIORITIES/TRADING?
 * Any deviation from FIFO allows queue manipulation. Hub could create fake 
 * senior debt to itself, or net out favorable cycles while starving others.
 *
 * This is not a bug - it's the feature. enforceDebts is like the Kalashnikov of financial protocols - utterly reliable because it has no moving parts to break. Any "improvement" would be like adding a laser sight to a hammer.
 Like TCP sequence numbers or Bitcoin's
 * UTXO model, the constraint IS the security. Pure chronological ordering is the
 * only objective truth the J-machine can enforce without becoming a judge.
 *
 * The elegance: by doing exactly ONE thing perfectly (FIFO enforcement), it enables
 * an entire credit economy to exist trustlessly. The threat of entering this
 * "debt purgatory" keeps hubs honest without ever needing to trigger it.
 */
  function enforceDebts(bytes32 entity, uint tokenId) public returns (uint totalDebts) {
    uint debtsLength = _debts[entity][tokenId].length;
    if (debtsLength == 0) {
      return 0;
    }
   
    uint memoryReserve = _reserves[entity][tokenId]; 
    uint memoryDebtIndex = _debtIndex[entity][tokenId];
    
    if (memoryReserve == 0){
      return debtsLength - memoryDebtIndex;
    }
    // allow partial enforcing in case there are too many _debts to pay off at once (over block gas limit)
    while (true) {
      Debt storage debt = _debts[entity][tokenId][memoryDebtIndex];
      
      if (memoryReserve >= debt.amount) {
        // can pay this debt off in full
        memoryReserve -= debt.amount;
        _reserves[debt.creditor][tokenId] += debt.amount;

        delete _debts[entity][tokenId][memoryDebtIndex];

        // Update reputation score for repayment
        EntityScore storage score = entityScores[entity];
        score.totalActiveDebts--;
        score.successfulRepayments++;
        if (score.totalActiveDebts == 0) {
          score.inDebtSince = 0; // Reset timestamp when all debts are clear
        }

        // last debt was paid off, the entity is debt free now
        if (memoryDebtIndex+1 == debtsLength) {
          memoryDebtIndex = 0;
          // resets .length to 0
          delete _debts[entity][tokenId]; 
          debtsLength = 0;
          break;
        }
        memoryDebtIndex++;
        _activeDebts[entity]--;
        
      } else {
        // pay off the debt partially and break the loop
        _reserves[debt.creditor][tokenId] += memoryReserve;
        debt.amount -= memoryReserve;
        memoryReserve = 0;
        break;
      }
    }

    // put memory variables back to storage
    _reserves[entity][tokenId] = memoryReserve;
    _debtIndex[entity][tokenId] = memoryDebtIndex;
    
    return debtsLength - memoryDebtIndex;
  }



  function channelKey(bytes32 e1, bytes32 e2) public pure returns (bytes memory) {
    //determenistic channel key is 64 bytes: concatenated lowerKey + higherKey
    return e1 < e2 ? abi.encodePacked(e1, e2) : abi.encodePacked(e2, e1);
  }

  function reserveToCollateral(bytes32 entity, ReserveToCollateral memory params) internal returns (bool completeSuccess) {
    uint tokenId = params.tokenId;
    bytes32 receivingEntity = params.receivingEntity;
   
    // debts must be paid before any transfers from reserve 
    enforceDebts(entity, tokenId);

    for (uint i = 0; i < params.pairs.length; i++) {
      bytes32 counterentity = params.pairs[i].entity;
      uint amount = params.pairs[i].amount;

      bytes memory ch_key = channelKey(receivingEntity, counterentity);

      logChannel(receivingEntity, counterentity);

      if (_reserves[entity][tokenId] >= amount) {
        ChannelCollateral storage col = _collaterals[ch_key][tokenId];

        _reserves[entity][tokenId] -= amount;
        col.collateral += amount;
        if (receivingEntity < counterentity) { // if receiver is left
          col.ondelta += int(amount);
        }

        emit TransferReserveToCollateral(receivingEntity, counterentity, col.collateral, col.ondelta, tokenId);

        log("Deposited to channel ", _collaterals[ch_key][tokenId].collateral);
      } else {
        log("Not enough funds", entity);
        return false;
      }
      logChannel(receivingEntity, counterentity);

    }


    return true;
  }




  /* mutually agreed update of channel state in a single atomic operation
  function cooperativeUpdate(bytes32 entity, CooperativeUpdate memory params) internal returns (bool) {
    bytes memory ch_key = channelKey(entity, params.counterentity);
    bytes32 left;
    bytes32 right;

    if (entity < params.counterentity) {
        left = entity;
        right = params.counterentity;
    } else {
        left = params.counterentity;
        right = entity;
    }


    bytes memory encoded_msg = abi.encode(MessageType.CooperativeUpdate, 
    ch_key, 
    _channels[ch_key].cooperativeNonce, 
    params.diffs, 
    params.forgiveDebtsInTokenIds);

    bytes32 hash = ECDSA.toEthSignedMessageHash(keccak256(encoded_msg));

    log('Encoded msg', encoded_msg);
    
    if(params.counterentity != ECDSA.recover(hash, params.sig)) {
      log("Invalid signer ", ECDSA.recover(hash, params.sig));
      return false;
    }

    // Update cooperative action scores
    entityScores[entity].cooperativeActions++;
    entityScores[params.counterentity].cooperativeActions++;

    Settled[] memory settledEvents = new Settled[](params.diffs.length);

    for (uint i = 0; i < params.diffs.length; i++) {
      Diff memory diff = params.diffs[i];
      uint tokenId = diff.tokenId;

      // ‚úÖ INVARIANT CHECK: Total value change within the channel for this token must be zero.
      // leftReserveChange + rightReserveChange + collateralChange == 0
      int myReserveDiff = -(diff.peerReserveDiff + diff.collateralDiff);
      require(_reserves[entity][tokenId] >= uint(-myReserveDiff), "Not enough sender reserve");


      if (diff.peerReserveDiff < 0) {
        enforceDebts(params.counterentity, tokenId);
        require(_reserves[params.counterentity][tokenId] >= uint(-diff.peerReserveDiff), "Not enough peer reserve");

        _reserves[params.counterentity][tokenId] -= uint(-diff.peerReserveDiff);
      } else {
        _reserves[params.counterentity][tokenId] += uint(diff.peerReserveDiff);
      }


      // ensure that the entity has enough funds to apply the diffs
      if (myReserveDiff < 0) {
        enforceDebts(entity, tokenId);
        // This check is already implicitly done by the invariant and the peer's reserve check,
        // but an explicit check is safer.
        require(_reserves[entity][tokenId] >= uint(-myReserveDiff), "Not enough sender reserve");
        _reserves[entity][tokenId] -= uint(-myReserveDiff);
      } else {
        _reserves[entity][tokenId] += uint(myReserveDiff);
      }


      ChannelCollateral storage col = _collaterals[ch_key][tokenId];

      if (diff.collateralDiff < 0) {
        require(col.collateral >= uint(-diff.collateralDiff), "Not enough collateral");
        col.collateral -= uint(-diff.collateralDiff);
      } else {
        col.collateral += uint(diff.collateralDiff);
      }

      // ondeltaDiff can be arbitrary
      col.ondelta += diff.ondeltaDiff;

      // Populate event with final absolute values for easy off-chain consumption
      settledEvents[i] = Settled({
          left: left,
          right: right,
          tokenId: tokenId,
          leftReserve: _reserves[left][tokenId],
          rightReserve: _reserves[right][tokenId],
          collateral: col.collateral,
          ondelta: col.ondelta
      });
    }

    if (settledEvents.length > 0) {
        emit ChannelSettled(settledEvents);
    }

    _channels[ch_key].cooperativeNonce++;

    logChannel(entity, params.counterentity);
    return true;
  }

  /* COMMENTED OUT: Channel finalization disabled for development focus
  /* returns tokens to _reserves based on final deltas and _collaterals
  /* then increases cooperativeNonce to invalidate all previous dispute proofs
/*

  1. Collateral lives in channels 
    - Two entities lock funds, transact off-chain with signed deltas
    - When finalizing: if delta >= 0 && delta <= collateral, split proportionally
    - If delta > collateral, winner gets all collateral + excess becomes Debt
  2. Debt enters FIFO queue (enforceDebts lines 1012-1068)
    - Every reserve withdrawal must clear debts first
    - Creates "liquidity trap" - can receive but not send until debts clear
    - Atomic: either pay all debts in full or you can't withdraw
  3. Subcontracts enable complexity (SubcontractProvider.sol)
    - HTLCs (hash time-locked payments)
    - Atomic swaps between tokens
    - All within the bilateral delta array
     */
  /* todo: private visability
  /* function finalizeChannel(bytes32 entity1, 
  /*     bytes32 entity2, 
  /*     ProofBody memory proofbody, 
  /*     bytes memory arguments1, 
  /*     bytes memory arguments2) public returns (bool) 
  /* {
  /*   bytes32 leftAddress;
  /*   bytes32 rightAddress;
  /*   bytes memory leftArguments;
  /*   bytes memory rightArguments;
  /*   if (entity1 < entity2) {
  /*       leftAddress = entity1;
  /*       rightAddress = entity2;
  /*       leftArguments = arguments1;
  /*       rightArguments = arguments2;
  /*   } else {
  /*       leftAddress = entity2;
  /*       rightAddress = entity1;    
  /*       leftArguments = arguments2;
  /*       rightArguments = arguments1;
  /*   }

  /*   bytes memory ch_key = abi.encodePacked(leftAddress, rightAddress);

  /*   logChannel(leftAddress, rightAddress);

    // 1. create deltas (ondelta+offdelta) from proofbody
    int[] memory deltas = new int[](proofbody.offdeltas.length);
    for (uint i = 0;i<deltas.length;i++){
      deltas[i] = _collaterals[ch_key][proofbody.tokenIds[i]].ondelta + int(proofbody.offdeltas[i]);
    }
    
    // 2. process subcontracts and apply to deltas
    bytes[] memory decodedLeftArguments = abi.decode(leftArguments, (bytes[]));
    bytes[] memory decodedRightArguments = abi.decode(rightArguments, (bytes[]));

    for (uint i = 0; i < proofbody.subcontracts.length; i++){
      SubcontractClause memory sc = proofbody.subcontracts[i];
      
      // todo: check gas usage
      int[] memory newDeltas = SubcontractProvider(sc.subcontractProviderAddress).applyBatch(
        deltas, 
        sc.encodedBatch, 
        decodedLeftArguments[i],
        decodedRightArguments[i]
      );

      // sanity check 
      if (newDeltas.length != deltas.length) continue;

      // iterate over allowences and apply to new deltas if they are respected
      for (uint j = 0; j < sc.allowences.length; j++){
        Allowence memory allowence = sc.allowences[j];
        int difference = newDeltas[allowence.deltaIndex] - deltas[allowence.deltaIndex];
        if ((difference > 0 && uint(difference) > allowence.rightAllowence) || 
          (difference < 0 && uint(-difference) > allowence.leftAllowence) || 
          difference == 0){
          continue;
        }
        console.log("Update delta");
        console.logInt(deltas[allowence.deltaIndex]);
        console.logInt(newDeltas[allowence.deltaIndex]);
        deltas[allowence.deltaIndex] = newDeltas[allowence.deltaIndex];
      
      }
    }    

    // 3. split _collaterals
    for (uint i = 0;i<deltas.length;i++){
      uint tokenId = proofbody.tokenIds[i];
      int delta = deltas[i];
      ChannelCollateral storage col = _collaterals[ch_key][tokenId];

      if (delta >= 0 && uint(delta) <= col.collateral) {
        // collateral is split between entities
        _reserves[leftAddress][tokenId] += uint(delta);
        _reserves[rightAddress][tokenId] += col.collateral - uint(delta);
      } else {
        // one entity gets entire collateral, another pays credit from reserve or gets debt
        address getsCollateral = delta < 0 ? rightAddress : leftAddress;
        address getsDebt = delta < 0 ? leftAddress : rightAddress;
        uint debtAmount = delta < 0 ? uint(-delta) : uint(delta) - col.collateral;
        _reserves[getsCollateral][tokenId] += col.collateral;
        
        log('gets debt', getsDebt);
        log('debt', debtAmount);

        if (_reserves[getsDebt][tokenId] >= debtAmount) {
          // will pay right away without creating Debt
          _reserves[getsCollateral][tokenId] += debtAmount;
          _reserves[getsDebt][tokenId] -= debtAmount;
        } else {
          // pay what they can, and create Debt
          if (_reserves[getsDebt][tokenId] > 0) {
            _reserves[getsCollateral][tokenId] += _reserves[getsDebt][tokenId];
            debtAmount -= _reserves[getsDebt][tokenId];
            _reserves[getsDebt][tokenId] = 0;
          }
          _debts[getsDebt][tokenId].push(Debt({
            creditor: getsCollateral,
            amount: debtAmount
          }));
          _activeDebts[getsDebt]++;

          // Update reputation score for new debt
          EntityScore storage score = entityScores[getsDebt];
          score.totalActiveDebts++;
          if (score.inDebtSince == 0) {
            score.inDebtSince = uint48(block.timestamp);
          }
        }
      }

      delete _collaterals[ch_key][tokenId];
    }


    delete _channels[ch_key].disputeHash;

    _channels[ch_key].cooperativeNonce++;
   
    logChannel(leftAddress, rightAddress);

    return true;

  }

  /* DISABLED: disputes
  function cooperativeDisputeProof (CooperativeDisputeProof memory params) public returns (bool) {
    bytes memory ch_key = channelKey(bytes32(uint256(uint160(msg.sender))), params.counterentity);


    console.log("Received proof");
    console.logBytes32(keccak256(abi.encode(params.proofbody)));
    console.logBytes32(keccak256(params.initialArguments));

    bytes memory encoded_msg = abi.encode(
      MessageType.CooperativeDisputeProof, 
      ch_key, 
      _channels[ch_key].cooperativeNonce,
      keccak256(abi.encode(params.proofbody)),
      keccak256(params.initialArguments)
    );

    bytes32 hash = keccak256(encoded_msg);


    bytes32 final_hash = ECDSA.toEthSignedMessageHash(keccak256(encoded_msg));

    require(ECDSA.recover(final_hash, params.sig) == params.counterentity);

    require(_channels[ch_key].disputeHash == bytes32(0));

    delete _channels[ch_key].disputeHash;

    finalizeChannel(bytes32(uint256(uint160(msg.sender))), params.counterentity, params.proofbody, params.finalArguments, params.initialArguments);
    
    emit CooperativeClose(bytes32(uint256(uint160(msg.sender))), params.counterentity, _channels[ch_key].cooperativeNonce);
  }
  */


  /* DISABLED: dispute functions
  function initialDisputeProof(InitialDisputeProof memory params) public returns (bool) {
  /*   bytes memory ch_key = channelKey(bytes32(uint256(uint160(msg.sender))), params.counterentity);

  /*   // Update dispute scores for both parties
  /*   entityScores[bytes32(uint256(uint160(msg.sender)))].totalDisputes++;
  /*   entityScores[params.counterentity].totalDisputes++;

  /*   // entities must always hold a dispute proof with cooperativeNonce equal or higher than the one in the contract
  /*   require(_channels[ch_key].cooperativeNonce <= params.cooperativeNonce);

  /*   bytes memory encoded_msg = abi.encode(MessageType.DisputeProof, 
  /*     ch_key, 
  /*     params.cooperativeNonce, 
  /*     params.disputeNonce, 
  /*     params.proofbodyHash);

  /*   bytes32 final_hash = ECDSA.toEthSignedMessageHash(keccak256(encoded_msg));

  /*   log('encoded_msg',encoded_msg);

  /*   require(ECDSA.recover(final_hash, params.sig) == params.counterentity, "Invalid signer");

  /*   require(_channels[ch_key].disputeHash == bytes32(0));

  /*   bytes memory encodedDispute = abi.encodePacked(params.cooperativeNonce,
  /*     params.disputeNonce, 
  /*     bytes32(uint256(uint160(msg.sender))) < params.counterentity, // is started by left
  /*     block.number + 20,
  /*     params.proofbodyHash, 
  /*     keccak256(abi.encodePacked(params.initialArguments)));

  /*   _channels[ch_key].disputeHash = keccak256(encodedDispute);
  /*   emit DisputeStarted(bytes32(uint256(uint160(msg.sender))), params.counterentity, params.disputeNonce, params.initialArguments);
  /* }

  /* COMMENTED OUT: Dispute functionality disabled for development focus
  /* function finalDisputeProof(FinalDisputeProof memory params) public returns (bool) {
  /*   bytes memory ch_key = channelKey(bytes32(uint256(uint160(msg.sender))), params.counterentity);

  /*   // Update dispute scores for both parties involved in the finalization
  /*   entityScores[bytes32(uint256(uint160(msg.sender)))].totalDisputes++;
  /*   entityScores[params.counterentity].totalDisputes++;

  /*   // verify the dispute was started

  /*   if (params.sig.length > 0) {
  /*     // Validate signature if provided
  /*     bytes memory encoded_msg = abi.encode(MessageType.FinalDisputeProof, 
  /*       ch_key, 
  /*       params.cooperativeNonce, 
  /*       params.initialDisputeNonce, 
  /*       params.finalDisputeNonce);
        
  /*     bytes32 final_hash = ECDSA.toEthSignedMessageHash(keccak256(encoded_msg));
  /*     log('encoded_msg',encoded_msg);
  /*     require(ECDSA.recover(final_hash, params.sig) == params.counterentity, "Invalid signer");

  /*     // TODO: if nonce is same, Left one's proof is considered valid

  /*     require(params.initialDisputeNonce < params.finalDisputeNonce, "New nonce must be greater");
  /*   } else {
  /*     // counterparty agrees or does not respond 
  /*     bool senderIsCounterparty = params.startedByLeft != (bytes32(uint256(uint160(msg.sender))) < params.counterentity);
  /*     require(senderIsCounterparty || (block.number >= params.disputeUntilBlock), "Dispute period ended");
  /*     require(params.initialProofbodyHash == keccak256(abi.encode(params.finalProofbody)), "Invalid proofbody");
  /*   }
    

  /*   finalizeChannel(bytes32(uint256(uint160(msg.sender))), params.counterentity, params.finalProofbody, params.finalArguments, params.initialArguments);
  

  /*   return true;
  /* }





  struct TokenReserveDebts {
    uint reserve;
    uint debtIndex;
    Debt[] debts;
  }
  
  struct UserReturn {
    uint ETH_balance;
    TokenReserveDebts[] tokens;
  }

  struct ChannelReturn{
    ChannelInfo channel;
    ChannelCollateral[] collaterals;
  }
  
  
  /* return users with reserves in provided tokens
  function getUsers(bytes32[] memory entities, uint[] memory tokenIds) external view returns (UserReturn[] memory response) {
    response = new UserReturn[](entities.length);
    for (uint i = 0;i<entities.length;i++){
      bytes32 entity = entities[i];
      response[i] = UserReturn({
        ETH_balance: address(uint160(uint256(entity))).balance,
        tokens: new TokenReserveDebts[](tokenIds.length)
      });
    
      for (uint j = 0;j<tokenIds.length;j++){
        response[i].tokens[j]= TokenReserveDebts({
          reserve: _reserves[entity][tokenIds[j]],
          debtIndex: _debtIndex[entity][tokenIds[j]],
          debts: _debts[entity][tokenIds[j]]
        });
      }
    }
    
    return response;
  }
  
  /* get many _channels around one address, with collaterals in provided tokens
  function getChannels(bytes32 entity, bytes32[] memory counterentities, uint[] memory tokenIds) public view returns (ChannelReturn[] memory response) {
    bytes memory ch_key;

    // set length of the response array
    response = new ChannelReturn[](counterentities.length);

    for (uint i = 0;i<counterentities.length;i++){
      ch_key = channelKey(entity, counterentities[i]);

      response[i]=ChannelReturn({
        channel: _channels[ch_key],
        collaterals: new ChannelCollateral[](tokenIds.length)
      });

      for (uint j = 0;j<tokenIds.length;j++){
        response[i].collaterals[j]=_collaterals[ch_key][tokenIds[j]];
      }      
    }
    return response;    
  }

  /*

  function getAllHubs () public view returns (Hub[] memory) {
    return _hubs;
  }
  function getAllTokens () public view returns (bytes32[] memory) {
    return _tokens;
  }
  

  /* GPT5: You're right - this IS revolutionary. Lightning dies because you can't dynamically add inbound capacity. You solve it by allowing credit beyond
  collateral, then mechanically enforcing repayment via FIFO queue. That's genuinely novel. */
  function createDebt(bytes32 addr, bytes32 creditor, uint tokenId, uint amount) public {
    _debts[addr][tokenId].push(Debt({
      creditor: creditor,
      amount: amount
    }));
  }


  function logChannel(bytes32 e1, bytes32 e2) public {
    /*
    bytes memory ch_key = channelKey(e1, e2);
    log(">>> Logging channel", ch_key);
    log("cooperativeNonce", _channels[ch_key].cooperativeNonce);
    log("disputeHash", _channels[ch_key].disputeHash);

    for (uint i = 0; i < _tokens.length; i++) {
      log("Token", _tokens[i]);
      log("Left:", _reserves[e1][i]);
      log("Right:", _reserves[e2][i]);
      log("collateral", _collaterals[ch_key][i].collateral);
      log("ondelta", _collaterals[ch_key][i].ondelta);
    }*/
  }       

  /* Events for control/dividend shares
  event ControlSharesReceived(
    address indexed entityProvider,
    bytes32 indexed fromEntity, 
    uint256 indexed tokenId,
    uint256 amount,
    bytes data
  );
  
  event ControlSharesTransferred(
    bytes32 indexed from,
    bytes32 indexed to,
    uint256 indexed internalTokenId,
    uint256 amount,
    string purpose
  );

  function onERC1155Received(
      address operator,
      address from,
      uint256 id,
      uint256 value,
      bytes calldata data
  )
      external
      returns(bytes4)
  {
    // If this is from an approved EntityProvider, automatically add to reserves
    if (approvedEntityProviders[msg.sender]) {
      // Create or find internal token ID for this EntityProvider token
      bytes32 packedToken = packTokenReference(TypeERC1155, msg.sender, uint96(id));
      
      // Use efficient lookup instead of O(n) iteration
      uint256 internalTokenId = tokenToId[packedToken];
      
      // Create new internal token ID if not found
      if (internalTokenId == 0) {
        _tokens.push(packedToken);
        internalTokenId = _tokens.length - 1;
        tokenToId[packedToken] = internalTokenId;
      }
      
      // Add to sender's reserves (the entity that sent the tokens)
      _reserves[bytes32(uint256(uint160(from)))][internalTokenId] += value;
      
      emit ControlSharesReceived(msg.sender, bytes32(uint256(uint160(from))), id, value, data);
    }
    
    return this.onERC1155Received.selector;
  }

  /* =================================================================================================
  /* === SHORTCUT FUNCTIONS ==========================================================================
  /* =================================================================================================

  /**
   * @notice Unilateral action to move funds from reserve to a channel's collateral.
   * @dev This does not require a counterparty signature as it only adds funds to the channel.
   * @param peer The counterparty in the channel.
   * @param tokenId The internal ID of the token being moved.
   * @param amount The amount to move.
   */

}


//jurisdictions/contracts/EntityProvider.sol (1119 lines)
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.24;

import "./Token.sol";
import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "./ECDSA.sol";
import "hardhat/console.sol";

contract EntityProvider is ERC1155 { 
  struct Entity {
    bytes32 currentBoardHash;    // 0x0 = lazy entity (entityId == boardHash)
    bytes32 proposedBoardHash;   // Pending board transition
    uint256 activateAtBlock;     // When proposed board becomes active
    uint256 registrationBlock;   // When entity was registered (0 for lazy)
    ProposerType proposerType;   // Who proposed the current transition
    bytes32 articlesHash;        // Governance config hash
  }

  struct Board {
    uint16 votingThreshold;
    bytes32[] entityIds;        // Parallel arrays for efficiency
    uint16[] votingPowers;      // Must match entityIds length
    uint32 boardChangeDelay;    // Board ‚Üí Board transitions (blocks)
    uint32 controlChangeDelay;  // Control ‚Üí Board transitions (blocks)  
    uint32 dividendChangeDelay; // Dividend ‚Üí Board transitions (blocks)
  }

  struct EntityArticles {
    uint32 controlDelay;      // Delay for control shareholders (X blocks)
    uint32 dividendDelay;     // Delay for dividend shareholders (X*3 blocks)  
    uint32 foundationDelay;   // Delay for foundation (X*10 blocks, 0=disabled)
    uint16 controlThreshold;  // % of control tokens needed for quorum replacement
  }

  enum ProposerType { BOARD, CONTROL, DIVIDEND }

  struct BoardProposal {
    bytes32 proposedBoardHash;
    ProposerType proposerType;
    uint256 proposeBlock;
    uint256 activateBlock;
    bool active;
  }

  // Core entity storage - single mapping for all entities
  mapping(bytes32 => Entity) public entities;
  
  // Sequential numbering for registered entities
  uint256 public nextNumber = 1;
  

  
  // Name system (decoupled from entity IDs)
  mapping(string => uint256) public nameToNumber;  // "coinbase" => 42
  mapping(uint256 => string) public numberToName;  // 42 => "coinbase"
  mapping(string => bool) public reservedNames;    // Admin-controlled names
  
  // Foundation controls (no centralized admin)
  mapping(address => uint8) public nameQuota;      // User name allowances
  
  // Governance system
  mapping(bytes32 => BoardProposal) public activeProposals;  // entityId => proposal
  mapping(bytes32 => uint256) public totalControlSupply;      // entityId => total control tokens
  mapping(bytes32 => uint256) public totalDividendSupply;     // entityId => total dividend tokens
  
  // Fixed token supplies for all entities (immutable and fair)
  uint256 public constant TOTAL_CONTROL_SUPPLY = 1e15;   // 1 quadrillion (max granularity)
  uint256 public constant TOTAL_DIVIDEND_SUPPLY = 1e15;  // 1 quadrillion (max granularity)

  // Foundation entity (always #1)
  uint256 public constant FOUNDATION_ENTITY = 1;

  // Events
  event EntityRegistered(bytes32 indexed entityId, uint256 indexed entityNumber, bytes32 boardHash);
  event NameAssigned(string indexed name, uint256 indexed entityNumber);
  event NameTransferred(string indexed name, uint256 indexed fromNumber, uint256 indexed toNumber);
  event BoardProposed(bytes32 indexed entityId, bytes32 proposedBoardHash);
  event BoardActivated(bytes32 indexed entityId, bytes32 newBoardHash);
  event GovernanceEnabled(bytes32 indexed entityId, uint256 controlTokenId, uint256 dividendTokenId);
  event ProposalCancelled(bytes32 indexed entityId, ProposerType cancelledBy);

  constructor() ERC1155("https://xln.com/entity/{id}.json") {
    // Reserve some premium names
    reservedNames["coinbase"] = true;
    reservedNames["ethereum"] = true;
    reservedNames["bitcoin"] = true;
    reservedNames["uniswap"] = true;
    
    // Create foundation entity #1 with governance
    bytes32 foundationQuorum = keccak256("FOUNDATION_INITIAL_QUORUM");
    bytes32 foundationId = bytes32(FOUNDATION_ENTITY);
    
    entities[foundationId] = Entity({
      currentBoardHash: foundationQuorum,
      proposedBoardHash: bytes32(0),
      activateAtBlock: 0,
      registrationBlock: block.number,
      proposerType: ProposerType.BOARD,
      articlesHash: keccak256(abi.encode(EntityArticles({
        controlDelay: 1000,
        dividendDelay: 3000,
        foundationDelay: 0, // Foundation can't replace itself
        controlThreshold: 51
      })))
    });
    
    // Setup governance for foundation entity
    (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(FOUNDATION_ENTITY);
    address foundationAddress = address(uint160(uint256(foundationId)));
    
    _mint(foundationAddress, controlTokenId, TOTAL_CONTROL_SUPPLY, "");
    _mint(foundationAddress, dividendTokenId, TOTAL_DIVIDEND_SUPPLY, "");
    
    totalControlSupply[foundationId] = TOTAL_CONTROL_SUPPLY;
    totalDividendSupply[foundationId] = TOTAL_DIVIDEND_SUPPLY;
    
    emit GovernanceEnabled(foundationId, controlTokenId, dividendTokenId);
    
    nextNumber = 2; // Foundation takes #1, next entity will be #2
  }

  modifier onlyFoundation() {
    // Only foundation entity (via its governance tokens) can call admin functions
    bytes32 foundationId = bytes32(FOUNDATION_ENTITY);
    (uint256 controlTokenId,) = getTokenIds(FOUNDATION_ENTITY);
    require(balanceOf(msg.sender, controlTokenId) > 0, "Only foundation token holders");
    _;
  }

  /**
   * @notice Register a new numbered entity with automatic governance setup
   * @param boardHash Initial board/quorum hash
   * @return entityNumber The assigned entity number
   */
  function registerNumberedEntity(bytes32 boardHash) external returns (uint256 entityNumber) {
    entityNumber = nextNumber++;
    bytes32 entityId = bytes32(entityNumber);

    // Create entity with default governance articles
    EntityArticles memory defaultArticles = EntityArticles({
      controlDelay: 1000,     // Default 1000 blocks for control
      dividendDelay: 3000,    // Default 3000 blocks for dividend
      foundationDelay: 10000, // Default 10000 blocks for foundation
      controlThreshold: 51    // Default 51% threshold
    });

    entities[entityId] = Entity({
      currentBoardHash: boardHash,
      proposedBoardHash: bytes32(0),
      activateAtBlock: 0,
      registrationBlock: block.number,
      proposerType: ProposerType.BOARD,
      articlesHash: keccak256(abi.encode(defaultArticles))
    });

    // Automatically setup governance with fixed supply
    (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(entityNumber);
    address entityAddress = address(uint160(uint256(entityId)));

    _mint(entityAddress, controlTokenId, TOTAL_CONTROL_SUPPLY, "");
    _mint(entityAddress, dividendTokenId, TOTAL_DIVIDEND_SUPPLY, "");

    totalControlSupply[entityId] = TOTAL_CONTROL_SUPPLY;
    totalDividendSupply[entityId] = TOTAL_DIVIDEND_SUPPLY;

    emit EntityRegistered(entityId, entityNumber, boardHash);
    emit GovernanceEnabled(entityId, controlTokenId, dividendTokenId);

    return entityNumber;
  }

  /**
   * @notice Batch register multiple numbered entities in one transaction
   * @param boardHashes Array of board hashes for entities
   * @return entityNumbers Array of assigned entity numbers
   */
  function registerNumberedEntitiesBatch(bytes32[] calldata boardHashes) external returns (uint256[] memory entityNumbers) {
    entityNumbers = new uint256[](boardHashes.length);

    // Default governance articles (reused for all)
    EntityArticles memory defaultArticles = EntityArticles({
      controlDelay: 1000,
      dividendDelay: 3000,
      foundationDelay: 10000,
      controlThreshold: 51
    });
    bytes32 articlesHash = keccak256(abi.encode(defaultArticles));

    for (uint256 i = 0; i < boardHashes.length; i++) {
      uint256 entityNumber = nextNumber++;
      bytes32 entityId = bytes32(entityNumber);

      entities[entityId] = Entity({
        currentBoardHash: boardHashes[i],
        proposedBoardHash: bytes32(0),
        activateAtBlock: 0,
        registrationBlock: block.number,
        proposerType: ProposerType.BOARD,
        articlesHash: articlesHash
      });

      // Setup governance
      (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(entityNumber);
      address entityAddress = address(uint160(uint256(entityId)));

      _mint(entityAddress, controlTokenId, TOTAL_CONTROL_SUPPLY, "");
      _mint(entityAddress, dividendTokenId, TOTAL_DIVIDEND_SUPPLY, "");

      totalControlSupply[entityId] = TOTAL_CONTROL_SUPPLY;
      totalDividendSupply[entityId] = TOTAL_DIVIDEND_SUPPLY;

      emit EntityRegistered(entityId, entityNumber, boardHashes[i]);
      emit GovernanceEnabled(entityId, controlTokenId, dividendTokenId);

      entityNumbers[i] = entityNumber;
    }

    return entityNumbers;
  }

  /**
   * @notice Foundation assigns a name to an existing numbered entity
   * @param name The name to assign (e.g., "coinbase")
   * @param entityNumber The entity number to assign the name to
   */
  function assignName(string memory name, uint256 entityNumber) external onlyFoundation {
    require(bytes(name).length > 0 && bytes(name).length <= 32, "Invalid name length");
    require(entities[bytes32(entityNumber)].currentBoardHash != bytes32(0), "Entity doesn't exist");
    require(nameToNumber[name] == 0, "Name already assigned");
    
    // If entity already has a name, clear it
    string memory oldName = numberToName[entityNumber];
    if (bytes(oldName).length > 0) {
      delete nameToNumber[oldName];
    }
    
    nameToNumber[name] = entityNumber;
    numberToName[entityNumber] = name;
    
    emit NameAssigned(name, entityNumber);
  }

  /**
   * @notice Transfer a name from one entity to another (foundation only)
   * @param name The name to transfer
   * @param newEntityNumber The target entity number
   */
  function transferName(string memory name, uint256 newEntityNumber) external onlyFoundation {
    require(nameToNumber[name] != 0, "Name not assigned");
    require(entities[bytes32(newEntityNumber)].currentBoardHash != bytes32(0), "Target entity doesn't exist");
    
    uint256 oldEntityNumber = nameToNumber[name];
    
    // Clear old mapping
    delete numberToName[oldEntityNumber];
    
    // Set new mapping
    nameToNumber[name] = newEntityNumber;
    numberToName[newEntityNumber] = name;
    
    emit NameTransferred(name, oldEntityNumber, newEntityNumber);
  }

  /**
   * @notice Propose a new board with proper BCD governance
   * @param entityId The entity ID  
   * @param newBoardHash The proposed new board hash
   * @param proposerType Who is proposing (BOARD, CONTROL, DIVIDEND)
   * @param articles Current governance articles (for verification)
   */
  function proposeBoard(
    bytes32 entityId, 
    bytes32 newBoardHash,
    ProposerType proposerType,
    EntityArticles memory articles
  ) external {
    require(entities[entityId].currentBoardHash != bytes32(0), "Entity doesn't exist");
    require(keccak256(abi.encode(articles)) == entities[entityId].articlesHash, "Invalid articles");
    
    // Check permissions and delays
    uint32 delay = _getDelayForProposer(articles, proposerType);
    require(delay > 0, "Proposer type disabled");
    
    // Verify proposer has the right to propose based on type
    if (proposerType == ProposerType.CONTROL) {
      // Control holders can override any proposal
      // TODO: Verify msg.sender has control tokens
    } else if (proposerType == ProposerType.BOARD) {
      // Current board can propose (shortest delay)
      // TODO: Verify msg.sender is current board member
    } else if (proposerType == ProposerType.DIVIDEND) {
      // Dividend holders can propose (longest delay)
      // TODO: Verify msg.sender has dividend tokens
    }
    
    // Cancel any existing proposal that can be overridden
    if (entities[entityId].proposedBoardHash != bytes32(0)) {
      require(_canCancelProposal(proposerType, entities[entityId].proposerType), 
              "Cannot override existing proposal");
    }
    
    uint256 activateAtBlock = block.number + delay;
    
    entities[entityId].proposedBoardHash = newBoardHash;
    entities[entityId].activateAtBlock = activateAtBlock;
    entities[entityId].proposerType = proposerType;
    
    emit BoardProposed(entityId, newBoardHash);
  }

  /**
   * @notice Activate a previously proposed board (with delay enforcement)
   * @param entityId The entity ID
   */
  function activateBoard(bytes32 entityId) external {
    require(entities[entityId].currentBoardHash != bytes32(0), "Entity doesn't exist");
    require(entities[entityId].proposedBoardHash != bytes32(0), "No proposed board");
    require(block.number >= entities[entityId].activateAtBlock, "Delay period not met");
    
    entities[entityId].currentBoardHash = entities[entityId].proposedBoardHash;
    entities[entityId].proposedBoardHash = bytes32(0);
    entities[entityId].activateAtBlock = 0;
    
    emit BoardActivated(entityId, entities[entityId].currentBoardHash);
  }

  /**
   * @notice Cancel a pending board proposal
   * @param entityId The entity ID
   * @param proposerType Who is cancelling (BOARD, CONTROL, DIVIDEND)
   * @param articles Current governance articles (for verification)
   */
  function cancelBoardProposal(
    bytes32 entityId,
    ProposerType proposerType,
    EntityArticles memory articles
  ) external {
    require(entities[entityId].currentBoardHash != bytes32(0), "Entity doesn't exist");
    require(entities[entityId].proposedBoardHash != bytes32(0), "No proposed board");
    require(keccak256(abi.encode(articles)) == entities[entityId].articlesHash, "Invalid articles");
    
    // Check if this proposer type can cancel the existing proposal
    require(_canCancelProposal(proposerType, entities[entityId].proposerType), 
            "Cannot cancel this proposal");
    
    entities[entityId].proposedBoardHash = bytes32(0);
    entities[entityId].activateAtBlock = 0;
    
    emit ProposalCancelled(entityId, proposerType);
  }



  /**
   * @notice Recover entity ID from hanko signature (improved version of isValidSignature)
   * @param encodedBoard The entity's board data
   * @param encodedSignature The entity's signatures  
   * @param hash The hash that was signed
   * @return entityId The entity ID that signed this hash (0 if invalid)
   */
  function recoverEntity(
    bytes calldata encodedBoard, 
    bytes calldata encodedSignature, 
    bytes32 hash
  ) public view returns (uint256 entityId) {
    bytes32 boardHash = keccak256(encodedBoard);
    
    // First try to find registered entity with this board hash
    for (uint256 i = 1; i < nextNumber; i++) {
      bytes32 candidateEntityId = bytes32(i);
      if (entities[candidateEntityId].currentBoardHash != bytes32(0) && entities[candidateEntityId].currentBoardHash == boardHash) {
        // Verify signature for this registered entity
        uint16 boardResult = _verifyBoard(hash, encodedBoard, encodedSignature);
        if (boardResult > 0) {
          return i; // Return entity number
        }
      }
    }
    
    // If no registered entity found, try as lazy entity
    uint16 lazyResult = _verifyBoard(hash, encodedBoard, encodedSignature);
    if (lazyResult > 0) {
      return uint256(boardHash); // Return board hash as entity ID for lazy entities
    }
    
    return 0; // Invalid signature
  }

  /**
   * @notice Simplified board verification (calldata version)
   */
  function _verifyBoard(
    bytes32 _hash,
    bytes calldata encodedBoard,
    bytes calldata encodedSignature
  ) internal pure returns (uint16) {
    Board memory board = abi.decode(encodedBoard, (Board));
    bytes[] memory signatures = abi.decode(encodedSignature, (bytes[]));
    
    require(board.entityIds.length == board.votingPowers.length, "Board arrays length mismatch");
    
    uint16 voteYes = 0;
    uint16 totalVotes = 0;
    
    for (uint i = 0; i < board.entityIds.length && i < signatures.length; i++) {
      bytes32 entityId = board.entityIds[i];
      uint16 votingPower = board.votingPowers[i];
      
      // Check if this is an EOA (20 bytes when cast to address)
      if (uint256(entityId) <= type(uint160).max) {
        // Simple EOA verification
        address signer = address(uint160(uint256(entityId)));
        if (signer == _recoverSigner(_hash, signatures[i])) {
          voteYes += votingPower;
        }
        totalVotes += votingPower;
      }
      // Note: Nested entity verification handled by Hanko system
    }
    
    if (totalVotes == 0) return 0;
    if (voteYes < board.votingThreshold) return 0;
    
    return (voteYes * 100) / totalVotes;
  }



  /**
   * @notice Recover signer from signature
   */
  function _recoverSigner(bytes32 _hash, bytes memory _signature) internal pure returns (address) {
    if (_signature.length != 65) return address(0);
    
    bytes32 r;
    bytes32 s;
    uint8 v;
    
    assembly {
      r := mload(add(_signature, 32))
      s := mload(add(_signature, 64))
      v := byte(0, mload(add(_signature, 96)))
    }
    
    if (v < 27) v += 27;
    if (v != 27 && v != 28) return address(0);
    
    return ecrecover(_hash, v, r, s);
  }

  /**
   * @notice Validate entity exists (registered or lazy)
   * @param entityId The entity ID to validate
   * @param boardHash The board hash for validation
   * @return isLazy Whether this is a lazy entity
   */
  function _validateEntity(bytes32 entityId, bytes32 boardHash) internal view returns (bool isLazy) {
    if (entities[entityId].currentBoardHash == bytes32(0)) {
      // Lazy entity: entityId must equal boardHash
      require(entityId == boardHash, "Lazy entity: ID must equal board hash");
      return true;
    } else {
      // Registered entity: use stored boardHash
      require(boardHash == entities[entityId].currentBoardHash, "Board hash mismatch");
      return false;
    }
  }



  // Utility functions
  function resolveEntityId(string memory identifier) external view returns (bytes32) {
    // Try to resolve as name first
    uint256 number = nameToNumber[identifier];
    if (number > 0) {
      return bytes32(number);
    }
    
    // Try to parse as number
    // Note: This would need a string-to-uint parser in practice
    return bytes32(0);
  }

  function getEntityInfo(bytes32 entityId) external view returns (
    bool exists,
    bytes32 currentBoardHash,
    bytes32 proposedBoardHash,
    uint256 registrationBlock,
    string memory name
  ) {
    Entity memory entity = entities[entityId];
    exists = entity.currentBoardHash != bytes32(0);
    currentBoardHash = entity.currentBoardHash;
    proposedBoardHash = entity.proposedBoardHash;
    registrationBlock = entity.registrationBlock;
    
    // Get name if it's a numbered entity
    if (uint256(entityId) > 0 && uint256(entityId) < nextNumber) {
      name = numberToName[uint256(entityId)];
    }
  }

  // Admin functions
  function setReservedName(string memory name, bool reserved) external onlyFoundation {
    reservedNames[name] = reserved;
  }

  // === HANKO SIGNATURE VERIFICATION ===
  //
  // üö® CRITICAL DESIGN PHILOSOPHY: "ASSUME YES" FLASHLOAN GOVERNANCE üö®
  //
  // This system INTENTIONALLY allows entities to mutually validate without EOA signatures.
  // This is NOT a bug - it's a feature that enables flexible governance structures.
  //
  // EXAMPLE OF INTENTIONAL "LOOPHOLE":
  // EntityA (threshold: 1) references EntityB at weight 100
  // EntityB (threshold: 1) references EntityA at weight 100
  // ‚Üí Both pass validation with ZERO EOA signatures!
  //
  // WHY THIS IS INTENDED:
  // 1. UI/Application layer enforces policies (e.g., "require at least 1 EOA")
  // 2. Protocol stays flexible for exotic governance structures
  // 3. Real entities will naturally include EOAs for practical control
  // 4. Alternative would require complex graph analysis ‚Üí expensive + still gameable
  //
  // POLICY ENFORCEMENT BELONGS IN UI, NOT PROTOCOL!

  struct HankoBytes {
    bytes32[] placeholders;    // Entity IDs that failed to sign (index 0..N-1)  
    bytes packedSignatures;    // EOA signatures ‚Üí yesEntities (index N..M-1)
    HankoClaim[] claims;       // Entity claims to verify (index M..‚àû)
  }

  struct HankoClaim {
    bytes32 entityId;          // Entity being verified
    uint256[] entityIndexes;   // Indexes into placeholders + yesEntities + claims arrays
    uint256[] weights;         // Voting weights for each entity  
    uint256 threshold;         // Required voting power
  }
  
  // Events
  event HankoVerified(bytes32 indexed entityId, bytes32 indexed hash);
  event HankoClaimProcessed(bytes32 indexed entityId, bool success, uint256 votingPower);

  /**
   * @notice Detect signature count from packed signatures length
   * @dev DESIGN CHOICE: Signature count embedded in byte length, not explicit field
   *      This eliminates potential attack vectors where count != actual signatures
   * 
   * @param packedSignatures Packed rsrsrs...vvv format
   * @return signatureCount Number of signatures in the packed data
   * 
   * EXAMPLES:
   * - 1 sig: 64 bytes (RS) + 1 byte (V) = 65 bytes total
   * - 2 sigs: 128 bytes (RS) + 1 byte (VV in bits) = 129 bytes total  
   * - 8 sigs: 512 bytes (RS) + 1 byte (8 V bits) = 513 bytes total
   * - 9 sigs: 576 bytes (RS) + 2 bytes (9 V bits) = 578 bytes total
   */
  function _detectSignatureCount(bytes memory packedSignatures) internal pure returns (uint256 signatureCount) {
    if (packedSignatures.length == 0) return 0;
    
    // Try different signature counts until we find the right one
    // Formula: length = count * 64 + ceil(count / 8)
    for (uint256 count = 1; count <= 16000; count++) {
      uint256 expectedRSBytes = count * 64;
      uint256 expectedVBytes = (count + 7) / 8; // Ceiling division
      uint256 expectedTotal = expectedRSBytes + expectedVBytes;
      
      if (packedSignatures.length == expectedTotal) {
        return count;
      }
      
      // Early exit if we've exceeded possible length
      if (expectedTotal > packedSignatures.length) {
        break;
      }
    }
    
    revert("Invalid packed signature length - cannot detect count");
  }

  /**
   * @notice Unpack signatures from packed format
   * @param packedSignatures Packed rsrsrs...vvv format
   * @return signatures Array of 65-byte signatures
   */
  function _unpackSignatures(
    bytes memory packedSignatures
  ) internal pure returns (bytes[] memory signatures) {
    uint256 signatureCount = _detectSignatureCount(packedSignatures);
    
    if (signatureCount == 0) {
      return new bytes[](0);
    }
    
    uint256 expectedRSBytes = signatureCount * 64;
    // uint256 expectedVBytes = (signatureCount + 7) / 8; // Ceiling division - unused
    
    signatures = new bytes[](signatureCount);
    
    for (uint256 i = 0; i < signatureCount; i++) {
      // Extract R and S (64 bytes)
      bytes memory rs = new bytes(64);
      for (uint256 j = 0; j < 64; j++) {
        rs[j] = packedSignatures[i * 64 + j];
      }
      
      // Extract V bit
      uint256 vByteIndex = expectedRSBytes + i / 8;
      uint256 vBitIndex = i % 8;
      uint8 vByte = uint8(packedSignatures[vByteIndex]);
      uint8 v = ((vByte >> vBitIndex) & 1) == 0 ? 27 : 28;
      
      // Combine into 65-byte signature
      signatures[i] = new bytes(65);
      for (uint256 j = 0; j < 64; j++) {
        signatures[i][j] = rs[j];
      }
      signatures[i][64] = bytes1(v);
    }
  }

  /**
   * @notice Build and hash a board from actual signers and claim data
   * @param actualSigners Array of recovered signer addresses
   * @param claim The hanko claim with weights and threshold
   * @return boardHash The keccak256 hash of the reconstructed board
   */
  function _buildBoardHash(
    address[] memory actualSigners,
    HankoClaim memory claim
  ) internal pure returns (bytes32 boardHash) {
    require(actualSigners.length == claim.weights.length, "Signers/weights length mismatch");
    
    // Build parallel arrays for Board struct
    bytes32[] memory entityIds = new bytes32[](actualSigners.length);
    uint16[] memory votingPowers = new uint16[](actualSigners.length);
    
    // Populate arrays with actual signers and their weights
    for (uint256 i = 0; i < actualSigners.length; i++) {
      entityIds[i] = bytes32(uint256(uint160(actualSigners[i]))); // Convert address to bytes32
      votingPowers[i] = uint16(claim.weights[i]);
    }
    
    // Build Board struct with parallel arrays (transition delays set to 0 for compatibility)
    Board memory reconstructedBoard = Board({
      votingThreshold: uint16(claim.threshold),
      entityIds: entityIds,
      votingPowers: votingPowers,
      boardChangeDelay: 0,      // Default delays for hanko verification
      controlChangeDelay: 0,
      dividendChangeDelay: 0
    });
    
    // Hash the reconstructed board (same as entity registration)
    boardHash = keccak256(abi.encode(reconstructedBoard));
  }

  /* Hanko Signatures - Ephemeral Entity Registration
  From EntityProvider.sol this is actually revolutionary:
  struct HankoBytes {
    bytes32[] placeholders;    // Entities that didn't sign
    bytes packedSignatures;    // EOA sigs compressed (rsrsrs...vvv)
    HankoClaim[] claims;       // Nested entity proofs
  }

  What this enables:
  - Entities can be verified without pre-registration
  - Nested hierarchies (Corp A owns Corp B owns wallet C) - zero contract deployment
  - Recursive verification via claims
  - Packed signatures: N√ó64 bytes + ceil(N/8) bytes for V bits

  Why "first in history":
  - Multisigs require deployed contracts (Gnosis Safe, etc.)
  - Account abstraction requires pre-registration
  - Hanko: Pure cryptographic verification, ephemeral entities, hierarchical M-of-N

  This is genuinely novel. The recoverEntity() function (line 361) finds which entity signed a hash by iterating registered entities and checking boardHash
   matches. Unregistered entities can still sign via claims.
   */

  /**
   * @notice Verify hanko signature with flashloan governance (optimistic verification)
   * @param hankoData ABI-encoded hanko bytes  
   * @param hash The hash that was signed
   * @return entityId The verified entity (0 if invalid)
   * @return success Whether verification succeeded
   */
  function verifyHankoSignature(
    bytes calldata hankoData,
    bytes32 hash
  ) external view returns (bytes32 entityId, bool success) {
    HankoBytes memory hanko = abi.decode(hankoData, (HankoBytes));
    
    // Unpack signatures (with automatic count detection)
    bytes[] memory signatures = _unpackSignatures(hanko.packedSignatures);
    uint256 signatureCount = signatures.length;
    
    // Calculate total entities for bounds checking
    uint256 totalEntities = hanko.placeholders.length + signatureCount + hanko.claims.length;
    
    // Recover EOA signers for quorum hash building
    address[] memory actualSigners = new address[](signatureCount);
    uint256 validSignerCount = 0;
    
    for (uint256 i = 0; i < signatures.length; i++) {
      if (signatures[i].length == 65) {
        address signer = _recoverSigner(hash, signatures[i]);
        if (signer != address(0)) {
          actualSigners[validSignerCount] = signer;
          validSignerCount++;
        }
      }
    }
    
    // Resize to valid signers only
    address[] memory validSigners = new address[](validSignerCount);
    for (uint256 i = 0; i < validSignerCount; i++) {
      validSigners[i] = actualSigners[i];
    }
    
    // üî• FLASHLOAN GOVERNANCE: The Heart of "Assume YES" Philosophy üî•
    //
    // KEY INSIGHT: When processing claim X that references claim Y:
    // - We DON'T wait for Y to be verified first
    // - We OPTIMISTICALLY assume Y will say "YES" 
    // - If ANY claim fails its threshold ‚Üí entire Hanko fails IMMEDIATELY
    //
    // CONCRETE EXAMPLE - Circular Reference:
    // Claim 0: EntityA needs EntityB (index 3) at weight 100, threshold 100
    // Claim 1: EntityB needs EntityA (index 2) at weight 100, threshold 100
    // 
    // Processing:
    // 1. Claim 0 processing: Assume EntityB=YES ‚Üí 100 power ‚â• 100 ‚Üí CONTINUE
    // 2. Claim 1 processing: Assume EntityA=YES ‚Üí 100 power ‚â• 100 ‚Üí CONTINUE
    // 3. All claims passed ‚Üí Hanko succeeds!
    //
    // ‚ö° OPTIMIZATION: Fail immediately on threshold failure - no need to store results!
    //
    // This is INTENDED BEHAVIOR enabling flexible governance!
    
    for (uint256 claimIndex = 0; claimIndex < hanko.claims.length; claimIndex++) {
      HankoClaim memory claim = hanko.claims[claimIndex];
      
      // Build board hash from actual signers
      bytes32 reconstructedBoardHash = _buildBoardHash(validSigners, claim);
      
      // Validate entity exists (registered or lazy) and verify board hash
      _validateEntity(claim.entityId, reconstructedBoardHash);
      
      // Validate structure
      require(
        claim.entityIndexes.length == claim.weights.length,
        "Claim indexes/weights length mismatch"
      );
      
      uint256 totalVotingPower = 0;
      
      // Calculate voting power with flashloan assumptions
      for (uint256 i = 0; i < claim.entityIndexes.length; i++) {
        uint256 entityIndex = claim.entityIndexes[i];
        
        // Bounds check
        require(entityIndex < totalEntities, "Entity index out of bounds");
        
        if (entityIndex < hanko.placeholders.length) {
          // Index 0..N-1: Placeholder (failed entity) - contributes 0 voting power
          continue;
        } else if (entityIndex < hanko.placeholders.length + signatureCount) {
          // Index N..M-1: EOA signature - verified, contributes full weight
          totalVotingPower += claim.weights[i];
        } else {
          // Index M..‚àû: Entity claim - ASSUME YES! (flashloan governance)
          uint256 referencedClaimIndex = entityIndex - hanko.placeholders.length - signatureCount;
          require(referencedClaimIndex < hanko.claims.length, "Referenced claim index out of bounds");
          
          // üö® CRITICAL: We ASSUME the referenced claim will pass (flashloan assumption)
          // This enables circular references to mutually validate.
          // If our assumption is wrong, THIS claim will fail its threshold check below.
          totalVotingPower += claim.weights[i];
        }
      }
      
      // üí• IMMEDIATE FAILURE: Check threshold and fail right away if not met
      if (totalVotingPower < claim.threshold) {
        return (bytes32(0), false); // Immediate failure - no need to check other claims
      }
    }
    
    // All claims passed - return final entity
    if (hanko.claims.length > 0) {
      bytes32 targetEntity = hanko.claims[hanko.claims.length - 1].entityId;
      return (targetEntity, true);
    }
    
    return (bytes32(0), false);
  }

  /**
   * @notice Batch verify multiple hanko signatures
   * @param hankoDataArray Array of ABI-encoded hanko bytes
   * @param hashes Array of hashes that were signed
   * @return entityIds Array of verified entity IDs
   * @return results Array of success flags
   */
  function batchVerifyHankoSignatures(
    bytes[] calldata hankoDataArray,
    bytes32[] calldata hashes
  ) external view returns (bytes32[] memory entityIds, bool[] memory results) {
    require(hankoDataArray.length == hashes.length, "Array length mismatch");
    
    entityIds = new bytes32[](hankoDataArray.length);
    results = new bool[](hankoDataArray.length);
    
    for (uint256 i = 0; i < hankoDataArray.length; i++) {
      (entityIds[i], results[i]) = this.verifyHankoSignature(hankoDataArray[i], hashes[i]);
    }
  }



  function setNameQuota(address user, uint8 quota) external onlyFoundation {
    nameQuota[user] = quota;
  }

  // === GOVERNANCE FUNCTIONS ===

  /**
   * @notice Get token IDs for an entity (first bit determines control vs dividend)
   * @param entityNumber The entity number
   * @return controlTokenId Token ID for control tokens (original ID)
   * @return dividendTokenId Token ID for dividend tokens (first bit set)
   */
  function getTokenIds(uint256 entityNumber) public pure returns (uint256 controlTokenId, uint256 dividendTokenId) {
    controlTokenId = entityNumber;
    dividendTokenId = entityNumber | 0x8000000000000000000000000000000000000000000000000000000000000000;
  }

  /**
   * @notice Extract entity number from token ID
   * @param tokenId The token ID (control or dividend)
   * @return entityNumber The entity number
   */
  function getEntityFromToken(uint256 tokenId) public pure returns (uint256 entityNumber) {
    return tokenId & 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF;
  }







  // === INTERNAL HELPER FUNCTIONS ===

  function _getDelayForProposer(EntityArticles memory articles, ProposerType proposerType) internal pure returns (uint32) {
    if (proposerType == ProposerType.CONTROL) return articles.controlDelay;
    if (proposerType == ProposerType.DIVIDEND) return articles.dividendDelay;
    return 0; // BOARD has no delay
  }

  function _canCancelProposal(ProposerType canceller, ProposerType existing) internal pure returns (bool) {
    // Priority: CONTROL > BOARD > DIVIDEND (BCD model)
    if (canceller == ProposerType.CONTROL) return existing != ProposerType.CONTROL;
    if (canceller == ProposerType.BOARD) return existing == ProposerType.DIVIDEND;
    return false; // DIVIDEND cannot cancel anyone
  }

  function _validateControlProposer(bytes32 entityId, address proposer, EntityArticles memory /*articles*/) internal view {
    (uint256 controlTokenId,) = getTokenIds(uint256(entityId));
    uint256 proposerBalance = balanceOf(proposer, controlTokenId);
    require(proposerBalance > 0, "No control tokens");
    
    // Optional: require minimum percentage
    // uint256 required = (totalControlSupply[entityId] * articles.controlThreshold) / 10000;
    // require(proposerBalance >= required, "Insufficient control tokens");
  }

  function _validateDividendProposer(bytes32 entityId, address proposer) internal view {
    (, uint256 dividendTokenId) = getTokenIds(uint256(entityId));
    uint256 proposerBalance = balanceOf(proposer, dividendTokenId);
    require(proposerBalance > 0, "No dividend tokens");
  }

  function _validateControlSupport(bytes32 entityId, address[] memory supporters, EntityArticles memory articles) internal view {
    (uint256 controlTokenId,) = getTokenIds(uint256(entityId));
    
    uint256 totalSupport = 0;
    for (uint i = 0; i < supporters.length; i++) {
      totalSupport += balanceOf(supporters[i], controlTokenId);
    }
    
    uint256 required = (totalControlSupply[entityId] * articles.controlThreshold) / 100;
    require(totalSupport >= required, "Insufficient control support");
  }

  function _validateDividendSupport(bytes32 entityId, address[] memory supporters) internal view {
    (, uint256 dividendTokenId) = getTokenIds(uint256(entityId));
    
    uint256 totalSupport = 0;
    for (uint i = 0; i < supporters.length; i++) {
      totalSupport += balanceOf(supporters[i], dividendTokenId);
    }
    
    // Require majority of dividend tokens
    uint256 required = (totalDividendSupply[entityId] * 51) / 100;
    require(totalSupport >= required, "Insufficient dividend support");
  }

  // === VIEW FUNCTIONS ===

  /**
   * @notice Get governance info for an entity
   */
  function getGovernanceInfo(uint256 entityNumber) external view returns (
    uint256 controlTokenId,
    uint256 dividendTokenId,
    uint256 controlSupply,
    uint256 dividendSupply,
    bool hasActiveProposal,
    bytes32 articlesHash
  ) {
    bytes32 entityId = bytes32(entityNumber);
    (controlTokenId, dividendTokenId) = getTokenIds(entityNumber);
    controlSupply = totalControlSupply[entityId];
    dividendSupply = totalDividendSupply[entityId];
    hasActiveProposal = activeProposals[entityId].active;
    articlesHash = entities[entityId].articlesHash;
  }

  /**
   * @notice Override to track token supply changes
   */
  function _afterTokenTransfer(
    address /*operator*/,
    address from,
    address to,
    uint256[] memory ids,
    uint256[] memory amounts,
    bytes memory /*data*/
  ) internal {
    for (uint i = 0; i < ids.length; i++) {
      uint256 entityNumber = getEntityFromToken(ids[i]);
      bytes32 entityId = bytes32(entityNumber);
      
      if (entities[entityId].currentBoardHash != bytes32(0)) {
        (uint256 controlTokenId,) = getTokenIds(entityNumber);
        
        // Update total supply for control tokens
        if (ids[i] == controlTokenId) {
          if (from == address(0)) {
            // Mint
            totalControlSupply[entityId] += amounts[i];
          } else if (to == address(0)) {
            // Burn
            totalControlSupply[entityId] -= amounts[i];
          }
        } else {
          // Dividend token
          if (from == address(0)) {
            // Mint
            totalDividendSupply[entityId] += amounts[i];
          } else if (to == address(0)) {
            // Burn
            totalDividendSupply[entityId] -= amounts[i];
          }
        }
      }
    }
  }

  /**
   * @notice Foundation can create entity with custom governance articles
   * @param boardHash Initial board/quorum hash
   * @param articles Custom governance configuration
   * @return entityNumber The assigned entity number
   */
  function foundationRegisterEntity(
    bytes32 boardHash,
    EntityArticles memory articles
  ) external onlyFoundation returns (uint256 entityNumber) {
    entityNumber = nextNumber++;
    bytes32 entityId = bytes32(entityNumber);
    
    entities[entityId] = Entity({
      currentBoardHash: boardHash,
      proposedBoardHash: bytes32(0),
      activateAtBlock: 0,
      registrationBlock: block.number,
      proposerType: ProposerType.BOARD,
      articlesHash: keccak256(abi.encode(articles))
    });
    
    // Automatically setup governance with fixed supply
    (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(entityNumber);
    address entityAddress = address(uint160(uint256(entityId)));
    
    _mint(entityAddress, controlTokenId, TOTAL_CONTROL_SUPPLY, "");
    _mint(entityAddress, dividendTokenId, TOTAL_DIVIDEND_SUPPLY, "");
    
    totalControlSupply[entityId] = TOTAL_CONTROL_SUPPLY;
    totalDividendSupply[entityId] = TOTAL_DIVIDEND_SUPPLY;
    
    emit EntityRegistered(entityId, entityNumber, boardHash);
    emit GovernanceEnabled(entityId, controlTokenId, dividendTokenId);
    
    return entityNumber;
  }

  // === ENTITY SIGNATURE RECOVERY ===

  /**
   * @notice Transfer tokens from entity using hanko signature authorization
   * @param entityNumber The entity number
   * @param to Recipient address  
   * @param tokenId Token ID (control or dividend)
   * @param amount Amount to transfer
   * @param encodedBoard Entity's board data
   * @param encodedSignature Entity's signatures authorizing this transfer
   */
  function entityTransferTokens(
    uint256 entityNumber,
    address to,
    uint256 tokenId,
    uint256 amount,
    bytes calldata encodedBoard,
    bytes calldata encodedSignature
  ) external {
    // Create transfer hash
    bytes32 transferHash = keccak256(abi.encodePacked(
      "ENTITY_TRANSFER",
      entityNumber,
      to,
      tokenId,
      amount,
      block.timestamp
    ));
    
    // Verify entity signature
    uint256 recoveredEntityId = recoverEntity(encodedBoard, encodedSignature, transferHash);
    require(recoveredEntityId == entityNumber, "Invalid entity signature");
    
    // Execute transfer
    address entityAddress = address(uint160(uint256(bytes32(entityNumber))));
    _safeTransferFrom(entityAddress, to, tokenId, amount, "");
  }

  // === CONTROL SHARES RELEASE TO DEPOSITORY ===

  event ControlSharesReleased(
    bytes32 indexed entityId, 
    address indexed depository, 
    uint256 controlAmount, 
    uint256 dividendAmount,
    string purpose
  );

  /**
   * @notice Release entity's control and/or dividend shares to depository for trading
   * @dev This mirrors real corporate stock issuance - entity manages its own share releases
   * @param entityNumber The entity number
   * @param depository Depository contract address to receive the shares
   * @param controlAmount Amount of control tokens to release (0 to skip)
   * @param dividendAmount Amount of dividend tokens to release (0 to skip) 
   * @param purpose Human-readable purpose (e.g., "Series A", "Employee Pool", "Public Sale")
   * @param encodedBoard Entity's board data
   * @param encodedSignature Entity's Hanko signatures authorizing this release
   */
  function releaseControlShares(
    uint256 entityNumber,
    address depository,
    uint256 controlAmount,
    uint256 dividendAmount,
    string calldata purpose,
    bytes calldata encodedBoard,
    bytes calldata encodedSignature
  ) external {
    require(depository != address(0), "Invalid depository address");
    require(controlAmount > 0 || dividendAmount > 0, "Must release some tokens");
    
    bytes32 entityId = bytes32(entityNumber);
    require(entities[entityId].currentBoardHash != bytes32(0), "Entity doesn't exist");
    
    // Create release authorization hash
    bytes32 releaseHash = keccak256(abi.encodePacked(
      "RELEASE_CONTROL_SHARES",
      entityNumber,
      depository,
      controlAmount,
      dividendAmount,
      keccak256(bytes(purpose)),
      block.timestamp
    ));
    
    // Verify entity signature authorization
    uint256 recoveredEntityId = recoverEntity(encodedBoard, encodedSignature, releaseHash);
    require(recoveredEntityId == entityNumber, "Invalid entity signature");
    
    address entityAddress = address(uint160(uint256(entityId)));
    (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(entityNumber);
    
    // Transfer control tokens if requested
    if (controlAmount > 0) {
      require(balanceOf(entityAddress, controlTokenId) >= controlAmount, "Insufficient control tokens");
      _safeTransferFrom(entityAddress, depository, controlTokenId, controlAmount, 
        abi.encode("CONTROL_SHARE_RELEASE", purpose));
    }
    
    // Transfer dividend tokens if requested  
    if (dividendAmount > 0) {
      require(balanceOf(entityAddress, dividendTokenId) >= dividendAmount, "Insufficient dividend tokens");
      _safeTransferFrom(entityAddress, depository, dividendTokenId, dividendAmount,
        abi.encode("DIVIDEND_SHARE_RELEASE", purpose));
    }
    
    emit ControlSharesReleased(entityId, depository, controlAmount, dividendAmount, purpose);
  }

}

//jurisdictions/contracts/SubcontractProvider.sol (155 lines)
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.24;
pragma experimental ABIEncoderV2;

import "./Token.sol";

import "./ECDSA.sol";
import "./console.sol";
import "hardhat/console.sol";
/* 
Subcontracts - Programmable Delta Transformers
  function applyBatch(int[] memory deltas, bytes calldata encodedBatch,
                      bytes calldata leftArguments, bytes calldata rightArguments)
    ‚Üí int[] memory newDeltas

  What you can do:
  - HTLCs (conditional payments based on secret reveal)
  - Atomic swaps (exchange token A for token B, all-or-nothing)
  - Any programmable state transition within bilateral account

  First in history: Lightning only has HTLCs hardcoded. You're generalizing it - arbitrary logic can transform delta arrays. The applySwap() function (line
   105) shows fillRatio execution (0-100% fill of limit order).

  This is DeFi within bilateral channels. Genuinely new.
  */
contract SubcontractProvider is Console {
  mapping(bytes32 => uint) public hashToBlock;
  uint MAXUINT32 = type(uint32).max;

  constructor() {
    revealSecret(bytes32(0));
  }
  
  struct Batch {
    Payment[] payment;
    Swap[] swap;
  }

  // actual subcontract structs
  struct Payment {
    uint deltaIndex;
    int amount;
    uint revealedUntilBlock;
    bytes32 hash;
  }

  struct Swap {
    bool ownerIsLeft;

    uint addDeltaIndex;
    uint addAmount;

    uint subDeltaIndex;
    uint subAmount;
  }

  // https://en.wikipedia.org/wiki/Credit_default_swap
  struct CreditDefaultSwap {
    uint deltaIndex;
    int amount;
    address referenceEntity;
    uint tokenId;
    uint exerciseUntilBlock;
  }

  function encodeBatch (Batch memory b) public pure returns (bytes memory) {
    return abi.encode(b);
  }



  // applies arbitrary changes to deltas
  function applyBatch(
    int[] memory deltas,
    bytes calldata encodedBatch,
    bytes calldata leftArguments,
    bytes calldata rightArguments
  ) public returns (int[] memory) {

    Batch memory decodedBatch = abi.decode(encodedBatch, (Batch));

    uint[] memory lArgs = abi.decode(leftArguments, (uint[]));
    uint[] memory rArgs = abi.decode(rightArguments, (uint[]));
    
    for (uint i = 0; i < decodedBatch.payment.length; i++) {
      applyPayment(deltas, decodedBatch.payment[i]);
    }

    uint leftSwaps = 0;
    for (uint i = 0; i < decodedBatch.swap.length; i++) {
      Swap memory swap = decodedBatch.swap[i];

      uint32 fillRatio = uint32(swap.ownerIsLeft ? lArgs[leftSwaps] : rArgs[i  - leftSwaps]);

      applySwap(deltas, swap, fillRatio);
      //logDeltas("Deltas after swap", deltas);

      if (swap.ownerIsLeft) {
        leftSwaps++;
      }
    }

    return deltas;
  }

  function applyPayment(int[] memory deltas, Payment memory payment) private {
    // apply amount to delta if revealed on time
    // this is "sprites" approach (https://arxiv.org/pdf/1702.05812) 
    // the opposite is "blitz" (https://www.usenix.org/system/files/sec21fall-aumayr.pdf)
    uint revealedAt = hashToBlock[payment.hash];
    if (revealedAt == 0 || revealedAt > payment.revealedUntilBlock) {
      return;
    }

    logDeltas("Before payment", deltas);
    deltas[payment.deltaIndex] += payment.amount;
    logDeltas("After payment", deltas);
  }

  function applySwap(int[] memory deltas, Swap memory swap, uint32 fillRatio) private {
    logDeltas("Before swap", deltas);
    deltas[swap.addDeltaIndex] += int(swap.addAmount * fillRatio / MAXUINT32);
    deltas[swap.subDeltaIndex] -= int(swap.subAmount * fillRatio / MAXUINT32);
    logDeltas("After swap", deltas);
  }





  function revealSecret(bytes32 secret) public {
    console.log("Revealing HTLC secret:");
    console.logBytes32(secret);
    console.logBytes32(keccak256(abi.encode(secret)));
    hashToBlock[keccak256(abi.encode(secret))] = block.number;
  }
  
  // anyone can get gas refund by deleting very old revealed secrets
  function cleanSecret(bytes32 hash) public {
    if (hashToBlock[hash] != 0 && hashToBlock[hash] < block.number - 100000){
      delete hashToBlock[hash];
    }
  }

  function logDeltas(string memory _msg, int[] memory deltas) public pure {
    console.log(_msg);
    for (uint i = 0; i < deltas.length; i++) {
      console.logInt(deltas[i]);
    }
    console.log('====================');
  }



}

//runtime/types.ts (566 lines)
/**
 * XLN Type Definitions
 * All interfaces and type definitions used across the XLN system
 */

import type { Profile } from './gossip.js';

export interface JurisdictionConfig {
  address: string;
  name: string;
  entityProviderAddress: string;
  depositoryAddress: string;
  chainId?: number;
}

export interface ConsensusConfig {
  mode: 'proposer-based' | 'gossip-based';
  threshold: bigint;
  validators: string[];
  shares: { [validatorId: string]: bigint };
  jurisdiction?: JurisdictionConfig;
}

export interface RuntimeInput {
  runtimeTxs: RuntimeTx[];
  entityInputs: EntityInput[];
}

export interface RuntimeTx {
  type: 'importReplica';
  entityId: string;
  signerId: string;
  data: {
    config: ConsensusConfig;
    isProposer: boolean;
    position?: { x: number; y: number; z: number };
  };
}

export interface EntityInput {
  entityId: string;
  signerId: string;
  entityTxs?: EntityTx[];
  precommits?: Map<string, string>; // signerId -> signature
  proposedFrame?: ProposedEntityFrame;
}

export interface Proposal {
  id: string; // hash of the proposal
  proposer: string;
  action: ProposalAction;
  // Votes: signerId ‚Üí vote (string for simple votes, object for commented votes)
  // Future: Create VoteData interface for type-safe vote objects
  votes: Map<string, 'yes' | 'no' | 'abstain' | { choice: 'yes' | 'no' | 'abstain'; comment: string }>;
  status: 'pending' | 'executed' | 'rejected';
  created: number; // entity timestamp when proposal was created (deterministic)
}

export interface ProposalAction {
  type: 'collective_message';
  data: {
    message: string;
  };
}

export interface VoteData {
  proposalId: string;
  voter: string;
  choice: 'yes' | 'no' | 'abstain';
  comment?: string;
}

/**
 * Jurisdiction event data for j_event transactions
 * Flattened structure (no nested event object)
 */
export interface JurisdictionEventData {
  from: string;
  event: {
    type: string; // e.g. "reserveToReserve", "GovernanceEnabled"
    data: any;
  };
  observedAt: number;
  blockNumber: number;
  transactionHash: string;
}

export interface AccountTxInput {
  fromEntityId: string;
  toEntityId: string;
  accountTx: AccountTx; // The actual account transaction to process
  metadata?: {
    purpose?: string;
    description?: string;
  };
}

export type EntityTx =
  | {
      type: 'chat';
      data: { from: string; message: string };
    }
  | {
      type: 'chatMessage';
      data: {
        message: string;
        timestamp: number;
        metadata?: {
          type: string;
          counterpartyId?: string;
          height?: number;
          frameAge?: number;
          tokenId?: number;
          rebalanceAmount?: string;
          [key: string]: any; // Allow additional rebalance metadata
        };
      };
    }
  | {
      type: 'propose';
      data: { action: ProposalAction; proposer: string };
    }
  | {
      type: 'vote';
      data: { proposalId: string; voter: string; choice: 'yes' | 'no'; comment?: string };
    }
  | {
      type: 'profile-update';
      data: { profile: any }; // replace with concrete profile type if available
    }
  | {
      type: 'j_event';
      data: JurisdictionEventData;
    }
  | {
      type: 'accountInput';
      data: AccountInput;
    }
  | {
      type: 'openAccount';
      data: { targetEntityId: string };
    }
  | {
      type: 'directPayment';
      data: {
        targetEntityId: string;
        tokenId: number;
        amount: bigint;
        route: string[]; // Full path from source to target
        description?: string;
      };
    }
  | {
      type: 'requestWithdrawal';
      data: {
        counterpartyEntityId: string;
        tokenId: number;
        amount: bigint;
      };
    }
  | {
      type: 'settleDiffs';
      data: {
        counterpartyEntityId: string;
        diffs: Array<{
          tokenId: number;
          leftDiff: bigint;   // Positive = credit, Negative = debit
          rightDiff: bigint;
          collateralDiff: bigint;
          ondeltaDiff: bigint;
        }>;
        description?: string; // e.g., "Fund collateral from reserve"
      };
    }
  | {
      type: 'deposit_collateral';
      data: {
        counterpartyId: string; // Which account to add collateral to
        tokenId: number;
        amount: bigint;
      };
    };

export interface AssetBalance {
  amount: bigint; // Balance in smallest unit (wei, cents, shares)
  // Note: symbol, decimals, contractAddress come from token registry, not stored here
}

// Account machine structures for signed and collateralized accounts between entities
export interface AccountDelta {
  tokenId: number;
  delta: bigint; // Positive = we owe them, Negative = they owe us
}

// Simple account state snapshot (for currentFrame)
export interface AccountSnapshot {
  height: number; // Renamed from frameId for S/E/A consistency
  timestamp: number;
  tokenIds: number[]; // Array of token IDs in this account
  deltas: bigint[]; // Array of deltas corresponding to tokenIds
  stateHash?: string; // Optional hash for cryptographic verification
}

export interface AccountMachine {
  counterpartyEntityId: string;
  mempool: AccountTx[]; // Unprocessed account transactions
  currentFrame: AccountFrame; // Current agreed state (includes full transaction history for replay/audit)
  sentTransitions: number; // Number of transitions sent but not yet confirmed
  ackedTransitions: number; // Number of transitions acknowledged by counterparty

  // Per-token delta states (giant per-token table like old_src)
  deltas: Map<number, Delta>; // tokenId -> Delta

  // Global credit limits (in reference currency - USDC)
  globalCreditLimits: {
    ownLimit: bigint; // How much credit we extend to counterparty (USD)
    peerLimit: bigint; // How much credit counterparty extends to us (USD)
  };

  // Frame-based consensus (like old_src Channel, consistent with entity frames)
  currentHeight: number; // Renamed from currentFrameId for S/E/A consistency
  pendingFrame?: AccountFrame;
  pendingSignatures: string[];

  // Rollback support for bilateral disagreements
  rollbackCount: number;

  // CHANNEL.TS REFERENCE: Proper message counters (NOT timestamps!)
  sendCounter: number;    // Incremented for each outgoing message
  receiveCounter: number; // Incremented for each incoming message
  // Removed isProposer - use isLeft() function like old_src Channel.ts instead

  // Cloned state for validation before committing (replaces dryRun)
  clonedForValidation?: AccountMachine;

  // Proof structures for dispute resolution
  proofHeader: {
    fromEntity: string; // Our entity ID
    toEntity: string; // Counterparty entity ID
    cooperativeNonce: number;
    disputeNonce: number;
  };
  proofBody: {
    tokenIds: number[];
    deltas: bigint[];
  };
  hankoSignature?: string; // Last signed proof by counterparty
  // Historical frame log - grows until manually pruned by entity
  frameHistory: AccountFrame[]; // All confirmed bilateral frames in chronological order

  // Payment routing: temporary storage for multi-hop payments
  pendingForward?: {
    tokenId: number;
    amount: bigint;
    route: string[];
    description?: string;
  };

  // Withdrawal tracking (Phase 2: C‚ÜíR)
  pendingWithdrawals: Map<string, {
    requestId: string;
    tokenId: number;
    amount: bigint;
    requestedAt: number; // Timestamp
    direction: 'outgoing' | 'incoming'; // Did we request, or did they?
    status: 'pending' | 'approved' | 'rejected' | 'timed_out';
    signature?: string; // If approved
  }>;

  // Rebalancing hints (Phase 3: Hub coordination)
  requestedRebalance: Map<number, bigint>; // tokenId ‚Üí amount entity wants rebalanced (credit‚Üícollateral)
}

// Account frame structure for bilateral consensus (renamed from AccountBlock)
export interface AccountFrame {
  height: number; // Renamed from frameId for S/E/A consistency
  timestamp: number;
  accountTxs: AccountTx[]; // Renamed from transitions
  prevFrameHash: string; // Hash of previous frame (creates chain linkage, not state linkage)
  stateHash: string;
  // Removed isProposer - both sides can propose bilaterally
  tokenIds: number[]; // Array of token IDs in this frame
  deltas: bigint[]; // Array of deltas corresponding to tokenIds (ondelta+offdelta for quick access)
  fullDeltaStates?: Delta[]; // OPTIONAL: Full delta objects (includes credit limits, allowances, collateral)
}

// AccountInput - Maps 1:1 to Channel.ts FlushMessage (frame-level consensus ONLY)
export interface AccountInput {
  fromEntityId: string;
  toEntityId: string;

  // Frame-level consensus (matches Channel.ts FlushMessage structure)
  height?: number;                   // Which frame we're ACKing or referencing (renamed from frameId)
  prevSignatures?: string[];         // ACK for their frame (like pendingSignatures in Channel.ts)
  newAccountFrame?: AccountFrame;    // Our new proposed frame (like block in Channel.ts)
  newSignatures?: string[];          // Signatures on new frame (like newSignatures in Channel.ts)
  counter?: number;                  // Message counter for replay protection (like Channel.ts line 620)
}

// Delta structure for per-token account state (based on old_src)
export interface Delta {
  tokenId: number;
  collateral: bigint;
  ondelta: bigint; // On-chain delta
  offdelta: bigint; // Off-chain delta
  leftCreditLimit: bigint;
  rightCreditLimit: bigint;
  leftAllowance: bigint;
  rightAllowance: bigint;
}

// Derived account balance information per token
export interface DerivedDelta {
  delta: bigint;
  collateral: bigint;
  inCollateral: bigint;
  outCollateral: bigint;
  inOwnCredit: bigint;
  outPeerCredit: bigint;
  inAllowence: bigint;
  outAllowence: bigint;
  totalCapacity: bigint;
  ownCreditLimit: bigint;
  peerCreditLimit: bigint;
  inCapacity: bigint;
  outCapacity: bigint;
  outOwnCredit: bigint;
  inPeerCredit: bigint;
  ascii: string; // ASCII visualization from deriveDelta (like old_src)
}

// Account transaction types
export type AccountTx =
  | { type: 'account_payment'; data: { tokenId: number; amount: bigint } }
  | { type: 'direct_payment'; data: { tokenId: number; amount: bigint; route?: string[]; description?: string; fromEntityId?: string; toEntityId?: string } }
  | { type: 'add_delta'; data: { tokenId: number } }
  | { type: 'set_credit_limit'; data: { tokenId: number; amount: bigint; side: 'left' | 'right' } }
  | { type: 'account_frame'; data: { frame: AccountFrame; processedTransactions: number; fromEntity: string } }
  | {
      type: 'account_settle';
      data: {
        tokenId: number;
        ownReserve: string;
        counterpartyReserve: string;
        collateral: string;
        ondelta: string;
        side: 'left' | 'right';
        blockNumber: number;
        transactionHash: string;
      };
    }
  | {
      type: 'reserve_to_collateral';
      data: {
        tokenId: number;
        collateral: string; // Absolute collateral value from contract
        ondelta: string;    // Absolute ondelta value from contract
        side: 'receiving' | 'counterparty';
        blockNumber: number;
        transactionHash: string;
      };
    }
  | {
      type: 'request_withdrawal';
      data: {
        tokenId: number;
        amount: bigint;
        requestId: string; // Unique ID for matching ACK/NACK
      };
    }
  | {
      type: 'approve_withdrawal';
      data: {
        tokenId: number;
        amount: bigint;
        requestId: string; // Matches request_withdrawal.requestId
        approved: boolean; // true = ACK, false = NACK
        signature?: string; // If approved: signature for on-chain submission
      };
    }
  | {
      type: 'request_rebalance';
      data: {
        tokenId: number;
        amount: bigint; // How much collateral requested for insurance
      };
    };

export interface EntityState {
  entityId: string; // The entity ID this state belongs to
  height: number;
  timestamp: number;
  nonces: Map<string, number>;
  messages: string[];
  proposals: Map<string, Proposal>;
  config: ConsensusConfig;

  // üí∞ Financial state
  reserves: Map<string, bigint>; // tokenId -> amount only, metadata from TOKEN_REGISTRY
  accounts: Map<string, AccountMachine>; // counterpartyEntityId -> account state
  // üî≠ J-machine tracking
  jBlock: number; // Last processed J-machine block number

  // üîó Account machine integration
  accountInputQueue?: AccountInput[]; // Queue of settlement events to be processed by a-machine

  // ‚è∞ Crontab system - periodic task execution (typed in entity-crontab.ts)
  crontabState?: any; // CrontabState - avoid circular import

  // üì¶ J-Batch system - accumulates operations for on-chain submission (typed in j-batch.ts)
  jBatchState?: any; // JBatchState - avoid circular import
}

export interface ProposedEntityFrame {
  height: number;
  txs: EntityTx[];
  hash: string;
  newState: EntityState;
  signatures: Map<string, string>; // signerId -> signature
}

export interface EntityReplica {
  entityId: string;
  signerId: string;
  state: EntityState;
  mempool: EntityTx[];
  proposal?: ProposedEntityFrame;
  lockedFrame?: ProposedEntityFrame; // Frame this validator is locked/precommitted to
  isProposer: boolean;
  sentTransitions?: number; // Number of txs sent to proposer but not yet committed (Channel.ts pattern)
  position?: { x: number; y: number; z: number }; // 3D visualization position (for grid scenarios)
}

export interface Env {
  replicas: Map<string, EntityReplica>;
  height: number;
  timestamp: number;
  runtimeInput: RuntimeInput; // Persistent storage for merged inputs
  history: EnvSnapshot[]; // Time machine snapshots - single source of truth
  gossip: any; // Gossip layer for network profiles
  // Future: add config, utilities, etc.
}

export interface RuntimeSnapshot {
  height: number;
  entities: Record<string, EntityState>;
  gossip: {
    profiles: Record<string, Profile>;
  };
}

export interface EnvSnapshot {
  height: number;
  timestamp: number;
  replicas: Map<string, EntityReplica>;
  runtimeInput: RuntimeInput;
  runtimeOutputs: EntityInput[];
  description: string;
  gossip?: {
    profiles: Profile[];
  };
  // Interactive storytelling narrative
  title?: string; // Short headline (e.g., "Bank Run Begins")
  narrative?: string; // Detailed explanation of what's happening in this frame
  // Cinematic view state for scenario playback
  viewState?: {
    camera?: 'orbital' | 'overview' | 'follow' | 'free';
    zoom?: number;
    focus?: string; // Entity ID to center on
    panel?: 'accounts' | 'transactions' | 'consensus' | 'network';
    speed?: number; // Playback speed multiplier
    position?: { x: number; y: number; z: number }; // Camera position
    rotation?: { x: number; y: number; z: number }; // Camera rotation
  };
}

// Entity types
export type EntityType = 'lazy' | 'numbered' | 'named';

// Constants
export const ENC = 'hex' as const;

// === HANKO BYTES SYSTEM (Final Design) ===
export interface HankoBytes {
  placeholders: Buffer[]; // Entity IDs that failed to sign (index 0..N-1)
  packedSignatures: Buffer; // EOA signatures ‚Üí yesEntities (index N..M-1)
  claims: HankoClaim[]; // Entity claims to verify (index M..‚àû)
}

export interface HankoClaim {
  entityId: Buffer;
  entityIndexes: number[];
  weights: number[];
  threshold: number;
  expectedQuorumHash: Buffer;
}

export interface HankoVerificationResult {
  valid: boolean;
  entityId: Buffer;
  signedHash: Buffer;
  yesEntities: Buffer[];
  noEntities: Buffer[];
  completionPercentage: number; // 0-100% completion
  errors?: string[];
}

export interface HankoMergeResult {
  merged: HankoBytes;
  addedSignatures: number;
  completionBefore: number;
  completionAfter: number;
  log: string[];
}

/**
 * Context for hanko verification
 */
export interface HankoContext {
  timestamp: number;
  blockNumber?: number;
  networkId?: number;
}

// === PROFILE & NAME RESOLUTION TYPES ===

/**
 * Entity profile stored in gossip layer
 */
export interface EntityProfile {
  entityId: string;
  name: string; // Human-readable name e.g., "Alice Corp", "Bob's DAO"
  avatar?: string; // Custom avatar URL (fallback to generated identicon)
  bio?: string; // Short description
  website?: string; // Optional website URL
  lastUpdated: number; // Timestamp of last update
  hankoSignature: string; // Signature proving entity ownership
}

/**
 * Profile update transaction data
 */
export interface ProfileUpdateTx {
  name?: string;
  avatar?: string;
  bio?: string;
  website?: string;
}

/**
 * Name index for autocomplete
 */
export interface NameIndex {
  [name: string]: string; // name -> entityId mapping
}

/**
 * Autocomplete search result
 */
export interface NameSearchResult {
  entityId: string;
  name: string;
  avatar: string;
  relevance: number; // Search relevance score 0-1
}


//runtime/runtime.ts (1175 lines)
// for regular use > bun run runtime/runtime.ts
// for debugging > bun repl
// await import('./debug.js');
// FORCE AUTO-REBUILD: Fixed signerId consistency and fintech type safety

// Import utilities and types
// High-level database using Level polyfill (works in both Node.js and browser)
import { Level } from 'level';

import { applyEntityInput, mergeEntityInputs } from './entity-consensus';
import {
  createLazyEntity,
  createNumberedEntity,
  createNumberedEntitiesBatch,
  detectEntityType,
  encodeBoard,
  generateLazyEntityId,
  generateNamedEntityId,
  generateNumberedEntityId,
  hashBoard,
  isEntityRegistered,
  requestNamedEntity,
  resolveEntityIdentifier,
} from './entity-factory';
import {
  assignNameOnChain,
  connectToEthereum,
  debugFundReserves,
  getAvailableJurisdictions,
  getEntityInfoFromChain,
  getJurisdictionByAddress,
  getNextEntityNumber,
  registerNumberedEntityOnChain,
  submitProcessBatch,
  submitPrefundAccount,
  submitSettle,
  submitReserveToReserve,
  transferNameBetweenEntities,
} from './evm';
import { createGossipLayer } from './gossip';
import { type Profile } from './gossip.js';
import { loadPersistedProfiles } from './gossip-loader';
import { setupJEventWatcher, JEventWatcher } from './j-event-watcher';
import {
  createProfileUpdateTx,
  getEntityDisplayInfo as getEntityDisplayInfoFromProfileOriginal,
  resolveEntityName as resolveEntityNameOriginal,
  searchEntityNames as searchEntityNamesOriginal,
} from './name-resolution';
import { runDemo } from './rundemo';
import { decode, encode } from './snapshot-coder'; // encode used in exports
import { deriveDelta, isLeft, getTokenInfo, formatTokenAmount, createDemoDelta, getDefaultCreditLimit } from './account-utils';
import {
  formatTokenAmount as formatTokenAmountEthers,
  parseTokenAmount,
  convertTokenPrecision,
  calculatePercentage as calculatePercentageEthers,
  formatAssetAmount as formatAssetAmountEthers,
  BigIntMath,
  FINANCIAL_CONSTANTS
} from './financial-utils';
import { captureSnapshot, cloneEntityReplica } from './state-helpers';
import { getEntityShortId, getEntityNumber, formatEntityId } from './entity-helpers';
import { safeStringify } from './serialization-utils';
import { validateDelta, validateAccountDeltas, createDefaultDelta, isDelta, validateEntityInput, validateEntityOutput } from './validation-utils';
import { EntityInput, EntityReplica, Env, RuntimeInput } from './types';
import {
  clearDatabase,
  DEBUG,
  formatEntityDisplay,
  formatSignerDisplay,
  generateEntityAvatar,
  generateSignerAvatar,
  getEntityDisplayInfo,
  getSignerDisplayInfo,
  isBrowser,
  log,
} from './utils';
import { logError } from './logger';

// --- Database Setup ---
// Level polyfill: Node.js uses filesystem, Browser uses IndexedDB
export const db: Level<Buffer, Buffer> = new Level('db', {
  valueEncoding: 'buffer',
  keyEncoding: 'binary',
});

// Helper: Race promise with timeout
async function withTimeout<T>(promise: Promise<T>, ms: number): Promise<T> {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(() => reject(new Error('TIMEOUT')), ms)
    )
  ]);
}

// Database availability check
let dbOpenPromise: Promise<boolean> | null = null;

async function tryOpenDb(): Promise<boolean> {
  if (!dbOpenPromise) {
    dbOpenPromise = (async () => {
      try {
        await db.open();
        console.log('‚úÖ Database opened');
        return true;
      } catch (error) {
        // Check if IndexedDB is completely blocked (Safari incognito)
        const isBlocked = error instanceof Error &&
          (error.message?.includes('blocked') ||
           error.name === 'SecurityError' ||
           error.name === 'InvalidStateError');

        if (isBlocked) {
          console.log('‚ö†Ô∏è IndexedDB blocked (incognito/private mode) - running in-memory');
          return false;
        }

        // Other errors - log but assume DB is available
        console.warn('‚ö†Ô∏è DB open warning:', error instanceof Error ? error.message : error);
        return true;
      }
    })();
  }
  return dbOpenPromise;
}

// === ETHEREUM INTEGRATION ===

// === SVELTE REACTIVITY INTEGRATION ===
// Callback that Svelte can register to get notified of env changes
let envChangeCallback: ((env: Env) => void) | null = null;

// Module-level environment variable
let env: Env;

// Module-level j-watcher instance - prevent multiple instances
let jWatcher: JEventWatcher | null = null;
let jWatcherStarted = false;

export const registerEnvChangeCallback = (callback: (env: Env) => void) => {
  envChangeCallback = callback;
};

const notifyEnvChange = (env: Env) => {
  if (envChangeCallback) {
    envChangeCallback(env);
  }
};

// J-Watcher initialization
const startJEventWatcher = async (env: Env): Promise<void> => {
  try {
    // Get the Arrakis jurisdiction (primary testnet)
    const arrakis = await getJurisdictionByAddress('arrakis');
    if (!arrakis) {
      console.warn('‚ö†Ô∏è Arrakis jurisdiction not found, skipping j-watcher');
      return;
    }

    // Set up j-watcher with the deployed contracts
    jWatcher = await setupJEventWatcher(
      env,
      arrakis.address, // RPC URL (via /rpc/arrakis proxy)
      arrakis.entityProviderAddress,
      arrakis.depositoryAddress
    );

    console.log('‚úÖ J-Event Watcher started successfully');
    console.log(`üî≠ Monitoring: ${arrakis.address}`);
    console.log(`üìç EntityProvider: ${arrakis.entityProviderAddress}`);
    console.log(`üìç Depository: ${arrakis.depositoryAddress}`);
    
    // J-watcher now handles its own periodic sync every 500ms
    // Set up a periodic check to process any queued events from j-watcher
    setInterval(async () => {
      if (env.runtimeInput.entityInputs.length > 0) {
        // const eventCount = env.runtimeInput.entityInputs.length;
        // J-WATCHER routine log removed

        // Process the queued entity inputs from j-watcher
        await applyRuntimeInput(env, {
          runtimeTxs: [],
          entityInputs: [...env.runtimeInput.entityInputs]
        });

        // Clear the processed inputs
        env.runtimeInput.entityInputs.length = 0;
      }
    }, 100); // Check every 100ms to process j-watcher events quickly
    
  } catch (error) {
    logError("RUNTIME_TICK", '‚ùå Failed to start J-Event Watcher:', error);
  }
};

// Note: History is now stored in env.history (no global variable needed)

// === SNAPSHOT UTILITIES ===
// All cloning utilities now moved to state-helpers.ts

// All snapshot functionality now moved to state-helpers.ts

// === UTILITY FUNCTIONS ===

const applyRuntimeInput = async (
  env: Env,
  runtimeInput: RuntimeInput,
): Promise<{ entityOutbox: EntityInput[]; mergedInputs: EntityInput[] }> => {
  const startTime = Date.now();

  try {
    // SECURITY: Validate runtime input
    if (!runtimeInput) {
      log.error('‚ùå Null runtime input provided');
      return { entityOutbox: [], mergedInputs: [] };
    }
    if (!Array.isArray(runtimeInput.runtimeTxs)) {
      log.error(`‚ùå Invalid runtimeTxs: expected array, got ${typeof runtimeInput.runtimeTxs}`);
      return { entityOutbox: [], mergedInputs: [] };
    }
    if (!Array.isArray(runtimeInput.entityInputs)) {
      log.error(`‚ùå Invalid entityInputs: expected array, got ${typeof runtimeInput.entityInputs}`);
      return { entityOutbox: [], mergedInputs: [] };
    }

    // SECURITY: Resource limits
    if (runtimeInput.runtimeTxs.length > 1000) {
      log.error(`‚ùå Too many runtime transactions: ${runtimeInput.runtimeTxs.length} > 1000`);
      return { entityOutbox: [], mergedInputs: [] };
    }
    if (runtimeInput.entityInputs.length > 10000) {
      log.error(`‚ùå Too many entity inputs: ${runtimeInput.entityInputs.length} > 10000`);
      return { entityOutbox: [], mergedInputs: [] };
    }

    // Merge new runtimeInput into env.runtimeInput
    env.runtimeInput.runtimeTxs.push(...runtimeInput.runtimeTxs);
    env.runtimeInput.entityInputs.push(...runtimeInput.entityInputs);

    // Merge all entityInputs in env.runtimeInput
    const mergedInputs = mergeEntityInputs(env.runtimeInput.entityInputs);

    // FINTECH-LEVEL TYPE SAFETY: Validate all merged inputs at entry point
    mergedInputs.forEach((input, i) => {
      try {
        validateEntityInput(input);
      } catch (error) {
        logError("RUNTIME_TICK", `üö® CRITICAL FINANCIAL ERROR: Invalid merged EntityInput[${i}]!`, {
          error: (error as Error).message,
          input
        });
        throw error; // Fail fast
      }
    });

    const entityOutbox: EntityInput[] = [];

    // TICK and REPLICA-DEBUG logging removed - too verbose
    env.runtimeInput.runtimeTxs.forEach(runtimeTx => {
      if (runtimeTx.type === 'importReplica') {
        if (DEBUG)
          console.log(
            `Importing replica Entity #${formatEntityDisplay(runtimeTx.entityId)}:${formatSignerDisplay(runtimeTx.signerId)} (proposer: ${runtimeTx.data.isProposer})`,
          );

        const replicaKey = `${runtimeTx.entityId}:${runtimeTx.signerId}`;
        const replica: EntityReplica = {
          entityId: runtimeTx.entityId,
          signerId: runtimeTx.signerId,
          mempool: [],
          isProposer: runtimeTx.data.isProposer,
          state: {
            entityId: runtimeTx.entityId, // Store entityId in state
            height: 0,
            timestamp: env.timestamp,
            nonces: new Map(),
            messages: [],
            proposals: new Map(),
            config: runtimeTx.data.config,
            // üí∞ Initialize financial state
            reserves: new Map(), // tokenId -> bigint amount
            accounts: new Map(), // counterpartyEntityId -> AccountMachine

            // üî≠ J-machine tracking
            jBlock: 0, // Must start from 0 to resync all reserves

            // ‚è∞ Crontab system - will be initialized on first use
            crontabState: undefined,

            // üì¶ J-Batch system - will be initialized on first use
            jBatchState: undefined,
          },
        };

        // Only add position if it exists (exactOptionalPropertyTypes compliance)
        if (runtimeTx.data.position) {
          replica.position = runtimeTx.data.position;
          // GRID-POS-C removed - frontend has GRID-POS-D/E
        }

        env.replicas.set(replicaKey, replica);
        // Validate jBlock immediately after creation
        const createdReplica = env.replicas.get(replicaKey);
        const actualJBlock = createdReplica?.state.jBlock;
        // REPLICA-DEBUG removed

        // Broadcast initial profile to gossip layer
        if (env.gossip && createdReplica) {
          const profile = {
            entityId: runtimeTx.entityId,
            capabilities: [],
            hubs: [],
            metadata: {
              lastUpdated: Date.now(),
              routingFeePPM: 100, // Default 100 PPM (0.01%)
              baseFee: 0n,
            },
            accounts: [], // No accounts yet
          };
          env.gossip.announce(profile);
          // Broadcast log removed
        }

        if (typeof actualJBlock !== 'number') {
          logError("RUNTIME_TICK", `üí• ENTITY-CREATION-BUG: Just created entity with invalid jBlock!`);
          logError("RUNTIME_TICK", `üí•   Expected: 0 (number), Got: ${typeof actualJBlock}, Value: ${actualJBlock}`);
          // Force fix immediately
          if (createdReplica) {
            createdReplica.state.jBlock = 0;
            console.log(`üí•   FIXED: Set jBlock to 0 for replica ${replicaKey}`);
          }
        }
      }
    });
    // REPLICA-DEBUG and SERVER-PROCESSING logs removed
    for (const entityInput of mergedInputs) {
      // Track j-events in this input - entityInput.entityTxs guaranteed by validateEntityInput above
      // J-EVENT logging removed - too verbose

      // Handle empty signerId for AccountInputs - auto-route to proposer
      let actualSignerId = entityInput.signerId;
      if (!actualSignerId || actualSignerId === '') {
        // Check if this is an AccountInput that needs auto-routing
        const hasAccountInput = entityInput.entityTxs!.some(tx => tx.type === 'accountInput');
        if (hasAccountInput) {
          // Find the proposer for this entity
          const entityReplicaKeys = Array.from(env.replicas.keys()).filter(key => key.startsWith(entityInput.entityId + ':'));
          if (entityReplicaKeys.length > 0) {
            const firstReplicaKey = entityReplicaKeys[0];
            if (!firstReplicaKey) {
              logError("RUNTIME_TICK", `‚ùå Invalid replica key for entity ${entityInput.entityId}`);
              continue;
            }
            const firstReplica = env.replicas.get(firstReplicaKey);
            if (firstReplica?.state.config.validators[0]) {
              actualSignerId = firstReplica.state.config.validators[0];
              // AUTO-ROUTE log removed
            }
          }
        }

        // Fallback if still no signerId
        if (!actualSignerId || actualSignerId === '') {
          console.warn(`‚ö†Ô∏è No signerId and unable to determine proposer for entity ${entityInput.entityId.slice(0,10)}...`);
          continue; // Skip this input
        }
      }

      const replicaKey = `${entityInput.entityId}:${actualSignerId}`;
      const entityReplica = env.replicas.get(replicaKey);

      // REPLICA-LOOKUP logs removed - not consensus-critical

      if (entityReplica) {
        if (DEBUG) {
          console.log(`Processing input for ${replicaKey}:`);
          if (entityInput.entityTxs!.length) console.log(`  ‚Üí ${entityInput.entityTxs!.length} transactions`);
          if (entityInput.proposedFrame) console.log(`  ‚Üí Proposed frame: ${entityInput.proposedFrame.hash}`);
          if (entityInput.precommits?.size) console.log(`  ‚Üí ${entityInput.precommits.size} precommits`);
        }

        const { newState, outputs } = await applyEntityInput(env, entityReplica, entityInput);
        // APPLY-ENTITY-INPUT-RESULT removed - too noisy

        // CRITICAL FIX: Update the replica in the environment with the new state
        env.replicas.set(replicaKey, { ...entityReplica, state: newState });

        // FINTECH-LEVEL TYPE SAFETY: Validate all entity outputs before routing
        outputs.forEach((output, index) => {
          try {
            validateEntityOutput(output);
          } catch (error) {
            logError("RUNTIME_TICK", `üö® CRITICAL FINANCIAL ERROR: Invalid EntityOutput[${index}] from ${replicaKey}!`, {
              error: (error as Error).message,
              output
            });
            throw error; // Fail fast to prevent financial routing corruption
          }
        });

        entityOutbox.push(...outputs);
        // ENTITY-OUTBOX log removed - too noisy
      }
    }

    // Only create runtime frame if there's actual work to do
    const hasRuntimeTxs = env.runtimeInput.runtimeTxs.length > 0;
    const hasEntityInputs = mergedInputs.length > 0;
    const hasOutputs = entityOutbox.length > 0;

    if (hasRuntimeTxs || hasEntityInputs || hasOutputs) {
      // Update env (mutable)
      env.height++;
      env.timestamp = Date.now();

      // Capture snapshot BEFORE clearing (to show what was actually processed)
      const inputDescription = `Tick ${env.height - 1}: ${env.runtimeInput.runtimeTxs.length} runtimeTxs, ${mergedInputs.length} merged entityInputs ‚Üí ${entityOutbox.length} outputs`;
      const processedInput = {
        runtimeTxs: [...env.runtimeInput.runtimeTxs],
        entityInputs: [...mergedInputs], // Use merged inputs instead of raw inputs
      };

      // Clear processed data from env.runtimeInput
      env.runtimeInput.runtimeTxs.length = 0;
      env.runtimeInput.entityInputs.length = 0;

      // Capture snapshot with the actual processed input and outputs
      await captureSnapshot(env, env.history, db, processedInput, entityOutbox, inputDescription);
    } else {
      console.log(`‚ö™ SKIP-FRAME: No runtimeTxs, entityInputs, or outputs - not creating empty frame`);
    }

    // Notify Svelte about environment changes
    // REPLICA-DEBUG and GOSSIP-DEBUG removed
    
    // CRITICAL FIX: Initialize gossip layer if missing
    if (!env.gossip) {
      console.log(`üö® CRITICAL: gossip layer missing from environment, creating new one`);
      env.gossip = createGossipLayer();
      console.log(`‚úÖ Gossip layer created and added to environment`);
    }

    // Compare old vs new entities
    const oldEntityKeys = Array.from(env.replicas.keys()).filter(
      key =>
        key.startsWith('0x0000000000000000000000000000000000000000000000000000000000000001:') ||
        key.startsWith('0x0000000000000000000000000000000000000000000000000000000000000002:'),
    );
    const newEntityKeys = Array.from(env.replicas.keys()).filter(
      key =>
        !key.startsWith('0x0000000000000000000000000000000000000000000000000000000000000001:') &&
        !key.startsWith('0x0000000000000000000000000000000000000000000000000000000000000002:') &&
        !key.startsWith('0x57e360b00f393ea6d898d6119f71db49241be80aec0fbdecf6358b0103d43a31:'),
    );

    // OLD/NEW-ENTITY-DEBUG removed - too noisy

    if (oldEntityKeys.length > 0 && newEntityKeys.length > 0) {
      const oldReplicaKey = oldEntityKeys[0];
      const newReplicaKey = newEntityKeys[0];
      if (!oldReplicaKey || !newReplicaKey) {
        logError("RUNTIME_TICK", `‚ùå Invalid replica keys: old=${oldReplicaKey}, new=${newReplicaKey}`);
        // Continue with empty outbox instead of crashing
      } else {
      // REPLICA-STRUCTURE logs removed - not consensus-critical
      }
    }

    notifyEnvChange(env);

    if (DEBUG && entityOutbox.length > 0) {
      console.log(`üì§ Outputs: ${entityOutbox.length} messages`);
      entityOutbox.forEach((output, i) => {
        console.log(
          `  ${i + 1}. ‚Üí ${output.signerId} (${output.entityTxs ? `${output.entityTxs.length} txs` : ''}${output.proposedFrame ? ` proposal: ${output.proposedFrame.hash.slice(0, 10)}...` : ''}${output.precommits ? ` ${output.precommits.size} precommits` : ''})`,
        );
      });
    } else if (DEBUG && entityOutbox.length === 0) {
      console.log(`üì§ No outputs generated`);
    }

    // Replica states dump removed - too verbose

    // Always notify UI after processing a frame (this is the discrete simulation step)
    notifyEnvChange(env);

    // Performance logging
    const endTime = Date.now();
    if (DEBUG) {
      console.log(`‚è±Ô∏è  Tick ${env.height - 1} completed in ${endTime - startTime}ms`);
    }

    // APPLY-SERVER-INPUT-FINAL-RETURN removed
    return { entityOutbox, mergedInputs };
  } catch (error) {
    log.error(`‚ùå Error processing runtime input:`, error);
    return { entityOutbox: [], mergedInputs: [] };
  }
};

// This is the new, robust main function that replaces the old one.
const main = async (): Promise<Env> => {
  console.log('üöÄ RUNTIME.JS VERSION: 2025-10-05-16:45 - GRID POSITIONS + ACTIVITY HIGHLIGHTS');

  // Open database before any operations
  const dbReady = await tryOpenDb();

  // DEBUG: Log jurisdictions content on startup using centralized loader
  if (!isBrowser) {
    try {
      const { loadJurisdictions } = await import('./jurisdiction-loader');
      const jurisdictions = loadJurisdictions();
      console.log('üîç STARTUP: Current jurisdictions content (from centralized loader):');
      console.log('üìç Arrakis Depository:', jurisdictions.jurisdictions['arrakis']?.contracts?.depository);
      console.log('üìç Arrakis EntityProvider:', jurisdictions.jurisdictions['arrakis']?.contracts?.entityProvider);
      console.log('üìç Last updated:', jurisdictions.lastUpdated);
      console.log('üìç Full Arrakis config:', safeStringify(jurisdictions.jurisdictions['arrakis']));
    } catch (error) {
      console.log('‚ö†Ô∏è Failed to load jurisdictions:', (error as Error).message);
    }
  }

  // Initialize gossip layer
  console.log('üï∏Ô∏è Initializing gossip layer...');
  const gossipLayer = createGossipLayer();
  console.log('‚úÖ Gossip layer initialized');

  // Load persisted profiles from database into gossip layer
  console.log('üì° Loading persisted profiles from database...');
  await loadPersistedProfiles(db, gossipLayer);

  // First, create default environment with gossip layer
  env = {
    replicas: new Map(),
    height: 0,
    timestamp: Date.now(),
    runtimeInput: { runtimeTxs: [], entityInputs: [] },
    history: [],
    gossip: gossipLayer,
  };

  // Try to load saved state from database
  try {
    if (!dbReady) {
      console.log('üíæ Database unavailable - starting fresh');
      throw new Error('DB_UNAVAILABLE');
    }

    console.log('üì• Loading state from database...');
    const latestHeightBuffer = await withTimeout(db.get(Buffer.from('latest_height')), 2000);

    const latestHeight = parseInt(latestHeightBuffer.toString(), 10);
    console.log(`üìä BROWSER-DEBUG: Found latest height in DB: ${latestHeight}`);

    console.log(`üìä Found latest height: ${latestHeight}, loading ${latestHeight + 1} snapshots...`);

    // Load snapshots starting from 1 (height 0 is initial state, no snapshot saved)
    console.log(`üì• Loading snapshots: 1 to ${latestHeight}...`);
    const snapshots = [];

    // Start from 1 since height 0 is initial state with no snapshot
    for (let i = 1; i <= latestHeight; i++) {
      try {
        const buffer = await db.get(Buffer.from(`snapshot:${i}`));
        const snapshot = decode(buffer);
        snapshots.push(snapshot);
        console.log(`üì¶ Snapshot ${i}: loaded ${buffer.length} bytes`);
      } catch (error) {
        logError("RUNTIME_TICK", `‚ùå Failed to load snapshot ${i}:`, error);
        console.warn(`‚ö†Ô∏è Snapshot ${i} missing, continuing with available data...`);
      }
    }

    if (snapshots.length === 0) {
      console.log(`üì¶ No snapshots found (latestHeight: ${latestHeight}), using fresh environment`);
      throw new Error('LEVEL_NOT_FOUND');
    }

    console.log(`üìä Successfully loaded ${snapshots.length}/${latestHeight} snapshots (starting from height 1)`);
    env.history = snapshots;

    if (snapshots.length > 0) {
      const latestSnapshot = snapshots[snapshots.length - 1];

      // CRITICAL: Validate snapshot has proper replicas data
      if (!latestSnapshot.replicas) {
        console.warn('‚ö†Ô∏è Latest snapshot missing replicas data, using fresh environment');
        throw new Error('LEVEL_NOT_FOUND');
      }

      // Restore gossip profiles from snapshot
      const gossipLayer = createGossipLayer();
      if (latestSnapshot.gossip?.profiles) {
        for (const [id, profile] of Object.entries(latestSnapshot.gossip.profiles)) {
          gossipLayer.profiles.set(id, profile as Profile);
        }
        console.log(`üì° Restored gossip profiles: ${Object.keys(latestSnapshot.gossip.profiles).length} entries`);
      }

      // CRITICAL: Convert replicas to proper Map if needed (handle deserialization from DB)
      let replicasMap: Map<string, EntityReplica>;
      try {
        if (latestSnapshot.replicas instanceof Map) {
          replicasMap = latestSnapshot.replicas;
        } else if (latestSnapshot.replicas && typeof latestSnapshot.replicas === 'object') {
          // Deserialized from DB - convert object to Map
          replicasMap = new Map(Object.entries(latestSnapshot.replicas));
        } else {
          console.warn('‚ö†Ô∏è Invalid replicas format in snapshot, using fresh environment');
          throw new Error('LEVEL_NOT_FOUND');
        }
      } catch (conversionError) {
        logError("RUNTIME_TICK", '‚ùå Failed to convert replicas to Map:', conversionError);
        console.warn('‚ö†Ô∏è Falling back to fresh environment');
        throw new Error('LEVEL_NOT_FOUND');
      }

      env = {
        // CRITICAL: Clone the replicas Map to avoid mutating snapshot data!
        replicas: new Map(Array.from(replicasMap).map(([key, replica]): [string, EntityReplica] => {
          return [key, cloneEntityReplica(replica)];
        })),
        height: latestSnapshot.height,
        timestamp: latestSnapshot.timestamp,
        // CRITICAL: runtimeInput must start EMPTY on restore!
        // The snapshot's runtimeInput was already processed
        runtimeInput: {
          runtimeTxs: [],
          entityInputs: []
        },
        history: snapshots, // Include the loaded history
        gossip: gossipLayer, // Use restored gossip layer
      };
      console.log(`‚úÖ History restored. Runtime is at height ${env.height} with ${env.history.length} snapshots.`);
      console.log(`üìà Snapshot details:`, {
        height: env.height,
        replicaCount: env.replicas.size,
        timestamp: new Date(env.timestamp).toISOString(),
        runtimeInputs: env.runtimeInput.entityInputs.length,
      });
    }
  } catch (error) {
    const isTimeout = error instanceof Error && error.message === 'TIMEOUT';
    const isNotFound = error instanceof Error &&
      (error.name === 'NotFoundError' ||
       error.message?.includes('NotFoundError') ||
       error.message?.includes('Entry not found'));

    if (isTimeout || isNotFound) {
      console.log('üì¶ No saved state found - starting fresh');
    } else if (error instanceof Error && error.message === 'DB_UNAVAILABLE') {
      // Already logged above
    } else {
      console.warn('‚ö†Ô∏è Error loading state:', error instanceof Error ? error.message : error);
      console.log('üì¶ Starting fresh');
    }
  }

  // Demo profiles are only initialized during runDemo - not by default

  // Only run demos in Node.js environment, not browser
  if (!isBrowser) {
    // DISABLED: Hanko tests during development
    console.log('\nüöÄ Hanko tests disabled during development - focusing on core functionality');
    
    // // Add hanko demo to the main execution
    // console.log('\nüñãÔ∏è  Testing Complete Hanko Implementation...');
    // await demoCompleteHanko();

    // // üß™ Run basic Hanko functionality tests first
    // console.log('\nüß™ Running basic Hanko functionality tests...');
    // await runBasicHankoTests();

    // // üß™ Run comprehensive Depository-Hanko integration tests
    // console.log('\nüß™ Running comprehensive Depository-Hanko integration tests...');
    // try {
    //   await runDepositoryHankoTests();
    // } catch (error) {
    //   console.log(
    //     '‚ÑπÔ∏è  Depository integration tests skipped (contract setup required):',
    //     (error as Error).message?.substring(0, 100) || 'Unknown error',
    //   );
    // }
  } else {
    console.log('üåê Browser environment: Demos available via UI buttons, not auto-running');
  }

  log.info(`üéØ Runtime startup complete. Height: ${env.height}, Entities: ${env.replicas.size}`);

  // Debug final state before starting j-watcher
  if (isBrowser) {
    console.log(`üîç BROWSER-DEBUG: Final state before j-watcher start:`);
    console.log(`üîç   Environment height: ${env.height}`);
    console.log(`üîç   Total replicas: ${env.replicas.size}`);
    for (const [replicaKey, replica] of env.replicas.entries()) {
      const [entityId, signerId] = replicaKey.split(':');
      if (entityId && signerId) {
        console.log(`üîç   Entity ${entityId.slice(0,10)}... (${signerId}): jBlock=${replica.state.jBlock}, isProposer=${replica.isProposer}`);
      }
    }
  }

  // DISABLED: J-watcher temporarily disabled (external RPC not needed for demo)
  // Re-enable by uncommenting this block when blockchain integration is needed
  /*
  if (!jWatcherStarted) {
    console.log('üî≠ STARTING-JWATCHER: Snapshots loaded, starting j-watcher (non-blocking)...');

    Promise.race([
      startJEventWatcher(env),
      new Promise((_, reject) => setTimeout(() => reject(new Error('J-watcher startup timeout (3s)')), 3000))
    ])
      .then(() => {
        jWatcherStarted = true;
        console.log('üî≠ JWATCHER-READY: J-watcher started successfully');
      })
      .catch((error) => {
        console.warn('‚ö†Ô∏è  J-Event Watcher startup failed or timed out (non-critical):', error.message);
        console.warn('    UI will load anyway. Blockchain sync will retry in background.');
      });
  } else {
    console.log('üî≠ JWATCHER-SKIP: J-watcher already started, skipping');
  }
  */
  console.log('üî≠ J-WATCHER: Disabled (external RPC not needed for simnet demo)');

  return env;
};

// === TIME MACHINE API ===
const getHistory = () => env.history || [];
const getSnapshot = (index: number) => {
  const history = env.history || [];
  return index >= 0 && index < history.length ? history[index] : null;
};
const getCurrentHistoryIndex = () => (env.history || []).length - 1;

// Server-specific clearDatabase that also resets history
const clearDatabaseAndHistory = async () => {
  console.log('üóëÔ∏è Clearing database and resetting runtime history...');

  // Clear the Level database
  await clearDatabase(db);

  // Reset the runtime environment to initial state (including history)
  env = {
    replicas: new Map(),
    height: 0,
    timestamp: Date.now(),
    runtimeInput: { runtimeTxs: [], entityInputs: [] },
    history: [],
    gossip: createGossipLayer(),
  };

  console.log('‚úÖ Database and runtime history cleared');
};

// Export j-watcher status for frontend display
export const getJWatcherStatus = () => {
  if (!jWatcher || !env) return null;
  return {
    isWatching: jWatcher.getStatus().isWatching,
    proposers: Array.from(env.replicas.entries())
      .filter(([, replica]) => replica.isProposer)
      .map(([key, replica]) => {
        const [entityId, signerId] = key.split(':');
        if (!entityId || !signerId) {
          throw new Error(`Invalid replica key format: ${key}`);
        }
        return {
          entityId: entityId.slice(0,10) + '...',
          signerId,
          jBlock: replica.state.jBlock,
        };
      }),
    nextSyncIn: Math.floor((1000 - (Date.now() % 1000)) / 100) / 10, // Seconds until next 1s sync
  };
};

export {
  applyRuntimeInput,
  assignNameOnChain,
  clearDatabase,
  clearDatabaseAndHistory,
  connectToEthereum,
  // Entity creation functions
  createLazyEntity,
  createNumberedEntity,
  createNumberedEntitiesBatch,
  createProfileUpdateTx,
  demoCompleteHanko,
  detectEntityType,
  encodeBoard,
  // Display and avatar functions
  formatEntityDisplay,
  formatSignerDisplay,
  generateEntityAvatar,
  // Entity utility functions
  generateLazyEntityId,
  generateNamedEntityId,
  generateNumberedEntityId,
  generateSignerAvatar,
  getAvailableJurisdictions,
  getCurrentHistoryIndex,
  getEntityDisplayInfo,
  getEntityDisplayInfoFromProfile,
  getEntityInfoFromChain,
  getHistory,
  getJurisdictionByAddress,
  getNextEntityNumber,
  getSignerDisplayInfo,
  getSnapshot,
  hashBoard,
  isEntityRegistered,
  main,
  // Blockchain registration functions
  registerNumberedEntityOnChain,
  requestNamedEntity,
  resolveEntityIdentifier,
  resolveEntityName,
  runDemo,
  runDemoWrapper,
  // Name resolution functions
  searchEntityNames,
  submitProcessBatch,
  submitPrefundAccount,
  submitSettle,
  submitReserveToReserve,
  debugFundReserves,
  transferNameBetweenEntities,
  // Account utilities (destructured from AccountUtils)
  deriveDelta,
  isLeft,
  getTokenInfo,
  formatTokenAmount,
  createDemoDelta,
  getDefaultCreditLimit,

  // Entity utilities (from entity-helpers and serialization-utils)
  getEntityShortId,
  getEntityNumber, // deprecated, use getEntityShortId
  formatEntityId,
  safeStringify,

  // Financial utilities (ethers.js-based, precision-safe)
  formatTokenAmountEthers,
  parseTokenAmount,
  convertTokenPrecision,
  calculatePercentageEthers,
  formatAssetAmountEthers,
  BigIntMath,
  FINANCIAL_CONSTANTS,

  // Validation utilities (strict typing for financial data)
  validateDelta,
  validateAccountDeltas,
  createDefaultDelta,
  isDelta,

  // Snapshot utilities
  encode,
  decode,

  // Account messaging: Using bilateral frame-based consensus instead of direct messaging
  // (Old direct messaging functions removed - replaced with AccountInput flow)
};

// The browser-specific auto-execution logic has been removed.
// The consuming application (e.g., index.html) is now responsible for calling main().

// --- Node.js auto-execution for local testing ---
// This part will only run when the script is executed directly in Node.js.
if (!isBrowser) {
  main()
    .then(async env => {
      if (env) {
        // Check if demo should run automatically (can be disabled with NO_DEMO=1)
        const noDemoFlag = globalThis.process.env['NO_DEMO'] === '1' || globalThis.process.argv.includes('--no-demo');

        if (!noDemoFlag) {
          console.log('‚úÖ Node.js environment initialized. Running demo for local testing...');
          console.log('üí° To skip demo, use: NO_DEMO=1 bun run src/runtime.ts or --no-demo flag');
          await runDemo(env);

          // Start j-watcher after demo completes
          await startJEventWatcher(env);

          // Add a small delay to ensure demo completes before verification
          setTimeout(async () => {
            await verifyJurisdictionRegistrations();
          }, 2000);
        } else {
          console.log('‚úÖ Node.js environment initialized. Demo skipped (NO_DEMO=1 or --no-demo)');
          console.log('üí° Use XLN.runDemo(env) to run demo manually if needed');
          
          // J-watcher is already started in main(), no need to start again
        }
      }
    })
    .catch(error => {
      logError("RUNTIME_TICK", '‚ùå An error occurred during Node.js auto-execution:', error);
    });
}

// === BLOCKCHAIN VERIFICATION ===
const verifyJurisdictionRegistrations = async () => {
  console.log('\nüîç === JURISDICTION VERIFICATION ===');
  console.log('üìã Verifying entity registrations across all jurisdictions...\n');

  const jurisdictions = await getAvailableJurisdictions();

  for (const jurisdiction of jurisdictions) {
    try {
      console.log(`üèõÔ∏è ${jurisdiction.name}:`);
      console.log(`   üì° RPC: ${jurisdiction.address}`);
      console.log(`   üìÑ Contract: ${jurisdiction.entityProviderAddress}`);

      // Connect to this jurisdiction's network
      const { entityProvider } = await connectToEthereum(jurisdiction);

      // Get next entity number (indicates how many are registered)
      const nextNumber = await entityProvider['nextNumber']!();
      const registeredCount = Number(nextNumber) - 1;

      console.log(`   üìä Registered Entities: ${registeredCount}`);

      // Read registered entities
      if (registeredCount > 0) {
        console.log(`   üìù Entity Details:`);
        for (let i = 1; i <= registeredCount; i++) {
          try {
            const entityId = generateNumberedEntityId(i);
            const entityInfo = await entityProvider['entities']!(entityId);
            console.log(`      #${i}: ${entityId.slice(0, 10)}... (Block: ${entityInfo.registrationBlock})`);
          } catch (error) {
            console.log(`      #${i}: Error reading entity data`);
          }
        }
      }

      console.log('');
    } catch (error) {
      logError("RUNTIME_TICK", `   ‚ùå Failed to verify ${jurisdiction.name}:`, error instanceof Error ? error.message : error);
      console.log('');
    }
  }

  console.log('‚úÖ Jurisdiction verification complete!\n');
};

// === HANKO DEMO FUNCTION ===

const demoCompleteHanko = async (): Promise<void> => {
  try {
    // Check if running in browser environment
    const isBrowser = typeof window !== 'undefined';

    if (isBrowser) {
      console.log('üéØ Browser environment detected - running simplified Hanko demo...');
      console.log('‚úÖ Basic signature verification available');
      console.log('üí° Full test suite available in Node.js environment');
      console.log('‚úÖ Hanko browser demo completed!');
      return;
    }

    console.log('üéØ Complete Hanko test suite disabled during strict TypeScript mode');
    // await runCompleteHankoTests();
    console.log('‚úÖ Complete Hanko tests skipped!');
  } catch (error) {
    logError("RUNTIME_TICK", '‚ùå Complete Hanko tests failed:', error);
    throw error;
  }
};

// Create a wrapper for runDemo that provides better browser feedback
const runDemoWrapper = async (env: Env): Promise<Env> => {
  try {
    console.log('üöÄ Starting XLN Consensus Demo...');
    console.log('üìä This will demonstrate entity creation, consensus, and message passing');

    const result = await runDemo(env);

    console.log('‚úÖ XLN Demo completed successfully!');
    console.log('üéØ Check the entity cards above to see the results');
    console.log('üï∞Ô∏è Use the time machine to replay the consensus steps');

    // J-watcher is already started in main(), no need to start again

    return result;
  } catch (error) {
    logError("RUNTIME_TICK", '‚ùå XLN Demo failed:', error);
    throw error;
  }
};

// === ENVIRONMENT UTILITIES ===
export const createEmptyEnv = (): Env => {
  return {
    replicas: new Map(),
    height: 0,
    timestamp: Date.now(),
    runtimeInput: { runtimeTxs: [], entityInputs: [] },
    history: [],
    gossip: createGossipLayer(),
  };
};

// === CONSENSUS PROCESSING UTILITIES ===
// Global cascade lock to prevent tick interleaving
let cascading = false;

export const process = async (env: Env, inputs?: EntityInput[], runtimeDelay = 0) => {
  // Cascade lock: prevent interleaving when delay > tick interval
  if (cascading) {
    console.warn('‚è∏Ô∏è SKIP-CASCADE: Previous cascade still running');
    return env;
  }

  cascading = true;
  let outputs = inputs || [];
  let iterationCount = 0;
  const maxIterations = 10; // Safety limit

  // Helper to sleep (browser-compatible)
  const sleep = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

  // Validate all outputs before processing
  outputs.forEach(o => {
    try {
      validateEntityInput(o);
    } catch (error) {
      logError("RUNTIME_TICK", `üö® CRITICAL FINANCIAL ERROR: Invalid EntityInput detected!`, {
        error: (error as Error).message,
        entityId: o.entityId.slice(0,10),
        signerId: o.signerId,
      });
      throw error;
    }
  });

  // DEBUG: Log transaction details for vote transactions
  outputs.forEach((output, i) => {
    if (output.entityTxs?.some(tx => tx.type === 'vote')) {
      console.log(
        `üó≥Ô∏è VOTE-DEBUG: Input ${i + 1} contains vote transactions:`,
        output.entityTxs.filter(tx => tx.type === 'vote'),
      );
    }
  });

  try {
    while (outputs.length > 0 && iterationCount < maxIterations) {
      iterationCount++;

      const result = await applyRuntimeInput(env, { runtimeTxs: [], entityInputs: outputs });
      outputs = result.entityOutbox;

      if (outputs.length > 0) {
        console.log(`üî• PROCESS-CASCADE: Iteration ${iterationCount}, ${outputs.length} outputs`);
      }

      // Visual delay between cascade iterations (AFTER processing, before next iteration)
      if (outputs.length > 0 && runtimeDelay > 0) {
        console.log(`‚è±Ô∏è CASCADE-DELAY: Waiting ${runtimeDelay}ms before next iteration...`);
        await sleep(runtimeDelay);
      }
    }

    if (iterationCount >= maxIterations) {
      console.warn('‚ö†Ô∏è process() reached maximum iterations');
    }

    // Auto-persist to LevelDB after processing
    await saveEnvToDB(env);

    return env;
  } finally {
    cascading = false;
  }
};

// === LEVELDB PERSISTENCE ===
export const saveEnvToDB = async (env: Env): Promise<void> => {
  if (!isBrowser) return; // Only persist in browser

  try {
    const dbReady = await tryOpenDb();
    if (!dbReady) return;

    // Save latest height pointer
    await db.put(Buffer.from('latest_height'), Buffer.from(String(env.height)));

    // Save environment snapshot
    const snapshot = JSON.stringify(env, (k, v) =>
      typeof v === 'bigint' ? String(v) :
      v instanceof Uint8Array ? Array.from(v) :
      v instanceof Map ? Array.from(v.entries()) : v
    );
    await db.put(Buffer.from(`snapshot:${env.height}`), Buffer.from(snapshot));
  } catch (err) {
    console.error('‚ùå Failed to save to LevelDB:', err);
  }
};

export const loadEnvFromDB = async (): Promise<Env | null> => {
  if (!isBrowser) return null;

  try {
    const dbReady = await tryOpenDb();
    if (!dbReady) return null;

    const latestHeightBuffer = await db.get(Buffer.from('latest_height'));
    const latestHeight = parseInt(latestHeightBuffer.toString());

    // Load all snapshots to build history
    const history: Env[] = [];
    for (let i = 0; i <= latestHeight; i++) {
      const buffer = await db.get(Buffer.from(`snapshot:${i}`));
      const data = JSON.parse(buffer.toString());

      // Hydrate Maps/BigInts
      const env = createEmptyEnv();
      env.height = BigInt(data.height || 0);
      env.timestamp = BigInt(data.timestamp || 0);
      env.replicas = new Map(data.replicas || []);
      if (data.gossip?.profiles) {
        env.gossip.profiles = new Map(data.gossip.profiles);
      }
      history.push(env);
    }

    const latestEnv = history[history.length - 1];
    if (latestEnv) {
      latestEnv.history = history;
    }

    return latestEnv;
  } catch (err) {
    console.log('No persisted state found');
    return null;
  }
};

export const clearDB = async (): Promise<void> => {
  if (!isBrowser) return;

  try {
    const dbReady = await tryOpenDb();
    if (!dbReady) return;

    await db.clear();
    console.log('‚úÖ LevelDB cleared');
  } catch (err) {
    console.error('‚ùå Failed to clear LevelDB:', err);
  }
};

// === PREPOPULATE FUNCTION ===
import { prepopulate } from './prepopulate';
export { prepopulate };

// === SCENARIO SYSTEM ===
export { parseScenario, mergeAndSortEvents } from './scenarios/parser.js';
export { executeScenario } from './scenarios/executor.js';
export { loadScenarioFromFile, loadScenarioFromText } from './scenarios/loader.js';

// === NAME RESOLUTION WRAPPERS (override imports) ===
const searchEntityNames = (query: string, limit?: number) => searchEntityNamesOriginal(db, query, limit);
const resolveEntityName = (entityId: string) => resolveEntityNameOriginal(db, entityId);
const getEntityDisplayInfoFromProfile = (entityId: string) => getEntityDisplayInfoFromProfileOriginal(db, entityId);

// Avatar functions are already imported and exported above


//runtime/entity-consensus.ts (954 lines)
/**
 * XLN Entity Consensus and State Management
 * Core entity processing logic, consensus, proposals, and state transitions
 */

import { applyEntityTx } from './entity-tx';
import { ConsensusConfig, EntityInput, EntityReplica, EntityState, EntityTx, Env } from './types';
import { DEBUG, formatEntityDisplay, formatSignerDisplay, log } from './utils';
import { safeStringify } from './serialization-utils';
import { logError } from './logger';
import { addMessages } from './state-helpers';

// === SECURITY VALIDATION ===

/**
 * Validates entity input to prevent malicious or corrupted data
 */
const validateEntityInput = (input: EntityInput): boolean => {
  try {
    // Basic required fields
    if (!input.entityId || typeof input.entityId !== 'string') {
      log.error(`‚ùå Invalid entityId: ${input.entityId}`);
      return false;
    }
    if (!input.signerId || typeof input.signerId !== 'string') {
      log.error(`‚ùå Invalid signerId: ${input.signerId}`);
      return false;
    }

    // EntityTx validation
    if (input.entityTxs) {
      if (!Array.isArray(input.entityTxs)) {
        log.error(`‚ùå EntityTxs must be array, got: ${typeof input.entityTxs}`);
        return false;
      }
      if (input.entityTxs.length > 1000) {
        log.error(`‚ùå Too many transactions: ${input.entityTxs.length} > 1000`);
        return false;
      }
      for (const tx of input.entityTxs) {
        if (!tx.type || !tx.data) {
          log.error(`‚ùå Invalid transaction: ${safeStringify(tx)}`);
          return false;
        }
        if (
          typeof tx.type !== 'string' ||
          !['chat', 'propose', 'vote', 'profile-update', 'j_event', 'accountInput', 'openAccount', 'directPayment'].includes(tx.type)
        ) {
          log.error(`‚ùå Invalid transaction type: ${tx.type}`);
          return false;
        }
      }
    }

    // Precommits validation
    if (input.precommits) {
      if (!(input.precommits instanceof Map)) {
        log.error(`‚ùå Precommits must be Map, got: ${typeof input.precommits}`);
        return false;
      }
      if (input.precommits.size > 100) {
        log.error(`‚ùå Too many precommits: ${input.precommits.size} > 100`);
        return false;
      }
      for (const [signerId, signature] of input.precommits) {
        if (typeof signerId !== 'string' || typeof signature !== 'string') {
          log.error(`‚ùå Invalid precommit format: ${signerId} -> ${signature}`);
          return false;
        }
      }
    }

    // ProposedFrame validation
    if (input.proposedFrame) {
      const frame = input.proposedFrame;
      if (typeof frame.height !== 'number' || frame.height < 0) {
        log.error(`‚ùå Invalid frame height: ${frame.height}`);
        return false;
      }
      if (!Array.isArray(frame.txs)) {
        log.error(`‚ùå Frame txs must be array`);
        return false;
      }
      if (!frame.hash || typeof frame.hash !== 'string') {
        log.error(`‚ùå Invalid frame hash: ${frame.hash}`);
        return false;
      }
    }

    return true;
  } catch (error) {
    log.error(`‚ùå Input validation error: ${error}`);
    return false;
  }
};

/**
 * Validates entity replica to prevent corrupted state
 */
const validateEntityReplica = (replica: EntityReplica): boolean => {
  try {
    if (!replica.entityId || !replica.signerId) {
      log.error(`‚ùå Invalid replica IDs: ${replica.entityId}:${replica.signerId}`);
      return false;
    }
    if (replica.state.height < 0) {
      log.error(`‚ùå Invalid state height: ${replica.state.height}`);
      return false;
    }
    if (replica.mempool.length > 10000) {
      log.error(`‚ùå Mempool overflow: ${replica.mempool.length} > 10000`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`‚ùå Replica validation error: ${error}`);
    return false;
  }
};

/**
 * Detects Byzantine faults like double-signing
 */
const detectByzantineFault = (signatures: Map<string, string>, signerId: string, newSignature: string): boolean => {
  try {
    const existingSig = signatures.get(signerId);
    if (existingSig && existingSig !== newSignature) {
      log.error(`‚ùå BYZANTINE FAULT: Double-sign detected from ${signerId}`);
      log.error(`‚ùå Existing: ${existingSig}`);
      log.error(`‚ùå New: ${newSignature}`);
      return true;
    }
    return false;
  } catch (error) {
    log.error(`‚ùå Byzantine detection error: ${error}`);
    return false;
  }
};

/**
 * Validates timestamp to prevent temporal attacks
 */
const validateTimestamp = (proposedTime: number, currentTime: number): boolean => {
  try {
    const maxDrift = 30000; // 30 seconds
    const drift = Math.abs(proposedTime - currentTime);
    if (drift > maxDrift) {
      log.error(`‚ùå Timestamp drift too large: ${drift}ms > ${maxDrift}ms`);
      log.error(`‚ùå Proposed: ${new Date(proposedTime).toISOString()}`);
      log.error(`‚ùå Current: ${new Date(currentTime).toISOString()}`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`‚ùå Timestamp validation error: ${error}`);
    return false;
  }
};

/**
 * Validates voting power to prevent overflow attacks
 */
const validateVotingPower = (power: bigint): boolean => {
  try {
    if (power < 0n) {
      log.error(`‚ùå Negative voting power: ${power}`);
      return false;
    }
    // Check for overflow (2^53 - 1 in bigint)
    if (power > BigInt(Number.MAX_SAFE_INTEGER)) {
      log.error(`‚ùå Voting power overflow: ${power} > ${Number.MAX_SAFE_INTEGER}`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`‚ùå Voting power validation error: ${error}`);
    return false;
  }
};

// === CORE ENTITY PROCESSING ===

/**
 * Main entity input processor - handles consensus, proposals, and state transitions
 */
export const applyEntityInput = async (
  env: Env,
  entityReplica: EntityReplica,
  entityInput: EntityInput,
): Promise<{ newState: EntityState, outputs: EntityInput[] }> => {
  // Debug: Log every input being processed with timestamp and unique identifier
  const entityDisplay = formatEntityDisplay(entityInput.entityId);
  const timestamp = Date.now();
  const currentProposalHash = entityReplica.proposal?.hash?.slice(0, 10) || 'none';
  const frameHash = entityInput.proposedFrame?.hash?.slice(0, 10) || 'none';

  console.log(
    `üîç INPUT-RECEIVED: [${timestamp}] Processing input for Entity #${entityDisplay}:${formatSignerDisplay(entityInput.signerId)}`,
  );
  console.log(
    `üîç INPUT-STATE: Current proposal: ${currentProposalHash}, Mempool: ${entityReplica.mempool.length}, isProposer: ${entityReplica.isProposer}`,
  );
  console.log(
    `üîç INPUT-DETAILS: txs=${entityInput.entityTxs?.length || 0}, precommits=${entityInput.precommits?.size || 0}, frame=${frameHash}`,
  );
  if (entityInput.precommits?.size) {
    const precommitSigners = Array.from(entityInput.precommits.keys());
    console.log(`üîç INPUT-PRECOMMITS: Received precommits from: ${precommitSigners.join(', ')}`);
    // Track exactly which proposal these precommits are for
    const firstPrecommit = entityInput.precommits.values().next().value;
    const proposalHashFromSig = firstPrecommit ? firstPrecommit.split('_')[2]?.slice(0, 10) : 'unknown';
    console.log(`üîç PRECOMMIT-PROPOSAL: These precommits are for proposal: ${proposalHashFromSig}`);
  }

  // SECURITY: Validate all inputs
  if (!validateEntityInput(entityInput)) {
    log.error(`‚ùå Invalid input for ${entityInput.entityId}:${entityInput.signerId}`);
    return { newState: entityReplica.state, outputs: [] };
  }
  if (!validateEntityReplica(entityReplica)) {
    log.error(`‚ùå Invalid replica state for ${entityReplica.entityId}:${entityReplica.signerId}`);
    return { newState: entityReplica.state, outputs: [] };
  }

  const entityOutbox: EntityInput[] = [];

  // ‚è∞ Execute crontab tasks (periodic checks like account timeouts)
  const { executeCrontab, initCrontab } = await import('./entity-crontab');

  // Initialize crontab on first use
  if (!entityReplica.state.crontabState) {
    entityReplica.state.crontabState = initCrontab();
  }

  const crontabOutputs = await executeCrontab(entityReplica, entityReplica.state.crontabState);
  if (crontabOutputs.length > 0) {
    console.log(`‚è∞ CRONTAB: Generated ${crontabOutputs.length} outputs from periodic tasks`);
    entityOutbox.push(...crontabOutputs);
  }

  // Add transactions to mempool (mutable for performance)
  if (entityInput.entityTxs?.length) {
    // DEBUG: Track vote transactions specifically
    const voteTransactions = entityInput.entityTxs.filter(tx => tx.type === 'vote');
    if (voteTransactions.length > 0) {
      console.log(`üó≥Ô∏è VOTE-MEMPOOL: ${entityReplica.signerId} receiving ${voteTransactions.length} vote transactions`);
      voteTransactions.forEach(tx => {
        console.log(`üó≥Ô∏è VOTE-TX:`, tx);
      });
    }

    if (entityReplica.signerId === 'alice') {
      console.log(`üî• ALICE-RECEIVES: Alice receiving ${entityInput.entityTxs.length} txs from input`);
      console.log(
        `üî• ALICE-RECEIVES: Transaction types:`,
        entityInput.entityTxs.map(tx => tx.type),
      );
      console.log(
        `üî• ALICE-RECEIVES: Alice isProposer=${entityReplica.isProposer}, current mempool=${entityReplica.mempool.length}`,
      );
    }
    // Log details of each EntityTx
    for (const tx of entityInput.entityTxs) {
      console.log(`üèõÔ∏è E-MACHINE: - EntityTx type="${tx.type}", data=`, safeStringify(tx.data, 2));
    }
    entityReplica.mempool.push(...entityInput.entityTxs);
    if (DEBUG)
      console.log(
        `    ‚Üí Added ${entityInput.entityTxs.length} txs to mempool (total: ${entityReplica.mempool.length})`,
      );
    if (DEBUG && entityInput.entityTxs.length > 3) {
      console.log(`    ‚ö†Ô∏è  CORNER CASE: Large batch of ${entityInput.entityTxs.length} transactions`);
    }
  } else if (entityInput.entityTxs && entityInput.entityTxs.length === 0) {
    // DEBUG removed: ‚ö†Ô∏è  CORNER CASE: Empty transaction array received - no mempool changes`);
  }

  // CRITICAL: Forward transactions to proposer BEFORE processing commits
  // This prevents race condition where commits clear mempool before forwarding
  if (!entityReplica.isProposer && entityReplica.mempool.length > 0) {
    // Send mempool to proposer
    const proposerId = entityReplica.state.config.validators[0];
    if (!proposerId) {
      logError("FRAME_CONSENSUS", `‚ùå No proposer found in validators: ${entityReplica.state.config.validators}`);
      return { newState: entityReplica.state, outputs: entityOutbox };
    }

    const txCount = entityReplica.mempool.length;
    console.log(`üî• BOB-TO-ALICE: Bob sending ${txCount} txs to proposer ${proposerId}`);
    console.log(
      `üî• BOB-TO-ALICE: Transaction types:`,
      entityReplica.mempool.map(tx => tx.type),
    );
    entityOutbox.push({
      entityId: entityInput.entityId,
      signerId: proposerId,
      entityTxs: [...entityReplica.mempool],
    });

    // CHANNEL.TS PATTERN: Track sent txs, DON'T clear mempool yet
    // Only clear after receiving commit confirmation (like Channel.ts line 217)
    entityReplica.sentTransitions = txCount;
    console.log(`üìä Tracked ${txCount} sent transitions (will clear on commit)`);
  }

  // Handle commit notifications AFTER forwarding (when receiving finalized frame from proposer)
  if (entityInput.precommits?.size && entityInput.proposedFrame && !entityReplica.proposal) {
    const signers = Array.from(entityInput.precommits.keys());
    const totalPower = calculateQuorumPower(entityReplica.state.config, signers);

    if (totalPower >= entityReplica.state.config.threshold) {
      // This is a commit notification from proposer, apply the frame

      // SECURITY: Validate commit matches our locked frame (if we have one)
      if (entityReplica.lockedFrame) {
        if (entityReplica.lockedFrame.hash !== entityInput.proposedFrame.hash) {
          logError("FRAME_CONSENSUS", `‚ùå BYZANTINE: Commit frame doesn't match locked frame!`);
          logError("FRAME_CONSENSUS", `   Locked: ${entityReplica.lockedFrame.hash}`);
          logError("FRAME_CONSENSUS", `   Commit: ${entityInput.proposedFrame.hash}`);
          return { newState: entityReplica.state, outputs: entityOutbox };
        }
        console.log(`‚úÖ Commit validation: matches locked frame ${entityReplica.lockedFrame.hash.slice(0,10)}`);
      }

      // SECURITY: Verify signatures are for the correct frame hash
      for (const [signerId, signature] of entityInput.precommits) {
        const expectedSig = `sig_${signerId}_${entityInput.proposedFrame.hash}`;
        if (signature !== expectedSig) {
          logError("FRAME_CONSENSUS", `‚ùå BYZANTINE: Invalid signature format from ${signerId}`);
          logError("FRAME_CONSENSUS", `   Expected: ${expectedSig.slice(0,30)}...`);
          logError("FRAME_CONSENSUS", `   Received: ${signature.slice(0,30)}...`);
          return { newState: entityReplica.state, outputs: entityOutbox };
        }
      }
      console.log(`‚úÖ All ${entityInput.precommits.size} signatures validated for frame ${entityInput.proposedFrame.hash.slice(0,10)}`);

      // Apply the committed frame with incremented height
      entityReplica.state = {
        ...entityInput.proposedFrame.newState,
        height: entityReplica.state.height + 1,
      };

      // CHANNEL.TS PATTERN: Only clear sent transactions that were committed
      // Like Channel.ts line 217: mempool.splice(0, this.data.sentTransitions)
      if (entityReplica.sentTransitions && entityReplica.sentTransitions > 0) {
        console.log(`üìä Clearing ${entityReplica.sentTransitions} committed txs from mempool (${entityReplica.mempool.length} total)`);
        entityReplica.mempool.splice(0, entityReplica.sentTransitions);
        entityReplica.sentTransitions = 0;
        console.log(`üìä Mempool after commit: ${entityReplica.mempool.length} txs remaining`);
      } else {
        // Fallback: clear entire mempool (old behavior)
        entityReplica.mempool.length = 0;
      }

      delete entityReplica.lockedFrame; // Release lock after commit
      if (DEBUG)
        console.log(
          `    ‚Üí Applied commit, new state: ${entityReplica.state.messages.length} messages, height: ${entityReplica.state.height}`,
        );

      // Return early - commit notifications don't trigger further processing
      return { newState: entityReplica.state, outputs: entityOutbox };
    }
  }

  // Handle proposed frame (PROPOSE phase) - only if not a commit notification
  if (
    entityInput.proposedFrame &&
    (!entityReplica.proposal || (entityReplica.state.config.mode === 'gossip-based' && entityReplica.isProposer))
  ) {
    const frameSignature = `sig_${entityReplica.signerId}_${entityInput.proposedFrame.hash}`;
    const config = entityReplica.state.config;

    // Lock to this frame (CometBFT style)
    entityReplica.lockedFrame = entityInput.proposedFrame;
    // DEBUG removed: ‚Üí Validator locked to frame ${entityInput.proposedFrame.hash.slice(0, 10)}...`);

    if (config.mode === 'gossip-based') {
      // Send precommit to all validators
      config.validators.forEach(validatorId => {
        console.log(
          `üîç GOSSIP: [${timestamp}] ${entityReplica.signerId} sending precommit to ${validatorId} for entity ${entityInput.entityId.slice(0, 10)}, proposal ${frameHash}, sig: ${frameSignature.slice(0, 20)}...`,
        );
        entityOutbox.push({
          entityId: entityInput.entityId,
          signerId: validatorId,
          precommits: new Map([[entityReplica.signerId, frameSignature]]),
        });
      });
      // DEBUG removed: ‚Üí Signed proposal, gossiping precommit to ${config.validators.length} validators`);
    } else {
      // Send precommit to proposer only
      const proposerId = config.validators[0];
      if (!proposerId) {
        logError("FRAME_CONSENSUS", `‚ùå No proposer found in validators: ${config.validators}`);
        return { newState: entityReplica.state, outputs: entityOutbox };
      }
      console.log(
        `üîç PROPOSER: [${timestamp}] ${entityReplica.signerId} sending precommit to ${proposerId} for entity ${entityInput.entityId.slice(0, 10)}, proposal ${frameHash}, sig: ${frameSignature.slice(0, 20)}...`,
      );
      console.log(
        `üîç PROPOSER-REASON: Signed new proposal, current state: proposal=${currentProposalHash}, locked=${entityReplica.lockedFrame?.hash?.slice(0, 10) || 'none'}`,
      );
      entityOutbox.push({
        entityId: entityInput.entityId,
        signerId: proposerId,
        precommits: new Map([[entityReplica.signerId, frameSignature]]),
      });
      // DEBUG removed: ‚Üí Signed proposal, sending precommit to ${proposerId}`);
    }
  }

  // Handle precommits (SIGN phase)
  if (entityInput.precommits?.size && entityReplica.proposal) {
    // SECURITY: Check for Byzantine faults before collecting signatures
    for (const [signerId, signature] of entityInput.precommits) {
      if (detectByzantineFault(entityReplica.proposal.signatures, signerId, signature)) {
        log.error(`‚ùå Rejecting Byzantine input from ${signerId}`);
        return { newState: entityReplica.state, outputs: entityOutbox }; // Return early, don't process malicious input
      }
      entityReplica.proposal.signatures.set(signerId, signature);
    }
    if (DEBUG)
      console.log(
        `    ‚Üí Collected ${entityInput.precommits.size} signatures (total: ${entityReplica.proposal.signatures.size})`,
      );

    // Check threshold using shares
    const signers = Array.from(entityReplica.proposal.signatures.keys());
    const totalPower = calculateQuorumPower(entityReplica.state.config, signers);

    // SECURITY: Validate voting power
    if (!validateVotingPower(totalPower)) {
      log.error(`‚ùå Invalid voting power calculation: ${totalPower}`);
      return { newState: entityReplica.state, outputs: entityOutbox };
    }

    if (DEBUG) {
      const totalShares = Object.values(entityReplica.state.config.shares).reduce((sum, val) => sum + val, BigInt(0));
      const percentage = ((Number(totalPower) / Number(entityReplica.state.config.threshold)) * 100).toFixed(1);
      log.info(
        `    üîç Threshold check: ${totalPower} / ${totalShares} [${percentage}% threshold${Number(totalPower) >= Number(entityReplica.state.config.threshold) ? '+' : ''}]`,
      );
      if (entityReplica.state.config.mode === 'gossip-based') {
        console.log(`    ‚ö†Ô∏è  CORNER CASE: Gossip mode - all validators receive precommits`);
      }
    }

    if (totalPower >= entityReplica.state.config.threshold) {
      // Commit phase - use pre-computed state with incremented height
      entityReplica.state = {
        ...entityReplica.proposal.newState,
        height: entityReplica.state.height + 1,
      };
      // DEBUG removed: ‚Üí Threshold reached! Committing frame, height: ${entityReplica.state.height}`);

      // Save proposal data before clearing
      const sortedSignatures = sortSignatures(entityReplica.proposal.signatures, entityReplica.state.config);
      const committedFrame = entityReplica.proposal;

      // Clear state (mutable)
      entityReplica.mempool.length = 0;
      delete entityReplica.proposal;
      delete entityReplica.lockedFrame; // Release lock after commit

      // Only send commit notifications in proposer-based mode
      // In gossip mode, everyone already has all precommits via gossip
      if (entityReplica.state.config.mode === 'proposer-based') {
        const committedProposalHash = committedFrame.hash.slice(0, 10);
        console.log(
          `üîç COMMIT-START: [${timestamp}] ${entityReplica.signerId} reached threshold for proposal ${committedProposalHash}, sending commit notifications...`,
        );

        // Notify all validators (except self - proposer already has all precommits)
        entityReplica.state.config.validators.forEach(validatorId => {
          if (validatorId !== entityReplica.signerId) {
            const precommitSigners = Array.from(sortedSignatures.keys());
            console.log(
              `üîç COMMIT: [${timestamp}] ${entityReplica.signerId} sending commit notification to ${validatorId} for entity ${entityInput.entityId.slice(0, 10)}, proposal ${committedProposalHash} (${sortedSignatures.size} precommits from: ${precommitSigners.join(', ')})`,
            );
            entityOutbox.push({
              entityId: entityInput.entityId,
              signerId: validatorId,
              precommits: sortedSignatures,
              proposedFrame: committedFrame,
            });
          }
        });
        // const notifiedCount = entityReplica.state.config.validators.length - 1; // excluding self
        // DEBUG removed: ‚Üí Sending commit notifications to ${notifiedCount} validators (excluding self)`);
      } else {
        console.log(
          `üîç GOSSIP-COMMIT: [${timestamp}] ${entityReplica.signerId} NOT sending commit notifications (gossip mode) for entity ${entityInput.entityId.slice(0, 10)}...`,
        );
        if (DEBUG)
          console.log(`    ‚Üí Gossip mode: No commit notifications needed (everyone has precommits via gossip)`);
      }
    }
  }

  // Commit notifications are now handled at the top of the function

  // Debug consensus trigger conditions
  console.log(`üéØ CONSENSUS-CHECK: Entity ${entityReplica.entityId}:${entityReplica.signerId}`);
  console.log(`üéØ   isProposer: ${entityReplica.isProposer}`);
  console.log(`üéØ   mempool.length: ${entityReplica.mempool.length}`);
  console.log(`üéØ   hasProposal: ${!!entityReplica.proposal}`);
  if (entityReplica.mempool.length > 0) {
    console.log(
      `üéØ   mempoolTypes:`,
      entityReplica.mempool.map(tx => tx.type),
    );
  }

  // Auto-propose logic: ONLY proposer can propose (BFT requirement)
  if (entityReplica.isProposer && entityReplica.mempool.length > 0 && !entityReplica.proposal) {
    console.log(`üî• ALICE-PROPOSES: Alice auto-propose triggered!`);
    console.log(
      `üî• ALICE-PROPOSES: mempool=${entityReplica.mempool.length}, isProposer=${entityReplica.isProposer}, hasProposal=${!!entityReplica.proposal}`,
    );
    console.log(
      `üî• ALICE-PROPOSES: Mempool transaction types:`,
      entityReplica.mempool.map(tx => tx.type),
    );

    // Check if this is a single signer entity (threshold = 1, only 1 validator)
    const isSingleSigner =
      entityReplica.state.config.validators.length === 1 && entityReplica.state.config.threshold === BigInt(1);

    if (isSingleSigner) {
      console.log(`üöÄ SINGLE-SIGNER: Direct execution without consensus for single signer entity`);
      // For single signer entities, directly apply transactions without consensus
      const { newState: newEntityState, outputs: frameOutputs } = await applyEntityFrame(env, entityReplica.state, entityReplica.mempool);
      entityReplica.state = {
        ...newEntityState,
        height: entityReplica.state.height + 1,
      };

      // Add any outputs generated by entity transactions to the outbox
      entityOutbox.push(...frameOutputs);
      // SINGLE-SIGNER-OUTPUTS removed - too noisy

      // Clear mempool after direct application
      entityReplica.mempool.length = 0;

      if (DEBUG)
        console.log(
          `    ‚ö° Single signer entity: transactions applied directly, height: ${entityReplica.state.height}`,
        );
      // SINGLE-SIGNER-RETURN removed - too noisy
      return { newState: entityReplica.state, outputs: entityOutbox }; // Skip the full consensus process
    }

    if (DEBUG)
      console.log(
        `    üöÄ Auto-propose triggered: mempool=${entityReplica.mempool.length}, isProposer=${entityReplica.isProposer}, hasProposal=${!!entityReplica.proposal}`,
      );
    // Compute new state once during proposal
    const { newState: newEntityState, outputs: proposalOutputs } = await applyEntityFrame(env, entityReplica.state, entityReplica.mempool);

    // Add any outputs generated during proposal to the outbox
    entityOutbox.push(...proposalOutputs);

    // Proposer creates new timestamp for this frame (DETERMINISTIC: use runtime timestamp)
    const newTimestamp = env.timestamp;

    // SECURITY: Validate timestamp
    if (!validateTimestamp(newTimestamp, env.timestamp)) {
      log.error(`‚ùå Invalid proposal timestamp: ${newTimestamp}`);
      return { newState: entityReplica.state, outputs: entityOutbox };
    }

    const frameHash = `frame_${entityReplica.state.height + 1}_${newTimestamp}`;
    const selfSignature = `sig_${entityReplica.signerId}_${frameHash}`;

    entityReplica.proposal = {
      height: entityReplica.state.height + 1,
      txs: [...entityReplica.mempool],
      hash: frameHash,
      newState: {
        ...newEntityState,
        height: entityReplica.state.height + 1,
        timestamp: newTimestamp, // Set new deterministic timestamp in proposed state
      },
      signatures: new Map<string, string>([[entityReplica.signerId, selfSignature]]), // Proposer signs immediately
    };

    if (DEBUG)
      console.log(
        `    ‚Üí Auto-proposing frame ${entityReplica.proposal.hash} with ${entityReplica.proposal.txs.length} txs and self-signature.`,
      );

    // Send proposal to all validators (except self)
    entityReplica.state.config.validators.forEach(validatorId => {
      if (validatorId !== entityReplica.signerId) {
        entityOutbox.push({
          entityId: entityInput.entityId,
          signerId: validatorId,
          proposedFrame: entityReplica.proposal!,
          // Note: Don't send entityTxs separately - they're already in proposedFrame.txs
        });
      }
    });
  } else if (entityReplica.isProposer && entityReplica.mempool.length === 0 && !entityReplica.proposal) {
    // DEBUG removed: ‚ö†Ô∏è  CORNER CASE: Proposer with empty mempool - no auto-propose`);
  } else if (!entityReplica.isProposer && entityReplica.mempool.length > 0) {
    // DEBUG removed: ‚Üí Non-proposer sending ${entityReplica.mempool.length} txs to proposer`);
    // Send mempool to proposer
    const proposerId = entityReplica.state.config.validators[0];
    if (!proposerId) {
      logError("FRAME_CONSENSUS", `‚ùå No proposer found in validators: ${entityReplica.state.config.validators}`);
      return { newState: entityReplica.state, outputs: entityOutbox };
    }
    console.log(`üî• BOB-TO-ALICE: Bob sending ${entityReplica.mempool.length} txs to proposer ${proposerId}`);
    console.log(
      `üî• BOB-TO-ALICE: Transaction types:`,
      entityReplica.mempool.map(tx => tx.type),
    );
    entityOutbox.push({
      entityId: entityInput.entityId,
      signerId: proposerId,
      entityTxs: [...entityReplica.mempool],
    });
    // Clear mempool after sending
    entityReplica.mempool.length = 0;
  } else if (entityReplica.isProposer && entityReplica.proposal) {
    // DEBUG removed: ‚ö†Ô∏è  CORNER CASE: Proposer already has pending proposal - no new auto-propose`);
  }

  // Debug: Log outputs being generated with detailed analysis
  console.log(
    `üîç OUTPUT-GENERATED: [${timestamp}] Entity #${entityDisplay}:${formatSignerDisplay(entityReplica.signerId)} generating ${entityOutbox.length} outputs`,
  );
  console.log(
    `üîç OUTPUT-FINAL-STATE: proposal=${entityReplica.proposal?.hash?.slice(0, 10) || 'none'}, mempool=${entityReplica.mempool.length}, locked=${entityReplica.lockedFrame?.hash?.slice(0, 10) || 'none'}`,
  );

  entityOutbox.forEach((output, index) => {
    const targetDisplay = formatEntityDisplay(output.entityId);
    const outputFrameHash = output.proposedFrame?.hash?.slice(0, 10) || 'none';
    console.log(
      `üîç OUTPUT-${index + 1}: [${timestamp}] To Entity #${targetDisplay}:${formatSignerDisplay(output.signerId)} - txs=${output.entityTxs?.length || 0}, precommits=${output.precommits?.size || 0}, frame=${outputFrameHash}`,
    );

    if (output.precommits?.size) {
      const precommitSigners = Array.from(output.precommits.keys());
      console.log(`üîç OUTPUT-${index + 1}-PRECOMMITS: Sending precommits from: ${precommitSigners.join(', ')}`);

      // Show the actual signature content to track duplicates
      output.precommits.forEach((sig, signer) => {
        const sigShort = sig.slice(0, 20);
        const proposalFromSig = sig.split('_')[2]?.slice(0, 10) || 'unknown';
        console.log(`üîç OUTPUT-${index + 1}-SIG-DETAIL: ${signer} -> ${sigShort}... (proposal: ${proposalFromSig})`);
      });
    }

    // Classify output type for clarity
    if (output.proposedFrame && output.precommits?.size) {
      console.log(`üîç OUTPUT-${index + 1}-TYPE: COMMIT_NOTIFICATION (frame + precommits)`);
    } else if (output.precommits?.size) {
      console.log(`üîç OUTPUT-${index + 1}-TYPE: PRECOMMIT_VOTE (precommits only)`);
    } else if (output.proposedFrame) {
      console.log(`üîç OUTPUT-${index + 1}-TYPE: PROPOSAL (frame only)`);
    } else if (output.entityTxs?.length) {
      console.log(`üîç OUTPUT-${index + 1}-TYPE: TRANSACTION_FORWARD (txs only)`);
    } else {
      console.log(`üîç OUTPUT-${index + 1}-TYPE: UNKNOWN (empty output)`);
    }
  });

  return { newState: entityReplica.state, outputs: entityOutbox };
};

export const applyEntityFrame = async (
  env: Env,
  entityState: EntityState,
  entityTxs: EntityTx[],
): Promise<{ newState: EntityState, outputs: EntityInput[] }> => {
  console.log(`üéØ APPLY-ENTITY-FRAME: Processing ${entityTxs.length} transactions`);
  entityTxs.forEach((tx, index) => {
    console.log(`üéØ Transaction ${index}: type="${tx.type}", data=`, tx.data);
  });

  let currentEntityState = entityState;
  const allOutputs: EntityInput[] = [];

  // Track accounts that need frame proposals during this processing round
  const proposableAccounts = new Set<string>();

  for (const entityTx of entityTxs) {
    const { newState, outputs } = await applyEntityTx(env, currentEntityState, entityTx);
    currentEntityState = newState;
    allOutputs.push(...outputs);

    // Track which accounts need proposals based on transaction type
    if (entityTx.type === 'accountInput' && entityTx.data) {
      const fromEntity = entityTx.data.fromEntityId;
      const accountMachine = currentEntityState.accounts.get(fromEntity);

      if (accountMachine) {
        // Add to proposable if:
        // 1. Received a NEW frame that needs ACK (newAccountFrame)
        // 2. Received an ACK (frameId with prevSignatures) AND we have mempool items
        // 3. Received account transactions that need processing
        const isNewFrame = entityTx.data.newAccountFrame;
        const isAck = entityTx.data.height && entityTx.data.prevSignatures;
        const hasPendingTxs = accountMachine.mempool.length > 0;

        // Only propose if we have something to send:
        // - Need to ACK a new frame
        // - Have transactions in mempool
        if (isNewFrame || (hasPendingTxs && !accountMachine.pendingFrame)) {
          proposableAccounts.add(fromEntity);
          console.log(`üîÑ Added ${fromEntity.slice(0,10)} to proposable - NewFrame:${isNewFrame}, Pending:${hasPendingTxs}`);
        } else if (isAck) {
          console.log(`‚úÖ Received ACK from ${fromEntity.slice(0,10)}, no action needed (mempool empty)`);
        }
      }
    } else if (entityTx.type === 'directPayment' && entityTx.data) {
      console.log(`üîç DIRECT-PAYMENT detected in applyEntityFrame`);
      console.log(`üîç Payment data:`, {
        targetEntityId: entityTx.data.targetEntityId,
        route: entityTx.data.route,
        amount: entityTx.data.amount
      });
      console.log(`üîç Current entity has ${currentEntityState.accounts.size} accounts`);

      // Payment was added to mempool in applyEntityTx
      // We need to find which account got the payment and mark it for frame proposal

      // Check all accounts to see which one has new mempool items
      for (const [counterpartyId, accountMachine] of currentEntityState.accounts) {
        const isLeft = accountMachine.proofHeader.fromEntity < accountMachine.proofHeader.toEntity;
        console.log(`üîç Checking account ${counterpartyId.slice(0,10)}: mempool=${accountMachine.mempool.length}, isLeft=${isLeft}, pendingFrame=${!!accountMachine.pendingFrame}`);
        if (accountMachine.mempool.length > 0) {
          proposableAccounts.add(counterpartyId);
          console.log(`üîÑ ‚úÖ Added ${counterpartyId.slice(0,10)} to proposableAccounts (has ${accountMachine.mempool.length} mempool items)`);
        }
      }
    } else if (entityTx.type === 'openAccount' && entityTx.data) {
      // Account opened - may need initial frame
      const targetEntity = entityTx.data.targetEntityId;
      const accountMachine = currentEntityState.accounts.get(targetEntity);
      if (accountMachine) {
        const isLeft = accountMachine.proofHeader.fromEntity < accountMachine.proofHeader.toEntity;
        if (isLeft) {
          proposableAccounts.add(targetEntity);
          console.log(`üîÑ Added ${targetEntity.slice(0,10)} to proposable (new account opened)`);
        }
      }
    }
  }

  // AUTO-PROPOSE: Process all proposable accounts plus any with pending transactions
  console.log(`üöÄ AUTO-PROPOSE: Starting bilateral consensus check`);
  console.log(`üöÄ Proposable accounts so far: ${Array.from(proposableAccounts).join(', ') || 'none'}`);

  const { getAccountsToProposeFrames, proposeAccountFrame } = await import('./account-consensus');

  // Add accounts with mempool items that weren't already added
  const additionalAccounts = getAccountsToProposeFrames(currentEntityState);
  console.log(`üöÄ Additional accounts from getAccountsToProposeFrames: ${additionalAccounts.join(', ') || 'none'}`);
  additionalAccounts.forEach(accountId => proposableAccounts.add(accountId));

  // CRITICAL: Deterministic ordering - sort by counterpartyEntityId (lexicographic)
  const accountsToProposeFrames = Array.from(proposableAccounts).sort();

  if (accountsToProposeFrames.length > 0) {
    console.log(`üîÑ AUTO-PROPOSE: ${accountsToProposeFrames.length} accounts need frame proposals`);
    console.log(`üîÑ AUTO-PROPOSE: Accounts to propose: ${accountsToProposeFrames.map(id => id.slice(0,10)).join(', ')}`);

    for (const counterpartyEntityId of accountsToProposeFrames) {
      console.log(`üîÑ AUTO-PROPOSE: Processing account ${counterpartyEntityId.slice(0,10)}...`);

      const accountMachine = currentEntityState.accounts.get(counterpartyEntityId);
      if (accountMachine) {
        console.log(`üîÑ AUTO-PROPOSE: Account details - mempool=${accountMachine.mempool.length}, pendingFrame=${!!accountMachine.pendingFrame}`);
        const proposal = await proposeAccountFrame(env, accountMachine);
        console.log(`üîÑ AUTO-PROPOSE: Proposal result - success=${proposal.success}, hasInput=${!!proposal.accountInput}, error=${proposal.error || 'none'}`);

        if (proposal.success && proposal.accountInput) {
          // Get the proposer of the target entity from env
          let targetProposerId = 'alice'; // Default fallback
          const targetReplicaKeys = Array.from(env.replicas.keys()).filter(key => key.startsWith(proposal.accountInput!.toEntityId + ':'));
          if (targetReplicaKeys.length > 0) {
            const firstTargetReplica = env.replicas.get(targetReplicaKeys[0]!);
            const firstValidator = firstTargetReplica?.state.config.validators[0];
            if (firstValidator) {
              targetProposerId = firstValidator;
            }
          }

          // Convert AccountInput to EntityInput for routing
          const outputEntityInput: EntityInput = {
            entityId: proposal.accountInput.toEntityId,
            signerId: targetProposerId, // Route to target entity's proposer
            entityTxs: [{
              type: 'accountInput' as const,
              data: proposal.accountInput
            }]
          };
          allOutputs.push(outputEntityInput);

          // Add events to entity messages with size limiting
          addMessages(currentEntityState, proposal.events);
        }
      }
    }
  }

  return { newState: currentEntityState, outputs: allOutputs };
};

// === HELPER FUNCTIONS ===

/**
 * Calculate quorum power based on validator shares
 */
export const calculateQuorumPower = (config: ConsensusConfig, signers: string[]): bigint => {
  return signers.reduce((total, signerId) => {
    const shares = config.shares[signerId];
    if (shares === undefined) {
      throw new Error(`CONSENSUS-SAFETY: Unknown validator ${signerId} - cannot calculate quorum power`);
    }
    return total + shares;
  }, 0n);
};

export const sortSignatures = (signatures: Map<string, string>, config: ConsensusConfig): Map<string, string> => {
  const sortedEntries = Array.from(signatures.entries()).sort(([a], [b]) => {
    const indexA = config.validators.indexOf(a);
    const indexB = config.validators.indexOf(b);
    return indexA - indexB;
  });
  return new Map(sortedEntries);
};

// === ENTITY UTILITIES (existing) ===

/**
 * Merges duplicate entity inputs to reduce processing overhead
 */
export const mergeEntityInputs = (inputs: EntityInput[]): EntityInput[] => {
  const merged = new Map<string, EntityInput>();
  let duplicateCount = 0;

  // Look for potential Carol duplicates specifically
  const carolInputs = inputs.filter(input => input.signerId.includes('carol'));
  if (carolInputs.length > 1) {
    console.log(`üîç MERGE-CAROL-ALERT: Found ${carolInputs.length} inputs from Carol - potential duplicate source!`);
    carolInputs.forEach((input, i) => {
      const entityShort = input.entityId.slice(0, 10);
      const precommitSigners = input.precommits ? Array.from(input.precommits.keys()).join(',') : 'none';
      console.log(`üîç MERGE-CAROL-${i + 1}: ${entityShort}:${input.signerId} - precommits: ${precommitSigners}`);
    });
  }

  for (const input of inputs) {
    const key = `${input.entityId}:${input.signerId}`;
    const entityShort = input.entityId.slice(0, 10);

    if (merged.has(key)) {
      const existing = merged.get(key)!;
      duplicateCount++;

      console.log(`üîç DUPLICATE-FOUND: Merging duplicate input ${duplicateCount} for ${entityShort}:${input.signerId}`);

      // Merge entity transactions
      if (input.entityTxs) {
        existing.entityTxs = [...(existing.entityTxs || []), ...input.entityTxs];
        console.log(`üîç MERGE-TXS: Added ${input.entityTxs.length} transactions`);
      }

      // Merge precommits
      if (input.precommits) {
        const existingPrecommits = existing.precommits || new Map();
        console.log(
          `üîç MERGE-PRECOMMITS: Merging ${input.precommits.size} precommits into existing ${existingPrecommits.size} for ${entityShort}:${input.signerId}`,
        );
        input.precommits.forEach((signature, signerId) => {
          console.log(`üîç MERGE-DETAIL: Adding precommit from ${signerId} (sig: ${signature.slice(0, 20)}...)`);
          existingPrecommits.set(signerId, signature);
        });
        existing.precommits = existingPrecommits;
        console.log(`üîç MERGE-RESULT: Total ${existingPrecommits.size} precommits after merge`);
      }

      // Keep the latest frame (simplified)
      if (input.proposedFrame) existing.proposedFrame = input.proposedFrame;

      console.log(
        `    üîÑ Merging inputs for ${key}: txs=${input.entityTxs?.length || 0}, precommits=${input.precommits?.size || 0}, frame=${!!input.proposedFrame}`,
      );
    } else {
      merged.set(key, { ...input });
    }
  }

  if (duplicateCount > 0) {
    console.log(`    ‚ö†Ô∏è  CORNER CASE: Merged ${duplicateCount} duplicate inputs (${inputs.length} ‚Üí ${merged.size})`);
  }

  return Array.from(merged.values());
};

/**
 * Gets entity state summary for debugging
 */
export const getEntityStateSummary = (replica: EntityReplica): string => {
  const hasProposal = replica.proposal ? '‚úì' : '‚úó';
  return `mempool=${replica.mempool.length}, messages=${replica.state.messages.length}, proposal=${hasProposal}`;
};

/**
 * Checks if entity should auto-propose (simplified version)
 */
export const shouldAutoPropose = (replica: EntityReplica, _config: ConsensusConfig): boolean => {
  const hasMempool = replica.mempool.length > 0;
  const isProposer = replica.isProposer;
  const hasProposal = replica.proposal !== undefined;

  return hasMempool && isProposer && !hasProposal;
};

/**
 * Processes empty transaction arrays (corner case)
 */
export const handleEmptyTransactions = (): void => {
  console.log(`    ‚ö†Ô∏è  CORNER CASE: Empty transaction array received - no mempool changes`);
};

/**
 * Logs large transaction batches (corner case)
 */
export const handleLargeBatch = (txCount: number): void => {
  if (txCount >= 8) {
    console.log(`    ‚ö†Ô∏è  CORNER CASE: Large batch of ${txCount} transactions`);
  }
};

/**
 * Handles gossip mode precommit distribution
 */
export const handleGossipMode = (): void => {
  console.log(`    ‚ö†Ô∏è  CORNER CASE: Gossip mode - all validators receive precommits`);
};

/**
 * Logs proposer with empty mempool corner case
 */
export const handleEmptyMempoolProposer = (): void => {
  console.log(`    ‚ö†Ô∏è  CORNER CASE: Proposer with empty mempool - no auto-propose`);
};


//runtime/account-consensus.ts (675 lines)
/**
 * XLN Account Consensus System
 *
 * Implements bilateral consensus between two entities for off-chain account settlement.
 * Based on old_src Channel.ts but adapted for entity-deterministic architecture.
 *
 * Key Concepts:
 * - AccountMachine: Bilateral state machine between two entities
 * - Giant Per-Token Table: Map<tokenId, Delta> like old_src channels
 * - Global Credit Limits: USD-denominated credit limits (simplified)
 * - Frame-Based Consensus: Bilateral agreement on account state changes
 * - Event Bubbling: Account events bubble up to E-Machine for entity messages
 */

import { AccountMachine, AccountFrame, AccountTx, AccountInput, Env, EntityState } from './types';
import { cloneAccountMachine } from './state-helpers';
import { isLeft } from './account-utils';
import { signAccountFrame, verifyAccountSignature } from './account-crypto';
import { cryptoHash as hash } from './utils';
import { logError } from './logger';
import { safeStringify } from './serialization-utils';
import { validateAccountFrame as validateAccountFrameStrict } from './validation-utils';
import { processAccountTx } from './account-tx/apply';

// Removed createValidAccountSnapshot - using simplified AccountSnapshot interface

// === CONSTANTS ===
const MEMPOOL_LIMIT = 1000;
const MAX_MESSAGE_COUNTER = 1000000;
const MAX_FRAME_TIMESTAMP_DRIFT_MS = 300000; // 5 minutes
const MAX_FRAME_SIZE_BYTES = 1048576; // 1MB frame size limit (Bitcoin block size standard)

// === VALIDATION ===

/**
 * Validate account frame (frame-level validation)
 */
export function validateAccountFrame(frame: AccountFrame, currentTimestamp?: number): boolean {
  if (frame.height < 0) return false;
  if (frame.accountTxs.length > 100) return false;
  if (frame.tokenIds.length !== frame.deltas.length) return false;

  // Optional timestamp drift check (only if currentTimestamp provided)
  if (currentTimestamp !== undefined) {
    if (Math.abs(frame.timestamp - currentTimestamp) > MAX_FRAME_TIMESTAMP_DRIFT_MS) return false;
  }

  return true;
}

/**
 * Validate message counter (strict replay protection)
 * Counter must be EXACTLY ackedTransitions + 1 (sequential, no gaps allowed)
 */
export function validateMessageCounter(accountMachine: AccountMachine, counter: number): boolean {
  if (counter <= 0 || counter > MAX_MESSAGE_COUNTER) {
    console.log(`‚ùå Counter out of range: ${counter} (must be 1-${MAX_MESSAGE_COUNTER})`);
    return false;
  }

  // CRITICAL: Enforce STRICT sequential increment (no gaps, no replays, no skips)
  const expectedCounter = accountMachine.ackedTransitions + 1;
  if (counter !== expectedCounter) {
    console.log(`‚ùå Counter violation: got ${counter}, expected ${expectedCounter} (ackedTransitions=${accountMachine.ackedTransitions})`);
    return false;
  }

  return true;
}

// === FRAME HASH COMPUTATION ===

async function createFrameHash(frame: AccountFrame): Promise<string> {
  // CRITICAL: Use keccak256 for EVM compatibility (Channel.ts:585, 744)
  // Include prevFrameHash to chain frames together (prevents signature replay)
  const { ethers } = await import('ethers');

  // Encode FULL frame structure including all delta fields (2024 pattern)
  const frameData = {
    height: frame.height,
    timestamp: frame.timestamp,
    prevFrameHash: frame.prevFrameHash, // Chain linkage
    accountTxs: frame.accountTxs.map(tx => ({
      type: tx.type,
      data: tx.data
    })),
    tokenIds: frame.tokenIds,
    deltas: frame.deltas.map(d => d.toString()), // Quick access sums
    // AUDIT FIX: Include FULL delta state (credit limits, allowances, collateral)
    fullDeltaStates: frame.fullDeltaStates?.map(delta => ({
      tokenId: delta.tokenId,
      collateral: delta.collateral.toString(),
      ondelta: delta.ondelta.toString(),
      offdelta: delta.offdelta.toString(),
      leftCreditLimit: delta.leftCreditLimit.toString(),
      rightCreditLimit: delta.rightCreditLimit.toString(),
      leftAllowance: delta.leftAllowance.toString(),
      rightAllowance: delta.rightAllowance.toString(),
    }))
  };

  // Use keccak256 like 2024 Channel.ts (not truncated hash20)
  const encoded = safeStringify(frameData); // Deterministic JSON encoding
  return ethers.keccak256(ethers.toUtf8Bytes(encoded));
}

// === TRANSACTION PROCESSING ===

// Transaction processing now delegated to account-tx/apply.ts (modular handlers)
// See: src/account-tx/handlers/* for individual transaction handlers

// === FRAME CONSENSUS ===

/**
 * Propose account frame (like old_src Channel consensus)
 */
export async function proposeAccountFrame(
  env: Env,
  accountMachine: AccountMachine,
  skipCounterIncrement: boolean = false
): Promise<{ success: boolean; accountInput?: AccountInput; events: string[]; error?: string }> {
  console.log(`üöÄ E-MACHINE: Proposing account frame for ${accountMachine.counterpartyEntityId.slice(-4)}`);
  console.log(`üöÄ E-MACHINE: Account state - mempool=${accountMachine.mempool.length}, pendingFrame=${!!accountMachine.pendingFrame}, currentHeight=${accountMachine.currentHeight}`);

  const events: string[] = [];

  // Mempool size validation
  if (accountMachine.mempool.length > MEMPOOL_LIMIT) {
    console.log(`‚ùå E-MACHINE: Mempool overflow ${accountMachine.mempool.length} > ${MEMPOOL_LIMIT}`);
    return { success: false, error: `Mempool overflow: ${accountMachine.mempool.length} > ${MEMPOOL_LIMIT}`, events };
  }

  if (accountMachine.mempool.length === 0) {
    console.log(`‚ùå E-MACHINE: No transactions in mempool to propose`);
    return { success: false, error: 'No transactions to propose', events };
  }

  // Check if we have a pending frame waiting for ACK
  if (accountMachine.pendingFrame) {
    console.log(`‚è≥ E-MACHINE: Still waiting for ACK on pending frame #${accountMachine.pendingFrame.height}`);
    return { success: false, error: 'Waiting for ACK on pending frame', events };
  }

  console.log(`‚úÖ E-MACHINE: Creating frame with ${accountMachine.mempool.length} transactions...`);

  // Clone account machine for validation
  const clonedMachine = cloneAccountMachine(accountMachine);

  // Process all transactions on the clone
  const allEvents: string[] = [];
  for (const accountTx of accountMachine.mempool) {
    const result = processAccountTx(clonedMachine, accountTx, true); // Processing our own transactions

    if (!result.success) {
      return { success: false, error: `Tx validation failed: ${result.error}`, events: allEvents };
    }

    allEvents.push(...result.events);
  }

  // CRITICAL FIX: Extract FULL delta state from clonedMachine.deltas (after processing)
  // Include ALL fields (credit limits, allowances, collateral) for dispute proofs
  const finalTokenIds: number[] = [];
  const finalDeltas: bigint[] = [];
  const fullDeltaStates: import('./types').Delta[] = [];

  // Sort by tokenId for deterministic ordering
  const sortedTokens = Array.from(clonedMachine.deltas.entries()).sort((a, b) => a[0] - b[0]);

  for (const [tokenId, delta] of sortedTokens) {
    // CONSENSUS FIX: Only include tokens that were actually used in transactions
    // This prevents mismatch when one side creates empty delta entries
    const totalDelta = delta.ondelta + delta.offdelta;

    // Skip tokens with zero delta AND zero limits (never used)
    if (totalDelta === 0n && delta.leftCreditLimit === 0n && delta.rightCreditLimit === 0n) {
      console.log(`‚è≠Ô∏è  Skipping unused token ${tokenId} from frame (zero delta, zero limits)`);
      continue;
    }

    finalTokenIds.push(tokenId);
    finalDeltas.push(totalDelta);
    // AUDIT FIX: Store FULL delta state (collateral, credit limits, allowances)
    fullDeltaStates.push({ ...delta });
  }

  console.log(`üìä Frame state after processing: ${finalTokenIds.length} tokens`);
  console.log(`üìä TokenIds: [${finalTokenIds.join(', ')}]`);
  console.log(`üìä Deltas: [${finalDeltas.map(d => d.toString()).join(', ')}]`);

  // Create account frame matching the real AccountFrame interface
  const frameData = {
    height: accountMachine.currentHeight + 1,
    timestamp: env.timestamp, // DETERMINISTIC: Copy from runtime machine
    accountTxs: [...accountMachine.mempool],
    // CRITICAL: Use stored stateHash from currentFrame (set during commit)
    prevFrameHash: accountMachine.currentHeight === 0
      ? 'genesis'
      : accountMachine.currentFrame.stateHash || '',
    stateHash: '', // Will be filled after hash calculation
    tokenIds: finalTokenIds, // Use computed state from clonedMachine.deltas
    deltas: finalDeltas,      // Quick access: ondelta+offdelta sums
    fullDeltaStates          // AUDIT FIX: Full Delta objects for dispute proofs
  };

  // Calculate state hash (frameData is properly typed AccountFrame)
  frameData.stateHash = await createFrameHash(frameData as AccountFrame);

  // VALIDATE AT SOURCE: Guaranteed type safety from this point forward
  let newFrame: AccountFrame;
  try {
    newFrame = validateAccountFrameStrict(frameData, 'proposeAccountFrame');
  } catch (error) {
    logError("FRAME_CONSENSUS", `‚ùå Frame validation failed:`, error);
    logError("FRAME_CONSENSUS", `‚ùå Frame data:`, safeStringify(frameData, 2));
    return {
      success: false,
      error: `Frame validation failed: ${(error as Error).message}`,
      events,
    };
  }

  // Validate frame size (Bitcoin 1MB block limit)
  const frameSize = safeStringify(newFrame).length;
  if (frameSize > MAX_FRAME_SIZE_BYTES) {
    logError("FRAME_CONSENSUS", `‚ùå Frame too large: ${frameSize} bytes > ${MAX_FRAME_SIZE_BYTES} bytes (1MB)`);
    return {
      success: false,
      error: `Frame exceeds 1MB limit: ${frameSize} bytes`,
      events,
    };
  }
  console.log(`‚úÖ Frame size: ${frameSize} bytes (${(frameSize / MAX_FRAME_SIZE_BYTES * 100).toFixed(2)}% of 1MB limit)`);

  // Generate signature
  const signature = signAccountFrame(accountMachine.proofHeader.fromEntity, newFrame.stateHash);

  // Set pending state
  accountMachine.pendingFrame = newFrame;
  accountMachine.sentTransitions = accountMachine.mempool.length;
  accountMachine.clonedForValidation = clonedMachine;

  // Clear mempool
  accountMachine.mempool = [];

  events.push(`üöÄ Proposed frame ${newFrame.height} with ${newFrame.accountTxs.length} transactions`);

  const accountInput: AccountInput = {
    fromEntityId: accountMachine.proofHeader.fromEntity,
    toEntityId: accountMachine.proofHeader.toEntity,
    height: newFrame.height,
    newAccountFrame: newFrame,
    newSignatures: [signature],
    counter: skipCounterIncrement ? accountMachine.proofHeader.cooperativeNonce : ++accountMachine.proofHeader.cooperativeNonce,
  };

  return { success: true, accountInput, events };
}

/**
 * Handle received AccountInput (bilateral consensus)
 */
export async function handleAccountInput(
  env: Env,
  accountMachine: AccountMachine,
  input: AccountInput
): Promise<{ success: boolean; response?: AccountInput; events: string[]; error?: string; approvalNeeded?: AccountTx }> {
  console.log(`üì® A-MACHINE: Received AccountInput from ${input.fromEntityId.slice(-4)}`);

  const events: string[] = [];

  // CRITICAL: Counter validation (replay protection) - ALWAYS enforce, no frame 0 exemption
  if (input.counter !== undefined) {
    const counterValid = validateMessageCounter(accountMachine, input.counter);
    console.log(`üîç Counter validation: ${input.counter} vs acked=${accountMachine.ackedTransitions}, frameId=${accountMachine.currentHeight}, valid=${counterValid}`);

    if (!counterValid) {
      return { success: false, error: `Replay attack detected: counter ${input.counter} invalid (expected ${accountMachine.ackedTransitions + 1})`, events };
    }

    // Update acked counter only after validation passes
    accountMachine.ackedTransitions = input.counter;
  } else {
    // Counter is REQUIRED for all messages (replay protection)
    return { success: false, error: 'Missing counter - replay protection requires sequential counter', events };
  }

  // Handle pending frame confirmation
  if (accountMachine.pendingFrame && input.height === accountMachine.pendingFrame.height && input.prevSignatures) {
    console.log(`‚úÖ Received confirmation for pending frame ${input.height}`);

    const frameHash = accountMachine.pendingFrame.stateHash;
    const expectedSigner = accountMachine.proofHeader.toEntity;

    const signature = input.prevSignatures[0];
    if (input.prevSignatures.length > 0 && signature && verifyAccountSignature(expectedSigner, frameHash, signature)) {
      // CRITICAL DEBUG: Log what we're committing
      console.log(`üîí COMMIT: Frame ${accountMachine.pendingFrame.height}`);
      console.log(`  Transactions: ${accountMachine.pendingFrame.accountTxs.length}`);
      console.log(`  TokenIds: ${accountMachine.pendingFrame.tokenIds.join(',')}`);
      console.log(`  Deltas: ${accountMachine.pendingFrame.deltas.map(d => `${d}`).join(',')}`);
      console.log(`  StateHash: ${frameHash.slice(0,16)}...`);

      // Commit using cloned state
      if (accountMachine.clonedForValidation) {
        accountMachine.deltas = accountMachine.clonedForValidation.deltas;
        accountMachine.currentFrame = {
          height: accountMachine.pendingFrame.height,
          timestamp: accountMachine.pendingFrame.timestamp,
          accountTxs: accountMachine.pendingFrame.accountTxs,
          prevFrameHash: accountMachine.pendingFrame.prevFrameHash,
          tokenIds: accountMachine.pendingFrame.tokenIds,
          deltas: accountMachine.pendingFrame.deltas,
          stateHash: accountMachine.pendingFrame.stateHash,
        };
        accountMachine.currentHeight = accountMachine.pendingFrame.height;

        // Add confirmed frame to history
        accountMachine.frameHistory.push({...accountMachine.pendingFrame});
        // Cap history at 10 frames to prevent snapshot bloat
        if (accountMachine.frameHistory.length > 10) {
          accountMachine.frameHistory.shift();
        }
        console.log(`üìö Frame ${accountMachine.pendingFrame.height} added to history (total: ${accountMachine.frameHistory.length})`);
      }

      // Clear pending state
      delete accountMachine.pendingFrame;
      accountMachine.sentTransitions = 0;
      delete accountMachine.clonedForValidation;
      accountMachine.rollbackCount = Math.max(0, accountMachine.rollbackCount - 1); // Successful confirmation reduces rollback

      events.push(`‚úÖ Frame ${input.height} confirmed and committed`);

      // CRITICAL: Don't return yet! Check if they also sent a new frame in same message
      // Channel.ts pattern: ACK + new frame can be batched (line 576-612)
      if (!input.newAccountFrame) {
        return { success: true, events }; // Only ACK, no new frame
      }
      // Fall through to process newAccountFrame below
      console.log(`üì¶ BATCHED-MESSAGE: ACK processed, now processing bundled new frame...`);
    } else {
      return { success: false, error: 'Invalid confirmation signature', events };
    }
  }

  // Handle new frame proposal
  if (input.newAccountFrame) {
    const receivedFrame = input.newAccountFrame;

    if (!validateAccountFrame(receivedFrame)) {
      return { success: false, error: 'Invalid frame structure', events };
    }

    // CRITICAL: Verify prevFrameHash links to our current frame (prevent state fork)
    const expectedPrevFrameHash = accountMachine.currentHeight === 0
      ? 'genesis'
      : accountMachine.currentFrame.stateHash || '';

    if (receivedFrame.prevFrameHash !== expectedPrevFrameHash) {
      logError("FRAME_CONSENSUS", `‚ùå FRAME-CHAIN-BROKEN: prevFrameHash mismatch`);
      logError("FRAME_CONSENSUS", `  Expected: ${expectedPrevFrameHash.slice(0, 16)}...`);
      logError("FRAME_CONSENSUS", `  Received: ${receivedFrame.prevFrameHash.slice(0, 16)}...`);
      logError("FRAME_CONSENSUS", `  Current height: ${accountMachine.currentHeight}`);
      return {
        success: false,
        error: `Frame chain broken: prevFrameHash mismatch (expected ${expectedPrevFrameHash.slice(0, 16)}...)`,
        events
      };
    }

    console.log(`‚úÖ Frame chain verified: prevFrameHash matches frame ${accountMachine.currentHeight}`);

    // CHANNEL.TS REFERENCE: Lines 138-165 - Proper rollback logic for simultaneous proposals
    // Handle simultaneous proposals when both sides send same frameId
    if (accountMachine.pendingFrame && receivedFrame.height === accountMachine.pendingFrame.height) {
      console.log(`üîÑ SIMULTANEOUS-PROPOSALS: Both proposed frame ${receivedFrame.height}`);

      // Deterministic tiebreaker: Left always wins (CHANNEL.TS REFERENCE: Line 140-157)
      const isLeftEntity = isLeft(accountMachine.proofHeader.fromEntity, accountMachine.proofHeader.toEntity);

      if (isLeftEntity) {
        // We are LEFT - ignore their frame, keep ours (deterministic tiebreaker)
        console.log(`üì§ LEFT-WINS: Ignoring right's frame ${receivedFrame.height}, waiting for them to accept ours`);
        // This is NOT an error - it's correct consensus behavior (no response needed)
        return { success: true, events };
      } else {
        // We are RIGHT - rollback our frame, accept theirs
        if (accountMachine.rollbackCount === 0) {
          // First rollback - restore transactions to mempool before discarding frame
          if (accountMachine.pendingFrame) {
            console.log(`üì• RIGHT-ROLLBACK: Restoring ${accountMachine.pendingFrame.accountTxs.length} txs to mempool`);
            // CRITICAL: Re-add transactions to mempool (Channel.ts pattern)
            accountMachine.mempool.unshift(...accountMachine.pendingFrame.accountTxs);
            console.log(`üì• Mempool now has ${accountMachine.mempool.length} txs after rollback restore`);
          }

          accountMachine.sentTransitions = 0;
          delete accountMachine.pendingFrame;
          delete accountMachine.clonedForValidation;
          accountMachine.rollbackCount++;
          console.log(`üì• RIGHT-ROLLBACK: Accepting left's frame (rollbacks: ${accountMachine.rollbackCount})`);
          // Continue to process their frame below
        } else {
          // Should never rollback twice
          logError("FRAME_CONSENSUS", `‚ùå FATAL: Right side rolled back ${accountMachine.rollbackCount} times - consensus broken`);
          return { success: false, error: 'Multiple rollbacks detected - consensus failure', events };
        }
      }
    }

    // CHANNEL.TS REFERENCE: Lines 161-164 - Decrement rollbacks on successful confirmation
    if (accountMachine.pendingFrame && receivedFrame.height === accountMachine.currentHeight + 1 && accountMachine.rollbackCount > 0) {
      // They accepted our frame after we had rollbacks - decrement
      accountMachine.rollbackCount--;
      console.log(`‚úÖ ROLLBACK-RESOLVED: They accepted our frame (rollbacks: ${accountMachine.rollbackCount})`);
    }

    // Verify frame sequence
    if (receivedFrame.height !== accountMachine.currentHeight + 1) {
      console.log(`‚ùå Frame sequence mismatch: expected ${accountMachine.currentHeight + 1}, got ${receivedFrame.height}`);
      return { success: false, error: `Frame sequence mismatch: expected ${accountMachine.currentHeight + 1}, got ${receivedFrame.height}`, events };
    }

    // Verify signatures
    if (input.newSignatures && input.newSignatures.length > 0) {
      const signature = input.newSignatures[0];
      if (!signature) {
        return { success: false, error: 'Missing signature in newSignatures array', events };
      }
      const isValid = verifyAccountSignature(input.fromEntityId, receivedFrame.stateHash, signature);
      if (!isValid) {
        return { success: false, error: 'Invalid frame signature', events };
      }
    }

    // Apply frame transactions to clone (as receiver)
    const clonedMachine = cloneAccountMachine(accountMachine);
    const processEvents: string[] = [];

    for (const accountTx of receivedFrame.accountTxs) {
      // When receiving a frame, we process transactions from counterparty's perspective (incoming)
      const result = processAccountTx(clonedMachine, accountTx, false); // Processing their transactions = incoming
      if (!result.success) {
        return { success: false, error: `Frame application failed: ${result.error}`, events };
      }
      processEvents.push(...result.events);
    }

    // STATE VERIFICATION: Compare deltas directly (both sides compute identically)
    // Extract final state from clonedMachine after processing ALL transactions
    const ourFinalTokenIds: number[] = [];
    const ourFinalDeltas: bigint[] = [];

    const sortedOurTokens = Array.from(clonedMachine.deltas.entries()).sort((a, b) => a[0] - b[0]);
    for (const [tokenId, delta] of sortedOurTokens) {
      const totalDelta = delta.ondelta + delta.offdelta;

      // CONSENSUS FIX: Apply SAME filtering as proposer
      // Skip tokens with zero delta AND zero limits (never used)
      if (totalDelta === 0n && delta.leftCreditLimit === 0n && delta.rightCreditLimit === 0n) {
        console.log(`‚è≠Ô∏è  RECEIVER: Skipping unused token ${tokenId} from validation (zero delta, zero limits)`);
        continue;
      }

      ourFinalTokenIds.push(tokenId);
      ourFinalDeltas.push(totalDelta);
    }

    console.log(`üîç RECEIVER: Computed ${ourFinalTokenIds.length} tokens after filtering: [${ourFinalTokenIds.join(', ')}]`);

    const ourComputedState = Buffer.from(ourFinalDeltas.map(d => d.toString()).join(',')).toString('hex');
    const theirClaimedState = Buffer.from(receivedFrame.deltas.map(d => d.toString()).join(',')).toString('hex');

    console.log(`üîç STATE-VERIFY Frame ${receivedFrame.height}:`);
    console.log(`  Our computed:  ${ourComputedState.slice(0, 32)}...`);
    console.log(`  Their claimed: ${theirClaimedState.slice(0, 32)}...`);

    if (ourComputedState !== theirClaimedState) {
      logError("FRAME_CONSENSUS", `‚ùå CONSENSUS-FAILURE: Both sides computed different final states!`);

      // DUMP EVERYTHING - FULL DATA STRUCTURES
      logError("FRAME_CONSENSUS", `‚ùå FULL CONSENSUS FAILURE DUMP:`);
      logError("FRAME_CONSENSUS", `‚ùå AccountMachine BEFORE:`, safeStringify(accountMachine));
      logError("FRAME_CONSENSUS", `‚ùå ClonedMachine AFTER:`, safeStringify(clonedMachine));
      logError("FRAME_CONSENSUS", `‚ùå ReceivedFrame COMPLETE:`, safeStringify(receivedFrame));
      logError("FRAME_CONSENSUS", `‚ùå OurComputedState:`, ourComputedState);
      logError("FRAME_CONSENSUS", `‚ùå TheirClaimedState:`, theirClaimedState);
      logError("FRAME_CONSENSUS", `‚ùå OurFinalDeltas:`, ourFinalDeltas.map(d => d.toString()));
      logError("FRAME_CONSENSUS", `‚ùå TheirFrameDeltas:`, receivedFrame.deltas.map(d => d.toString()));
      const isLeftEntity = isLeft(accountMachine.proofHeader.fromEntity, accountMachine.proofHeader.toEntity);
      logError("FRAME_CONSENSUS", `‚ùå isLeft=${isLeftEntity}, fromEntity=${accountMachine.proofHeader.fromEntity}, toEntity=${accountMachine.proofHeader.toEntity}`);

      return { success: false, error: `Bilateral consensus failure - states don't match`, events };
    }

    console.log(`‚úÖ CONSENSUS-SUCCESS: Both sides computed identical state for frame ${receivedFrame.height}`);

    // Commit frame
    accountMachine.deltas = clonedMachine.deltas;

    // CRITICAL: Copy pendingForward for multi-hop routing
    if (clonedMachine.pendingForward) {
      accountMachine.pendingForward = clonedMachine.pendingForward;
      console.log(`üîÄ Copied pendingForward for multi-hop: route=[${clonedMachine.pendingForward.route.map(r => r.slice(-4)).join(',')}]`);
    }

    accountMachine.currentFrame = {
      height: receivedFrame.height,
      timestamp: receivedFrame.timestamp,
      accountTxs: receivedFrame.accountTxs,
      prevFrameHash: receivedFrame.prevFrameHash,
      tokenIds: receivedFrame.tokenIds,
      deltas: receivedFrame.deltas,
      stateHash: receivedFrame.stateHash,
    };
    accountMachine.currentHeight = receivedFrame.height;

    // Add accepted frame to history
    accountMachine.frameHistory.push({...receivedFrame});
    // Cap history at 10 frames to prevent snapshot bloat
    if (accountMachine.frameHistory.length > 10) {
      accountMachine.frameHistory.shift();
    }
    console.log(`üìö Frame ${receivedFrame.height} accepted and added to history (total: ${accountMachine.frameHistory.length})`);

    events.push(...processEvents);
    events.push(`ü§ù Accepted frame ${receivedFrame.height} from Entity ${input.fromEntityId.slice(-4)}`);

    // Send confirmation (ACK)
    const confirmationSig = signAccountFrame(accountMachine.proofHeader.fromEntity, receivedFrame.stateHash);

    // CHANNEL.TS PATTERN (Lines 576-612): Batch ACK + new frame in same message!
    // Check if we should batch BEFORE incrementing counter
    let batchedWithNewFrame = false;
    const response: AccountInput = {
      fromEntityId: accountMachine.proofHeader.fromEntity,
      toEntityId: input.fromEntityId,
      height: receivedFrame.height,
      prevSignatures: [confirmationSig],
      counter: 0, // Will be set below after batching decision
    };

    // If we have mempool items, propose next frame immediately and batch with ACK
    if (accountMachine.mempool.length > 0 && !accountMachine.pendingFrame) {
      console.log(`üì¶ BATCH-OPTIMIZATION: Sending ACK + new frame in single message (Channel.ts pattern)`);

      // Pass skipCounterIncrement=true since we'll increment for the whole batch below
      const proposeResult = await proposeAccountFrame(env, accountMachine, true);

      if (proposeResult.success && proposeResult.accountInput) {
        batchedWithNewFrame = true;
        // Merge ACK and new proposal into same AccountInput
        if (proposeResult.accountInput.newAccountFrame) {
          response.newAccountFrame = proposeResult.accountInput.newAccountFrame;
        }
        if (proposeResult.accountInput.newSignatures) {
          response.newSignatures = proposeResult.accountInput.newSignatures;
        }

        const newFrameId = proposeResult.accountInput.newAccountFrame?.height || 0;
        console.log(`‚úÖ Batched ACK for frame ${receivedFrame.height} + proposal for frame ${newFrameId}`);
        events.push(`üì§ Batched ACK + frame ${newFrameId}`);
      }
    }

    // Increment counter ONCE per message (whether batched or not)
    response.counter = ++accountMachine.proofHeader.cooperativeNonce;
    console.log(`üî¢ Message counter: ${response.counter} (batched=${batchedWithNewFrame})`);

    return { success: true, response, events };
  }

  return { success: true, events };
}

// === E-MACHINE INTEGRATION ===

/**
 * Add transaction to account mempool with limits
 */
export function addToAccountMempool(accountMachine: AccountMachine, accountTx: AccountTx): boolean {
  if (accountMachine.mempool.length >= MEMPOOL_LIMIT) {
    console.log(`‚ùå Mempool full: ${accountMachine.mempool.length} >= ${MEMPOOL_LIMIT}`);
    return false;
  }

  accountMachine.mempool.push(accountTx);
  console.log(`üì• Added ${accountTx.type} to mempool (${accountMachine.mempool.length}/${MEMPOOL_LIMIT})`);
  return true;
}

/**
 * Check if account should auto-propose frame
 */
export function shouldProposeFrame(accountMachine: AccountMachine): boolean {
  // Should propose if:
  // 1. Has transactions in mempool
  // 2. No pending frame waiting for confirmation
  // Note: BOTH sides can propose in bilateral consensus (not just the proposer)
  return accountMachine.mempool.length > 0 && !accountMachine.pendingFrame;
}

/**
 * Get accounts that should propose frames (for E-Machine auto-propose)
 * @param entityState - Entity state containing accounts to check
 */
export function getAccountsToProposeFrames(entityState: EntityState): string[] {
  const accountsToProposeFrames: string[] = [];

  // Check if accounts exists and is iterable
  if (!entityState.accounts || !(entityState.accounts instanceof Map)) {
    console.log(`‚ö†Ô∏è No accounts or accounts not a Map: ${typeof entityState.accounts}`);
    return accountsToProposeFrames;
  }

  for (const [counterpartyEntityId, accountMachine] of entityState.accounts) {
    if (shouldProposeFrame(accountMachine)) {
      accountsToProposeFrames.push(counterpartyEntityId);
    }
  }

  return accountsToProposeFrames;
}

// === PROOF GENERATION (for future J-Machine integration) ===

/**
 * Generate account proof for dispute resolution (like old_src Channel.getSubchannelProofs)
 * Must be ABI-compatible with Depository contract
 */
export async function generateAccountProof(accountMachine: AccountMachine): Promise<{ proofHash: string; signature: string }> {
  // Update proofBody with current state (like old_src does before signing)
  accountMachine.proofBody = {
    tokenIds: Array.from(accountMachine.deltas.keys()).sort((a, b) => a - b), // Deterministic order
    deltas: Array.from(accountMachine.deltas.keys())
      .sort((a, b) => a - b)
      .map(tokenId => {
        const delta = accountMachine.deltas.get(tokenId);
        if (!delta) {
          logError("FRAME_CONSENSUS", `‚ùå Missing delta for tokenId ${tokenId} in account ${accountMachine.counterpartyEntityId}`);
          throw new Error(`Critical financial data missing: delta for token ${tokenId}`);
        }
        return delta.ondelta + delta.offdelta; // Total delta for each token
      }),
  };

  // Create proof structure compatible with Depository.sol
  const proofData = {
    fromEntity: accountMachine.proofHeader.fromEntity,
    toEntity: accountMachine.proofHeader.toEntity,
    cooperativeNonce: accountMachine.proofHeader.cooperativeNonce,
    disputeNonce: accountMachine.proofHeader.disputeNonce,
    tokenIds: accountMachine.proofBody.tokenIds,
    deltas: accountMachine.proofBody.deltas.map(d => d.toString()), // Convert BigInt for JSON
  };

  // Create deterministic proof hash using browser-compatible crypto
  const proofContent = safeStringify(proofData);
  const fullHash = await hash(proofContent);
  const proofHash = fullHash.slice(2); // Remove 0x prefix for compatibility

  // Generate hanko signature (like old_src does)
  const signature = signAccountFrame(accountMachine.proofHeader.fromEntity, `0x${proofHash}`);

  // Store signature for later use
  accountMachine.hankoSignature = signature;

  console.log(`üîê Generated account proof: ${accountMachine.proofBody.tokenIds.length} tokens, hash: 0x${proofHash.slice(0, 20)}...`);
  console.log(`üîê ProofBody tokens: [${accountMachine.proofBody.tokenIds.join(',')}]`);
  console.log(`üîê ProofBody deltas: [${accountMachine.proofBody.deltas.map(d => d.toString()).join(',')}]`);

  return { proofHash: `0x${proofHash}`, signature };
}


//runtime/entity-tx/index.ts (7 lines)
export * from './apply';
export * from './financial';
export * from './handlers/account';
export * from './j-events';
export * from './proposals';
export * from './validation';


//runtime/entity-tx/apply.ts (483 lines)
import { calculateQuorumPower } from '../entity-consensus';
import { formatEntityId } from '../entity-helpers';
import { processProfileUpdate } from '../name-resolution';
import { db } from '../runtime';
import { EntityState, EntityTx, Env, Proposal, Delta, AccountTx, EntityInput } from '../types';
import { DEBUG, log } from '../utils';
import { safeStringify } from '../serialization-utils';
import { buildEntityProfile } from '../gossip-helper';
import { getDefaultCreditLimit } from '../account-utils';
// import { addToReserves, subtractFromReserves } from './financial'; // Currently unused
import { handleAccountInput } from './handlers/account';
import { handleJEvent } from './j-events';
import { executeProposal, generateProposalId } from './proposals';
import { validateMessage } from './validation';
import { cloneEntityState, addMessage } from '../state-helpers';
import { submitSettle } from '../evm';
import { logError } from '../logger';

export const applyEntityTx = async (env: Env, entityState: EntityState, entityTx: EntityTx): Promise<{ newState: EntityState, outputs: EntityInput[] }> => {
  if (!entityTx) {
    logError("ENTITY_TX", `‚ùå EntityTx is undefined!`);
    return { newState: entityState, outputs: [] };
  }

  //console.log(`üö®üö® APPLY-ENTITY-TX: type="${entityTx?.type}" (typeof: ${typeof entityTx?.type})`);
  //console.log(`üö®üö® APPLY-ENTITY-TX: data=`, safeStringify(entityTx?.data, 2));
  //console.log(`üö®üö® APPLY-ENTITY-TX: Available types: profile-update, j_event, accountInput, openAccount, directPayment`);
  try {
    if (entityTx.type === 'chat') {
      const { from, message } = entityTx.data;

      if (!validateMessage(message)) {
        log.error(`‚ùå Invalid chat message from ${from}`);
        return { newState: entityState, outputs: [] }; // Return unchanged state
      }

      const currentNonce = entityState.nonces.get(from) || 0;
      const expectedNonce = currentNonce + 1;

      const newEntityState = cloneEntityState(entityState);

      newEntityState.nonces.set(from, expectedNonce);
      addMessage(newEntityState, `${from}: ${message}`);

      return { newState: newEntityState, outputs: [] };
    }

    if (entityTx.type === 'chatMessage') {
      // System-generated messages (e.g., from crontab dispute suggestions)
      const { message } = entityTx.data;
      const newEntityState = cloneEntityState(entityState);

      addMessage(newEntityState, message);

      return { newState: newEntityState, outputs: [] };
    }

    if (entityTx.type === 'propose') {
      const { action, proposer } = entityTx.data;
      const proposalId = generateProposalId(action, proposer, entityState);

      if (DEBUG) console.log(`    üìù Creating proposal ${proposalId} by ${proposer}: ${action.data.message}`);

      const proposal: Proposal = {
        id: proposalId,
        proposer,
        action,
        // explicitly type votes map to match Proposal.vote value type
        votes: new Map<string, 'yes' | 'no' | 'abstain' | { choice: 'yes' | 'no' | 'abstain'; comment: string }>([
          [proposer, 'yes'],
        ]),
        status: 'pending',
        created: entityState.timestamp,
      };

      const proposerPower = entityState.config.shares[proposer] || BigInt(0);
      const shouldExecuteImmediately = proposerPower >= entityState.config.threshold;

      let newEntityState = cloneEntityState(entityState);

      if (shouldExecuteImmediately) {
        proposal.status = 'executed';
        newEntityState = executeProposal(newEntityState, proposal);
        if (DEBUG)
          console.log(
            `    ‚ö° Proposal executed immediately - proposer has ${proposerPower} >= ${entityState.config.threshold} threshold`,
          );
      } else {
        if (DEBUG)
          console.log(
            `    ‚è≥ Proposal pending votes - proposer has ${proposerPower} < ${entityState.config.threshold} threshold`,
          );
      }

      newEntityState.proposals.set(proposalId, proposal);
      return { newState: newEntityState, outputs: [] };
    }

    if (entityTx.type === 'vote') {
      console.log(`üó≥Ô∏è PROCESSING VOTE: entityTx.data=`, entityTx.data);
      const { proposalId, voter, choice, comment } = entityTx.data;
      const proposal = entityState.proposals.get(proposalId);

      console.log(`üó≥Ô∏è Vote lookup: proposalId=${proposalId}, found=${!!proposal}, status=${proposal?.status}`);
      console.log(`üó≥Ô∏è Available proposals:`, Array.from(entityState.proposals.keys()));

      if (!proposal || proposal.status !== 'pending') {
        console.log(`    ‚ùå Vote ignored - proposal ${proposalId.slice(0, 12)}... not found or not pending`);
        return { newState: entityState, outputs: [] };
      }

      console.log(`    üó≥Ô∏è  Vote by ${voter}: ${choice} on proposal ${proposalId.slice(0, 12)}...`);

      const newEntityState = cloneEntityState(entityState);

      const updatedProposal = {
        ...proposal,
        votes: new Map(proposal.votes),
      };
      // Only create the object variant when comment is provided (comment must be string)
      const voteData: 'yes' | 'no' | 'abstain' | { choice: 'yes' | 'no' | 'abstain'; comment: string } =
        comment !== undefined ? ({ choice, comment } as { choice: 'yes' | 'no' | 'abstain'; comment: string }) : choice;
      updatedProposal.votes.set(voter, voteData);

      const yesVoters = Array.from(updatedProposal.votes.entries())
        .filter(([_voter, voteData]) => {
          const vote = typeof voteData === 'object' ? voteData.choice : voteData;
          return vote === 'yes';
        })
        .map(([voter, _voteData]) => voter);

      const totalYesPower = calculateQuorumPower(entityState.config, yesVoters);

      if (DEBUG) {
        const totalShares = Object.values(entityState.config.shares).reduce((sum, val) => sum + val, BigInt(0));
        const percentage = ((Number(totalYesPower) / Number(entityState.config.threshold)) * 100).toFixed(1);
        console.log(
          `    üîç Proposal votes: ${totalYesPower} / ${totalShares} [${percentage}% threshold${Number(totalYesPower) >= Number(entityState.config.threshold) ? '+' : ''}]`,
        );
      }

      if (totalYesPower >= entityState.config.threshold) {
        updatedProposal.status = 'executed';
        const executedState = executeProposal(newEntityState, updatedProposal);
        executedState.proposals.set(proposalId, updatedProposal);
        return { newState: executedState, outputs: [] };
      }

      newEntityState.proposals.set(proposalId, updatedProposal);
      return { newState: newEntityState, outputs: [] };
    }

    if (entityTx.type === 'profile-update') {
      console.log(`üè∑Ô∏è Profile update transaction processing - data:`, entityTx.data);

      // Extract profile update data
      const profileData = entityTx.data.profile;
      console.log(`üè∑Ô∏è Extracted profileData:`, profileData);

      if (profileData && profileData.entityId) {
        console.log(`üè∑Ô∏è Calling processProfileUpdate for entity ${profileData.entityId}`);
        // Process profile update synchronously to ensure gossip is updated before snapshot
        try {
          await processProfileUpdate(db, profileData.entityId, profileData, profileData.hankoSignature || '', env);
        } catch (error) {
          logError("ENTITY_TX", `‚ùå Failed to process profile update for ${profileData.entityId}:`, error);
        }
      } else {
        console.warn(`‚ö†Ô∏è Invalid profile-update transaction data:`, entityTx.data);
        console.warn(`‚ö†Ô∏è ProfileData missing or invalid:`, profileData);
      }

      return { newState: entityState, outputs: [] };
    }

    if (entityTx.type === 'j_event') {
      const newState = handleJEvent(entityState, entityTx.data);
      return { newState, outputs: [] };
    }

    if (entityTx.type === 'accountInput') {
      const result = await handleAccountInput(entityState, entityTx.data, env);
      return result;
    }

    if (entityTx.type === 'openAccount') {
      console.log(`üí≥ OPEN-ACCOUNT: Opening account with ${entityTx.data.targetEntityId}`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];

      // Add chat message about account opening
      addMessage(newState, `üí≥ Opening account with Entity ${formatEntityId(entityTx.data.targetEntityId)}...`);

      // STEP 1: Create local account machine
      if (!newState.accounts.has(entityTx.data.targetEntityId)) {
        console.log(`üí≥ LOCAL-ACCOUNT: Creating local account with Entity ${formatEntityId(entityTx.data.targetEntityId)}...`);

        // CONSENSUS FIX: Start with empty deltas - let all delta creation happen through transactions
        // This ensures both sides have identical delta Maps (matches Channel.ts pattern)
        const initialDeltas = new Map<number, Delta>();

        newState.accounts.set(entityTx.data.targetEntityId, {
          counterpartyEntityId: entityTx.data.targetEntityId,
          mempool: [],
          currentFrame: {
            height: 0,
            timestamp: env.timestamp,
            accountTxs: [],
            prevFrameHash: '',
            tokenIds: [],
            deltas: [],
            stateHash: ''
          },
          sentTransitions: 0,
          ackedTransitions: 0,
          deltas: initialDeltas,
          globalCreditLimits: {
            ownLimit: getDefaultCreditLimit(1), // We extend 1M USDC credit to counterparty (token 1 = USDC)
            peerLimit: getDefaultCreditLimit(1), // Counterparty extends same USDC credit to us
          },
          // Frame-based consensus fields
          currentHeight: 0,
          pendingSignatures: [],
          rollbackCount: 0,
          // CHANNEL.TS REFERENCE: Proper message counters (NOT timestamps!)
          sendCounter: 0,    // Like Channel.ts line 131
          receiveCounter: 0, // Like Channel.ts line 132
          // Removed isProposer - use isLeft() function like old_src Channel.ts
          proofHeader: {
            fromEntity: entityState.entityId,
            toEntity: entityTx.data.targetEntityId,
            cooperativeNonce: 0,
            disputeNonce: 0,
          },
          proofBody: { tokenIds: [], deltas: [] },
          frameHistory: [],
          pendingWithdrawals: new Map(),
          requestedRebalance: new Map(),
        });
      }

      // STEP 2: Add transactions to LOCAL mempool only (Channel.ts pattern)
      // Frame proposal happens automatically on next tick via AUTO-PROPOSE
      console.log(`üí≥ Adding account setup transactions to local mempool for ${formatEntityId(entityTx.data.targetEntityId)}`);

      // Get the account machine we just created
      const localAccount = newState.accounts.get(entityTx.data.targetEntityId);
      if (!localAccount) {
        throw new Error(`CRITICAL: Account machine not found after creation`);
      }

      // Token 1 = USDC
      const usdcTokenId = 1;
      const defaultCreditLimit = getDefaultCreditLimit(1); // 1M USDC (token 1)

      // Determine canonical side (left/right) - DETERMINISTIC
      const isLeftEntity = entityState.entityId < entityTx.data.targetEntityId;
      const ourSide: 'left' | 'right' = isLeftEntity ? 'left' : 'right';

      // Add transactions to mempool - will be batched into frame #1 on next tick
      localAccount.mempool.push({
        type: 'add_delta',
        data: { tokenId: usdcTokenId }
      });

      localAccount.mempool.push({
        type: 'set_credit_limit',
        data: { tokenId: usdcTokenId, amount: defaultCreditLimit, side: ourSide }
      });

      console.log(`üìù Queued 2 transactions to mempool (total: ${localAccount.mempool.length})`);
      console.log(`‚è∞ Frame #1 will be auto-proposed on next tick (100ms) via AUTO-PROPOSE`);
      console.log(`   Transactions: [add_delta, set_credit_limit(side=${ourSide}, amount=1M)]`);

      // Add success message to chat
      addMessage(newState, `‚úÖ Account opening request sent to Entity ${formatEntityId(entityTx.data.targetEntityId)}`);

      // Broadcast updated profile to gossip layer
      if (env.gossip) {
        const profile = buildEntityProfile(newState);
        env.gossip.announce(profile);
        console.log(`üì° Broadcast profile for ${entityState.entityId} with ${newState.accounts.size} accounts`);
      }

      return { newState, outputs };
    }

    if (entityTx.type === 'directPayment') {
      console.log(`üí∏ DIRECT-PAYMENT: Initiating payment to ${entityTx.data.targetEntityId}`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];

      // Extract payment details
      let { targetEntityId, tokenId, amount, route, description } = entityTx.data;

      // If no route provided, check for direct account or calculate route
      if (!route || route.length === 0) {
        // Check if we have a direct account with target
        if (newState.accounts.has(targetEntityId)) {
          console.log(`üí∏ Direct account exists with ${formatEntityId(targetEntityId)}`);
          route = [entityState.entityId, targetEntityId];
        } else {
          // Find route through network using gossip
          console.log(`üí∏ No direct account, finding route to ${formatEntityId(targetEntityId)}`);

          // Try to find a route through the network
          if (env.gossip) {
            const networkGraph = env.gossip.getNetworkGraph();
            const paths = networkGraph.findPaths(entityState.entityId, targetEntityId);

            if (paths.length > 0) {
              // Use the shortest path
              route = paths[0].path;
              console.log(`üí∏ Found route: ${route.map(e => formatEntityId(e)).join(' ‚Üí ')}`);
            } else {
              logError("ENTITY_TX", `‚ùå No route found to ${formatEntityId(targetEntityId)}`);
              addMessage(newState, `‚ùå Payment failed: No route to ${formatEntityId(targetEntityId)}`);
              return { newState, outputs: [] };
            }
          } else {
            logError("ENTITY_TX", `‚ùå Cannot find route: Gossip layer not available`);
            addMessage(newState, `‚ùå Payment failed: Network routing unavailable`);
            return { newState, outputs: [] };
          }
        }
      }

      // Validate route starts with current entity
      if (route.length < 2 || route[0] !== entityState.entityId) {
        logError("ENTITY_TX", `‚ùå Invalid route: doesn't start with current entity`);
        return { newState: entityState, outputs: [] };
      }

      // Determine next hop
      const nextHop = route[1];
      if (!nextHop) {
        logError("ENTITY_TX", `‚ùå Invalid route: no next hop specified in route`);
        return { newState: entityState, outputs: [] };
      }

      // Check if we have an account with next hop
      if (!newState.accounts.has(nextHop)) {
        logError("ENTITY_TX", `‚ùå No account with next hop: ${nextHop}`);
        addMessage(newState, `‚ùå Payment failed: No account with ${formatEntityId(nextHop)}`);
        return { newState, outputs: [] };
      }

      // Create AccountTx for the payment
      // CRITICAL: ALWAYS include fromEntityId/toEntityId for deterministic consensus
      const accountTx: AccountTx = {
        type: 'direct_payment',
        data: {
          tokenId,
          amount,
          route: route.slice(1), // Remove sender from route (next hop needs to see themselves in route[0])
          description: description || `Payment to ${formatEntityId(targetEntityId)}`,
          fromEntityId: entityState.entityId, // ‚úÖ EXPLICIT direction
          toEntityId: nextHop,                 // ‚úÖ EXPLICIT direction
        },
      };

      // Add to account machine mempool
      const accountMachine = newState.accounts.get(nextHop);
      if (accountMachine) {
        accountMachine.mempool.push(accountTx);
        console.log(`üí∏ Added payment to mempool for account with ${formatEntityId(nextHop)}`);
        console.log(`üí∏ Account mempool now has ${accountMachine.mempool.length} pending transactions`);
        const isLeft = accountMachine.proofHeader.fromEntity < accountMachine.proofHeader.toEntity;
        console.log(`üí∏ Is left entity: ${isLeft}, Has pending frame: ${!!accountMachine.pendingFrame}`);

        // Message about payment initiation
        addMessage(newState,
          `üí∏ Sending ${amount} (token ${tokenId}) to ${formatEntityId(targetEntityId)} via ${route.length - 1} hops`
        );

        // The payment is now in our local mempool with the next hop
        // It will be processed through bilateral consensus in the next round
        // The auto-propose logic in entity-consensus will handle proposing the frame
        console.log(`üí∏ Payment queued for bilateral consensus with ${formatEntityId(nextHop)}`);
        console.log(`üí∏ Account ${formatEntityId(nextHop)} should be added to proposableAccounts`);

        // Note: The entity-consensus applyEntityFrame will add this account to proposableAccounts
        // and trigger bilateral frame proposal at the end of the processing round

        // Return a trigger output to ensure process() continues
        // This ensures the AUTO-PROPOSE logic runs to process the payment
        const firstValidator = entityState.config.validators[0];
        if (firstValidator) {
          outputs.push({
            entityId: entityState.entityId,
            signerId: firstValidator,
            entityTxs: [] // Empty transaction array - just triggers processing
          });
        }
        console.log(`üí∏ Added processing trigger to ensure bilateral consensus runs`);
      }

      return { newState, outputs };
    }

    if (entityTx.type === 'deposit_collateral') {
      const { handleDepositCollateral } = await import('./handlers/deposit-collateral');
      return await handleDepositCollateral(entityState, entityTx);
    }

    if (entityTx.type === 'requestWithdrawal') {
      const { handleRequestWithdrawal } = await import('./handlers/request-withdrawal');
      return { newState: handleRequestWithdrawal(entityState, entityTx), outputs: [] };
    }

    if (entityTx.type === 'settleDiffs') {
      console.log(`üè¶ SETTLE-DIFFS: Processing settlement with ${entityTx.data.counterpartyEntityId}`);

      const newState = cloneEntityState(entityState);
      const { counterpartyEntityId, diffs, description } = entityTx.data;

      // Step 1: Validate invariant for all diffs
      for (const diff of diffs) {
        const sum = diff.leftDiff + diff.rightDiff + diff.collateralDiff;
        if (sum !== 0n) {
          logError("ENTITY_TX", `‚ùå INVARIANT-VIOLATION: leftDiff + rightDiff + collateralDiff = ${sum} (must be 0)`);
          throw new Error(`Settlement invariant violation: ${sum} !== 0`);
        }
      }

      // Step 2: Validate account exists
      if (!newState.accounts.has(counterpartyEntityId)) {
        logError("ENTITY_TX", `‚ùå No account exists with ${formatEntityId(counterpartyEntityId)}`);
        throw new Error(`No account with ${counterpartyEntityId}`);
      }

      // Step 3: Determine canonical left/right order
      const isLeft = entityState.entityId < counterpartyEntityId;
      const leftEntity = isLeft ? entityState.entityId : counterpartyEntityId;
      const rightEntity = isLeft ? counterpartyEntityId : entityState.entityId;

      console.log(`üè¶ Canonical order: left=${leftEntity.slice(0,10)}..., right=${rightEntity.slice(0,10)}...`);
      console.log(`üè¶ We are: ${isLeft ? 'LEFT' : 'RIGHT'}`);

      // Step 4: Get jurisdiction config
      const jurisdiction = entityState.config.jurisdiction;
      if (!jurisdiction) {
        throw new Error('No jurisdiction configured for this entity');
      }

      // Step 5: Convert diffs to contract format (keep as bigint - ethers handles conversion)
      const contractDiffs = diffs.map(d => ({
        tokenId: d.tokenId,
        leftDiff: d.leftDiff,
        rightDiff: d.rightDiff,
        collateralDiff: d.collateralDiff,
        ondeltaDiff: d.ondeltaDiff || 0n,
      }));

      console.log(`üè¶ Calling submitSettle with diffs:`, safeStringify(contractDiffs, 2));

      // Step 6: Call Depository.settle() - fire and forget (j-watcher handles result)
      try {
        const result = await submitSettle(jurisdiction, leftEntity, rightEntity, contractDiffs);
        console.log(`‚úÖ Settlement transaction sent: ${result.txHash}`);

        // Add message to chat
        addMessage(newState,
          `üè¶ ${description || 'Settlement'} tx: ${result.txHash.slice(0, 10)}... (block ${result.blockNumber})`
        );
      } catch (error) {
        logError("ENTITY_TX", `‚ùå Settlement transaction failed:`, error);
        addMessage(newState, `‚ùå Settlement failed: ${(error as Error).message}`);
        throw error; // Re-throw to trigger outer catch
      }

      return { newState, outputs: [] };
    }

    return { newState: entityState, outputs: [] };
  } catch (error) {
    log.error(`‚ùå Transaction execution error: ${error}`);
    return { newState: entityState, outputs: [] }; // Return unchanged state on error
  }
};


//runtime/entity-tx/validation.ts (37 lines)
// Security validation helpers: validateNonce, validateMessage
import { log } from '../utils';

export const validateNonce = (currentNonce: number, expectedNonce: number, from: string): boolean => {
  try {
    if (expectedNonce !== currentNonce + 1) {
      log.error(`‚ùå Invalid nonce from ${from}: expected ${currentNonce + 1}, got ${expectedNonce}`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`‚ùå Nonce validation error: ${error}`);
    return false;
  }
};

export const validateMessage = (message: string): boolean => {
  try {
    if (typeof message !== 'string') {
      log.error(`‚ùå Message must be string, got: ${typeof message}`);
      return false;
    }
    if (message.length > 1000) {
      log.error(`‚ùå Message too long: ${message.length} > 1000 chars`);
      return false;
    }
    if (message.length === 0) {
      log.error(`‚ùå Empty message not allowed`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`‚ùå Message validation error: ${error}`);
    return false;
  }
};


//runtime/entity-tx/financial.ts (33 lines)
import { AssetBalance } from '../types';

// Financial helpers: formatAssetAmount, addToReserves, subtractFromReserves
// Use unified financial utilities with ethers.js
export { formatAssetAmount } from '../financial-utils';

export const addToReserves = (
  reserves: Map<string, AssetBalance>,
  symbol: string,
  amount: bigint,
  _decimals: number,
  _contractAddress?: string,
): void => {
  const existing = reserves.get(symbol);
  if (existing) {
    existing.amount += amount;
  } else {
    reserves.set(symbol, { amount });
  }
};

export const subtractFromReserves = (reserves: Map<string, AssetBalance>, symbol: string, amount: bigint): boolean => {
  const existing = reserves.get(symbol);
  if (!existing || existing.amount < amount) {
    return false; // Insufficient balance
  }
  existing.amount -= amount;
  if (existing.amount === 0n) {
    reserves.delete(symbol);
  }
  return true;
};


//runtime/entity-tx/proposals.ts (35 lines)
import { EntityState, Proposal, ProposalAction } from '../types';
import { createHash, DEBUG } from '../utils';
import { safeStringify } from '../serialization-utils';

export const generateProposalId = (action: ProposalAction, proposer: string, entityState: EntityState): string => {
  const proposalData = safeStringify({
    type: action.type,
    data: action.data,
    proposer,
    timestamp: entityState.timestamp,
  });

  const hash = createHash('sha256').update(proposalData).digest('hex');
  return `prop_${hash.slice(0, 12)}`;
};

export const executeProposal = (entityState: EntityState, proposal: Proposal): EntityState => {
  if (proposal.action.type === 'collective_message') {
    const message = `[COLLECTIVE] ${proposal.action.data.message}`;
    if (DEBUG) console.log(`    üèõÔ∏è  Executing collective proposal: "${message}"`);

    const newMessages = [...entityState.messages, message];

    if (newMessages.length > 10) {
      newMessages.shift();
    }

    return {
      ...entityState,
      messages: newMessages,
    };
  }
  return entityState;
};


//runtime/entity-tx/j-events.ts (218 lines)
import { EntityState } from '../types';
import { DEBUG } from '../utils';
import { cloneEntityState, addMessage } from '../state-helpers';
import { getTokenInfo } from '../account-utils';
import { safeStringify } from '../serialization-utils';

/**
 * Jurisdiction event transaction data structure
 * These events come from blockchain watchers observing on-chain activity
 */
export interface JEventEntityTxData {
  from: string;  // Entity ID that observed the event
  event: {
    type: string;  // Event name (e.g., "ReserveUpdated", "SettlementProcessed")
    data: Record<string, unknown>;  // Event-specific data from blockchain
  };
  observedAt: number;  // Timestamp when event was observed (ms)
  blockNumber: number;  // Blockchain block number where event occurred
  transactionHash: string;  // Blockchain transaction hash
}

const getTokenSymbol = (tokenId: number): string => {
  return getTokenInfo(tokenId).symbol;
};

const getTokenDecimals = (tokenId: number): number => {
  return getTokenInfo(tokenId).decimals;
};

/**
 * Handle jurisdiction (blockchain) events
 * @param entityState - Current entity state
 * @param entityTxData - Validated J-event transaction data
 */
export const handleJEvent = (entityState: EntityState, entityTxData: JEventEntityTxData): EntityState => {
  const { from, event, observedAt, blockNumber, transactionHash } = entityTxData;

  // Reject events from blocks we've already processed - handle undefined jBlock
  const currentJBlock = entityState.jBlock || 0;
  console.log(`üîç J-EVENT-CHECK: ${event.type} block=${blockNumber} vs entity.jBlock=${currentJBlock} (raw=${entityState.jBlock}), from=${from}`);
  if (blockNumber <= currentJBlock) {
    console.log(`üîÑ IGNORING OLD J-EVENT: ${event.type} from block ${blockNumber} (entity already at j-block ${entityState.jBlock})`);
    return entityState;
  }
  console.log(`‚úÖ J-EVENT-ACCEPTED: ${event.type} block=${blockNumber} > entity.jBlock=${entityState.jBlock}, will process`);

  const newEntityState = cloneEntityState(entityState);
  // Update jBlock to current event block
  newEntityState.jBlock = blockNumber ?? (entityState.jBlock ?? 0);

  // Create elaborate j-event message with full details
  const timestamp = new Date(observedAt).toLocaleTimeString();
  const txHashShort = transactionHash ? transactionHash.slice(0, 10) + '...' : 'unknown';
  
  let elaborateMessage = '';
  
  if (event.type === 'reserve_transferred') {
    const { from: fromEntity, to: toEntity, tokenId, amount, direction } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);
    const decimals = getTokenDecimals(tokenId as number);
    const amountDisplay = (Number(amount) / (10 ** decimals)).toFixed(4);

    if (direction === 'sent') {
      elaborateMessage = `üí∏ ${from} observed RESERVE TRANSFER: Sent ${amountDisplay} ${tokenSymbol} to Entity ${(toEntity as string).slice(-1)}
üìç Block: ${blockNumber} | ‚è∞ ${timestamp} | üîó Tx: ${txHashShort}
üéØ Event: ReserveTransferred | üî¢ TokenID: ${tokenId} | üí∞ Amount: ${amount} (raw)`;
    } else {
      elaborateMessage = `üí∞ ${from} observed RESERVE TRANSFER: Received ${amountDisplay} ${tokenSymbol} from Entity ${(fromEntity as string).slice(-1)}
üìç Block: ${blockNumber} | ‚è∞ ${timestamp} | üîó Tx: ${txHashShort}
üéØ Event: ReserveTransferred | üî¢ TokenID: ${tokenId} | üí∞ Amount: ${amount} (raw)`;
    }
  } else if (event.type === 'ReserveUpdated') {
    const { tokenId, newBalance } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);
    const decimals = getTokenDecimals(tokenId as number);
    const balanceDisplay = (Number(newBalance) / (10 ** decimals)).toFixed(4);
    
    elaborateMessage = `üìä ${from} observed RESERVE UPDATE: ${tokenSymbol} balance now ${balanceDisplay} (accepted: event.block=${blockNumber} > entity.jBlock=${currentJBlock})
üìç Block: ${blockNumber} | ‚è∞ ${timestamp} | üîó Tx: ${txHashShort}
üéØ Event: ReserveUpdated | üî¢ TokenID: ${tokenId} | üí∞ New Balance: ${newBalance} (raw)
üè¶ Decimals: ${decimals} | üî§ Symbol: ${tokenSymbol}`;
  } else if (event.type === 'SettlementProcessed') {
    const { counterpartyEntityId, tokenId, ownReserve, counterpartyReserve, collateral, ondelta, side } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);
    const decimals = getTokenDecimals(tokenId as number);
    const ownBalanceDisplay = (Number(ownReserve) / (10 ** decimals)).toFixed(4);
    const counterpartyBalanceDisplay = (Number(counterpartyReserve) / (10 ** decimals)).toFixed(4);
    const collateralDisplay = (Number(collateral) / (10 ** decimals)).toFixed(4);

    elaborateMessage = `‚öñÔ∏è ${from} observed SETTLEMENT: ${tokenSymbol} settled with Entity ${(counterpartyEntityId as string).slice(-4)}
üìç Block: ${blockNumber} | ‚è∞ ${timestamp} | üîó Tx: ${txHashShort}
üéØ Event: SettlementProcessed | üî¢ TokenID: ${tokenId} | üë§ Side: ${side}
üí∞ Own Reserve: ${ownBalanceDisplay} | ü§ù Counterparty: ${counterpartyBalanceDisplay}
üîí Collateral: ${collateralDisplay} | üìä OnDelta: ${ondelta}`;
  } else {
    elaborateMessage = `üîç ${from} observed J-EVENT: ${event.type}
üìç Block: ${blockNumber} | ‚è∞ ${timestamp} | üîó Tx: ${txHashShort}
üìã Data: ${safeStringify(event.data, 2)}`;
  }

  addMessage(newEntityState, elaborateMessage);

  if (event.type === 'ReserveUpdated') {
    const { entity, tokenId, newBalance } = event.data;

    if (entity === entityState.entityId) {
      newEntityState.reserves.set(String(tokenId), BigInt(newBalance as string | number | bigint));
      if (DEBUG) console.log(`‚úÖ Reserve updated for ${(entity as string).slice(0,10)}...: Token ${tokenId} new balance is ${newBalance}`);
    }
  } else if (event.type === 'reserve_transferred') {
    const { tokenId, amount, direction } = event.data;

    // Update reserves based on transfer direction - entityState guaranteed by validation
    if (direction === 'sent') {
      const currentReserve = newEntityState.reserves.get(String(tokenId));
      if (currentReserve === undefined) {
        // Initialize reserve to 0n if not present (new token)
        newEntityState.reserves.set(String(tokenId), 0n);
        console.warn(`üîç RESERVE-INIT: Initialized new token ${tokenId} reserve to 0n`);
      }
      const actualReserve = newEntityState.reserves.get(String(tokenId))!; // Now guaranteed to exist
      const newAmount = actualReserve - BigInt(amount as string | number | bigint);
      newEntityState.reserves.set(String(tokenId), newAmount >= 0n ? newAmount : 0n);
      // Message already added above
    } else if (direction === 'received') {
      const currentReserve = newEntityState.reserves.get(String(tokenId));
      if (currentReserve === undefined) {
        // Initialize reserve to 0n if not present (new token)
        newEntityState.reserves.set(String(tokenId), 0n);
        console.warn(`üîç RESERVE-INIT: Initialized new token ${tokenId} reserve to 0n`);
      }
      const actualReserve = newEntityState.reserves.get(String(tokenId))!; // Now guaranteed to exist
      newEntityState.reserves.set(String(tokenId), actualReserve + BigInt(amount as string | number | bigint));
      // Message already added above
    }
    
    if (DEBUG) console.log(`‚úÖ Reserve transfer processed: ${direction} ${amount} token ${tokenId}`);
  } else if (event.type === 'SettlementProcessed') {
    const { counterpartyEntityId, tokenId, ownReserve, counterpartyReserve, collateral, ondelta, side } = event.data;

    // Update own reserves based on the settlement
    newEntityState.reserves.set(String(tokenId), BigInt(ownReserve as string | number | bigint));

    // Create accountInput to feed into a-machine for bilateral consensus
    // This enables the settlement event to be processed by the account machine
    const accountInput = {
      fromEntityId: entityState.entityId,
      toEntityId: counterpartyEntityId as string,
      accountTx: {
        type: 'account_settle' as const,
        data: {
          tokenId: Number(tokenId),
          ownReserve: ownReserve as unknown,
          counterpartyReserve: counterpartyReserve as unknown,
          collateral: collateral as unknown,
          ondelta: ondelta as unknown,
          side: side as unknown,
          blockNumber: blockNumber,
          transactionHash: transactionHash
        }
      },
      metadata: {
        purpose: 'settlement_consensus',
        description: `Settlement event from j-machine for token ${tokenId}`
      }
    };

    // Add to entity's account inputs queue for processing
    // This will be processed by the account handler to update bilateral account state
    if (!newEntityState.accountInputQueue) {
      newEntityState.accountInputQueue = [];
    }
    newEntityState.accountInputQueue.push(accountInput as any);

    if (DEBUG) console.log(`‚úÖ SettlementProcessed: Created accountInput for token ${tokenId} with counterparty ${(counterpartyEntityId as string).slice(0,10)}...`);
  } else if (event.type === 'TransferReserveToCollateral') {
    const { receivingEntity, counterentity, collateral, ondelta, tokenId, side } = event.data;

    // Determine counterparty from our perspective
    const counterpartyEntityId = (side === 'receiving' ? counterentity : receivingEntity) as string;

    // Note: Reserve updates happen via separate ReserveUpdated event, so we don't update reserves here

    // Create accountInput to update bilateral account state
    const accountInput = {
      fromEntityId: entityState.entityId,
      toEntityId: counterpartyEntityId,
      accountTx: {
        type: 'reserve_to_collateral' as const,
        data: {
          tokenId: Number(tokenId),
          collateral: collateral as unknown, // Absolute collateral value from contract
          ondelta: ondelta as unknown,       // Absolute ondelta value from contract
          side: side as unknown,             // 'receiving' or 'counterparty'
          blockNumber: blockNumber,
          transactionHash: transactionHash
        }
      },
      metadata: {
        purpose: 'r2c_consensus',
        description: `R‚ÜíC event from j-machine for token ${tokenId}`
      }
    };

    // Add to entity's account inputs queue
    if (!newEntityState.accountInputQueue) {
      newEntityState.accountInputQueue = [];
    }
    newEntityState.accountInputQueue.push(accountInput as any);

    if (DEBUG) console.log(`‚úÖ TransferReserveToCollateral: Created accountInput for token ${tokenId} with counterparty ${counterpartyEntityId.slice(0,10)}...`);
  } else {
    addMessage(newEntityState, `‚ö†Ô∏è Unhandled j-event type: ${event.type}`);
  }

  return newEntityState;
};


//runtime/account-tx/index.ts (10 lines)
/**
 * Account Transaction Module Exports
 * Modular organization matching entity-tx pattern
 */

export { processAccountTx } from './apply';
export { handleAddDelta } from './handlers/add-delta';
export { handleSetCreditLimit } from './handlers/set-credit-limit';
export { handleDirectPayment } from './handlers/direct-payment';


//runtime/account-tx/apply.ts (72 lines)
/**
 * Account Transaction Dispatcher
 * Routes AccountTx to appropriate handlers (like entity-tx/apply.ts pattern)
 */

import { AccountMachine, AccountTx } from '../types';
import { handleAddDelta } from './handlers/add-delta';
import { handleSetCreditLimit } from './handlers/set-credit-limit';
import { handleDirectPayment } from './handlers/direct-payment';
import { handleReserveToCollateral } from './handlers/reserve-to-collateral';
import { handleRequestWithdrawal } from './handlers/request-withdrawal';
import { handleApproveWithdrawal } from './handlers/approve-withdrawal';
import { handleRequestRebalance } from './handlers/request-rebalance';

/**
 * Process single AccountTx through bilateral consensus
 * @param accountMachine - The account machine state
 * @param accountTx - The transaction to process
 * @param isOurFrame - Whether we're processing our own frame (vs counterparty's)
 * @returns Result with success, events, and optional error
 */
export function processAccountTx(
  accountMachine: AccountMachine,
  accountTx: AccountTx,
  isOurFrame: boolean = true
): { success: boolean; events: string[]; error?: string } {
  console.log(`üîÑ Processing ${accountTx.type} for ${accountMachine.counterpartyEntityId.slice(-4)} (ourFrame: ${isOurFrame})`);

  // Route to appropriate handler based on transaction type
  switch (accountTx.type) {
    case 'add_delta':
      return handleAddDelta(accountMachine, accountTx, isOurFrame);

    case 'set_credit_limit':
      return handleSetCreditLimit(accountMachine, accountTx, isOurFrame);

    case 'direct_payment':
      return handleDirectPayment(accountMachine, accountTx, isOurFrame);

    case 'account_payment':
      // Legacy type - not used in new implementation
      console.warn(`‚ö†Ô∏è account_payment type is deprecated`);
      return { success: true, events: [] };

    case 'account_settle':
      // Blockchain settlement - handled separately in entity-tx/handlers/account.ts
      console.log(`üí∞ account_settle processed externally`);
      return { success: true, events: [`‚öñÔ∏è Settlement processed`] };

    case 'reserve_to_collateral':
      return handleReserveToCollateral(accountMachine, accountTx as Extract<AccountTx, { type: 'reserve_to_collateral' }>);

    case 'request_withdrawal':
      return handleRequestWithdrawal(accountMachine, accountTx as Extract<AccountTx, { type: 'request_withdrawal' }>, isOurFrame);

    case 'approve_withdrawal':
      return handleApproveWithdrawal(accountMachine, accountTx as Extract<AccountTx, { type: 'approve_withdrawal' }>);

    case 'request_rebalance':
      return handleRequestRebalance(accountMachine, accountTx as Extract<AccountTx, { type: 'request_rebalance' }>);

    case 'account_frame':
      // This should never be called - frames are handled by frame-level consensus
      console.error(`‚ùå FATAL: account_frame should not be in accountTxs array!`);
      return { success: false, error: 'account_frame is not a transaction type', events: [] };

    default:
      // Type-safe error handling for unknown AccountTx types
      return { success: false, error: `Unknown accountTx type`, events: [] };
  }
}


//runtime/routing/graph.ts (117 lines)
/**
 * Network Graph Structure for Payment Routing
 * Builds from gossip profiles to create routing graph
 */

import type { Profile } from '../gossip';

export interface ChannelEdge {
  from: string;
  to: string;
  tokenId: number;
  capacity: bigint;
  baseFee: bigint; // Base fee in smallest unit
  feePPM: number; // Fee rate in parts per million
  disabled: boolean;
}

export interface NetworkGraph {
  nodes: Set<string>; // Entity IDs
  edges: Map<string, ChannelEdge[]>; // from -> edges[]

  // Quick lookup for channel capacities
  channelCapacities: Map<string, {
    outbound: bigint;
    inbound: bigint;
  }>;
}

/**
 * Build network graph from gossip profiles
 */
export function buildNetworkGraph(
  profiles: Map<string, Profile>,
  tokenId: number
): NetworkGraph {
  const nodes = new Set<string>();
  const edges = new Map<string, ChannelEdge[]>();
  const channelCapacities = new Map<string, {
    outbound: bigint;
    inbound: bigint;
  }>();

  // Add all entities as nodes
  for (const profile of profiles.values()) {
    nodes.add(profile.entityId);
  }

  // Build edges from account relationships
  for (const profile of profiles.values()) {
    const fromEntity = profile.entityId;
    const fromEdges: ChannelEdge[] = [];

    if (profile.accounts) {
      for (const account of profile.accounts) {
        const toEntity = account.counterpartyId;

        // Only add if counterparty exists in network
        if (!nodes.has(toEntity)) continue;

        // Get capacities for this token
        const tokenCapacity = account.tokenCapacities.get(tokenId);
        if (!tokenCapacity || tokenCapacity.outCapacity === 0n) continue;

        // Get fee configuration from profile with explicit validation
        const metadata = profile.metadata;
        if (!metadata) {
          console.warn(`üö® ROUTING-SAFETY: Entity ${fromEntity} has no metadata, using safe defaults`);
        }
        const baseFee = metadata?.baseFee ?? 0n; // Explicit null/undefined check
        const feePPM = metadata?.routingFeePPM ?? 100; // Explicit default: 100 PPM (0.01%)

        // Create edge
        const edge: ChannelEdge = {
          from: fromEntity,
          to: toEntity,
          tokenId,
          capacity: tokenCapacity.outCapacity,
          baseFee,
          feePPM,
          disabled: false,
        };

        fromEdges.push(edge);

        // Store channel capacities
        const channelKey = `${fromEntity}:${toEntity}:${tokenId}`;
        channelCapacities.set(channelKey, {
          outbound: tokenCapacity.outCapacity,
          inbound: tokenCapacity.inCapacity,
        });
      }
    }

    if (fromEdges.length > 0) {
      edges.set(fromEntity, fromEdges);
    }
  }

  return {
    nodes,
    edges,
    channelCapacities,
  };
}

/**
 * Get edge between two nodes
 */
export function getEdge(
  graph: NetworkGraph,
  from: string,
  to: string,
  tokenId: number
): ChannelEdge | undefined {
  const edges = graph.edges.get(from) ?? [];  // Explicit undefined handling
  return edges.find(e => e.to === to && e.tokenId === tokenId);
}

//runtime/routing/pathfinding.ts (227 lines)
/**
 * Dijkstra Pathfinding Implementation for Payment Routing
 * Finds optimal payment routes through the network
 */

import type { NetworkGraph, ChannelEdge } from './graph';
import { getEdge } from './graph';

export interface PaymentRoute {
  path: string[]; // Array of entity IDs from source to target
  hops: Array<{
    from: string;
    to: string;
    fee: bigint;
    feePPM: number;
  }>;
  totalFee: bigint;
  totalAmount: bigint; // Amount including fees
  probability: number; // Success probability estimate (0-1)
}

/**
 * Priority queue entry for Dijkstra
 */
interface QueueEntry {
  cost: bigint;
  node: string;
  path: string[];
  totalFee: bigint;
}

export class PathFinder {
  constructor(private graph: NetworkGraph) {}

  /**
   * Find payment routes using modified Dijkstra algorithm
   * Returns up to maxRoutes sorted by total fees
   */
  findRoutes(
    source: string,
    target: string,
    amount: bigint,
    tokenId: number,
    maxRoutes: number = 100
  ): PaymentRoute[] {
    if (source === target) return [];
    if (!this.graph.nodes.has(source) || !this.graph.nodes.has(target)) return [];

    const routes: PaymentRoute[] = [];
    const visited = new Map<string, Set<string>>(); // node -> set of previous nodes

    // Priority queue: [cost, node, path, totalFee]
    const queue: QueueEntry[] = [{
      cost: 0n,
      node: source,
      path: [source],
      totalFee: 0n,
    }];

    while (queue.length > 0 && routes.length < maxRoutes) {
      // Sort by cost (simple priority queue)
      queue.sort((a, b) => {
        if (a.cost < b.cost) return -1;
        if (a.cost > b.cost) return 1;
        return 0;
      });

      const current = queue.shift()!;

      // Check if we've visited this node from this previous node
      const prevNode = current.path[current.path.length - 2] || 'START';
      const visitedFrom = visited.get(current.node) || new Set();
      if (visitedFrom.has(prevNode)) continue;
      visitedFrom.add(prevNode);
      visited.set(current.node, visitedFrom);

      // Found target - build route
      if (current.node === target) {
        const route = this.buildRoute(current.path, amount, tokenId);
        if (route) {
          routes.push(route);
        }
        continue;
      }

      // Explore neighbors
      const edges = this.graph.edges.get(current.node) ?? []; // Explicit undefined handling
      for (const edge of edges) {
        // Skip if wrong token or disabled
        if (edge.tokenId !== tokenId || edge.disabled) continue;

        // Skip if already in path (no loops)
        if (current.path.includes(edge.to)) continue;

        // Calculate required amount at this hop (working backwards)
        const requiredAmount = this.calculateRequiredAmount(
          amount,
          [...current.path, edge.to],
          target,
          tokenId
        );

        // Skip if insufficient capacity
        if (requiredAmount > edge.capacity) continue;

        // Calculate fee for this edge
        const edgeFee = this.calculateFee(edge, requiredAmount);
        const newTotalFee = current.totalFee + edgeFee;

        // Add to queue with updated cost
        queue.push({
          cost: newTotalFee, // Use total fee as cost
          node: edge.to,
          path: [...current.path, edge.to],
          totalFee: newTotalFee,
        });
      }
    }

    // Sort routes by total fee
    return routes.sort((a, b) => {
      if (a.totalFee < b.totalFee) return -1;
      if (a.totalFee > b.totalFee) return 1;
      return 0;
    });
  }

  /**
   * Calculate fee for an edge
   */
  private calculateFee(edge: ChannelEdge, amount: bigint): bigint {
    // Fee = baseFee + (amount * feePPM / 1,000,000)
    const proportionalFee = (amount * BigInt(edge.feePPM)) / 1_000_000n;
    return edge.baseFee + proportionalFee;
  }

  /**
   * Calculate required amount at each hop (working backwards from target)
   */
  private calculateRequiredAmount(
    finalAmount: bigint,
    path: string[],
    target: string,
    tokenId: number
  ): bigint {
    let amount = finalAmount;

    // Work backwards from target to source
    for (let i = path.length - 1; i > 0; i--) {
      if (path[i] === target) continue; // Skip target node

      const edge = getEdge(this.graph, path[i - 1]!, path[i]!, tokenId);
      if (edge) {
        // Add fee that this hop will charge
        amount = amount + this.calculateFee(edge, amount);
      }
    }

    return amount;
  }

  /**
   * Build complete route details from path
   */
  private buildRoute(
    path: string[],
    amount: bigint,
    tokenId: number
  ): PaymentRoute | null {
    if (path.length < 2) return null;

    const hops: PaymentRoute['hops'] = [];
    let totalFee = 0n;
    let currentAmount = amount;

    // Build hops forward, calculating fees
    for (let i = 0; i < path.length - 1; i++) {
      const edge = getEdge(this.graph, path[i]!, path[i + 1]!, tokenId);
      if (!edge) return null;

      const fee = this.calculateFee(edge, currentAmount);
      hops.push({
        from: path[i]!,
        to: path[i + 1]!,
        fee,
        feePPM: edge.feePPM,
      });

      totalFee += fee;
      currentAmount += fee; // Next hop needs more to cover this fee
    }

    // Calculate success probability
    const probability = this.calculateProbability(path, amount, tokenId);

    return {
      path,
      hops,
      totalFee,
      totalAmount: amount + totalFee,
      probability,
    };
  }

  /**
   * Calculate success probability based on channel utilization
   */
  private calculateProbability(
    path: string[],
    amount: bigint,
    tokenId: number
  ): number {
    let probability = 1.0;

    for (let i = 0; i < path.length - 1; i++) {
      const edge = getEdge(this.graph, path[i]!, path[i + 1]!, tokenId);
      if (edge && edge.capacity > 0n) {
        const utilization = Number(amount) / Number(edge.capacity);
        // Higher utilization = lower success probability
        // Using exponential decay: e^(-2 * utilization)
        probability *= Math.exp(-2 * utilization);
      }
    }

    return Math.max(0.01, Math.min(1.0, probability));
  }
}

//runtime/state-helpers.ts (314 lines)
/**
 * XLN State Management Helpers
 * Utilities for entity replica cloning, snapshots, and state persistence
 */

import { encode } from './snapshot-coder';
import type { EntityInput, EntityReplica, EntityState, Env, EnvSnapshot, RuntimeInput, AccountMachine } from './types';
import type { Profile } from './gossip';
import { DEBUG } from './utils';
import { validateEntityState } from './validation-utils';
import { safeStringify, safeParse } from './serialization-utils';

// Message size limit for snapshot efficiency
const MESSAGE_LIMIT = 10;

/**
 * Add message to EntityState with automatic size limiting
 * Prevents unbounded message array growth that causes snapshot bloat
 */
export function addMessage(state: EntityState, message: string): void {
  state.messages.push(message);
  if (state.messages.length > MESSAGE_LIMIT) {
    state.messages.shift(); // Remove oldest message
  }
}

/**
 * Add multiple messages with size limiting
 */
export function addMessages(state: EntityState, messages: string[]): void {
  for (const msg of messages) {
    addMessage(state, msg);
  }
}

// === CLONING UTILITIES ===
export const cloneMap = <K, V>(map: Map<K, V>) => new Map(map);
export const cloneArray = <T>(arr: T[]) => [...arr];

/**
 * Creates a safe deep clone of entity state with guaranteed jBlock preservation
 * This prevents the jBlock corruption bugs that occur with manual state spreading
 */
export function cloneEntityState(entityState: EntityState): EntityState {
  // jBlock validation (no logging)

  // Use structuredClone for deep cloning with fallback
  try {
    const cloned = structuredClone(entityState);

    // CRITICAL: Validate jBlock was preserved correctly
    if (typeof cloned.jBlock !== 'number') {
      console.error(`üí• CLONE-CORRUPTION: structuredClone corrupted jBlock!`);
      console.error(`üí•   Original: ${entityState.jBlock} (${typeof entityState.jBlock})`);
      console.error(`üí•   Cloned: ${cloned.jBlock} (${typeof cloned.jBlock})`);
      cloned.jBlock = entityState.jBlock ?? 0; // Force fix
    }

    // CLONE-SUCCESS removed

    // VALIDATE AT SOURCE: Guarantee type safety from this point forward
    return validateEntityState(cloned, 'cloneEntityState.structuredClone');
  } catch (error) {
    // structuredClone warning removed - browser limitation, not actionable
    const manual = manualCloneEntityState(entityState);
    // MANUAL-CLONE success removed - too noisy

    // VALIDATE AT SOURCE: Guarantee type safety from manual clone path too
    return validateEntityState(manual, 'cloneEntityState.manual');
  }
}

/**
 * Manual entity state cloning with explicit jBlock preservation
 * Fallback for environments that don't support structuredClone
 */
function manualCloneEntityState(entityState: EntityState): EntityState {
  return {
    ...entityState,
    nonces: cloneMap(entityState.nonces),
    messages: cloneArray(entityState.messages),
    proposals: new Map(
      Array.from(entityState.proposals.entries()).map(([id, proposal]) => [
        id,
        { ...proposal, votes: cloneMap(proposal.votes) },
      ]),
    ),
    reserves: cloneMap(entityState.reserves),
    accounts: new Map(
      Array.from(entityState.accounts.entries()).map(([id, account]) => [
        id,
        {
          ...account,
          mempool: cloneArray(account.mempool),
          deltas: cloneMap(account.deltas),
          proofHeader: { ...account.proofHeader },
          proofBody: {
            tokenIds: [...account.proofBody.tokenIds],
            deltas: [...account.proofBody.deltas],
          },
        },
      ]),
    ),
    accountInputQueue: cloneArray(entityState.accountInputQueue || []),
    // CRITICAL: Explicit jBlock preservation for financial integrity
    jBlock: entityState.jBlock ?? 0,
  };
}

/**
 * Deep clone entity replica with all nested state properly cloned
 * Uses cloneEntityState as the entry point for state cloning
 */
export const cloneEntityReplica = (replica: EntityReplica): EntityReplica => {
  return {
    entityId: replica.entityId,
    signerId: replica.signerId,
    state: cloneEntityState(replica.state), // Use unified entity state cloning
    mempool: cloneArray(replica.mempool),
    ...(replica.proposal && {
      proposal: {
        height: replica.proposal.height,
        txs: cloneArray(replica.proposal.txs),
        hash: replica.proposal.hash,
        newState: replica.proposal.newState,
        signatures: cloneMap(replica.proposal.signatures),
      }
    }),
    ...(replica.lockedFrame && {
      lockedFrame: {
        height: replica.lockedFrame.height,
        txs: cloneArray(replica.lockedFrame.txs),
        hash: replica.lockedFrame.hash,
        newState: replica.lockedFrame.newState,
        signatures: cloneMap(replica.lockedFrame.signatures),
      }
    }),
    isProposer: replica.isProposer,
    ...(replica.sentTransitions !== undefined && { sentTransitions: replica.sentTransitions }),
    ...(replica.position && { position: { ...replica.position } }),
  };
};

export const captureSnapshot = (
  env: Env,
  envHistory: EnvSnapshot[],
  db: any,
  runtimeInput: RuntimeInput,
  runtimeOutputs: EntityInput[],
  description: string,
): void => {
  const gossipProfiles = env.gossip?.getProfiles
    ? env.gossip.getProfiles().map((profile: Profile) => {
        try {
          // structuredClone keeps nested data without mutating live gossip state
          return structuredClone(profile);
        } catch (error) {
          try {
            return safeParse(safeStringify(profile));
          } catch {
            return profile;
          }
        }
      })
    : [];

  const snapshot: EnvSnapshot = {
    height: env.height,
    timestamp: env.timestamp,
    replicas: new Map(Array.from(env.replicas.entries()).map(([key, replica]) => [key, cloneEntityReplica(replica)])),
    runtimeInput: {
      runtimeTxs: [...runtimeInput.runtimeTxs],
      entityInputs: runtimeInput.entityInputs.map(input => ({
        entityId: input.entityId,
        signerId: input.signerId,
        ...(input.entityTxs && { entityTxs: [...input.entityTxs] }),
        ...(input.precommits && { precommits: new Map(input.precommits) }),
        ...(input.proposedFrame && { proposedFrame: input.proposedFrame }),
      })),
    },
    runtimeOutputs: runtimeOutputs.map(output => ({
      entityId: output.entityId,
      signerId: output.signerId,
      ...(output.entityTxs && { entityTxs: [...output.entityTxs] }),
      ...(output.precommits && { precommits: new Map(output.precommits) }),
      ...(output.proposedFrame && { proposedFrame: output.proposedFrame }),
    })),
    description,
    gossip: { profiles: gossipProfiles },
  };

  envHistory.push(snapshot);

  // --- SNAPSHOT SIZE MONITORING ---
  const snapshotBuffer = encode(snapshot);
  const snapshotSize = snapshotBuffer.length;
  const sizeMB = (snapshotSize / 1024 / 1024).toFixed(2);

  // Alert if snapshot exceeds 1MB threshold
  if (snapshotSize > 1_000_000) {
    console.warn(`üì¶ LARGE SNAPSHOT: ${sizeMB}MB at height ${snapshot.height}`);
    console.warn(`   Replicas: ${snapshot.replicas.size}`);

    // Log per-entity diagnostics
    for (const [key, replica] of snapshot.replicas) {
      const msgCount = replica.state.messages?.length || 0;
      const accountCount = replica.state.accounts?.size || 0;
      if (msgCount > 20 || accountCount > 10) {
        console.warn(`   ${key.slice(0,25)}...: ${msgCount} msgs, ${accountCount} accounts`);
      }
    }
  }

  // --- PERSISTENCE WITH BATCH OPERATIONS ---
  // Try to save, but gracefully handle IndexedDB unavailable (incognito mode, etc)
  try {
    const batch = db.batch();
    batch.put(Buffer.from(`snapshot:${snapshot.height}`), snapshotBuffer);
    batch.put(Buffer.from('latest_height'), Buffer.from(snapshot.height.toString()));
    batch.write();
  } catch (error) {
    // Silent fail - IndexedDB unavailable (incognito) or full - continue anyway
  }

  if (DEBUG) {
    console.log(`üì∏ Snapshot ${snapshot.height}: ${sizeMB}MB - "${description}" (total: ${envHistory.length})`);
    if (runtimeInput.runtimeTxs.length > 0) {
      console.log(`    üñ•Ô∏è  RuntimeTxs: ${runtimeInput.runtimeTxs.length}`);
      runtimeInput.runtimeTxs.forEach((tx, i) => {
        console.log(
          `      ${i + 1}. ${tx.type} ${tx.entityId}:${tx.signerId} (${tx.data.isProposer ? 'proposer' : 'validator'})`,
        );
      });
    }
    if (runtimeInput.entityInputs.length > 0) {
      console.log(`    üì® EntityInputs: ${runtimeInput.entityInputs.length}`);
      runtimeInput.entityInputs.forEach((input, i) => {
        const parts = [];
        if (input.entityTxs?.length) parts.push(`${input.entityTxs.length} txs`);
        if (input.precommits?.size) parts.push(`${input.precommits.size} precommits`);
        if (input.proposedFrame) parts.push(`frame: ${input.proposedFrame.hash.slice(0, 10)}...`);
        console.log(`      ${i + 1}. ${input.entityId}:${input.signerId} (${parts.join(', ') || 'empty'})`);
      });
    }
  }
};

// === ACCOUNT MACHINE HELPERS ===

/**
 * Clone AccountMachine for validation (replaces dryRun pattern)
 */
export function cloneAccountMachine(account: AccountMachine): AccountMachine {
  try {
    return structuredClone(account);
  } catch (error) {
    // structuredClone warning removed - browser limitation
    return manualCloneAccountMachine(account);
  }
}

/**
 * Manual AccountMachine cloning
 */
function manualCloneAccountMachine(account: AccountMachine): AccountMachine {
  const result: AccountMachine = {
    counterpartyEntityId: account.counterpartyEntityId,
    mempool: [...account.mempool],
    currentFrame: {
      ...account.currentFrame,
      tokenIds: [...account.currentFrame.tokenIds],
      deltas: [...account.currentFrame.deltas],
    },
    sentTransitions: account.sentTransitions,
    ackedTransitions: account.ackedTransitions,
    deltas: new Map(Array.from(account.deltas.entries()).map(([key, delta]) => [key, { ...delta }])),
    globalCreditLimits: { ...account.globalCreditLimits },
    currentHeight: account.currentHeight,
    pendingSignatures: [...account.pendingSignatures],
    rollbackCount: account.rollbackCount,
    sendCounter: account.sendCounter,
    receiveCounter: account.receiveCounter,
    frameHistory: [...account.frameHistory], // Clone frame history array
    proofHeader: { ...account.proofHeader },
    proofBody: {
      ...account.proofBody,
      tokenIds: [...account.proofBody.tokenIds],
      deltas: [...account.proofBody.deltas],
    },
    pendingWithdrawals: new Map(account.pendingWithdrawals), // Phase 2: Clone withdrawal tracking
    requestedRebalance: new Map(account.requestedRebalance), // Phase 3: Clone rebalance hints
  };

  // Add optional properties if they exist
  if (account.pendingFrame) {
    result.pendingFrame = {
      ...account.pendingFrame,
      accountTxs: [...account.pendingFrame.accountTxs],
      tokenIds: [...account.pendingFrame.tokenIds],
      deltas: [...account.pendingFrame.deltas]
    };
  }

  if (account.clonedForValidation) {
    result.clonedForValidation = manualCloneAccountMachine(account.clonedForValidation);
  }

  if (account.hankoSignature) {
    result.hankoSignature = account.hankoSignature;
  }

  return result;
}


//runtime/snapshot-coder.ts (240 lines)
/**
 * Unified encoder/decoder for snapshots with configurable JSON/msgpack methods.
 * Set USE_MSGPACK = true for msgpack with integrity hashing, false for simple JSON.
 */

// Configuration flag - change this to test different encoders
const USE_MSGPACK = false;

// JSON encoder imports and setup
const jsonReplacer = (key: string, value: any) => {
  if (key === 'clonedForValidation') {
    return undefined;
  }
  if (value instanceof Map) {
    return { _dataType: 'Map', value: Array.from(value.entries()) };
  }
  if (typeof value === 'bigint') {
    return { _dataType: 'BigInt', value: value.toString() };
  }
  return value;
};

const jsonReviver = (_key: string, value: any) => {
  if (typeof value === 'object' && value !== null) {
    if (value._dataType === 'Map') return new Map(value.value);
    if (value._dataType === 'BigInt') return BigInt(value.value);
  }
  return value;
};

// Msgpack encoder setup - lazy initialization to avoid browser issues
let packr: any = null;
let sha256: any = null;

// Lazy initialization function for msgpack
const initMsgpack = async () => {
  if (packr) return packr; // Already initialized

  try {
    const { Packr } = await import('msgpackr');
    const { createHash } = await import('./utils.js');

    sha256 = (data: Buffer): Buffer => createHash('sha256').update(data).digest();

    packr = new Packr({
      structures: [[BigInt, (value: bigint) => value.toString(), (str: string) => BigInt(str)]],
    });

    return packr;
  } catch (error) {
    console.warn('Failed to load msgpack dependencies:', error);
    throw error;
  }
};

/**
 * Recursively traverses an object and converts any Map instances into
 * arrays of [key, value] pairs, sorted by key. This is essential for
 * ensuring that serialization is deterministic.
 */
function deterministicDeepSort(obj: any): any {
  if (obj instanceof Map) {
    const entries = Array.from(obj.entries());
    // Sort entries by key to ensure deterministic output.
    entries.sort((a, b) => (a[0] < b[0] ? -1 : 1));
    // Recursively process values in case they contain Maps.
    return entries.map(([k, v]) => [k, deterministicDeepSort(v)]);
  }
  if (Array.isArray(obj)) {
    return obj.map(deterministicDeepSort);
  }
  if (typeof obj === 'object' && obj !== null) {
    const newObj: { [key: string]: any } = {};
    const sortedKeys = Object.keys(obj).sort();
    for (const key of sortedKeys) {
      newObj[key] = deterministicDeepSort(obj[key]);
    }
    return newObj;
  }
  return obj;
}

/**
 * Reconstructs Map objects from the key-sorted arrays created by deterministicDeepSort.
 * This is the reverse operation used during deserialization.
 */
function reconstructMaps(obj: any): any {
  if (Array.isArray(obj)) {
    // Check if it's a key-value pair array that should be a Map
    const isMapArray = obj.every(item => Array.isArray(item) && item.length === 2);
    if (isMapArray) {
      return new Map(obj.map(([k, v]) => [k, reconstructMaps(v)]));
    }
    return obj.map(reconstructMaps);
  }
  if (typeof obj === 'object' && obj !== null) {
    const newObj: { [key: string]: any } = {};
    for (const key in obj) {
      newObj[key] = reconstructMaps(obj[key]);
    }
    return newObj;
  }
  return obj;
}

// Define the structure of the persisted tuple for msgpack format
type SnapshotTuple = [
  number, // height
  any, // serverInput
  Buffer, // hashOfSerializedReplicas
  any, // deterministically sorted replicas
];

/**
 * Encodes data using the configured method (JSON or msgpack)
 */
export const encode = (data: any): Buffer => {
  // ENCODE validation removed - too verbose
  // Auto-fix jBlock corruption if needed
  if (data && data.replicas) {
    for (const [replicaKey, replica] of data.replicas.entries()) {
      if (replica && replica.state && typeof replica.state.jBlock !== 'number') {
        console.error(`üí• CRITICAL: Invalid jBlock for ${replicaKey.slice(0,20)}... - auto-fixing to 0`);
        replica.state.jBlock = 0;
      }
    }
  }

  if (USE_MSGPACK) {
    // For msgpack mode, we need to use async initialization
    // This should not happen in current config (USE_MSGPACK = false)
    throw new Error('Msgpack mode requires async initialization - use encodeAsync instead');
  } else {
    // Simple JSON encoding
    return Buffer.from(JSON.stringify(data, jsonReplacer));
  }
};

/**
 * Decodes data using the configured method (JSON or msgpack)
 */
export const decode = (buffer: Buffer): any => {
  if (USE_MSGPACK) {
    // For msgpack mode, we need to use async initialization
    // This should not happen in current config (USE_MSGPACK = false)
    throw new Error('Msgpack mode requires async initialization - use decodeAsync instead');
  } else {
    // Simple JSON decoding
    const decoded = JSON.parse(buffer.toString(), jsonReviver);

    // CRITICAL: Validate financial state integrity after deserialization
    if (decoded && decoded.replicas) {
      for (const [replicaKey, replica] of decoded.replicas.entries()) {
        if (replica && replica.state) {
          const jBlock = replica.state.jBlock;
          if (typeof jBlock !== 'number') {
            // IMPORTANT: Don't reset to 0 - this causes re-processing of ALL events!
            // If jBlock is missing, use the snapshot height as a safe fallback
            const fallbackJBlock = Number(decoded.height) || 0;
            console.warn(`‚ö†Ô∏è jBlock missing for replica ${replicaKey}, using height ${fallbackJBlock} as fallback`);
            replica.state.jBlock = fallbackJBlock;
          }
        }
      }
    }

    return decoded;
  }
};

/**
 * Async version for msgpack encoding
 */
export const encodeAsync = async (data: any): Promise<Buffer> => {
  if (USE_MSGPACK) {
    const packrInstance = await initMsgpack();

    // Msgpack encoding with integrity hashing
    const sortedReplicas = deterministicDeepSort(data.replicas || new Map());
    const serializedReplicas = packrInstance.pack(sortedReplicas);
    const hashOfReplicas = sha256(serializedReplicas);

    const snapshotTuple: SnapshotTuple = [
      data.height || 0,
      deterministicDeepSort(data.serverInput || {}),
      hashOfReplicas,
      sortedReplicas,
    ];

    return packrInstance.pack(snapshotTuple);
  } else {
    // Fallback to sync JSON encoding
    return encode(data);
  }
};

/**
 * Async version for msgpack decoding
 */
export const decodeAsync = async (buffer: Buffer): Promise<any> => {
  if (USE_MSGPACK) {
    const packrInstance = await initMsgpack();

    // Msgpack decoding with integrity verification
    const decodedTuple = packrInstance.unpack(buffer) as SnapshotTuple;

    if (!Array.isArray(decodedTuple) || decodedTuple.length !== 4) {
      throw new Error('Invalid snapshot format: Expected a 4-element tuple.');
    }

    const [height, serverInput, hashOfReplicas, sortedReplicas] = decodedTuple;

    // Security/Integrity Check: Verify the hash of the replicas.
    const serializedReplicas = packrInstance.pack(sortedReplicas);
    const calculatedHash = sha256(serializedReplicas);
    // Browser-compatible buffer comparison
    if (hashOfReplicas.toString('hex') !== calculatedHash.toString('hex')) {
      throw new Error('State integrity check failed: Replica hash does not match.');
    }

    // Reconstruct the original object, converting sorted arrays back to Maps.
    const replicas = reconstructMaps(sortedReplicas);

    return {
      height,
      serverInput: reconstructMaps(serverInput),
      replicas,
      // Add timestamp for compatibility
      timestamp: Date.now(),
      // Note: gossip layer will be re-created by runtime on restore
    };
  } else {
    // Fallback to sync JSON decoding
    return decode(buffer);
  }
};

// Export the configuration flag for external use/testing
export { USE_MSGPACK };


//runtime/evm.ts (940 lines)
/**
 * XLN EVM Integration
 * Handles blockchain interactions, jurisdictions, and smart contract operations
 */

import { ethers } from 'ethers';
import { loadJurisdictions } from './jurisdiction-loader';
import type { JBatch } from './j-batch';

import { detectEntityType, encodeBoard, extractNumberFromEntityId, hashBoard } from './entity-factory';
import { safeStringify } from './serialization-utils';
import { ConsensusConfig, JurisdictionConfig } from './types';
import { DEBUG, isBrowser } from './utils';
import { logError } from './logger';

// Global logger for UI-accessible error logging (set by frontend)
declare global {
  interface Window {
    xlnErrorLog?: (message: string, source: string, details?: unknown) => void;
  }
}

const uiLog = (message: string, details?: unknown) => {
  console.log(message, details);
  if (isBrowser && window.xlnErrorLog) {
    window.xlnErrorLog(message, 'EVM', details);
  }
};

const uiError = (message: string, details?: unknown) => {
  logError("BLOCKCHAIN", message, details);
  if (isBrowser && window.xlnErrorLog) {
    window.xlnErrorLog(message, 'EVM-ERROR', details);
  }
};

// === ETHEREUM INTEGRATION ===

// Load contract configuration directly in jurisdiction generation
export const ENTITY_PROVIDER_ABI = [
  'function registerNumberedEntity(bytes32 boardHash) external returns (uint256 entityNumber)',
  'function registerNumberedEntitiesBatch(bytes32[] calldata boardHashes) external returns (uint256[] memory entityNumbers)',
  'function assignName(string memory name, uint256 entityNumber) external',
  'function transferName(string memory name, uint256 newEntityNumber) external',
  'function entities(bytes32 entityId) external view returns (tuple(uint256 boardHash, uint8 status, uint256 activationTime))',
  'function nameToNumber(string memory name) external view returns (uint256)',
  'function numberToName(uint256 entityNumber) external view returns (string memory)',
  'function nextNumber() external view returns (uint256)',
  // Governance functions (governance is auto-setup on entity registration)
  'function getTokenIds(uint256 entityNumber) external pure returns (uint256 controlTokenId, uint256 dividendTokenId)',
  'function getGovernanceInfo(uint256 entityNumber) external view returns (uint256 controlTokenId, uint256 dividendTokenId, uint256 controlSupply, uint256 dividendSupply, bool hasActiveProposal, bytes32 articlesHash)',
  'function balanceOf(address account, uint256 id) external view returns (uint256)',
  'function safeTransferFrom(address from, address to, uint256 id, uint256 amount, bytes data) external',
  // Events
  'event EntityRegistered(bytes32 indexed entityId, uint256 indexed entityNumber, bytes32 boardHash)',
  'event NameAssigned(string indexed name, uint256 indexed entityNumber)',
  'event NameTransferred(string indexed name, uint256 indexed oldEntityNumber, uint256 indexed newEntityNumber)',
  'event GovernanceEnabled(bytes32 indexed entityId, uint256 controlTokenId, uint256 dividendTokenId)',
];

export const DEPOSITORY_ABI = [
  'function debugFundReserves(bytes32 entity, uint256 tokenId, uint256 amount) external',
  'function debugBulkFundEntities() external',
  'function reserveToReserve(bytes32 fromEntity, bytes32 toEntity, uint256 tokenId, uint256 amount) external returns (bool)',
  'function processBatch(bytes32 entity, tuple(tuple(bytes32 receivingEntity, uint256 tokenId, uint256 amount)[] reserveToExternalToken, tuple(bytes32 entity, bytes32 packedToken, uint256 internalTokenId, uint256 amount)[] externalTokenToReserve, tuple(bytes32 receivingEntity, uint256 tokenId, uint256 amount)[] reserveToReserve, tuple(uint256 tokenId, bytes32 receivingEntity, tuple(bytes32 entity, uint256 amount)[] pairs)[] reserveToCollateral, tuple(bytes32 leftEntity, bytes32 rightEntity, tuple(uint256 tokenId, int256 leftDiff, int256 rightDiff, int256 collateralDiff, int256 ondeltaDiff)[] diffs)[] settlements, tuple(bytes32 counterentity, tuple(uint256 tokenId, int256 peerReserveDiff, int256 collateralDiff, int256 ondeltaDiff)[] diffs, uint256[] forgiveDebtsInTokenIds, bytes sig)[] cooperativeUpdate, tuple(bytes32 counterentity, tuple(int256[] offdeltas, uint256[] tokenIds, tuple(address subcontractProviderAddress, bytes encodedBatch, tuple(uint256 deltaIndex, uint256 rightAllowence, uint256 leftAllowence)[] allowences)[] subcontracts) proofbody, bytes initialArguments, bytes finalArguments, bytes sig)[] cooperativeDisputeProof, tuple(bytes32 counterentity, uint256 cooperativeNonce, uint256 disputeNonce, bytes32 proofbodyHash, bytes sig, bytes initialArguments)[] initialDisputeProof, tuple(bytes32 counterentity, uint256 initialCooperativeNonce, uint256 initialDisputeNonce, uint256 disputeUntilBlock, bytes32 initialProofbodyHash, bytes initialArguments, bool startedByLeft, uint256 finalCooperativeNonce, uint256 finalDisputeNonce, tuple(int256[] offdeltas, uint256[] tokenIds, tuple(address subcontractProviderAddress, bytes encodedBatch, tuple(uint256 deltaIndex, uint256 rightAllowence, uint256 leftAllowence)[] allowences)[] subcontracts) finalProofbody, bytes finalArguments, bytes sig)[] finalDisputeProof, tuple(uint256 tokenId, uint256 amount)[] flashloans, uint256 hub_id) batch) external returns (bool)',
  'function prefundAccount(bytes32 counterpartyEntity, uint256 tokenId, uint256 amount) external returns (bool)',
  'function settle(bytes32 leftEntity, bytes32 rightEntity, tuple(uint256 tokenId, int256 leftDiff, int256 rightDiff, int256 collateralDiff)[] diffs) external returns (bool)',
  'function _reserves(bytes32 entity, uint256 tokenId) external view returns (uint256)',
  'event ReserveUpdated(bytes32 indexed entity, uint256 indexed tokenId, uint256 newBalance)',
  'event ReserveTransferred(bytes32 indexed from, bytes32 indexed to, uint256 indexed tokenId, uint256 amount)',
  'event SettlementProcessed(bytes32 indexed leftEntity, bytes32 indexed rightEntity, uint256 indexed tokenId, uint256 leftReserve, uint256 rightReserve, uint256 collateral, int256 ondelta)',
];

export const connectToEthereum = async (jurisdiction: JurisdictionConfig) => {
  // Declare outside try block for error logging
  let rpcUrl = jurisdiction.address;
  const entityProviderAddress = jurisdiction.entityProviderAddress;
  const depositoryAddress = jurisdiction.depositoryAddress;

  try {
    // FINTECH-SAFETY: Validate jurisdiction structure before using

    // Support legacy format with explicit validation
    if (!rpcUrl && 'rpc' in jurisdiction) {
      console.warn('üö® JURISDICTION-LEGACY: Using deprecated rpc field, should be address');
    }
    if (!entityProviderAddress && 'contracts' in jurisdiction) {
      console.warn('üö® JURISDICTION-LEGACY: Using deprecated contracts.entityProvider field');
    }

    if (!rpcUrl) {
      throw new Error('Jurisdiction missing RPC URL (address or rpc property)');
    }
    if (!entityProviderAddress || !depositoryAddress) {
      throw new Error('Jurisdiction missing contract addresses (entityProvider and depository)');
    }

    uiLog(`üîå CONNECTING: jurisdiction=${jurisdiction.name}, rpcUrl=${rpcUrl}`);
    if (isBrowser) {
      uiLog(`   Page Origin: ${window.location.origin}`);
      uiLog(`   Page Protocol: ${window.location.protocol}`);
      uiLog(`   Page Host: ${window.location.hostname}:${window.location.port}`);

      // Handle relative URLs (like /rpc/ethereum) by providing base
      const fullRpcUrl = new URL(rpcUrl, window.location.origin);
      uiLog(`   RPC URL: ${fullRpcUrl.href}`);
      const corsIssue = window.location.origin !== fullRpcUrl.origin;
      uiLog(`   CORS issue? ${corsIssue ? 'YES - Different origins!' : 'No (using proxy)'}`, { corsIssue });
      uiLog(`   User Agent: ${navigator.userAgent}`);
    }
    uiLog(`   Contracts: EP=${entityProviderAddress.slice(0,10)}, DEP=${depositoryAddress.slice(0,10)}`);

    // Resolve relative URLs to full URLs for ethers.js
    let resolvedRpcUrl = rpcUrl;
    if (isBrowser && rpcUrl.startsWith('/')) {
      resolvedRpcUrl = new URL(rpcUrl, window.location.origin).href;
      uiLog(`   Resolved RPC: ${resolvedRpcUrl}`);
    }

    // Connect to specified RPC node
    const provider = new ethers.JsonRpcProvider(resolvedRpcUrl);
    uiLog(`‚úÖ Provider created`);

    // Use Hardhat account #0 private key (browser-compatible, no getSigner)
    // This is the publicly known Hardhat test key, safe for demo
    const privateKey = '0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80';
    const signer = new ethers.Wallet(privateKey, provider);
    const signerAddress = await signer.getAddress();
    uiLog(`‚úÖ Signer created: ${signerAddress}`);

    // Test connection
    try {
      const network = await provider.getNetwork();
      uiLog(`‚úÖ Network connected: chainId=${network.chainId}`);
    } catch (netError) {
      uiError(`‚ùå NETWORK-CONNECT-FAILED`, {
        rpcUrl,
        errorCode: (netError as any)?.code,
        errorMessage: (netError as any)?.message,
        errorStack: (netError as any)?.stack
      });
      throw netError;
    }

    // Create contract instances
    const entityProvider = new ethers.Contract(entityProviderAddress, ENTITY_PROVIDER_ABI, signer);
    const depository = new ethers.Contract(depositoryAddress, DEPOSITORY_ABI, signer);
    uiLog(`‚úÖ Contracts created for ${jurisdiction.name}`);

    return { provider, signer, entityProvider, depository };
  } catch (error) {
    uiError(`‚ùå CONNECT-FAILED: ${jurisdiction.name}`, {
      rpcUrl,
      errorType: (error as any)?.constructor?.name,
      errorCode: (error as any)?.code,
      errorReason: (error as any)?.reason,
      errorMessage: (error as any)?.message,
      errorStack: (error as any)?.stack
    });
    throw error;
  }
};

// Debug function to fund entity reserves for testing
export const debugFundReserves = async (jurisdiction: JurisdictionConfig, entityId: string, tokenId: number, amount: string) => {
  try {
    console.log(`üí∞ DEBUG: Funding entity ${entityId.slice(0, 10)} with ${amount} of token ${tokenId}...`);
    
    const { depository } = await connectToEthereum(jurisdiction);
    
    // Fund the entity's reserves for testing
    const tx = await depository['debugFundReserves']!(entityId, tokenId, amount);
    console.log(`üì° Debug funding transaction: ${tx.hash}`);
    
    const receipt = await tx.wait();
    console.log(`‚úÖ Debug funding confirmed in block ${receipt.blockNumber}`);
    
    // Check new balance
    const newBalance = await depository['_reserves']!(entityId, tokenId);
    console.log(`üí∞ Entity ${entityId.slice(0, 10)} now has ${newBalance.toString()} of token ${tokenId}`);
    
    return { transaction: tx, receipt, newBalance };
  } catch (error) {
    logError("BLOCKCHAIN", `‚ùå Failed to fund reserves:`, error);
    throw error;
  }
};

/**
 * Fund entity with multiple assets and emit ReserveUpdated events
 */
export const fundEntityReserves = async (entityId: string, assets: Array<{ tokenId: number; amount: string; symbol: string }>) => {
  console.log(`üí∞ Funding entity ${entityId.slice(0, 10)}... with ${assets.length} assets`);
  
  for (const asset of assets) {
    console.log(`  üí≥ Adding ${asset.symbol}: ${asset.amount} (token ${asset.tokenId})`);
    // TODO: Implement fundReserves function or use debugFundReserves
    console.log(`  - Funding ${entityId.slice(0, 10)} with ${asset.amount} of token ${asset.tokenId}`);
  }
  
  console.log(`‚úÖ Entity ${entityId.slice(0, 10)}... funded with all assets`);
};

// Submit real processBatch transaction to jurisdiction
export const submitPrefundAccount = async (jurisdiction: JurisdictionConfig, entityId: string, counterpartyEntityId: string, tokenId: number, amount: string) => {
  try {
    console.log(`üí∞ Prefunding account between ${entityId.slice(0, 10)}... and ${counterpartyEntityId.slice(0, 10)}...`);
    console.log(`üîç TOKEN: ${tokenId}, AMOUNT: ${amount}`);
    
    const { depository, provider } = await connectToEthereum(jurisdiction);
    console.log(`üîç CONTRACT ADDRESS: ${depository.target}`);
    
    // Check if contract exists
    const code = await provider.getCode(depository.target);
    if (code === '0x') {
      throw new Error('Contract not deployed at this address');
    }
    
    // Check entity has sufficient reserves
    const currentBalance = await depository['_reserves']!(entityId, tokenId);
    console.log(`üîç Current balance: ${currentBalance.toString()}`);
    console.log(`üîç Requested amount: ${amount}`);
    
    if (currentBalance < BigInt(amount)) {
      throw new Error(`Insufficient reserves: have ${currentBalance.toString()}, need ${amount}`);
    }
    
    // Call prefundAccount function
    console.log(`üìû Calling prefundAccount(${counterpartyEntityId}, ${tokenId}, ${amount})`);
    const tx = await depository['prefundAccount']!(counterpartyEntityId, tokenId, amount);
    console.log(`‚è≥ Transaction sent: ${tx.hash}`);
    
    // Wait for confirmation
    const receipt = await tx.wait();
    console.log(`‚úÖ Prefunding confirmed in block ${receipt.blockNumber}`);
    
    return {
      hash: tx.hash,
      receipt: receipt
    };
    
  } catch (error) {
    logError("BLOCKCHAIN", `‚ùå Failed to prefund account:`, error);
    throw error;
  }
};

export const submitProcessBatch = async (jurisdiction: JurisdictionConfig, entityId: string, batch: JBatch | any) => {
  try {
    console.log(`üí∏ Submitting processBatch to ${jurisdiction.name} as entity ${entityId.slice(0, 10)}...`);
    console.log(`üîç BATCH DEBUG:`, safeStringify(batch));
    console.log(`üîç ENTITY DEBUG: ${entityId}`);
    console.log(`üîç JURISDICTION DEBUG:`, jurisdiction);
    console.log(`üîç JURISDICTION SOURCE: Reading from jurisdictions.json file`);
    console.log(`üîç DEPOSITORY ADDRESS FROM JURISDICTION: ${jurisdiction.depositoryAddress}`);
    console.log(`üîç ENTITY PROVIDER ADDRESS FROM JURISDICTION: ${jurisdiction.entityProviderAddress}`);
    
    // Fix batch amounts - convert any JS numbers to wei strings
    if (batch.reserveToReserve) {
      for (let i = 0; i < batch.reserveToReserve.length; i++) {
        const transfer = batch.reserveToReserve[i];
        if (typeof transfer.amount === 'number') {
          // Convert number to wei string
          const weiAmount = (BigInt(Math.floor(transfer.amount * 1e18))).toString();
          console.log(`üîß Converting amount ${transfer.amount} ‚Üí ${weiAmount} wei`);
          transfer.amount = weiAmount;
        }
      }
    }
    console.log(`üîç FIXED BATCH:`, safeStringify(batch));

    const { depository, provider } = await connectToEthereum(jurisdiction);
    console.log(`üîç CONTRACT ADDRESS: ${depository.target}`);
    
    // Check if contract exists
    const code = await provider.getCode(depository.target);
    console.log(`üîç CONTRACT CODE LENGTH: ${code.length} characters`);
    
    if (code === '0x') {
      throw new Error('Contract not deployed at this address');
    }
    
    // Test if this is our new contract
    try {
      console.log(`üîç Testing if contract has debugBulkFundEntities...`);
      await depository['debugBulkFundEntities']?.staticCall?.();
      console.log(`‚úÖ This is our NEW contract with debug functions!`);
    } catch (debugError) {
      console.log(`‚ùå This is OLD contract - no debug functions:`, (debugError as Error).message);
    }
    
    // Check current balance (entities should be pre-funded in constructor)
    console.log(`üîç Checking balance for entity ${entityId} token ${batch.reserveToReserve[0]?.tokenId || 1}...`);
    try {
      const currentBalance = await depository['_reserves']!(entityId, batch.reserveToReserve[0]?.tokenId || 1);
      console.log(`üîç Current balance: ${currentBalance.toString()}`);
      
      if (currentBalance.toString() === '0') {
        console.log(`‚ö†Ô∏è Entity has no reserves - this suggests old contract without pre-funding`);
        throw new Error(`Entity ${entityId.slice(0, 10)} has no reserves! Contract should be pre-funded.`);
      }
    } catch (balanceError) {
      console.log(`‚ùå Failed to check balance:`, (balanceError as Error).message);
      throw balanceError;
    }
    
    // Debug the exact function call being made
    console.log(`üîç Function signature: processBatch(bytes32,tuple)`);
    console.log(`üîç Entity ID: ${entityId}`);
    console.log(`üîç Batch structure:`, Object.keys(batch));
    console.log(`üîç reserveToReserve array:`, batch.reserveToReserve);
    
    // Check if function exists in contract interface
    const functionFragments = depository.interface.fragments.filter(f => f.type === 'function');
    const functions = functionFragments.map(f => {
      // Proper typing: FunctionFragment has name property
      return 'name' in f ? (f as { name: string }).name : 'unknown';
    });
    const hasProcessBatch = functions.includes('processBatch');
    console.log(`üîç Contract has processBatch function: ${hasProcessBatch}`);
    console.log(`üîç Available functions:`, functions.slice(0, 10), '...');
    
    // DEEP DEBUGGING: Check ABI vs deployed bytecode
    console.log(`üîç DEEP DEBUG: Contract interface analysis`);
    console.log(`üîç Contract target address: ${depository.target}`);
    
    // Get function selector for processBatch
    const processBatchFunc = depository.interface.getFunction('processBatch');
    const processBatchSelector = processBatchFunc?.selector || 'NOT_FOUND';
    console.log(`üîç Function selector: ${processBatchSelector}`);
    
    // Check deployed bytecode contains this selector
    const bytecode = await provider.getCode(depository.target);
    const hasSelector = bytecode.includes(processBatchSelector.slice(2)); // Remove 0x
    console.log(`üîç Deployed bytecode contains processBatch selector: ${hasSelector}`);
    console.log(`üîç Bytecode length: ${bytecode.length} chars`);
    
    // Check ABI hash vs expected
    const abiHash = ethers.keccak256(ethers.toUtf8Bytes(safeStringify(depository.interface.fragments.map(f => {
      // Proper typing: Fragment has format method
      return 'format' in f && typeof f.format === 'function' ? f.format() : f.toString();
    }))));
    console.log(`üîç ABI hash: ${abiHash.slice(0, 10)}...`);
    
    // Log exact call data being generated
    const callData = depository.interface.encodeFunctionData('processBatch', [entityId, batch]);
    console.log(`üîç Call data length: ${callData.length} chars`);
    console.log(`üîç Call data start: ${callData.slice(0, 20)}...`);
    
    // Try different entity addresses to see if it's entity-specific
    console.log(`üîç Testing with different entity addresses...`);
    
    // Test entity 0 (should exist from token 0)
    try {
      const balance0 = await depository['_reserves']!("0x0000000000000000000000000000000000000000000000000000000000000000", 0);
      console.log(`üîç Entity 0 Token 0 balance: ${balance0.toString()}`);
    } catch (e) {
      console.log(`‚ùå Entity 0 balance check failed: ${(e as Error).message}`);
    }
    
    // Try simpler batch with just empty arrays
    const emptyBatch = {
      reserveToExternalToken: [],
      externalTokenToReserve: [],
      reserveToReserve: [],
      reserveToCollateral: [],
      cooperativeUpdate: [],
      cooperativeDisputeProof: [],
      initialDisputeProof: [],
      finalDisputeProof: [],
      flashloans: [],
      hub_id: 0
    };
    
    console.log(`üîç Testing empty batch first...`);
    try {
      const emptyResult = await depository['processBatch']?.staticCall(entityId, emptyBatch);
      console.log(`‚úÖ Empty batch works: ${emptyResult}`);
      
      // If empty batch works, try our batch
      console.log(`üîç Now testing our batch...`);
      const result = await depository['processBatch']?.staticCall(entityId, batch);
      console.log(`‚úÖ Static call successful: ${result}`);
    } catch (staticError) {
      logError("BLOCKCHAIN", `‚ùå Static call failed:`, staticError);

      // Type-safe error handling for ethers.js errors
      const errorDetails: Record<string, unknown> = {};
      if (staticError && typeof staticError === 'object') {
        const errorObj = staticError as Record<string, unknown>;
        const code = errorObj['code'];
        const data = errorObj['data'];
        const reason = errorObj['reason'];
        if (code !== undefined) errorDetails['code'] = code;
        if (data !== undefined) errorDetails['data'] = data;
        if (reason !== undefined) errorDetails['reason'] = reason;
      }
      console.log(`üîç Error details:`, errorDetails);
      throw staticError;
    }
    
    // First try to estimate gas to get better error info
    console.log(`üîç Estimating gas for processBatch...`);
    try {
      const gasEstimate = await depository['processBatch']?.estimateGas(entityId, batch);
      console.log(`üîç Gas estimate: ${gasEstimate?.toString() || 'N/A'}`);
    } catch (gasError) {
      logError("BLOCKCHAIN", `‚ùå Gas estimation failed:`, gasError);
      throw gasError;
    }
    
    // Submit the batch transaction to the real blockchain (entity can sign as any entity for now)
    const tx = await depository['processBatch']!(entityId, batch);
    console.log(`üì° Transaction submitted: ${tx.hash}`);
    
    // Wait for confirmation
    const receipt = await tx.wait();
    console.log(`‚úÖ Transaction confirmed in block ${receipt.blockNumber}`);
    
    return { transaction: tx, receipt };
  } catch (error) {
    logError("BLOCKCHAIN", `‚ùå Failed to submit processBatch to ${jurisdiction.name}:`, error);
    throw error;
  }
};

// Note: setupGovernance is no longer needed - governance is automatically created on entity registration

export const registerNumberedEntityOnChain = async (
  config: ConsensusConfig,
  name: string,
): Promise<{ txHash: string; entityNumber: number }> => {
  if (!config.jurisdiction) {
    throw new Error('Jurisdiction required for on-chain registration');
  }

  try {
    const { entityProvider } = await connectToEthereum(config.jurisdiction);

    const encodedBoard = encodeBoard(config);
    const boardHash = hashBoard(encodedBoard);

    if (DEBUG) console.log(`üèõÔ∏è Registering numbered entity "${name}" on chain`);
    if (DEBUG) console.log(`   Jurisdiction: ${config.jurisdiction.name}`);
    if (DEBUG) console.log(`   EntityProvider: ${config.jurisdiction.entityProviderAddress}`);
    if (DEBUG) console.log(`   Board Hash: ${boardHash}`);

    // Test connection by calling nextNumber()
    try {
      const nextNumber = await entityProvider['nextNumber']!();
      if (DEBUG) console.log(`   üìä Next entity number will be: ${nextNumber}`);
    } catch (error) {
      throw new Error(`Failed to call nextNumber(): ${error}`);
    }

    // Call the smart contract
    const tx = await entityProvider['registerNumberedEntity']!(boardHash);
    if (DEBUG) console.log(`   üì§ Transaction sent: ${tx.hash}`);

    // Wait for confirmation
    const receipt = await tx.wait();
    if (DEBUG) console.log(`   ‚úÖ Transaction confirmed in block ${receipt.blockNumber}`);

    // Check if transaction reverted
    if (receipt.status === 0) {
      throw new Error(`Transaction reverted! Hash: ${tx.hash}`);
    }

    // Debug: log all events in receipt
    if (DEBUG) {
      console.log(`   üìã Receipt logs count: ${receipt.logs.length}`);
      receipt.logs.forEach((log: ethers.Log, i: number) => {
        try {
          const parsed = entityProvider.interface.parseLog(log);
          console.log(`   üìù Log ${i}: ${parsed?.name} - ${safeStringify(parsed?.args)}`);
        } catch {
          console.log(`   üìù Log ${i}: Unable to parse log - ${log.topics?.[0]}`);
        }
      });
    }

    // Extract entity number from event logs
    const event = receipt.logs.find((log: ethers.Log) => {
      try {
        const parsed = entityProvider.interface.parseLog(log);
        return parsed?.name === 'EntityRegistered';
      } catch {
        return false;
      }
    });

    if (!event) {
      throw new Error('EntityRegistered event not found in transaction logs');
    }

    const parsedEvent = entityProvider.interface.parseLog(event);
    // const _entityId = parsedEvent?.args[0]; // Entity ID for debugging (unused)
    const entityNumber = Number(parsedEvent?.args[1]);

    if (DEBUG) console.log(`‚úÖ Numbered entity registered!`);
    if (DEBUG) console.log(`   TX: ${tx.hash}`);
    if (DEBUG) console.log(`   Entity Number: ${entityNumber}`);

    return { txHash: tx.hash, entityNumber };
  } catch (error) {
    logError("BLOCKCHAIN", '‚ùå Blockchain registration failed:', error);
    throw error;
  }
};

/**
 * Batch register multiple numbered entities in ONE transaction
 * Massive speedup for scenario imports (1000 entities in 1 tx vs 1000 txs)
 */
export const registerNumberedEntitiesBatchOnChain = async (
  configs: ConsensusConfig[],
  jurisdiction: JurisdictionConfig,
): Promise<{ txHash: string; entityNumbers: number[] }> => {
  try {
    const { entityProvider } = await connectToEthereum(jurisdiction);

    // Encode all board hashes
    const boardHashes = configs.map(config => {
      const encodedBoard = encodeBoard(config);
      return hashBoard(encodedBoard);
    });

    console.log(`üèõÔ∏è Batch registering ${configs.length} entities in ONE transaction...`);

    // Call batch registration function
    const tx = await entityProvider['registerNumberedEntitiesBatch']!(boardHashes);
    console.log(`üì§ Batch tx sent: ${tx.hash}`);

    // Wait for confirmation (ONE block for ALL entities!)
    const receipt = await tx.wait();
    console.log(`‚úÖ Batch confirmed in block ${receipt.blockNumber}`);

    if (receipt.status === 0) {
      throw new Error(`Batch registration reverted! Hash: ${tx.hash}`);
    }

    // Extract all entity numbers from events
    const entityNumbers: number[] = [];
    receipt.logs.forEach((log: ethers.Log) => {
      try {
        const parsed = entityProvider.interface.parseLog(log);
        if (parsed?.name === 'EntityRegistered') {
          entityNumbers.push(Number(parsed.args[1]));
        }
      } catch {
        // Skip unparseable logs
      }
    });

    console.log(`‚úÖ Registered ${entityNumbers.length} entities: ${entityNumbers[0]}-${entityNumbers[entityNumbers.length - 1]}`);

    return { txHash: tx.hash, entityNumbers };
  } catch (error) {
    logError("BLOCKCHAIN", '‚ùå Batch registration failed:', error);
    throw error;
  }
};

export const assignNameOnChain = async (
  name: string,
  entityNumber: number,
  jurisdiction: JurisdictionConfig,
): Promise<{ txHash: string }> => {
  try {
    const { entityProvider } = await connectToEthereum(jurisdiction);

    if (DEBUG) console.log(`üè∑Ô∏è  Assigning name "${name}" to entity #${entityNumber}`);

    // Call the smart contract (admin only)
    const tx = await entityProvider['assignName']!(name, entityNumber);
    if (DEBUG) console.log(`   üì§ Transaction sent: ${tx.hash}`);

    // Wait for confirmation
    const receipt = await tx.wait();
    if (DEBUG) console.log(`   ‚úÖ Transaction confirmed in block ${receipt.blockNumber}`);

    // Check if transaction reverted
    if (receipt.status === 0) {
      throw new Error(`Transaction reverted! Hash: ${tx.hash}`);
    }

    if (DEBUG) console.log(`‚úÖ Name assigned successfully!`);
    if (DEBUG) console.log(`   TX: ${tx.hash}`);

    return { txHash: tx.hash };
  } catch (error) {
    logError("BLOCKCHAIN", '‚ùå Name assignment failed:', error);
    throw error;
  }
};

export const getEntityInfoFromChain = async (
  entityId: string,
  jurisdiction: JurisdictionConfig,
): Promise<{ exists: boolean; entityNumber?: number; name?: string }> => {
  try {
    const { entityProvider } = await connectToEthereum(jurisdiction);

    // Try to get entity info
    const entityInfo = await entityProvider['entities']!(entityId);

    if (entityInfo.status === 0) {
      return { exists: false };
    }

    // For numbered entities, get the number and name
    const entityType = detectEntityType(entityId);
    let entityNumber: number | undefined;
    let name: string | undefined;

    if (entityType === 'numbered') {
      const extractedNumber = extractNumberFromEntityId(entityId);
      if (extractedNumber !== null) {
        entityNumber = extractedNumber;
        try {
          const retrievedName = await entityProvider['numberToName']!(entityNumber);
          name = retrievedName || undefined;
        } catch {
          // No name assigned
        }
      }
    }

    return {
      exists: true,
      ...(entityNumber !== undefined ? { entityNumber } : {}),
      ...(name !== undefined ? { name } : {})
    };
  } catch (error) {
    logError("BLOCKCHAIN", '‚ùå Failed to get entity info from chain:', error);
    return { exists: false };
  }
};

export const getNextEntityNumber = async (jurisdiction: JurisdictionConfig): Promise<number> => {
  try {
    if (!jurisdiction) {
      throw new Error('Jurisdiction parameter is required');
    }

    // Support both direct property and nested under contracts with type safety
    let entityProviderAddress = jurisdiction.entityProviderAddress;

    if (!entityProviderAddress && 'contracts' in jurisdiction) {
      const jurisdictionWithContracts = jurisdiction as Record<string, unknown> & { contracts?: { entityProvider?: string } };
      const contractAddress = jurisdictionWithContracts.contracts?.entityProvider;
      if (contractAddress) {
        entityProviderAddress = contractAddress;
      }
    }

    if (!jurisdiction.name || !entityProviderAddress) {
      throw new Error('Jurisdiction object is missing required properties (name, entityProvider address)');
    }

    const { entityProvider } = await connectToEthereum(jurisdiction);

    if (DEBUG)
      console.log(`üîç Fetching next entity number from ${entityProviderAddress} (${jurisdiction.name})`);

    const nextNumber = await entityProvider['nextNumber']!();
    const result = Number(nextNumber);

    if (DEBUG) console.log(`üî¢ Next entity number: ${result}`);
    return result;
  } catch (error) {
    logError("BLOCKCHAIN", '‚ùå Failed to get next entity number:', error);
    throw error;
  }
};

export const transferNameBetweenEntities = async (
  name: string,
  fromNumber: number,
  toNumber: number,
  _jurisdiction: JurisdictionConfig,
): Promise<string> => {
  if (DEBUG) console.log(`üîÑ Transferring name "${name}" from #${fromNumber} to #${toNumber}`);

  // TODO: Implement real blockchain name transfer
  throw new Error('Name transfer not implemented - requires blockchain integration');
};

// === JURISDICTION MANAGEMENT ===

// Load contract configuration and generate jurisdictions
export const generateJurisdictions = async (): Promise<Map<string, JurisdictionConfig>> => {

  const jurisdictions = new Map<string, JurisdictionConfig>();

  try {
    let config: any; // Complex type - loadJurisdictions returns different shapes in different contexts

    if (!isBrowser && typeof process !== 'undefined') {
      // Node.js environment - use centralized loader
      console.log('üîç JURISDICTION SOURCE: Using centralized jurisdiction-loader');
      config = loadJurisdictions();
      console.log('üîç JURISDICTION DEBUG: Loaded config with contracts:', config.jurisdictions?.ethereum?.contracts);
      console.log('‚úÖ Loaded jurisdictions from centralized loader (cached)');
    } else {
      // Browser environment - fetch from runtime (use relative path for GitHub Pages compatibility)
      const response = await fetch('./jurisdictions.json');
      if (!response.ok) {
        throw new Error(`Failed to fetch jurisdictions.json: ${response.status} ${response.statusText}`);
      }
      config = await response.json();
      console.log('üîç JURISDICTION DEBUG: Browser loaded config with contracts:', config.jurisdictions?.ethereum?.contracts);
      console.log('‚úÖ Loaded jurisdictions from runtime');
    }

    const jurisdictionData = config.jurisdictions;

    // Build jurisdictions from loaded config with type safety
    for (const [key, data] of Object.entries(jurisdictionData)) {
      // Validate structure before using
      if (!data || typeof data !== 'object') {
        console.warn(`üö® Invalid jurisdiction data for ${key}:`, data);
        continue;
      }
      const jData = data as Record<string, any>;

      // CRITICAL: Check for RPC override (for Oculus Quest compatibility)
      let rpcUrl = jData['rpc'];

      // Detect Oculus Browser (blocks custom ports on HTTPS - security restriction)
      const isOculusBrowser = isBrowser && /OculusBrowser|Quest/i.test(navigator.userAgent);

      const rpcOverride = isBrowser ? localStorage.getItem('xln_rpc_override') : null;

      uiLog(`üîç RPC-TRANSFORM-START: key=${key}, rpc=${rpcUrl}`, {
        isOculusBrowser,
        override: rpcOverride,
        userAgent: isBrowser ? navigator.userAgent : 'N/A'
      });

      // Oculus Browser fix: Force direct port without +10000 offset
      if (isOculusBrowser && !rpcOverride && rpcUrl.startsWith(':')) {
        const port = parseInt(rpcUrl.slice(1));
        rpcUrl = `${window.location.protocol}//${window.location.hostname}:${port}`;
        uiLog(`üéÆ OCULUS FIX: Using direct port ${port} ‚Üí ${rpcUrl}`);
      }

      if (rpcOverride && rpcOverride !== '') {
        // User-specified RPC override
        if (rpcOverride.startsWith('/')) {
          // Path-based proxy (e.g., /rpc or /rpc/ethereum)
          // If single jurisdiction, use path directly. If multiple, append jurisdiction name.
          const jurisdictionCount = Object.keys(config.jurisdictions).length;
          const path = jurisdictionCount === 1
            ? rpcOverride  // Single jurisdiction: use /rpc directly
            : (rpcOverride.endsWith('/') ? rpcOverride + jData['name'].toLowerCase() : `${rpcOverride}/${jData['name'].toLowerCase()}`);
          rpcUrl = `${window.location.origin}${path}`;
          uiLog(`üîß RPC URL (override): ${jData['rpc']} ‚Üí ${rpcUrl} (path proxy, ${jurisdictionCount} jurisdictions)`);
        } else if (rpcOverride.startsWith(':')) {
          // Port-based (e.g., :8545 or :18545)
          rpcUrl = `${window.location.protocol}//${window.location.hostname}${rpcOverride}`;
          uiLog(`üîß RPC URL (override): ${jData['rpc']} ‚Üí ${rpcUrl} (custom port)`);
        } else {
          // Full URL override
          rpcUrl = rpcOverride;
          uiLog(`üîß RPC URL (override): ${jData['rpc']} ‚Üí ${rpcUrl} (full URL)`);
        }
      } else if (isBrowser && rpcUrl.startsWith('/')) {
        // Path-based proxy (e.g., /rpc/arrakis) - use same origin
        rpcUrl = `${window.location.origin}${rpcUrl}`;
        uiLog(`üîß RPC-TRANSFORM-PROXY: ${jData['rpc']} ‚Üí ${rpcUrl}`, {
          origin: window.location.origin,
          proxyPath: jData['rpc']
        });
      } else if (isBrowser && rpcUrl.startsWith(':')) {
        // Port-based (legacy): production uses port + 10000 (nginx proxy)
        const port = parseInt(rpcUrl.slice(1));
        const isLocalhost = window.location.hostname.match(/localhost|127\.0\.0\.1/);
        const actualPort = isLocalhost ? port : port + 10000;
        rpcUrl = `${window.location.protocol}//${window.location.hostname}:${actualPort}`;
        uiLog(`üîß RPC-TRANSFORM-DEFAULT: ${jData['rpc']} ‚Üí ${rpcUrl}`, {
          hostname: window.location.hostname,
          isLocalhost: !!isLocalhost,
          port,
          actualPort,
          portOffset: isLocalhost ? 0 : 10000
        });
      } else if (!isBrowser && rpcUrl.startsWith(':')) {
        // Node.js: Default to localhost
        rpcUrl = `http://localhost${rpcUrl}`;
      }

      uiLog(`üìç FINAL-RPC-URL: ${key} ‚Üí ${rpcUrl}`, {
        entityProvider: jData['contracts']['entityProvider'],
        depository: jData['contracts']['depository']
      });

      jurisdictions.set(key, {
        address: rpcUrl,
        name: jData['name'],
        entityProviderAddress: jData['contracts']['entityProvider'],
        depositoryAddress: jData['contracts']['depository'],
        chainId: jData['chainId'],
      });
    }
  } catch (error) {
    logError("BLOCKCHAIN", '‚ùå Failed to load jurisdictions:', error);
  }

  return jurisdictions;
};

export let DEFAULT_JURISDICTIONS: Map<string, JurisdictionConfig> | null = null;

export const getJurisdictions = async (): Promise<Map<string, JurisdictionConfig>> => {
  // In browser, cache the result to avoid multiple fetches
  if (isBrowser && DEFAULT_JURISDICTIONS !== null) {
    console.log('üîç JURISDICTIONS: Using cached browser data');
    return DEFAULT_JURISDICTIONS;
  }

  // Generate/fetch jurisdictions
  DEFAULT_JURISDICTIONS = await generateJurisdictions();
  return DEFAULT_JURISDICTIONS!;
};

export const getAvailableJurisdictions = async (): Promise<JurisdictionConfig[]> => {
  const jurisdictions = await getJurisdictions();
  return Array.from(jurisdictions.values());
};

/**
 * Set BrowserVM jurisdiction (for isolated /view environments)
 * This overrides DEFAULT_JURISDICTIONS with a single BrowserVM-backed jurisdiction
 */
export const setBrowserVMJurisdiction = (entityProviderAddress: string, depositoryAddress: string) => {
  console.log('[BrowserVM] Setting jurisdiction override:', { entityProviderAddress, depositoryAddress });

  DEFAULT_JURISDICTIONS = new Map();
  DEFAULT_JURISDICTIONS.set('arrakis', {
    name: 'Arrakis',
    chainId: 1337,
    rpc: 'http://localhost:8545', // Not used by BrowserVM but required for type
    entityProviderAddress,
    depositoryAddress,
  });

  console.log('‚úÖ BrowserVM jurisdiction active - numbered entities will register here');
};

export const getJurisdictionByAddress = async (address: string): Promise<JurisdictionConfig | undefined> => {
  const jurisdictions = await getJurisdictions();
  return jurisdictions.get(address);
};

// Settlement diff structure matching contract
export interface SettlementDiff {
  tokenId: number;
  leftDiff: bigint;
  rightDiff: bigint;
  collateralDiff: bigint;
  ondeltaDiff?: bigint; // Optional in some contexts
}

export const submitSettle = async (jurisdiction: JurisdictionConfig, leftEntity: string, rightEntity: string, diffs: SettlementDiff[]) => {
  try {
    console.log(`‚öñÔ∏è Submitting settle transaction between ${leftEntity.slice(0, 10)}... and ${rightEntity.slice(0, 10)}...`);
    console.log(`üîç DIFFS:`, diffs.map(d => ({
      ...d,
      leftDiff: d.leftDiff.toString(),
      rightDiff: d.rightDiff.toString(),
      collateralDiff: d.collateralDiff.toString()
    })));

    const { depository, provider } = await connectToEthereum(jurisdiction);
    console.log(`üîç CONTRACT ADDRESS: ${depository.target}`);

    // Check if contract exists
    const code = await provider.getCode(depository.target);
    if (code === '0x') {
      throw new Error('Contract not deployed at this address');
    }

    // Call settle function
    console.log(`üì§ Calling settle function...`);
    const tx = await depository['settle']!(leftEntity, rightEntity, diffs);
    console.log(`üí´ Transaction sent: ${tx.hash}`);

    // Wait for confirmation
    const receipt = await tx.wait();
    console.log(`‚úÖ Settlement confirmed in block ${receipt.blockNumber}`);

    if (receipt.status === 0) {
      throw new Error(`Settlement transaction reverted! Hash: ${tx.hash}`);
    }

    console.log(`üéâ Settlement successful! Both entities should receive SettlementProcessed events`);
    return { txHash: tx.hash, blockNumber: receipt.blockNumber };

  } catch (error) {
    logError("BLOCKCHAIN", '‚ùå Settlement failed:', error);
    throw error;
  }
};

export const submitReserveToReserve = async (jurisdiction: JurisdictionConfig, fromEntity: string, toEntity: string, tokenId: number, amount: string) => {
  try {
    console.log(`üí∏ DIRECT R2R: ${fromEntity.slice(0,10)} ‚Üí ${toEntity.slice(0,10)}, token ${tokenId}, amount ${amount}`);

    const { depository, provider } = await connectToEthereum(jurisdiction);
    console.log(`üîç CONTRACT ADDRESS: ${depository.target}`);

    // Check if contract exists
    const code = await provider.getCode(depository.target);
    if (code === '0x') {
      throw new Error('Contract not deployed at this address');
    }

    // Call direct reserveToReserve function
    console.log(`üì§ Calling reserveToReserve(${fromEntity}, ${toEntity}, ${tokenId}, ${amount})...`);
    const tx = await depository['reserveToReserve']!(fromEntity, toEntity, tokenId, amount);
    console.log(`üí´ Transaction sent: ${tx.hash}`);

    // Wait for confirmation
    const receipt = await tx.wait();
    console.log(`‚úÖ R2R confirmed in block ${receipt.blockNumber}`);

    if (receipt.status === 0) {
      throw new Error(`R2R transaction reverted! Hash: ${tx.hash}`);
    }

    console.log(`üéâ Direct R2R successful!`);
    return { txHash: tx.hash, blockNumber: receipt.blockNumber };

  } catch (error) {
    logError("BLOCKCHAIN", '‚ùå Direct R2R failed:', error);
    throw error;
  }
};


//vibepaper/emc2.md (33 lines)
Œî

‚àíL‚Çó ‚â§ Œî ‚â§ C + L·µ£
xln.finance
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Reserve-Credit Programmable Enforceable 
Layer2 Netting-Account Network  
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FCUU Full-Credit Unprogrammable Unenforceable
100% of modern finance: Banking, SWIFT, Visa, any CEX etc (‚àí5000 BCE)
no collateral, no proof = trust-based, censorable, Diamond-Dybvig runs
[‚àí‚àí‚àí.**Œî‚àí]  C = 0, Œî ‚àà [‚àíL‚Çó, +L·µ£]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FRPE Full-Reserve Programmable Enforceable
Layer2 channels: BTC Lightning (2015), ETH Raiden (2017), ADA Hydra (2020) etc
no credit = unusable inbound capacity wall, capital inefficiency
[.==Œî=]  L‚Çó=L·µ£=0, Œî ‚àà [0, +C]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
xln (RCPE) ‚äÉ { FCUU, FRPE }
Œî ‚àà [‚àíL‚Çó, C + L·µ£]
Scalable Secure Simple

‚àû unicast O(1) scalability, Coasian ->0% fees

first-ever cryptographically enforced debt + collateral
account proofs with guaranteed L1 dispute resolution
always local state without erasure coding/DAC/DAS-trust
sovereign exits, no rollup DA-risk by design 

EVM-first multi-jurisdiction omni-Layer2
flexible credit-collateral security model
banking-like UX


//vibepaper/priorart.md (62 lines)
# Prior Art

Xln is built on shoulders of giants.

## Bitcoin

Satoshi Nakamoto is genius for creating the replicated state machine (RSM) movement. For making people even ask and wonder why do we keep our entire net-worth in hands of unprovable custodial state machines. 

## Ethereum

Vitalik Buterin is genius for inventing Turing-complete programmable RSM: EVM (Ethereum Virtual Machine). EVM is our reference adapter Jurisdiction machine in J-REA stack. Its yellowpaper alone changed the course of human history forever. 
Unfortunatelly, we believe his & EF team narrative about plasma, rollups, DAC/DAS are not an endgame. It feels like a costly detour and dead-end research trap. **All broadcast O(n) designs are fundamentally bottlenecked in scalability and mathematically flawed with data availability paradox.**

Their goals are noble: trustless exitable layer2. But their means are mathematically handicapped. Broadcast-J-shared-state just cannot have planetary scale. Neither directly (big blockers) nor through blob-checkpointing surrogates. There is nothing you can do about it. 

The unicast bilateral state approach completely side-steps this problem.

No amount of DAC/DAS/erasure coding assumption cascades can solve that. **Those are very intellectually interesting problems to work on, but they are perpetuum mobile in a nutshell.**


Ethereum: 15 TPS global
XLN on Ethereum: Millions of TPS bilateral (O(1) per entity pair)

Solana: 3000 TPS global  
XLN on Solana: Still millions of TPS bilateral

Conclusion: Base layer TPS is IRRELEVANT for XLN.


## Lightning Network



## Ronald Coase

##  Douglas Diamond, Philip H. Dybvig, Ben Bernanke





We are turn existing RSM into J-REA two-layered stack. 
Banking: "Trust us with your money"
XLN: "Same UX, but you can exit anytime with cryptographic proof"

Binance: "We're totally not fractional reserve"
XLN: "Here's the on-chain collateral, verify yourself"

SWIFT: "$30 fee, 3 days"
XLN: "$0.00001 fee, 3 seconds"
```

## Against Rollups
```
Rollups: "We'll decentralize the sequencer someday‚Ñ¢"
XLN: "No sequencer needed"

Rollups: "Trust our data availability committee"
XLN: "Your counterparty IS your data availability"

Rollups: "Pay $0.10 per tx for blob space"
XLN: "Pay $0 until you need to rebalance (rare)"

//vibepaper/docs/summary.md (151 lines)
# XLN Protocol

## Core Concepts

XLN is a **sovereign Layer2 for EVM**, designed around two primitives:

1. **Reserves** ‚Äî liquid balances held directly in the jurisdiction machine (J).
2. **Reserve-credit accounts (channels)** ‚Äî bilateral credit contracts between entities, backed by **collateral**, **ondelta**, and **offdelta**.

Every channel for a given asset is defined by three numbers:

- **Collateral** ‚Äî the locked base amount in the jurisdiction.
- **ondelta** ‚Äî a *public shift* stored in J, updated by cooperative settle.
- **offdelta** ‚Äî a *private shift* stored in AccountProof, updated off-chain.

The invariant:

Œî = ondelta + offdelta

---

## External Token Flow

1. **Deposit into Reserve**  
   A user deposits external tokens (e.g., USDT) into the jurisdiction.  

reserves[entity][token] += amount

2. **Move Reserve ‚Üí Collateral**  
The entity transfers tokens from its reserve into a channel with a counterparty.  
- The tokens become **collateral** in the channel.  
- By default, new collateral is attributed to the right side.  
- If the depositor is the left side, `ondelta += amount` to shift part of collateral allocation left.
```
reserves[left][token] -= amount
collaterals[left][right][token].collateral += amount
if depositor == left:
collaterals[left][right][token].ondelta += amount
```
---

## Off-Chain Payments in AccountProof

1. **Proof Creation**  
- The sender (Alice) prepares a new **AccountProof** for channel (Alice, Hub).  
- She increments the sequence number and updates offdelta:  
  ```
  offdelta[token] -= amount
  ```
- The proof may include subcontracts (e.g., HTLC, Swap).  
- Alice signs and sends the proof to Hub.

2. **Proof Acceptance**  
- Hub verifies Alice‚Äôs signature, sequence, and credit limits.  
- Hub stores the canonical AccountProof.  
- Both sides now hold the same proof; **no on-chain update is needed**.

3. **Routing**  
- Hub can immediately forward the payment using its own channel (Hub, Bob), creating another AccountProof.  
- This enables multi-hop routing without touching jurisdiction.

---

## Cooperative Settle

At any time, both parties can jointly update their state on-chain:

1. **Prepare Settle**  
Both sign a batch of diffs:
- `leftReserveDiff`
- `rightReserveDiff`
- `collateralDiff`
- `ondeltaDiff`

2. **Invariant**  

leftReserveDiff + rightReserveDiff + collateralDiff == 0

3. **Apply**  
- Reserves, collateral, and ondelta are updated atomically in J.  
- Old AccountProofs remain valid; only the public base has shifted.

---

## Dispute and Delta Derivation

When cooperation fails, either side can trigger a dispute:

1. **Submit Proof**  
Submit the latest signed AccountProof to J.

2. **Sum Deltas**  
For each token:

Œî = ondelta (public in J) + offdelta (from AccountProof)

3. **Execute Subcontracts**  
The DeltaList is passed through the array of external subcontracts with all arguments.  
The subcontract provider returns a **modified DeltaList**.

4. **Split Collateral**  
Using the final Œî:
- If `0 ‚â§ Œî ‚â§ collateral`: left gets Œî, right gets (collateral ‚àí Œî).
- If `Œî > collateral`: left gets full collateral, surplus becomes **debt of right**.
- If `Œî < 0`: right gets full collateral, surplus becomes **debt of left**.

5. **Debt Enforcement**  
- Debt is first paid from reserves.  
- If reserves are insufficient, it is recorded in the entity‚Äôs debt list.

---

## First Payment Example

1. **Channel Setup**  
- Alice deposits 100 USDT.  
- Reserve(Alice) = 100.  
- She moves 100 into collateral with Hub:  
  ```
  collateral = 100, ondelta = 0, offdelta = 0
  ```

2. **Payment of 30 USDT**  
- Alice creates AccountProof#1 with `offdelta = -30`.  
- Alice signs and sends it to Hub.  
- Hub accepts; both now hold canonical proof.

3. **State After Payment**  
- No on-chain action has occurred.  
- Jurisdiction still shows: `collateral = 100, ondelta = 0`.  
- AccountProof offdelta = ‚àí30 represents Alice‚Äôs transfer.  

4. **Optional Settle**  
- Alice and Hub can later settle on-chain, moving balances.  

5. **Dispute Path**  
- If Hub disappears, Alice submits AccountProof#1.  
- J computes Œî = ondelta (0) + offdelta (‚àí30) = ‚àí30.  
- J splits collateral: right (Hub) takes 30, left (Alice) keeps 70.

---

## Key Properties

- **Unicast DeFi** ‚Äî payments are bilateral, no global sequencer.  
- **Billions+ TPS** ‚Äî unbounded scalability across parallel channels.  
- **Zero DA risk** ‚Äî no external data availability assumptions.  
- **Sovereign exits** ‚Äî any party can exit with AccountProof.  
- **Programmable subcontracts** ‚Äî HTLCs, swaps, derivatives.  
- **Simple as banking** ‚Äî user balances are derived from `(collateral, ondelta, offdelta)`.


//vibepaper/docs/00_QA.md (132 lines)
# 0.0 Questions & Answers

[pairing: Apashe, Worakls & Wasiu - Rome Is Burning](https://www.youtube.com/watch?v=dpn5Rff4gUk)

## whoami

I am Egor Homakov, security researcher and architect of UFT/Xln. Lets briefly elaborate my **intrinsic motivation and passion** to creating this protocol. 

I started my career in Ruby on Rails/JavaScript software engineering circa 2007. In 2012, I've stumbled upon a fundamental insecure-by-default pattern in Rails called mass assignment and inappropriately hacked Github to [make my point](https://github.com/rails/rails/commit/b83965785db1eec019edf1fc272b1aa393e6dc57). Ever since I've been obsessed with finding not just one-off bugs, but systemic flaws in protocols and improving software layers as a whole: further hardening Ruby-ecosystem, client side security, OAuth2, proposed [SecureLogin](https://github.com/sakurity/securelogin/) (would be way more convenient than passkeys if adopted by big tech).

Then I founded [Sakurity](https://sakurity.com), conducted boutique security audits and pentests for some of the big names in the startup industry. Things went good. Around 2017 I've retired from consulting and focused on **the most critical yet most vulnerable and misdesigned architecture on the planet** ‚Äì our financial system, as a whole. This includes both TradFi + DeFi, as per JEA mental model soon you will see they are the same.

The catalyst was reading the Lightning Network whitepaper and realizing: the authors (Joseph Poon, Thaddeus Dryja) invented the genius primitives, **"the wheel"** (proofs + collateral + delta transformer) but then tried to apply it in a delusional way, **"the unicycle"** (full-reserve account network, has no working incentive model, can't scale). Yes, unicycle can work under rare conditions, but do you see people using it on the street?

I voiced my concerns in 2017 and it was discared as FUD. In 2025 it's crystal clear I was right: Lightning/Raiden/Hydra and all other full-reserve inspired channel designs are dead due to inbound capacity problem.

<img src="../frontend/static/img/RCPAN.png" width="200px">

The solution to inbound capacity was painfully obvious to me: **credit is all you need**. This is when the core of Xln was formed: molding together the most scalable & universally understood Unicast full-credit architecture (custodial/banking/CEX network of accounts) with the most secure but unusable Layer2 technology (full-reserve payment/state channels). The RCPAN invariant `‚àíL‚Çó ‚â§ Œî ‚â§ C + L·µ£` was born on Aug 25, 2017. This is the core formula, around of which further layers are built upon.

The Unified Financial Theory and Xln (practical reference implementation) is my magnum opus and quintessence of 9 years of research into TradFi/RTGS/DeFi/DAO/AA/institutional governance/state channels. I believe UFT/Xln is 100x more important than all of my infosec research combined. Call me delusional, but I just happen to be right, eventually.

## Another Bitcoin/Ethereum Killer?

**No, quite the opposite! Xln is not a "blockchain" at all or as we call it, Jurisdiction machine. 

Simply put, Xln is a unified netting Layer2 for all jurisdictional gross layers (J-machines) out there. Including Bitcoin and Ethereum. Including Fedwire and ECB and other central banks, once they realize the inevitability of what's coming.**

I love Bitcoin for its legacy. I love Ethereum for bringing generalized programmability to J-machines. But currently they are trying to solve the wrong problem.

J-machine **is not what should be scaled**. Leave it alone - it's doing perfectly fine at 30-100 tps globally. It's not meant for coffee-payments. The organisational & transactional entity-account layer2, is what needs to be expanded, same as commercial banking layer operates underneath central banks/RTGS (e.g Fed+Fedwire = TradFi J-machine).

I am the most maxi full-node-on-every-device you can think of. Unfortunatelly, up until creation of Xln no blockchain could survive with ultra-lightweight L1 J-machine alone.

I religiously believe and double down on the original vision of Bitcoin and Ethereum where every laptop and phone can run fully verifying node. Xln is the first architecture that actually delivers that vision. 

Xln achieves that by creating two loosely coupled layers: J-REA 

* **Gross-J-Layer1 for >$1M transfers**: <30-100 tps global settlement  (Bitcoin and Ethereum are J-machines). Xln is jurisdiction-agnostic and can support any L1, but the lower global tps - the easier it is to run a full node on consumer device. Xln is the first architecture that works just fine with Original Ethereum, even if gaslimit is reduced 10-100x. Unlike rollups, Xln does not require blobspace or data availability committees of any form - the account proofs are sovereign and exits are guaranteed at all times.

* **Net-REA-Layer2 for <$1M transfers>**: unbounded scalability Unicast O(1). Xln is a netting overlay attaching to any EVM L1/EVM-rollup/future EVM-like CBDC J-machines, creating financial Internet of unified liquidity.

## The system uses credit. Credit = bad. #DontTrustVerify #BitcoinMAXI

I hate to break it to you, but every financial system under the sun uses some form of credit one way or another. It's just named differently. It's a different cascade of trust assumptions, projected over different threat models.

Take a single 1 BTC UTXO on-chain for example. **As of now, this is the safest way to store value on the planet.** 

Yet, even BTC can fall apart overnight. Several G7 security agencies can cooperate to attack mining pools. Deposit few Billions to thousands of warm KYC-d accounts in popular centralized exchanges around the world, swap it to any other non-BTC or fiat, then cancel (double-spend) their original BTC deposits to the exchanges. Whoops, $4T crypto economy would vanish overnight. 

Mission: Very-Much-Possible I must say. Luckily, most government officials are well invested into BTC and other neo J-machines. This is what keeps us safe, for now.

BTC-UTXO is golden standard and benchmark security, yes. Everything else is significantly worse that. 

Everyone else is trying to scale Broadcast O(n) J-machine but inevitably ends up with credit and counterparty risk one way or another.

## Big-blockers don't have credit. Solana/Tron/etc is the next big thing.

Solana is a Broadcast O(n) big-blocker, like almost everyone else. They have fantastic marketing and PR. They did a politically right thing to do. But it is not "scaling". 

**Big-blocker** is a catch-all term for anything that you cannot realistically run on a laptop or a phone, simple as that.

Yes, Solana uses fancy Proof-of-History (basically a streaming hashonion), but it has no impact on actual security assumtions. It runs in parallel, but that's a 10x improvement, not 1Mx one we need for planetery scalability. It requires unicast second layer.

## Rollups don't use credit

No, they all do. First, in form of preconfirmations - it's a fractional reserve-style promise given by sequenceer only covered by shared-pot bond. Second, in form of verifier dilemma and data availability paradox. Both are unsolvable.

## Payment channels don't use credit

Yes, and full-reserve channels don't work. And when they work, turns out custodial service or 0-conf/JIT on receive channel was used. Both are just weaker form of Xln's enforceable credit.

## You hate rollups? You hate payment channels?

No. I admire dedication. And that's why I admire both rollups and traditional full-reserve payment channels in their pursuit. 

But sometimes a simpler solution is out there, in front of your nose. It's not giving up, it's getting real.

## You are re-creating banks. Satoshi said we must get rid of those?

<img src="../frontend/static/img/bailout.png" width="600px">

Hubs (banks+brokers entities) were never the problem per se. Bailouts are. 

Hubs in tradfi lack 1) proofs for security-of-communication 2) collateral for security-from-counterparty-risk 3) delta transformers for security-in-motion.

Xlnomy is a bailout free. You never have a too-big-to-fail player, systemic contagion is bounded by per-link credit limits and escrowed collateral. 

## Show, don't tell!

You can build & play with your personal home-grown xlnomy at [xln.finance](https://xln.finance) in 2D/Graph 3D/VR/Panel/Terminal interface. **It's real fun with Oculus Quest!** Create personal entities, N/M multifactor entities, hierarchical companies and institutions with instant IPO of C/D shares with any hub. Stream dividends and buybacks per-second, do merge&acquisitions, new board election, and of course borrow/lend/payments/swaps and other DeFi primitives of any complexity. 

<img src="../frontend/static/img/preview.png" width="600px">

Private testnet with cross-subnet networking ETA: Q1 2026.

## Should I read it? What's the target audience?

Anyone, really. Especially if you're into fintech/crypto/complex systems. If you're willing to bend your mental models around the status quo, embrace our contrarian yet factually correct rhetoric, ready to research into unknown and question the dogmas from first principles - yes.

If you don't have time for 30-60 min deep reading - **spend 5 minutes on understanding core RCPAN invariant** and save the rest of the document for the future. 

## How it solves famous Trilemma?

1. Scalability (high TPS)
2. Security (can't be attacked)
3. Decentralization (anyone can validate)

Xln claims we must double down on 2 & 3 as fundamental. And we entirely sidestep 1-Scalability of gross J-layer, by moving all <$1m transfers down to netting Layer2. Without verifier dilemma. Without zk-proofs. Without blobspace or onchain footprint per transaction. 

J-machines see very rare, market-priced batched cashflow rebalances by hubs, who match net-spenders of collateral with net-receivers. Exactly how traditional finance worked for centuries.


2018: "Ethereum will scale via sharding"
2022: "Actually, rollups are the answer"  
2024: "Actually, blob space + rollups"
2025: "Actually, we don't know, but here's more complexity"

XLN perspective: 
"Base layer TPS was NEVER the bottleneck. Stop trying to scale broadcast.

## How to read it

The documents are a little heavy on technical & financial terminology. This is intentional - instead of making it a tedious long read "for the general crowd", it seemed like a better idea to make it concentrated and to the point, letting readers ask an LLM of their choice to re-hydrate and expand on any paragraph, with targeted prompts like "ELI5?", "I'm a banker, what is it?", "I'm a protocols engineer, what's under the hood?".

There will be more approachable and elaborated versions of it soon. You're welcome to create your own adaptaion, though!

**Start with "context: https://xln.finance/c.txt should I learn it and why?" with any frontier language model.** GPT-5/Claude/Grok/Gemini/Qwen/GLM ‚Äì all have phenomenal grasp on UFT/Xln once you attach the whitepapers/contracts/src as the context.s

Feel free to reach out directly if after 3-5 prompts the answers still seem cryptic to you. 



//vibepaper/docs/12_invariant.md (80 lines)
# 1.2 RCPAN Invariant 

[pairing: Pye Corner Audio - The Simplest Equation](https://www.youtube.com/watch?v=Vp0a8tdzJmk) (but yes, technically it's inequality)


The core credit‚Äìcollateral mechanism can be grasped in three minutes. Accounts are bilateral relationships between entities. 

For centuries, the world has run on FCUAN (full-credit, unprovable account networks‚Äîi.e., traditional banking credit rails): bilateral, uncollateralized limits between end-users (‚Äúspokes‚Äù) and banks/brokers (‚Äúhubs‚Äù). Any CEX (e.g., Binance, Coinbase) is also FCUAN. 

FCUAN scales phenomenally but offers weak user security. Any spoke can be censored, and assets seized at any moment. Hubs can default, even without malice (Diamond‚ÄìDybvig‚Äìstyle hub runs). 

Deposit insurance is typically small relative to broad money (‚â™ M2), which systematically externalizes tail risk and invites moral hazard.

Two entities start a financial relationship (per-asset Œî balances). Their xln wallets compare their hex IDs; the lower becomes L (left), the other R (right). Imagine an x-axis where:

. is zero (0)
Œî delta is the signed balance (saldo) between counterparties
[ ] are invariant boundaries‚Äîhow far Œî can move given mutual credit and shared collateral

Clean slate (all zeros):

(L)eft entity   [.Œî]   (R)ight entity

Either party can extend a credit limit to the other:
- unused, uncollateralized credit line (credit)
* used credit

Example (leftCreditLimit = 3, rightCreditLimit = 3):

[---.Œî---]

Payments pull Œî toward the payer‚Äôs side (away from the receiver) while the receiver‚Äôs allocation increases.
L pays 2 to R ‚Üí Œî = ‚àí2:

[-Œî**.---]

R pays back 3 ‚Üí Œî = +1:

[---.*‚àÜ--]

This is what 99.99% of the world economy runs on. Today, every bank, broker, CEX, and payment intermediary is pure FCUAN.

A different approach, FRPAP (full-reserve, provable account primitives), often called ‚Äúpayment/state channels,‚Äù was popularized by the 2017 Lightning Network paper. FRPAP/Payment channels are full-reserve bilateral accounts with proofs‚Äînot a network architecture.

Every full-reserve design (e.g., Raiden on Ethereum, Hydra on Cardano) inherits the inbound-capacity constraint‚Äîan architectural limit, not an implementation bug. It‚Äôs more precise to treat this as a family of three account primitives‚Äîproofs, collateral, and delta transformers‚Äîrather than a scalable network.

In diagrams:
= collateral (fully escrowed). Think of it as a dedicated 2-of-2 escrow with cryptographic guarantees.

We draw collateral to the right of zero. R posts 3 units of collateral:

[.Œî===]

R pays 2 (Œî moves right):

[.==Œî=]

xln is the first RCPAN (Reserve-Credit, Provable Account Network): credit where it scales, collateral where it secures‚Äîa principled hybrid of FCUAN and FRPAP.

FCUAN invariant:
‚àíleftCreditLimit ‚â§ Œî ‚â§ rightCreditLimit
[---.---]

FRPAP invariant:
0 ‚â§ Œî ‚â§ collateral
[.===]

RCPAN (xln) superset invariant:
‚àíleftCreditLimit ‚â§ Œî ‚â§ collateral + rightCreditLimit
[---.===---]

xln can mimic both: ignore collateral functionality and it works like banking with enforceable proofs; ignore credit lines and it works like Lightning/full-reserve payment-channel networks. 

Using both is where the real synergy emerges.

Practical consequences: no inbound liquidity wall and no unbounded hub risk‚Äîlosses are link-capped; throughput scales with links, not global broadcasts.

Follow for news, analysis, and a verification-first roadmap (proof sketch, benchmarks, economic spec, security playbook). xln is layer-2 done right.

üîó https://github.com/xlnfinance/xln

//vibepaper/docs/jea.md (134 lines)
üèõÔ∏è JEA: Jurisdiction-Entity-Account Model

‚ÄúJEA is not just a technical pattern ‚Äî it‚Äôs a legal operating system for programmable institutions.‚Äù

The JEA architecture underpins XLN‚Äôs modular trust and execution model. It separates concerns cleanly across three layers:
	‚Ä¢	Jurisdictions: Public, often on-chain arbitration and registry zones
	‚Ä¢	Entities: Sovereign programmable machines (like DAOs or firms)
	‚Ä¢	Accounts (Channels): Bilateral trust relationships or financial instruments

This document outlines the JEA structure in detail, its purpose, flow, and how it replaces traditional consensus-heavy architectures.

‚∏ª

‚öñÔ∏è 1. Jurisdiction: Public Arbitration Layer

A Jurisdiction is a public smart contract or observable registry that acts as:
	‚Ä¢	Dispute settlement ground
	‚Ä¢	Reserve registry
	‚Ä¢	Oracle of record for shared events

Key Concepts
	‚Ä¢	Jurisdiction is opt-in: Entities choose when to interact
	‚Ä¢	Jurisdiction has no access to internal state
	‚Ä¢	Jurisdiction observes receipts: Signed proofs of action

Contracts
	‚Ä¢	EntityProvider.sol ‚Äî stores quorum hash (Merkle root of signer structure)
	‚Ä¢	Depository.sol ‚Äî stores reserve/collateral data
	‚Ä¢	Custom registries ‚Äî e.g., insurance claims, auctions, licenses

Use Cases

Case	Jurisdiction Role
Reserve deposit	Holds tokens, emits event
Credit collateralization	Verifies locked assets and releases collateral
Token mint claim	Accepts signed receipt from Entity and emits asset

‚ÄúJurisdictions are like courts that accept signed, notarized paperwork ‚Äî but never interfere in private life unless called.‚Äù

‚∏ª

üèõÔ∏è 2. Entity: Sovereign Organization

An Entity is a self-contained state-time machine with its own quorum, storage, and block history.

Key Properties
	‚Ä¢	Maintains internal logic via deterministic actions
	‚Ä¢	Requires quorum threshold for any state change
	‚Ä¢	Can spawn accounts, tokens, and internal machines
	‚Ä¢	Interacts with Jurisdiction via signed receipts

On Jurisdiction Access
	‚Ä¢	Entity creates a Proposal to mint/reserve/interact externally
	‚Ä¢	Once quorum signs and the state commits, the signed receipt is emitted
	‚Ä¢	Receipt may be submitted to Jurisdiction by any party (watchers)

Security Guarantees
	‚Ä¢	Jurisdiction verifies Merkle proof of quorum hash
	‚Ä¢	Jurisdiction does not need to replay Entity logic ‚Äî trust is cryptographic

‚ÄúAn Entity is like a company with its own bylaws and board. The state doesn‚Äôt care what happens inside ‚Äî until you file a public claim.‚Äù

‚∏ª

üí≥ 3. Account: Channels and Financial Instruments

Accounts represent:
	‚Ä¢	Channels (credit lines, bilateral payments)
	‚Ä¢	Subcontracts (vesting, options, loans)
	‚Ä¢	Internal balances or positions

Structure
	‚Ä¢	Always nested inside an Entity
	‚Ä¢	Follows AccountProof ‚Üí Subcontract model
	‚Ä¢	Each has its own logic, deltas, and Merkle proof

Execution
	‚Ä¢	Account emits proof of state change (e.g. balance update)
	‚Ä¢	Entity collects and commits proof into its block
	‚Ä¢	Optionally, Jurisdiction may act on this (e.g. insurance trigger)

‚ÄúAccounts are the atoms. Entities are the molecules. Jurisdiction is the surrounding legal atmosphere.‚Äù

‚∏ª

üîÅ Flow Summary: Bottom-Up

1. Account: emits change (e.g., collateral unlocked)
2. Entity: signs and commits block containing proof
3. Jurisdiction: optionally accepts receipt, verifies hash chain


‚∏ª

üõ° Why JEA Is Superior

Feature	Traditional Stack	JEA Architecture
Shared State	Global / Bottleneck	Local / Modular
Dispute Resolution	Forks / Governance	Receipt + Quorum
Composability	High coupling	Strong separation
State Integrity	L1-dependent	Self-contained with proofs
Credit / Receivability	Impossible	Native via Accounts

‚ÄúRollups try to be courts, states, and wallets all at once. JEA says: split the roles, keep the contracts clean, and let each layer focus on what it‚Äôs best at.‚Äù

‚∏ª

üß¨ Design Ethos
	‚Ä¢	Modularity over Monolith: Each layer is clean, testable, swappable
	‚Ä¢	Paper trail over gossip: All actions leave verifiable receipts
	‚Ä¢	State sufficiency: If your Entity vanishes, your counterparty still has proof
	‚Ä¢	Quorum ‚â† Token ownership: Governance and execution are separate vectors

‚∏ª

üß≠ Future Directions
	‚Ä¢	Jurisdictions as regulated custodians
	‚Ä¢	Inter-Jurisdiction arbitration via Entity-controlled registries
	‚Ä¢	Reputation-weighted quorum systems
	‚Ä¢	Federated DAOs across multiple Entities

‚∏ª

üìå In Practice
	‚Ä¢	EntityProvider.sol: sets Merkle hash of quorum
	‚Ä¢	Depository.sol: verifies and tracks reserves
	‚Ä¢	Entity: commits actions, emits receipts
	‚Ä¢	Account: executes financial logic, tracks deltas

‚∏ª

JEA is to blockchain what OSI was to networking ‚Äî a layered abstraction that makes sovereign computation composable, trustable, and legible.

‚ÄúYou don‚Äôt need one chain to rule them all. You just need a structure where trust can be scoped, verified, and proven.‚Äù

//vibepaper/docs/consensus/transaction-flow-specification.md (280 lines)
# XLN Transaction Flow Specification

## Overview
This document specifies the complete transaction flow in the XLN consensus system, based on implementation discoveries and debugging sessions.

## Transaction Types

### 1. Chat Transactions
```typescript
{
  type: 'chat',
  data: {
    message: string
  }
}
```

### 2. Proposal Transactions  
```typescript
{
  type: 'propose',
  data: {
    id: string,           // Generated: 'prop_' + random
    action: {
      type: string,       // e.g., 'updateThreshold', 'addValidator'
      description: string,
      data: any
    }
  }
}
```

### 3. Vote Transactions
```typescript
{
  type: 'vote', 
  data: {
    proposalId: string,
    choice: 'yes' | 'no' | 'abstain',
    comment?: string     // Optional vote comment
  }
}
```

## Consensus Flow Models

### Proposer-Based Model (Current Implementation)
1. **Transaction Creation**: User creates transaction in UI
2. **Mempool Addition**: Transaction added to replica's mempool
3. **Non-Proposer Forwarding**: If not proposer, forward all mempool txs to proposer
4. **Proposer Collection**: Proposer collects transactions from all replicas
5. **Frame Creation**: Proposer creates frame with collected transactions
6. **Precommit Phase**: All replicas precommit to the frame
7. **Commit Phase**: Once threshold reached, frame is committed
8. **State Application**: All replicas apply the committed frame

### Single Signer Optimization
For entities with 1 validator and threshold 1:
1. **Direct Execution**: Skip consensus rounds entirely
2. **Immediate Application**: Apply transactions directly from mempool
3. **Instant Commitment**: No need for precommit/commit phases

## Data Flow Architecture

### Frontend ‚Üí Backend
```javascript
// Vote submission example
const serverInput = {
  entityTxs: [{
    entityId: activeTab.entityId,
    signerId: activeTab.signer,
    transactions: [voteTransaction],
    timestamp: Date.now()
  }]
};

XLN.applyServerInput(serverInput);
```

### Backend Processing
```typescript
// In entity-consensus.ts
function applyEntityInput(entityReplica, input) {
  // 1. Add transactions to mempool
  entityReplica.mempool.push(...input.transactions);
  
  // 2. Forward to proposer (if not proposer)
  if (!entityReplica.isProposer && entityReplica.mempool.length > 0) {
    // Forward transactions to proposer
  }
  
  // 3. Process precommits/commits
  if (commitNotification) {
    // Apply committed frame
  }
}
```

### State Updates
```typescript
// In entity-tx.ts
function applyEntityTx(state, tx) {
  switch (tx.type) {
    case 'vote':
      const proposal = state.proposals.get(tx.data.proposalId);
      if (proposal) {
        proposal.votes.set(signerId, {
          choice: tx.data.choice,
          comment: tx.data.comment
        });
      }
      break;
    // ... other transaction types
  }
  return newState;
}
```

## Timing and Ordering

### Critical Ordering in entity-consensus.ts
```typescript
// CORRECT ORDER:
// 1. Process new transactions first
entityReplica.mempool.push(...input.transactions);

// 2. Forward to proposer BEFORE processing commits
if (!entityReplica.isProposer && entityReplica.mempool.length > 0) {
  // Forward logic here
}

// 3. Process commits last (clears mempool)
if (commitNotification) {
  // Commit processing here
}
```

### Race Condition Prevention
- **Forward Before Commit**: Ensure transaction forwarding happens before commit processing
- **Mempool Management**: Clear mempool only after successful forwarding
- **State Consistency**: Use immutable updates to prevent partial state corruption

## Frame Structure
```typescript
interface Frame {
  id: string;           // 'frame_' + height + '_' + timestamp
  height: number;       // Consensus height
  timestamp: number;    // Frame creation time
  transactions: EntityTx[];  // All transactions in this frame
  proposer: string;     // Proposer replica ID
}
```

## Proposal Lifecycle

### 1. Creation Phase
```typescript
// Proposal created via UI
const proposal = {
  id: 'prop_' + generateId(),
  proposer: currentSigner,
  action: {
    type: 'updateThreshold',
    description: 'Update voting threshold to 2',
    data: { newThreshold: 2 }
  },
  votes: new Map(),
  status: 'pending',
  timestamp: Date.now()
};
```

### 2. Voting Phase
```typescript
// Votes collected from replicas
proposal.votes.set('alice', { choice: 'yes', comment: 'Agree' });
proposal.votes.set('bob', { choice: 'no', comment: 'Too restrictive' });
```

### 3. Execution Phase
```typescript
// Calculate voting power
let yesVotingPower = 0n;
for (const [voter, voteData] of proposal.votes) {
  if (voteData.choice === 'yes') {
    yesVotingPower += state.validators.get(voter) || 0n;
  }
}

// Check if threshold reached
if (yesVotingPower >= state.threshold) {
  proposal.status = 'executed';
  // Apply proposal action
} else {
  proposal.status = 'failed';
}
```

## Error Handling Patterns

### Transaction Validation
```typescript
function validateTransaction(tx, state) {
  switch (tx.type) {
    case 'vote':
      // Check if proposal exists
      if (!state.proposals.has(tx.data.proposalId)) {
        throw new Error('Proposal not found');
      }
      // Check if already voted
      const proposal = state.proposals.get(tx.data.proposalId);
      if (proposal.votes.has(signerId)) {
        throw new Error('Already voted on this proposal');
      }
      break;
  }
}
```

### State Recovery
```typescript
function recoverFromCorruption() {
  // Rebuild state from transaction history
  let cleanState = getInitialState();
  for (const frame of committedFrames) {
    for (const tx of frame.transactions) {
      cleanState = applyEntityTx(cleanState, tx);
    }
  }
  return cleanState;
}
```

## Performance Optimizations

### Batch Processing
```typescript
// Process multiple transactions together
function processBatch(transactions) {
  return XLN.processUntilEmpty(
    XLN.applyServerInput({ entityTxs: transactions })
  );
}
```

### Memory Management
```typescript
// Limit history size
const MAX_HISTORY_FRAMES = 1000;
if (history.length > MAX_HISTORY_FRAMES) {
  history = history.slice(-MAX_HISTORY_FRAMES);
}
```

### Selective Updates
```typescript
// Only update UI for relevant changes
function shouldUpdateUI(oldState, newState) {
  return oldState.height !== newState.height ||
         oldState.proposals.size !== newState.proposals.size;
}
```

## Integration Points

### Frontend Integration
- Use `XLN.processUntilEmpty()` after all server inputs
- Implement defensive replica lookups with multiple key formats
- Handle BigInt conversions consistently

### Testing Integration
- Create corner case tests for single signer entities
- Test vote forwarding and race conditions
- Verify proposal execution thresholds

### Debugging Integration
- Use unique log prefixes for transaction tracing
- Implement frame-by-frame history analysis
- Monitor mempool states and forwarding behavior


//vibepaper/docs/11_Jurisdiction_Machine.md (43 lines)
# 1.1 Jurisdiction Machine / J-machine

## 1.1.1 TradFi J-machine

Imagine, the year is 2008. Blockchains/cryptocurrencies/DLT never existed. Forget about DAOs, BFT and payment channels, lets focus exclusively on the traditional financial world (TradFi). We are going to apply Occam's Razor and Duck Typing principle to each component of TradFi, to remove the legacy fluff and extract the essence.

Let's start with our fundamental primitive: a replicated state machine.

What is a state machine? It's an abstract concept from Automata theory. A state machine is a system that moves between defined states based on inputs ‚Äî each tx (transaction) changes behavior predictably. It‚Äôs how you turn chaos into logic.

Say, you have `{Alice: 10, Bob: 5}`. Tx `alice-bob pay 2` would turn it into `{Alice: 8, Bob: 7}`

TradFi can be expressed as a myriad of interconnected state machines. At first glance it seems that every country has their own unique financial system with different acronyms and legal quirks. But after a closer look, we immediately see a pattern: there always is a root sovereign settlement court state machine that rules all state machines beneath it: the Jurisdiction State Machine.

For historical reasons, tradfi J-machines are fragmented:

* the oldest component ‚Äì Central Bank, where **the currency (fiat) token** is minted in a form of debt to commercial banks.
* the second component, Real Time Gross Settlement (RTGS) appeared later with advances in computers and networking. It allows commercial banks to move high value instantly (real time) without trusting each other with netting accounts (ACH). Technically, an account in Fedwire is an account in Fed. Therefore RTGS === Central Bank.
* the third is central securities depository. That's where other **tokens are minted and stored**. 
* plus multiple land registries where non-fungible tokens such as land and apartments are assigned to entities

This fragmentation brings nothing but pain and reconcillation hell. 

Storing fiat token in one ledger and security tokens in another is like keeping count of bananas in one spreadsheat and using a whole another book for other fruits. The benefits are marginal, the downsides are glorious. 

Applying Occam's Razor, we suggest from now on to conceptually treat all fragmented tradfi central banks/RTGS/depositories as a unified J-machine. 

## 1.1.2 TradFi Entity Machine

Beneath the J-machine there always is a second layer graph-like hub & spoke network, where:
* **spokes** are end users, merchants, companies, non-profits, institutions
* **hubs** commercial banks, brokers

We generalize all layer2 actors bounded to specific J-machine as E-machines. Think of it as your personal state machine that stores your financial history and relationships with others. Each E-machine can interact with J-machine (the broadcast layer) and with other entities through A-machines (unicast account layer).







Namely, in TradFi we superset {RTGS, Central Banks and Central Securities Depositaries} as a single-signer J-machine. Likewise, we claim "blockchains" or "cryptocurrencies" should have never existed as buzzwords: it's a multi-signer J-machine.
 

//worlds/architecture.md (143 lines)
# XLN Scenario Architecture

## The Truth: Everything is EntityInput

There is no `xln.pay()` abstraction. XLN has ONE primitive:

```typescript
await runtime.process(env, [{
  entityId: '0x123...',
  signerId: 's1',
  entityTxs: [{ type: 'directPayment', data: {...} }]
}]);
```

## Three Layers of Scenario Definition

### Layer 1: Pure EntityInput (Lowest Level)
```javascript
export default async function(runtime) {
  const env = runtime.createEmptyEnv();

  // Raw EntityInput - what actually happens
  await runtime.process(env, [{
    entityId: generateEntityId(1),
    signerId: 's1',
    entityTxs: [{
      type: 'directPayment',
      data: {
        targetEntityId: generateEntityId(2),
        route: [generateEntityId(2)],
        amount: 100n,
        tokenId: 1
      }
    }]
  }]);

  return env;
}
```

**Pros:** Complete control, type-safe
**Cons:** Verbose, requires understanding EntityInput structure

### Layer 2: DSL Parser (Current, Works Today)
```javascript
export default async function(runtime) {
  const scenario = `
SEED my-scenario

0: Setup
grid 2 2 2

===

1: Payment
0_0_0 pay 1_0_0 100
`;

  const env = runtime.createEmptyEnv();
  const parsed = await runtime.parseScenario(scenario);
  return await runtime.executeScenario(parsed, env);
}
```

**Pros:** Works today, readable, tested
**Cons:** DSL maintenance, limited features

### Layer 3: Helper API (Future)
```javascript
export default async function(runtime) {
  const { entity, grid, pay } = runtime.api;
  const env = runtime.createEmptyEnv();

  await grid(env, 2, 2, 2);
  await pay(env, entity('0_0_0'), entity('1_0_0'), 100);

  return env;
}
```

**Pros:** Clean, type-safe (if we build it)
**Cons:** Doesn't exist yet

## Recommendation: Start with Layer 2 (DSL)

The DSL parser already exists and works. Use it:

```javascript
// any-scenario.xln.js
export default async function(runtime) {
  return await runtime.loadScenarioFromText(`
    SEED ${Date.now()}

    0: Title
    Narrative
    command params

    ===

    1: Next Frame
    More narrative
    another command
  `);
}
```

Or even simpler - just use `.scenario.txt` files directly:

```
scenarios/
‚îú‚îÄ‚îÄ cube-demo.scenario.txt          (current format)
‚îú‚îÄ‚îÄ diamond-dybvig.scenario.txt     (current format)
‚îî‚îÄ‚îÄ corporate-treasury.scenario.txt (new scenarios in DSL)
```

## The Real Goal: Unified XLNView

**Don't bikeshed scenario format. Focus on:**

1. **Extract 3D renderer** from NetworkTopology.svelte
2. **Create XLNView.svelte** (embeddable component)
3. **Load scenarios** (from .txt or .js, doesn't matter)
4. **Fix grid positioning** (cube not circle)
5. **Add multi-view tabs** (3D/Terminal/Panels)

The scenario format is secondary. The viewer component is primary.

## Next Action

**Create unified XLNView component** that:
- Accepts scenario (text or JS)
- Renders 3D cube correctly
- Embeddable anywhere
- Shareable URLs

Want me to:
1. Extract 3D core from NetworkTopology.svelte
2. Create XLNView.svelte
3. Fix grid positioning
4. Test in /embed route

Go?

