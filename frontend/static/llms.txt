# XLN Context - Core System Files (~205k tokens)
# Generated: 2026-01-19 17:17:58 | Git: 940a4f3

## THE CORE INNOVATION: RCPAN Invariant

XLN solves what was thought impossible: **instant settlement without blockchain latency**.

The breakthrough is the RCPAN invariant that unifies credit and collateral:
  âˆ’Lâ‚— â‰¤ Î” â‰¤ C + Láµ£

Where:
- Î” = net balance (positive = you owe me, negative = I owe you)
- C = my collateral (what I can lose)
- Lâ‚— = credit I extend to you (unsecured lending)
- Láµ£ = credit you extend to me (your trust in me)

This single invariant:
- Eliminates the FCUAN problem (Full Credit Unprovable Account Networks)
- Eliminates the FRPAP problem (Full Reserve Provable Account Primitives)
- Enables instant bilateral netting with partial collateral
- Makes credit programmable and composable

## Competitive Landscape

| System | Settlement | Collateral | Credit | Netting | Trust Model |
|--------|-----------|------------|---------|---------|-------------|
| **XLN** | Instant (bilateral) | Partial (RCPAN) | Programmable | Yes (bilateral) | BFT consensus |
| Lightning | Near-instant | Full (100%) | No | No | Unilateral exit |
| Rollups | 7-day finality | Full (100%) | No | No (batch only) | Fraud proof |
| Banks | T+2 settlement | Fractional (~10%) | Yes | Yes (multilateral) | Legal system |
| Ripple/Stellar | 3-5 sec | Trust lines | Trust lines | Limited | Consensus |

**XLN uniquely combines**: Bank-like netting + Lightning-like instant settlement + Programmable credit

## Impossible Before XLN

1. **Instant cross-chain atomic swaps with <100% collateral** - Lightning requires full collateral, XLN uses RCPAN
2. **Bilateral settlement without fraud period** - Rollups need 7 days, XLN settles instantly via consensus
3. **Programmable credit as a first-class primitive** - Banks have credit but not programmable, crypto has programs but not credit
4. **Multi-hop payments that NET positions** - Ripple batches, Lightning routes, only XLN nets bilaterally
5. **Entity-owned subcontracts (HTLCs, limit orders) without separate channels** - One bilateral account, many subcontracts

## Token Budget Guide (~205k tokens total)

**Critical path (read first, ~30min):**
- âš¡ emc2.md (5min) - Why credit = stored energy
- âš¡ docs/12_invariant.md (10min) - RCPAN derivation
- âš¡ docs/jea.md (8min) - 3-layer architecture
- âš¡ Depository.sol (7min) - enforceDebts() FIFO + RCPAN enforcement

**Implementation (read second, ~45min):**
- types.ts (10min) - All data structures
- entity-consensus.ts (15min) - BFT state machine
- account-consensus.ts (12min) - Bilateral consensus
- entity-tx/apply.ts (8min) - Transaction dispatcher

**Deep dives (optional, ~60min):**
- runtime.ts (15min) - Main coordinator
- routing/pathfinding.ts (10min) - Dijkstra multi-hop
- priorart.md (20min) - Why Lightning/rollups fail
- 11_Jurisdiction_Machine.md (15min) - Full architecture

## Building on XLN: Delta Transformers

Every bilateral account is a **programmable state machine** that transforms deltas. Examples:

**1. HTLC (Hash Time-Locked Contract):**
```typescript
// Alice â†’ Bob payment locked by hash H
Î”_proposed = +1000  // Bob's balance increases IF he reveals R where hash(R) = H
// If Bob reveals R: commit Î”_proposed
// If timeout: revert Î”_proposed
```

**2. Limit Order:**
```typescript
// "Buy 100 USDC at 0.5 ETH each when ETH/USDC â‰¤ 2000"
if (oraclePrice <= 2000) {
  Î”_USDC = +100
  Î”_ETH = -50
}
```

**3. Dividend Distribution:**
```typescript
// Entity pays 10% dividend to all C-share holders
for (const holder of cShareHolders) {
  Î”[holder] = entity.reserves * 0.1 * (holder.cShares / totalCShares)
}
```

**4. Netting Optimizer:**
```typescript
// Instead of Aâ†’Bâ†’Câ†’D, net to Aâ†’D
multiHopDeltas = [{A: -100}, {B: +100, C: -100}, {D: +100}]
nettedDelta = {A: -100, D: +100}  // B and C netting canceled
```

Every subcontract is just a **delta transformer** that respects RCPAN invariant.

## Proof & Verification

**How to verify XLN's core claims:**

1. **RCPAN invariant eliminates FCUAN/FRPAP**: Read docs/12_invariant.md lines 45-120 (proof by construction)
2. **Instant bilateral settlement**: See account-consensus.ts ADD_TX â†’ PROPOSE â†’ SIGN â†’ COMMIT (no fraud period)
3. **BFT consensus correctness**: entity-consensus.ts implements PBFT-style 3-phase commit (â…” threshold)
4. **On-chain enforcement**: Depository.sol enforceDebts() FIFO queue processes debts until reserves depleted
5. **Deterministic state**: snapshot-coder.ts RLP encoding + Keccak-256 hashing ensures identical state roots

**Run scenarios yourself:**
```bash
bun run src/server.ts  # Starts server
# Visit localhost:8080
# Load scenario: "phantom-grid" or "diamond-dybvig"
# Inspect entity states in console: inspect("alice")
```

## Cross-Local Network: Off-chain settlement with on-chain anchoring

ðŸ”´ **READ SOLIDITY FIRST** - Contracts are the source of truth for all invariants

xln/
  jurisdictions/contracts/
    Types.sol                  186 lines - Shared types: Diff, BatchArgs, InsuranceReg
    Depository.sol             1160 lines - enforceDebts() FIFO, collateral + credit (INVARIANT: L+R+C=0)
    EntityProvider.sol         1137 lines - Hanko sigs, Control/Dividend, governance
    Account.sol                362 lines - A-machine on-chain: bilateral accounts, settlements
    DeltaTransformer.sol       191 lines - Delta transformations: HTLCs, swaps, limit orders

  runtime/
    types.ts                     1684 lines - All TypeScript interfaces (START HERE)
    ids.ts                       519 lines - Identity system: EntityId, SignerId, JId, ReplicaKey
    runtime.ts                   2252 lines - Main coordinator, 100ms ticks, R->E->A routing
    entity-consensus.ts          1209 lines - BFT consensus (ADD_TX -> PROPOSE -> SIGN -> COMMIT)
    account-consensus.ts         1377 lines - Bilateral consensus, left/right perspective
    account-consensus-state.ts   171 lines - Bilateral state machine
    j-batch.ts                   807 lines - J-batch: E-machine accumulates â†’ jBroadcast â†’ J-machine
    account-utils.ts             221 lines - deriveDelta() RCPAN calculation
    serialization-utils.ts       116 lines - BigInt serialization
    account-crypto.ts            397 lines - Signature verification

    entity-tx/
      index.ts                   7 lines - Entity transaction types
      apply.ts                   928 lines - Entity tx dispatcher
      validation.ts              37 lines - Transaction validation
      financial.ts               33 lines - Financial accounting
      proposals.ts               35 lines - Proposal logic
      j-events.ts                793 lines - Jurisdiction events
      handlers/account.ts              872 lines - Account operations
      handlers/deposit-collateral.ts   74 lines - R2C deposits
      handlers/htlc-payment.ts         238 lines - HTLC routing
      handlers/create-settlement.ts    62 lines - Settlement creation
      handlers/mint-reserves.ts        55 lines - Reserve minting

    account-tx/
      index.ts                   10 lines - Account transaction types
      apply.ts                   215 lines - Account tx dispatcher
      handlers/add-delta.ts      42 lines - Delta addition

    routing/
      graph.ts                   117 lines - Network graph
      pathfinding.ts             227 lines - Dijkstra routing

    state-helpers.ts             675 lines - Pure state management
    snapshot-coder.ts            316 lines - Deterministic RLP serialization
    evm.ts                       961 lines - Blockchain integration

  docs/
    emc2.md                      33 lines - âš¡ Energy-Mass-Credit equivalence (CRITICAL PATH)
    12_invariant.md              80 lines - âš¡ RCPAN innovation (CRITICAL PATH)
    jea.md                       134 lines - âš¡ Jurisdiction-Entity-Account model (CRITICAL PATH)
    11_Jurisdiction_Machine.md   43 lines - Architecture deep-dive
    PriorArt.md                  62 lines - Why Lightning/rollups don't work

Reading Guide:
1. Start with header sections (RCPAN invariant, competitive landscape, impossibilities)
2. Follow the token budget guide for efficient learning:
   - Critical path (30min): emc2.md â†’ 12_invariant.md â†’ jea.md â†’ Depository.sol
   - Implementation (45min): types.ts â†’ entity-consensus.ts â†’ account-consensus.ts â†’ entity-tx/apply.ts
   - Deep dives (60min): runtime.ts â†’ routing/pathfinding.ts â†’ priorart.md â†’ 11_Jurisdiction_Machine.md
3. Verify claims using the Proof & Verification section
4. Explore delta transformer examples for extensibility patterns

Suggested LLM prompt: "Read the critical path docs (30min budget), then explain how RCPAN enables instant settlement with partial collateral. Compare to Lightning and rollups."


//jurisdictions/contracts/Types.sol (186 lines)
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.24;

/**
 * Types.sol - Shared type definitions for Depository and Account library
 * Both contracts import this to ensure type compatibility
 */

// ========== ACCOUNT STATE ==========

struct AccountInfo {
  uint cooperativeNonce;
  bytes32 disputeHash;
  uint256 disputeTimeout;
}

struct AccountCollateral {
  uint collateral;
  int ondelta;
}

// ========== SETTLEMENT ==========

struct SettlementDiff {
  uint tokenId;
  int leftDiff;
  int rightDiff;
  int collateralDiff;
  int ondeltaDiff;
}

struct Settled {
  bytes32 left;
  bytes32 right;
  uint tokenId;
  uint leftReserve;
  uint rightReserve;
  uint collateral;
  int ondelta;
}

// ========== DEBT & INSURANCE ==========

struct Debt {
  bytes32 creditor;
  uint amount;
}

struct InsuranceLine {
  bytes32 insurer;
  uint256 tokenId;
  uint256 remaining;
  uint256 expiresAt;
}

struct InsuranceRegistration {
  bytes32 insured;
  bytes32 insurer;
  uint256 tokenId;
  uint256 limit;
  uint256 expiresAt;
}

// ========== TRANSFORMERS (was Subcontracts) ==========

struct Allowance {
  uint deltaIndex;
  uint rightAllowance;
  uint leftAllowance;
}

struct TransformerClause {
  address transformerAddress;
  bytes encodedBatch;
  Allowance[] allowances;
}

struct ProofBody {
  int[] offdeltas;
  uint[] tokenIds;
  TransformerClause[] transformers;
}

// ========== DISPUTE ==========

struct InitialDisputeProof {
  bytes32 counterentity;
  uint cooperativeNonce;
  uint disputeNonce;
  bytes32 proofbodyHash;
  bytes sig;
  bytes initialArguments;
}

struct FinalDisputeProof {
  bytes32 counterentity;
  uint initialCooperativeNonce;  // Nonce from when dispute was started
  uint finalCooperativeNonce;
  uint initialDisputeNonce;
  uint finalDisputeNonce;
  bytes32 initialProofbodyHash;
  ProofBody finalProofbody;
  bytes finalArguments;
  bytes initialArguments;
  bytes sig;
  bool startedByLeft;
  uint disputeUntilBlock;
  bool cooperative; // NEW: if true, skip timeout (mutual agreement)
}

// ========== BATCH OPERATIONS ==========

struct Settlement {
  bytes32 leftEntity;
  bytes32 rightEntity;
  SettlementDiff[] diffs;
  uint[] forgiveDebtsInTokenIds;
  InsuranceRegistration[] insuranceRegs;
  bytes sig;
  address entityProvider;
  bytes hankoData;
  uint256 nonce;
}

struct Flashloan {
  uint tokenId;
  uint amount;
}

struct ReserveToReserve {
  bytes32 receivingEntity;
  uint tokenId;
  uint amount;
}

struct ReserveToCollateral {
  uint tokenId;
  bytes32 receivingEntity;
  EntityAmount[] pairs;
}

struct EntityAmount {
  bytes32 entity;
  uint amount;
}

struct ExternalTokenToReserve {
  bytes32 entity; // The entity to credit. If bytes32(0), defaults to msg.sender
  bytes32 packedToken;
  uint internalTokenId;
  uint amount;
}

struct ReserveToExternalToken {
  bytes32 receivingEntity;
  uint tokenId;
  uint amount;
}

struct SecretReveal {
  address transformer;
  bytes32 secret;
}

struct Batch {
  Flashloan[] flashloans;
  ReserveToReserve[] reserveToReserve;
  ReserveToCollateral[] reserveToCollateral;
  Settlement[] settlements;
  InitialDisputeProof[] disputeStarts;
  FinalDisputeProof[] disputeFinalizations;
  ExternalTokenToReserve[] externalTokenToReserve;
  ReserveToExternalToken[] reserveToExternalToken;
  SecretReveal[] revealSecrets;
  uint hub_id;
}

// ========== ENUMS ==========

enum MessageType {
  CooperativeUpdate,
  DisputeProof,
  FinalDisputeProof,
  CooperativeDisputeProof
}


//jurisdictions/contracts/Depository.sol (1160 lines)
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.24;

import "./EntityProvider.sol";
import "./DeltaTransformer.sol";
import "./Types.sol";
import "./Account.sol";

abstract contract ReentrancyGuardLite {
  error E0();
  uint256 private constant _NOT_ENTERED = 1;
  uint256 private constant _ENTERED = 2;
  uint256 private _status = _NOT_ENTERED;

  modifier nonReentrant() {
    if (_status == _ENTERED) revert E0();
    _status = _ENTERED;
    _;
    _status = _NOT_ENTERED;
  }
}

interface IERC20 {
  function transfer(address to, uint256 value) external returns (bool);
  function transferFrom(address from, address to, uint256 value) external returns (bool);
}
interface IERC721 {
  function transferFrom(address from, address to, uint256 tokenId) external;
}

contract Depository is ReentrancyGuardLite {

  // Custom errors
  error E1(); // ZeroAmount
  error E2(); // Unauthorized
  error E3(); // InsufficientBalance
  error E4(); // InvalidSigner
  error E5(); // NoActiveDispute
  error E6(); // DisputeInProgress
  error E7(); // InvalidParty
  error E8(); // LengthMismatch
  error E9(); // HashMismatch

  // Immutable EntityProvider (set in constructor, gas-efficient static calls)
  address public immutable entityProvider;

  // Multi-provider support (legacy - will be removed)
  mapping(address => bool) public approvedEntityProviders;
  address[] public entityProvidersList;
  
  mapping (bytes32 => mapping (uint => uint)) public _reserves;

  mapping (bytes => AccountInfo) public _accounts;
  mapping (bytes => mapping(uint => AccountCollateral)) public _collaterals;

  // Configurable dispute delays (block count) - lower for hubs, higher for end users
  uint256 public defaultDisputeDelay = 20; // ~5 min at 15s blocks
  mapping (bytes32 => uint256) public entityDisputeDelays; // per-entity override 
  

  mapping (bytes32 => mapping (uint => Debt[])) public _debts;
  // the current debt index to pay
  mapping (bytes32 => mapping (uint => uint)) public _debtIndex;
  // total number of debts of an entity  
  mapping (bytes32 => uint) public _activeDebts;


  address public immutable admin;
  bool public emergencyPause;

  // Insurance cursor - tracks iteration position per insured entity
  mapping(bytes32 => uint256) public insuranceCursor;

  event DebtCreated(bytes32 indexed debtor, bytes32 indexed creditor, uint256 indexed tokenId, uint256 amount, uint256 debtIndex);
  event DebtEnforced(bytes32 indexed debtor, bytes32 indexed creditor, uint256 indexed tokenId, uint256 amountPaid, uint256 remainingAmount, uint256 newDebtIndex);
  event DebtForgiven(bytes32 indexed debtor, bytes32 indexed creditor, uint256 indexed tokenId, uint256 amountForgiven, uint256 debtIndex);
  event EmergencyPauseToggled(bool isPaused);

  modifier onlyAdmin() {
    if (msg.sender != admin) revert E2();
    _;
  }

  modifier whenNotPaused() {
    if (emergencyPause) revert E2();
    _;
  }


  // EntityScore tracking removed for size reduction
  // Hub tracking removed for size reduction

  // Events related to disputes and cooperative closures
  event DisputeStarted(bytes32 indexed sender, bytes32 indexed counterentity, uint indexed disputeNonce, bytes32 proofbodyHash, bytes initialArguments);
  event DisputeFinalized(bytes32 indexed sender, bytes32 indexed counterentity, uint indexed initialDisputeNonce, bytes32 initialProofbodyHash, bytes32 finalProofbodyHash);
  event CooperativeClose(bytes32 indexed sender, bytes32 indexed counterentity, uint indexed cooperativeNonce);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CANONICAL J-EVENTS (Single Source of Truth - must match j-event-watcher.ts)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  //
  // These events are the ONLY events that j-watcher processes for entity state.
  // Each event type has exactly ONE purpose:
  //
  // ReserveUpdated  - Entity reserve balance changed (mint, R2R, settlement)
  // AccountSettled  - Bilateral account state changed (in Account.sol)
  //
  // REMOVED (redundant):
  // - ReserveMinted: redundant with ReserveUpdated (newBalance is sufficient)
  // - ReserveTransferred: redundant with 2x ReserveUpdated (one per entity)
  // - SettlementProcessed: duplicate of AccountSettled
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /**
   * @notice Emitted whenever an entity's reserve balance changes.
   * @dev This is THE canonical event for reserve state. Covers: mint, R2R, settlement.
   *      j-watcher uses this to set entity.reserves[tokenId] = newBalance
   * @param entity The entity whose reserve was updated.
   * @param tokenId The internal ID of the token.
   * @param newBalance The absolute new balance of the token for the entity.
   */
  event ReserveUpdated(bytes32 indexed entity, uint indexed tokenId, uint newBalance);
  event SecretRevealed(bytes32 indexed hashlock, bytes32 indexed revealer, bytes32 secret);

  // Debug events (remove in production)
  event DebugSettleStart(bytes32 leftEntity, bytes32 rightEntity, uint256 sigLen, address entityProvider);

  //event ChannelUpdated(address indexed receiver, address indexed addr, uint tokenId);


  uint8 constant TypeERC20 = 0;
  uint8 constant TypeERC721 = 1;
  uint8 constant TypeERC1155 = 2;   




  bytes32[] public _tokens;
  
  // Efficient token lookup: packedToken -> internalTokenId
  mapping(bytes32 => uint256) public tokenToId;

  // === MULTI-PROVIDER MANAGEMENT ===
  
  event EntityProviderAdded(address indexed provider);
  event EntityProviderRemoved(address indexed provider);
  
  modifier onlyApprovedProvider(address provider) {
    require(approvedEntityProviders[provider], "!provider");
    _;
  }
  
  /**
   * @notice Add an EntityProvider to approved list
   * @param provider EntityProvider contract address
   */
  function addEntityProvider(address provider) external onlyAdmin {
    require(provider != address(0), "!addr");
    require(!approvedEntityProviders[provider], "exists");
    approvedEntityProviders[provider] = true;
    entityProvidersList.push(provider);
    emit EntityProviderAdded(provider);
  }
  
  /**
   * @notice Remove an EntityProvider from approved list  
   * @param provider EntityProvider contract address
   */
  function removeEntityProvider(address provider) external onlyAdmin {
    require(provider != address(0), "!addr");
    require(approvedEntityProviders[provider], "!ok");
    approvedEntityProviders[provider] = false;
    
    // Remove from list
    for (uint i = 0; i < entityProvidersList.length; i++) {
      if (entityProvidersList[i] == provider) {
        entityProvidersList[i] = entityProvidersList[entityProvidersList.length - 1];
        entityProvidersList.pop();
        break;
      }
    }
    emit EntityProviderRemoved(provider);
  }
  
  /**
   * @notice Get all approved EntityProviders
   */
  function getApprovedProviders() external view returns (address[] memory) {
    return entityProvidersList;
  }

  constructor(address _entityProvider) {
    require(_entityProvider != address(0), "EntityProvider cannot be zero address");
    entityProvider = _entityProvider;
    approvedEntityProviders[_entityProvider] = true;
    entityProvidersList.push(_entityProvider);
    admin = msg.sender;
    _tokens.push(bytes32(0));
  }

  function setEmergencyPause(bool isPaused) external onlyAdmin {
    if (emergencyPause == isPaused) {
      return;
    }
    emergencyPause = isPaused;
    emit EmergencyPauseToggled(isPaused);
  }

  /// @notice Set dispute delay for an entity (0 = use default)
  /// @dev Hubs get shorter delays, end users get longer delays
  function setEntityDisputeDelay(bytes32 entity, uint256 delayBlocks) external onlyAdmin {
    entityDisputeDelays[entity] = delayBlocks;
  }

  /// @notice Set default dispute delay for entities without custom setting
  function setDefaultDisputeDelay(uint256 delayBlocks) external onlyAdmin {
    require(delayBlocks > 0, "!delay");
    defaultDisputeDelay = delayBlocks;
  }


  function getTokensLength() public view returns (uint) {
    return _tokens.length;
  }

  function getTokenMetadata(uint256 tokenId) external view returns (address contractAddress, uint96 externalTokenId, uint8 tokenType) {
    require(tokenId < _tokens.length, "!tok");
    return unpackTokenReference(_tokens[tokenId]);
  }





  // Batch struct is in Types.sol
  // === HANKO INTEGRATION ===

  /// @notice Sequential nonce for each entity authorising batches via Hanko.
  mapping(address => uint256) public entityNonces;

  /// @notice Domain separator used when hashing Hanko payloads for verification.
  bytes32 public constant DOMAIN_SEPARATOR = keccak256("XLN_DEPOSITORY_HANKO_V1");

  event HankoBatchProcessed(bytes32 indexed entityId, bytes32 indexed hankoHash, uint256 nonce, bool success);

  /// @notice Process a batch authorized by entity Hanko.
  /// @dev Hanko is required; use unsafeProcessBatch only for admin/test flows.
  function processBatch(
    bytes calldata encodedBatch,
    address entityProvider,
    bytes calldata hankoData,
    uint256 nonce
  ) external whenNotPaused nonReentrant onlyApprovedProvider(entityProvider) returns (bool completeSuccess) {
    (bytes32 entityId, bool hankoValid) = EntityProvider(entityProvider).verifyHankoSignature(hankoData, Account.computeBatchHankoHash(DOMAIN_SEPARATOR, block.chainid, address(this), encodedBatch, nonce));
    if (!hankoValid || entityId == bytes32(0)) revert E4();
    address ea = address(uint160(uint256(entityId)));
    if (nonce != entityNonces[ea] + 1) revert E2();
    entityNonces[ea] = nonce;
    completeSuccess = _processBatch(entityId, abi.decode(encodedBatch, (Batch)));
    emit HankoBatchProcessed(entityId, keccak256(hankoData), nonce, completeSuccess);
  }

  /**
   * @notice Mint new reserves to an entity (admin only).
   * @dev In production, minting would be gated by governance. For testnet/demo, admin can mint freely.
   *      Emits both ReserveMinted (for j-watchers tracking mint events) and ReserveUpdated (for balance sync).
   * @param entity The entity receiving the minted reserves.
   * @param tokenId The internal token ID.
   * @param amount The amount to mint.
   */
  function mintToReserve(bytes32 entity, uint tokenId, uint amount) external onlyAdmin {
    if (amount == 0) revert E1();
    
    
    
    
    
    

    _reserves[entity][tokenId] += amount;
    uint newBalance = _reserves[entity][tokenId];

    // Single canonical event for reserve changes
    emit ReserveUpdated(entity, tokenId, newBalance);

    
    
  }


  /// @notice UNSAFE batch processing - entity or admin can call
  /// @dev Use processBatch() (Hanko) in production. This is for explicit unsafe/admin flows.
  /// @dev Settlements still require counterparty signatures (cooperative proof)
  function unsafeProcessBatch(bytes32 entity, Batch calldata batch) public whenNotPaused nonReentrant returns (bool completeSuccess) {
    // Entity itself OR admin can call (admin for J-machine execution)
    // Executes full batch deterministically via _processBatch.
    // NOTE: Admin path bypasses Hanko authorization; prefer processBatch in production.
    require(
      msg.sender == address(uint160(uint256(entity))) || msg.sender == admin,
      "E2: caller must be entity or admin"
    );
    return _processBatch(entity, batch);
  }


  // ========== DIRECT R2R FUNCTION ==========
  /// @notice Simple reserve-to-reserve transfer - fromEntity or admin can call
  /// @dev For multi-sig/Hanko auth, use processBatch() instead
  function reserveToReserve(
    bytes32 fromEntity,
    bytes32 toEntity,
    uint tokenId,
    uint amount
  ) public whenNotPaused nonReentrant returns (bool) {
    // fromEntity itself OR admin can call
    require(
      msg.sender == address(uint160(uint256(fromEntity))) || msg.sender == admin,
      "E2: caller must be fromEntity or admin"
    );
    if (fromEntity == toEntity) revert E2();
    if (amount == 0) revert E1();
    enforceDebts(fromEntity, tokenId);
    if (_reserves[fromEntity][tokenId] < amount) revert E3();

    _reserves[fromEntity][tokenId] -= amount;
    _reserves[toEntity][tokenId] += amount;

    emit ReserveUpdated(fromEntity, tokenId, _reserves[fromEntity][tokenId]);
    emit ReserveUpdated(toEntity, tokenId, _reserves[toEntity][tokenId]);

    return true;
  }

  // ========== SETTLE FUNCTION ==========
  /// @notice External settle with signature verification
  /// @dev Counterparty signature REQUIRED when there are changes
  function settle(
    bytes32 leftEntity,
    bytes32 rightEntity,
    SettlementDiff[] memory diffs,
    uint[] memory forgiveDebtsInTokenIds,
    InsuranceRegistration[] memory insuranceRegs,
    bytes memory sig
  ) public whenNotPaused nonReentrant returns (bool) {
    emit DebugSettleStart(leftEntity, rightEntity, sig.length, entityProvider);
    // Caller is assumed to be leftEntity for signature verification
    bytes32 caller = leftEntity;

    Settlement[] memory settlements = new Settlement[](1);
    settlements[0] = Settlement({
      leftEntity: leftEntity,
      rightEntity: rightEntity,
      diffs: diffs,
      forgiveDebtsInTokenIds: forgiveDebtsInTokenIds,
      insuranceRegs: insuranceRegs,
      sig: sig,
      entityProvider: entityProvider,  // Use Depository's entityProvider for Hanko verification
      hankoData: "",
      nonce: 0
    });

    // Process diffs via Account library (signature validation skipped if no sig provided)
    if (!Account.processSettlements(_reserves, _accounts, _collaterals, caller, settlements)) {
      return false;
    }
    // Handle debt/insurance in Depository
    _handleSettlementDebtAndInsurance(leftEntity, rightEntity, forgiveDebtsInTokenIds, insuranceRegs);
    return true;
  }

  function _processBatch(bytes32 entityId, Batch memory batch) private returns (bool completeSuccess) {
    // SECURITY FIX: Aggregate flashloans by tokenId (prevent duplicate tokenId exploit)
    uint256[] memory flashloanTokenIds = new uint256[](batch.flashloans.length);
    uint256[] memory flashloanStarting = new uint256[](batch.flashloans.length);
    uint256[] memory flashloanTotals = new uint256[](batch.flashloans.length);
    uint uniqueCount = 0;

    // Aggregate flashloans per tokenId
    for (uint i = 0; i < batch.flashloans.length; i++) {
      uint tid = batch.flashloans[i].tokenId;
      uint amt = batch.flashloans[i].amount;

      // Find if this tokenId already seen
      uint j = 0;
      for (; j < uniqueCount; j++) {
        if (flashloanTokenIds[j] == tid) break;
      }

      // New tokenId - record starting reserve
      if (j == uniqueCount) {
        flashloanTokenIds[uniqueCount] = tid;
        flashloanStarting[uniqueCount] = _reserves[entityId][tid];
        uniqueCount++;
      }

      // Accumulate total for this tokenId
      flashloanTotals[j] += amt;
    }

    // Grant aggregated flashloans (flash-mint)
    for (uint j = 0; j < uniqueCount; j++) {
      _reserves[entityId][flashloanTokenIds[j]] += flashloanTotals[j];
    }

    // the order is important: first go methods that increase entity's balance
    // then methods that deduct from it

    completeSuccess = true;

    // Process external token deposits (increases reserves)
    // msg.sender must have approved tokens before calling processBatch
    for (uint i = 0; i < batch.externalTokenToReserve.length; i++) {
      ExternalTokenToReserve memory params = batch.externalTokenToReserve[i];
      // If entity is not specified, default to batch initiator
      if (params.entity == bytes32(0)) {
        params.entity = entityId;
      }
      // Security: entity must be the batch initiator (can't credit others arbitrarily)
      if (params.entity != entityId) revert E2();
      _externalTokenToReserve(params);
    }

    // Process reserveToReserve transfers (the core functionality we need)
    
    
    for (uint i = 0; i < batch.reserveToReserve.length; i++) {
      
      
      
      
      
      
      
      
      
      
      reserveToReserve(entityId, batch.reserveToReserve[i]);
    }

    // Delegate settlement diffs to Account library, handle debt/insurance in Depository
    if (batch.settlements.length > 0) {
      if (!Account.processSettlements(_reserves, _accounts, _collaterals, entityId, batch.settlements)) {
        completeSuccess = false;
      }
      // Handle debt forgiveness and insurance registration (not in Account due to stack limits)
      for (uint i = 0; i < batch.settlements.length; i++) {
        Settlement memory s = batch.settlements[i];
        _handleSettlementDebtAndInsurance(s.leftEntity, s.rightEntity, s.forgiveDebtsInTokenIds, s.insuranceRegs);
      }
    }

    if (batch.disputeStarts.length > 0) {
      if (!Account.processDisputeStarts(_accounts, entityId, batch.disputeStarts, defaultDisputeDelay, entityProvider)) {
        completeSuccess = false;
      }
    }

    // HTLC secret reveals (must run before dispute finalizations)
    for (uint i = 0; i < batch.revealSecrets.length; i++) {
      SecretReveal memory reveal = batch.revealSecrets[i];
      if (reveal.transformer == address(0)) revert E2();
      DeltaTransformer(reveal.transformer).revealSecret(reveal.secret);
      emit SecretRevealed(keccak256(abi.encode(reveal.secret)), entityId, reveal.secret);
    }

    // Dispute finalizations stay in Depository (too many storage refs for Account)
    for (uint i = 0; i < batch.disputeFinalizations.length; i++) {
      if (!_disputeFinalizeInternal(entityId, batch.disputeFinalizations[i])) {
        completeSuccess = false;
      }
    }

    for (uint i = 0; i < batch.reserveToCollateral.length; i++) {
      if(!(reserveToCollateral(entityId, batch.reserveToCollateral[i]))){
        completeSuccess = false;
      }
    }

    // Process external token withdrawals (decreases reserves)
    // Security: batch initiator can only withdraw from their own reserves
    for (uint i = 0; i < batch.reserveToExternalToken.length; i++) {
      reserveToExternalToken(entityId, batch.reserveToExternalToken[i]);
    }

    // SECURITY FIX: Check aggregated flashloan return + burn
    for (uint j = 0; j < uniqueCount; j++) {
      uint tid = flashloanTokenIds[j];
      uint expectedFinal = flashloanStarting[j] + flashloanTotals[j];

      // Check entity returned borrowed amount
      if (_reserves[entityId][tid] < expectedFinal) revert E3(); // Flashloan not returned

      // Burn flashloan (remove temporary mint)
      _reserves[entityId][tid] -= flashloanTotals[j];

      // Final check: reserves back to original or higher
      if (_reserves[entityId][tid] < flashloanStarting[j]) revert E3(); // Reserve decreased
    }

    return completeSuccess;

  }

  // MessageType enum is in Types.sol

  // ReserveToCollateral and EntityAmount (was AddrAmountPair) are in Types.sol


  // Allowance, TransformerClause, ProofBody, InitialDisputeProof, FinalDisputeProof, Debt are in Types.sol

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  //                              INSURANCE
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  // InsuranceLine and InsuranceRegistration structs are in Types.sol

  // insured entity => insurance lines (FIFO queue)
  mapping(bytes32 => InsuranceLine[]) public insuranceLines;

  event InsuranceRegistered(bytes32 indexed insured, bytes32 indexed insurer, uint256 indexed tokenId, uint256 limit, uint256 expiresAt);
  event InsuranceClaimed(bytes32 indexed insured, bytes32 indexed insurer, bytes32 indexed creditor, uint256 tokenId, uint256 amount);

  // DebtSnapshot moved to DepositoryView.sol

  function _addDebt(bytes32 debtor, uint256 tokenId, bytes32 creditor, uint256 amount) internal returns (uint256 index) {
    if (creditor == bytes32(0)) revert E2();
    if (amount == 0) revert E1();
    _debts[debtor][tokenId].push(Debt({ amount: amount, creditor: creditor }));
    index = _debts[debtor][tokenId].length - 1;

    if (index == 0) {
      _debtIndex[debtor][tokenId] = 0;
    }

    _activeDebts[debtor]++;
    emit DebtCreated(debtor, creditor, tokenId, amount, index);
  }

  function _afterDebtCleared(bytes32 entity, bool) internal {
    if (_activeDebts[entity] > 0) {
      unchecked {
        _activeDebts[entity]--;
      }
    }
  }


  function _clearDebtAtIndex(bytes32 entity, uint256 tokenId, uint256 index, bool isRepayment) internal returns (uint256 amountCleared, bytes32 creditor) {
    Debt storage debt = _debts[entity][tokenId][index];
    amountCleared = debt.amount;
    creditor = debt.creditor;

    if (amountCleared > 0) {
      _afterDebtCleared(entity, isRepayment);
    }

    delete _debts[entity][tokenId][index];
  }

  function _countRemainingDebts(Debt[] storage queue, uint256 cursor) internal view returns (uint256 count) {
    uint256 length = queue.length;
    if (cursor >= length) {
      return 0;
    }
    for (uint256 i = cursor; i < length; i++) {
      if (queue[i].amount > 0) {
        count++;
      }
    }
  }

  function _syncDebtIndex(bytes32 entity, uint256 tokenId) internal {
    Debt[] storage queue = _debts[entity][tokenId];
    uint256 length = queue.length;
    if (length == 0) {
      _debtIndex[entity][tokenId] = 0;
      return;
    }

    uint256 cursor = _debtIndex[entity][tokenId];
    if (cursor >= length) {
      cursor = 0;
    }

    while (cursor < length && queue[cursor].amount == 0) {
      cursor++;
    }

    if (cursor >= length) {
      _debtIndex[entity][tokenId] = 0;
      delete _debts[entity][tokenId];
    } else {
      _debtIndex[entity][tokenId] = cursor;
    }
  }

  function packTokenReference(uint8 tokenType, address contractAddress, uint96 externalTokenId) public pure returns (bytes32) {
    return Account.packTokenReference(tokenType, contractAddress, externalTokenId);
  }

  function unpackTokenReference(bytes32 packed) public pure returns (address contractAddress, uint96 externalTokenId, uint8 tokenType) {
    return Account.unpackTokenReference(packed);
  }





  // registerHub removed for size reduction

  // ExternalTokenToReserve struct is in Types.sol
  // Public entry point with reentrancy guard for standalone calls
  function externalTokenToReserve(ExternalTokenToReserve memory params) public nonReentrant {
    _externalTokenToReserve(params);
  }

  // Internal version for batch processing (already inside nonReentrant context)
  function _externalTokenToReserve(ExternalTokenToReserve memory params) internal {
    bytes32 targetEntity = params.entity == bytes32(0) ? bytes32(uint256(uint160(msg.sender))) : params.entity;
    if (params.amount == 0) revert E1();

    if (params.internalTokenId == 0) {
      params.internalTokenId = tokenToId[params.packedToken];
      if (params.internalTokenId == 0) {
        _tokens.push(params.packedToken);
        params.internalTokenId = _tokens.length - 1;
        tokenToId[params.packedToken] = params.internalTokenId;
      }
    } else {
      params.packedToken = _tokens[params.internalTokenId];
    }

    (address contractAddress, uint96 tokenId, uint8 tokenType) = unpackTokenReference(params.packedToken);
    if (tokenType == TypeERC20) {
      if (!IERC20(contractAddress).transferFrom(msg.sender, address(this), params.amount)) revert E3();
    } else if (tokenType == TypeERC721) {
      IERC721(contractAddress).transferFrom(msg.sender, address(this), uint(tokenId));
      params.amount = 1;
    } else if (tokenType == TypeERC1155) {
      IERC1155(contractAddress).safeTransferFrom(msg.sender, address(this), uint(tokenId), params.amount, "");
    }

    _reserves[targetEntity][params.internalTokenId] += params.amount;
    emit ReserveUpdated(targetEntity, params.internalTokenId, _reserves[targetEntity][params.internalTokenId]);
  }


  // ReserveToExternalToken struct is in Types.sol
  function reserveToExternalToken(bytes32 entity, ReserveToExternalToken memory params) internal {
    enforceDebts(entity, params.tokenId);

    (address contractAddress, uint96 tokenId, uint8 tokenType) = unpackTokenReference(_tokens[params.tokenId]);
    if (_reserves[entity][params.tokenId] < params.amount) revert E3();

    _reserves[entity][params.tokenId] -= params.amount;
    emit ReserveUpdated(entity, params.tokenId, _reserves[entity][params.tokenId]);

    if (tokenType == TypeERC20) {
      if (!IERC20(contractAddress).transfer(address(uint160(uint256(params.receivingEntity))), params.amount)) revert E3();
    } else if (tokenType == TypeERC721) {
      IERC721(contractAddress).transferFrom(address(this), address(uint160(uint256(params.receivingEntity))), uint(tokenId));
    } else if (tokenType == TypeERC1155) {
      IERC1155(contractAddress).safeTransferFrom(address(this), address(uint160(uint256(params.receivingEntity))), uint(tokenId), params.amount, "");
    }
  }
  // ReserveToReserve struct is in Types.sol
  function reserveToReserve(bytes32 entity, ReserveToReserve memory params) internal {
    
    
    
    
    
    
    
    
    
    
    

    enforceDebts(entity, params.tokenId);

    
    if (_reserves[entity][params.tokenId] >= params.amount) {
      
    } else {
      
      
      
      
      
    }

    if (_reserves[entity][params.tokenId] < params.amount) revert E3();
    
    
    _reserves[entity][params.tokenId] -= params.amount;
    _reserves[params.receivingEntity][params.tokenId] += params.amount;
    
    
    
    
    
    
    
    // Single canonical event per entity whose reserve changed
    emit ReserveUpdated(entity, params.tokenId, _reserves[entity][params.tokenId]);
    emit ReserveUpdated(params.receivingEntity, params.tokenId, _reserves[params.receivingEntity][params.tokenId]);
    
  }

  // transferControlShares and getControlShareTokenId removed for size




  
  // getDebts moved to DepositoryView.sol

  // FIFO debt enforcement - enforces chronological payment order
  function enforceDebts(bytes32 entity, uint tokenId) public returns (uint256) {
    return _enforceDebts(entity, tokenId, type(uint256).max);
  }

  function _enforceDebts(bytes32 entity, uint256 tokenId, uint256 maxIterations) internal returns (uint256 totalDebts) {
    Debt[] storage queue = _debts[entity][tokenId];
    uint256 length = queue.length;
    if (length == 0) {
      _debtIndex[entity][tokenId] = 0;
      return 0;
    }

    uint256 cursor = _debtIndex[entity][tokenId];
    if (cursor >= length) {
      cursor = 0;
    }

    uint256 available = _reserves[entity][tokenId];
    uint256 iterationCap = maxIterations == 0 ? type(uint256).max : maxIterations;
    uint256 iterations = 0;

    if (available == 0) {
      _debtIndex[entity][tokenId] = cursor;
      _syncDebtIndex(entity, tokenId);

      Debt[] storage untouchedQueue = _debts[entity][tokenId];
      if (untouchedQueue.length == 0) {
        return 0;
      }

      return _countRemainingDebts(untouchedQueue, _debtIndex[entity][tokenId]);
    }

    while (cursor < length && available > 0 && iterations < iterationCap) {
      Debt storage debt = queue[cursor];
      uint256 amount = debt.amount;
      if (amount == 0) {
        cursor++;
        continue;
      }

      bytes32 creditor = debt.creditor;
      uint256 payableAmount = available < amount ? available : amount;

      // Pay from reserves first
      if (payableAmount > 0) {
        _reserves[creditor][tokenId] += payableAmount;
        available -= payableAmount;
        amount -= payableAmount;
      }

      // If reserves exhausted but debt remains, try insurance
      if (amount > 0 && available == 0) {
        uint256 insuranceRemaining = _claimFromInsurance(entity, creditor, tokenId, amount);
        uint256 insurancePaid = amount - insuranceRemaining;
        if (insurancePaid > 0) {
          amount = insuranceRemaining;
        }
      }

      // Update debt state
      uint256 totalPaid = debt.amount - amount;
      if (amount == 0) {
        debt.amount = 0;
        emit DebtEnforced(entity, creditor, tokenId, totalPaid, 0, cursor + 1);
        _afterDebtCleared(entity, true);
        delete queue[cursor];
        cursor++;
      } else {
        debt.amount = amount;
        emit DebtEnforced(entity, creditor, tokenId, totalPaid, debt.amount, cursor);
      }

      iterations++;
    }

    _reserves[entity][tokenId] = available;
    _debtIndex[entity][tokenId] = cursor;
    _syncDebtIndex(entity, tokenId);

    Debt[] storage refreshedQueue = _debts[entity][tokenId];
    if (refreshedQueue.length == 0) {
      return 0;
    }

    return _countRemainingDebts(refreshedQueue, _debtIndex[entity][tokenId]);
  }



  function accountKey(bytes32 e1, bytes32 e2) public pure returns (bytes memory) {
    return e1 < e2 ? abi.encodePacked(e1, e2) : abi.encodePacked(e2, e1);
  }

  // DEBUG: Compute settlement hash for comparison with TypeScript
  function computeSettlementHash(
    bytes32 leftEntity,
    bytes32 rightEntity,
    SettlementDiff[] memory diffs,
    uint[] memory forgiveDebtsInTokenIds,
    InsuranceRegistration[] memory insuranceRegs
  ) public view returns (bytes32 hash, uint256 nonce, uint256 encodedMsgLength) {
    bytes memory ch_key = accountKey(leftEntity, rightEntity);
    nonce = _accounts[ch_key].cooperativeNonce;
    bytes memory encoded_msg = abi.encode(MessageType.CooperativeUpdate, ch_key, nonce, diffs, forgiveDebtsInTokenIds, insuranceRegs);
    hash = keccak256(encoded_msg);
    encodedMsgLength = encoded_msg.length;
  }

  function reserveToCollateral(bytes32 entity, ReserveToCollateral memory params) internal returns (bool completeSuccess) {
    uint tokenId = params.tokenId;
    bytes32 receivingEntity = params.receivingEntity;
   
    // debts must be paid before any transfers from reserve 
    enforceDebts(entity, tokenId);

    for (uint i = 0; i < params.pairs.length; i++) {
      bytes32 counterentity = params.pairs[i].entity;
      uint amount = params.pairs[i].amount;

      bytes memory ch_key = accountKey(receivingEntity, counterentity);

      
      if (_reserves[entity][tokenId] >= amount) {
        AccountCollateral storage col = _collaterals[ch_key][tokenId];

        _reserves[entity][tokenId] -= amount;
        col.collateral += amount;
        if (receivingEntity < counterentity) { // if receiver is left
          col.ondelta += int(amount);
        }

        // Emit AccountSettled event (canonical ordering: left < right)
        bytes32 leftEntity = receivingEntity < counterentity ? receivingEntity : counterentity;
        bytes32 rightEntity = receivingEntity < counterentity ? counterentity : receivingEntity;

        Settled[] memory settledEvents = new Settled[](1);
        settledEvents[0] = Settled({
          left: leftEntity,
          right: rightEntity,
          tokenId: tokenId,
          leftReserve: _reserves[leftEntity][tokenId],
          rightReserve: _reserves[rightEntity][tokenId],
          collateral: col.collateral,
          ondelta: col.ondelta
        });
        emit Account.AccountSettled(settledEvents);


      } else {
        
        return false;
      }
      
    }


    return true;
  }


  // Handle debt forgiveness and insurance registration for settlements (separated from Account due to stack limits)
  function _handleSettlementDebtAndInsurance(
    bytes32 leftEntity,
    bytes32 rightEntity,
    uint[] memory forgiveDebtsInTokenIds,
    InsuranceRegistration[] memory insuranceRegs
  ) internal {
    // Forgive debts
    for (uint i = 0; i < forgiveDebtsInTokenIds.length; i++) {
      uint tokenId = forgiveDebtsInTokenIds[i];
      _forgiveDebtsBetweenEntities(leftEntity, rightEntity, tokenId);
      _forgiveDebtsBetweenEntities(rightEntity, leftEntity, tokenId);
    }

    // Register insurance
    for (uint i = 0; i < insuranceRegs.length; i++) {
      InsuranceRegistration memory reg = insuranceRegs[i];
      if (reg.insurer != leftEntity && reg.insurer != rightEntity) revert E7();
      if (reg.insured != leftEntity && reg.insured != rightEntity) revert E7();
      if (reg.insurer == reg.insured || reg.limit == 0) revert E2();
      if (reg.expiresAt <= block.timestamp) revert E2();

      insuranceLines[reg.insured].push(InsuranceLine({
        insurer: reg.insurer,
        tokenId: reg.tokenId,
        remaining: reg.limit,
        expiresAt: reg.expiresAt
      }));
      emit InsuranceRegistered(reg.insured, reg.insurer, reg.tokenId, reg.limit, reg.expiresAt);
    }
  }

  function _forgiveDebtsBetweenEntities(bytes32 debtor, bytes32 creditor, uint tokenId) internal {
    uint256 idx = _debtIndex[debtor][tokenId];
    Debt[] storage queue = _debts[debtor][tokenId];
    uint256 len = queue.length;
    for (uint256 j = idx; j < len; j++) {
      if (queue[j].creditor == creditor && queue[j].amount > 0) {
        uint256 amt = queue[j].amount;
        queue[j].amount = 0;
        if (_activeDebts[debtor] > 0) _activeDebts[debtor]--;
        emit DebtForgiven(debtor, creditor, tokenId, amt, j);
      }
    }
    _syncDebtIndex(debtor, tokenId);
  }

  function _increaseReserve(bytes32 entity, uint256 tokenId, uint256 amount) internal {
    if (amount == 0) return;
    _reserves[entity][tokenId] += amount;
    emit ReserveUpdated(entity, tokenId, _reserves[entity][tokenId]);
  }

  // Claims from debtor's insurance lines in FIFO order
  function _claimFromInsurance(bytes32 debtor, bytes32 creditor, uint256 tokenId, uint256 shortfall) internal returns (uint256 remaining) {
    remaining = shortfall;
    InsuranceLine[] storage lines = insuranceLines[debtor];
    uint256 length = lines.length;
    if (length == 0) return remaining;

    uint256 cursor = insuranceCursor[debtor];
    for (uint256 i = cursor; i < length && remaining > 0; i++) {
      InsuranceLine storage line = lines[i];
      if (line.tokenId != tokenId || block.timestamp > line.expiresAt || line.remaining == 0) continue;

      uint256 insurerReserves = _reserves[line.insurer][tokenId];
      uint256 claimAmount = line.remaining < insurerReserves ? line.remaining : insurerReserves;
      if (claimAmount > remaining) claimAmount = remaining;
      if (claimAmount == 0) continue;

      _reserves[line.insurer][tokenId] -= claimAmount;
      emit ReserveUpdated(line.insurer, tokenId, _reserves[line.insurer][tokenId]);
      _increaseReserve(creditor, tokenId, claimAmount);
      line.remaining -= claimAmount;
      remaining -= claimAmount;
      _addDebt(debtor, tokenId, line.insurer, claimAmount);
      emit InsuranceClaimed(debtor, line.insurer, creditor, tokenId, claimAmount);
      cursor = i + 1;
    }
    insuranceCursor[debtor] = cursor;
  }

  // ========== DISPUTE FUNCTIONS ==========
  /// @notice Start dispute - uses Account library
  function disputeStart(InitialDisputeProof memory params) public nonReentrant returns (bool) {
    bytes32 caller = bytes32(uint256(uint160(msg.sender)));
    InitialDisputeProof[] memory starts = new InitialDisputeProof[](1);
    starts[0] = params;
    return Account.processDisputeStarts(_accounts, caller, starts, defaultDisputeDelay, entityProvider);
  }

  /// @notice Finalize dispute - stays in Depository due to storage complexity
  function disputeFinalize(FinalDisputeProof memory params) public nonReentrant returns (bool) {
    bytes32 caller = bytes32(uint256(uint160(msg.sender)));
    return _disputeFinalizeInternal(caller, params);
  }

  /// @notice Internal dispute finalize with full storage access
  function _disputeFinalizeInternal(bytes32 entityId, FinalDisputeProof memory params) internal returns (bool) {
    bytes memory ch_key = accountKey(entityId, params.counterentity);

    if (params.cooperative) {
      // SECURITY: Prevent cooperative finalize on virgin accounts
      // This prevents social engineering attacks where victim signs over empty account
      // Accounts must have at least one prior settlement (cooperativeNonce > 0)
      if (_accounts[ch_key].cooperativeNonce == 0) revert E5();

      require(params.sig.length > 0, "Signature required for cooperative finalize");
      if (!Account.verifyCooperativeProofHanko(entityProvider, ch_key, _accounts[ch_key].cooperativeNonce, keccak256(abi.encode(params.finalProofbody)), keccak256(params.initialArguments), params.sig, params.counterentity)) revert E4();
    } else {
      bytes32 storedHash = _accounts[ch_key].disputeHash;
      if (storedHash == bytes32(0)) revert E5();

      bytes32 expectedHash = Account.encodeDisputeHash(
        params.initialCooperativeNonce, params.initialDisputeNonce, params.startedByLeft,
        _accounts[ch_key].disputeTimeout, params.initialProofbodyHash, params.initialArguments
      );
      if (storedHash != expectedHash) revert E9();

      // Counter-dispute or unilateral finalization
      if (params.sig.length > 0) {
        // Counter-dispute: verify counterparty signed the NEWER dispute proof
        // Uses SAME DisputeProof message type (not FinalDisputeProof)
        // Signature is on: DisputeProof(ch_key, finalCooperativeNonce, finalDisputeNonce, finalProofbodyHash)
        bytes32 finalProofbodyHash = keccak256(abi.encode(params.finalProofbody));

        // Full hanko - verify DisputeProof hanko (not FinalDisputeProof)
        if (!Account.verifyDisputeProofHanko(entityProvider, ch_key, params.finalCooperativeNonce, params.finalDisputeNonce, finalProofbodyHash, params.sig, params.counterentity)) revert E4();
        if (params.initialDisputeNonce >= params.finalDisputeNonce) revert E2();
      } else {
        // Unilateral finalization after timeout (no signature needed)
        bool senderIsCounterparty = params.startedByLeft != (entityId < params.counterentity);
        if (!senderIsCounterparty && block.number < _accounts[ch_key].disputeTimeout) revert E2();
        if (params.initialProofbodyHash != keccak256(abi.encode(params.finalProofbody))) revert E2();
      }
    }

    _accounts[ch_key].disputeHash = bytes32(0);
    _accounts[ch_key].disputeTimeout = 0;

    bool ok = _finalizeAccount(entityId, params.counterentity, params.finalProofbody, params.finalArguments, params.initialArguments);
    if (ok) {
      emit DisputeFinalized(
        entityId,
        params.counterentity,
        params.initialDisputeNonce,
        params.initialProofbodyHash,
        keccak256(abi.encode(params.finalProofbody))
      );
    }
    return ok;
  }

  /// @notice Finalize account - applies deltas and clears collateral
  function _finalizeAccount(
    bytes32 entity1, bytes32 entity2, ProofBody memory proofbody, bytes memory arguments1, bytes memory arguments2
  ) internal returns (bool) {
    if (proofbody.tokenIds.length != proofbody.offdeltas.length) revert E8();

    bytes32 leftAddr = entity1 < entity2 ? entity1 : entity2;
    bytes32 rightAddr = entity1 < entity2 ? entity2 : entity1;
    bytes memory leftArgs = entity1 < entity2 ? arguments1 : arguments2;
    bytes memory rightArgs = entity1 < entity2 ? arguments2 : arguments1;
    bytes memory ch_key = accountKey(leftAddr, rightAddr);

    // NOTE: On-chain settlement must apply TOTAL delta (ondelta + offdelta).
    // - `col.ondelta` tracks the on-chain component (e.g., collateral funding events).
    // - `proofbody.offdeltas` is the off-chain component agreed/derived by parties.
    uint256 tokenCount = proofbody.tokenIds.length;
    int[] memory deltas = new int[](tokenCount);
    for (uint256 i = 0; i < tokenCount; i++) {
      uint256 tokenId = proofbody.tokenIds[i];
      deltas[i] = _collaterals[ch_key][tokenId].ondelta + proofbody.offdeltas[i];
    }

    bytes[] memory decodedLeft = leftArgs.length > 0 ? abi.decode(leftArgs, (bytes[])) : new bytes[](0);
    bytes[] memory decodedRight = rightArgs.length > 0 ? abi.decode(rightArgs, (bytes[])) : new bytes[](0);

    // Apply transformers
    for (uint256 i = 0; i < proofbody.transformers.length; i++) {
      TransformerClause memory tc = proofbody.transformers[i];
      int[] memory newDeltas = DeltaTransformer(tc.transformerAddress).applyBatch(
        deltas, tc.encodedBatch,
        i < decodedLeft.length ? decodedLeft[i] : bytes(""),
        i < decodedRight.length ? decodedRight[i] : bytes("")
      );

      for (uint256 j = 0; j < tc.allowances.length; j++) {
        Allowance memory allow = tc.allowances[j];
        int diff = newDeltas[allow.deltaIndex] - deltas[allow.deltaIndex];
        if (diff > 0 && uint256(diff) > allow.leftAllowance) revert E2();
        if (diff < 0 && uint256(-diff) > allow.rightAllowance) revert E2();
      }
      deltas = newDeltas;
    }

    // Apply deltas
    for (uint256 i = 0; i < proofbody.tokenIds.length; i++) {
      _applyAccountDelta(ch_key, proofbody.tokenIds[i], leftAddr, rightAddr, deltas[i]);
    }

    _accounts[ch_key].cooperativeNonce++;
    return true;
  }

  /// @notice Apply delta to account collateral and reserves
  function _applyAccountDelta(bytes memory ch_key, uint256 tokenId, bytes32 leftEntity, bytes32 rightEntity, int delta) internal {
    AccountCollateral storage col = _collaterals[ch_key][tokenId];
    uint256 collateral = col.collateral;

    // Î” is LEFT's allocation (ondelta + offdelta), bounded by RCPAN:
    //   âˆ’leftCreditLimit â‰¤ Î” â‰¤ collateral + rightCreditLimit
    //
    // Collateral only exists on the right side of 0. Therefore:
    // - If Î” â‰¤ 0: LEFT gets 0, RIGHT gets all collateral, and LEFT owes âˆ’Î” (credit/debt).
    // - If 0 < Î” < collateral: split collateral (LEFT = Î”, RIGHT = collateral âˆ’ Î”).
    // - If Î” â‰¥ collateral: LEFT gets all collateral and RIGHT owes Î” âˆ’ collateral (credit/debt).
    if (delta <= 0) {
      if (collateral > 0) _increaseReserve(rightEntity, tokenId, collateral);
      uint256 shortfall = uint256(-delta);
      if (shortfall > 0) _settleShortfall(leftEntity, rightEntity, tokenId, shortfall);
    } else {
      uint256 desired = uint256(delta);
      if (desired >= collateral) {
        if (collateral > 0) _increaseReserve(leftEntity, tokenId, collateral);
        uint256 shortfall = desired - collateral;
        if (shortfall > 0) _settleShortfall(rightEntity, leftEntity, tokenId, shortfall);
      } else {
        _increaseReserve(leftEntity, tokenId, desired);
        _increaseReserve(rightEntity, tokenId, collateral - desired);
      }
    }
    col.collateral = 0;
    col.ondelta = 0;
  }

  /// @notice Settle shortfall via reserves, insurance, then debt
  function _settleShortfall(bytes32 debtor, bytes32 creditor, uint256 tokenId, uint256 amount) internal {
    if (amount == 0) return;

    uint256 available = _reserves[debtor][tokenId];
    uint256 payAmount = available >= amount ? amount : available;
    if (payAmount > 0) {
      _reserves[debtor][tokenId] -= payAmount;
      emit ReserveUpdated(debtor, tokenId, _reserves[debtor][tokenId]);
      _increaseReserve(creditor, tokenId, payAmount);
    }

    uint256 remaining = amount - payAmount;
    if (remaining == 0) return;

    remaining = _claimFromInsurance(debtor, creditor, tokenId, remaining);
    if (remaining > 0) {
      _addDebt(debtor, tokenId, creditor, remaining);
      _syncDebtIndex(debtor, tokenId);
    }
  }





  // getUsers and getAccounts moved to DepositoryView.sol

  // createDebt removed for size reduction

  function onERC1155Received(address, address from, uint256 id, uint256 value, bytes calldata) external returns (bytes4) {
    // SECURITY FIX: Don't credit here - _externalTokenToReserve:713 already credits
    // This prevents double-crediting when ERC1155.safeTransferFrom triggers this callback
    // If tokens sent directly (not via externalTokenToReserve), they will be stuck but not inflate reserves
    bytes32 packedToken = packTokenReference(TypeERC1155, msg.sender, uint96(id));
    uint256 tid = tokenToId[packedToken];
    if (tid == 0) { _tokens.push(packedToken); tid = _tokens.length - 1; tokenToId[packedToken] = tid; }
    // DO NOT credit reserves here to avoid double-crediting
    // _reserves[entity][tid] += value; // REMOVED
    return this.onERC1155Received.selector;
  }
  function onERC1155BatchReceived(address,address,uint256[] calldata,uint256[] calldata,bytes calldata) external pure returns (bytes4) { revert("!batch"); }
}


//jurisdictions/contracts/EntityProvider.sol (1137 lines)
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.24;

import "./Token.sol";
import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "./ECDSA.sol";
import "hardhat/console.sol";

contract EntityProvider is ERC1155 { 
  struct Entity {
    bytes32 currentBoardHash;    // 0x0 = lazy entity (entityId == boardHash)
    bytes32 proposedBoardHash;   // Pending board transition
    uint256 activateAtBlock;     // When proposed board becomes active
    uint256 registrationBlock;   // When entity was registered (0 for lazy)
    ProposerType proposerType;   // Who proposed the current transition
    bytes32 articlesHash;        // Governance config hash
  }

  struct Board {
    uint16 votingThreshold;
    bytes32[] entityIds;        // Parallel arrays for efficiency
    uint16[] votingPowers;      // Must match entityIds length
    uint32 boardChangeDelay;    // Board â†’ Board transitions (blocks)
    uint32 controlChangeDelay;  // Control â†’ Board transitions (blocks)  
    uint32 dividendChangeDelay; // Dividend â†’ Board transitions (blocks)
  }

  struct EntityArticles {
    uint32 controlDelay;      // Delay for control shareholders (X blocks)
    uint32 dividendDelay;     // Delay for dividend shareholders (X*3 blocks)  
    uint32 foundationDelay;   // Delay for foundation (X*10 blocks, 0=disabled)
    uint16 controlThreshold;  // % of control tokens needed for quorum replacement
  }

  enum ProposerType { BOARD, CONTROL, DIVIDEND }

  struct BoardProposal {
    bytes32 proposedBoardHash;
    ProposerType proposerType;
    uint256 proposeBlock;
    uint256 activateBlock;
    bool active;
  }

  // Core entity storage - single mapping for all entities
  mapping(bytes32 => Entity) public entities;
  
  // Sequential numbering for registered entities
  uint256 public nextNumber = 1;
  

  
  // Name system (decoupled from entity IDs)
  mapping(string => uint256) public nameToNumber;  // "coinbase" => 42
  mapping(uint256 => string) public numberToName;  // 42 => "coinbase"
  mapping(string => bool) public reservedNames;    // Admin-controlled names
  
  // Foundation controls (no centralized admin)
  mapping(address => uint8) public nameQuota;      // User name allowances
  
  // Governance system
  mapping(bytes32 => BoardProposal) public activeProposals;  // entityId => proposal
  mapping(bytes32 => uint256) public totalControlSupply;      // entityId => total control tokens
  mapping(bytes32 => uint256) public totalDividendSupply;     // entityId => total dividend tokens
  
  // Fixed token supplies for all entities (immutable and fair)
  uint256 public constant TOTAL_CONTROL_SUPPLY = 1e15;   // 1 quadrillion (max granularity)
  uint256 public constant TOTAL_DIVIDEND_SUPPLY = 1e15;  // 1 quadrillion (max granularity)

  // Foundation entity (always #1)
  uint256 public constant FOUNDATION_ENTITY = 1;

  // Events
  event EntityRegistered(bytes32 indexed entityId, uint256 indexed entityNumber, bytes32 boardHash);
  event NameAssigned(string indexed name, uint256 indexed entityNumber);
  event NameTransferred(string indexed name, uint256 indexed fromNumber, uint256 indexed toNumber);
  event BoardProposed(bytes32 indexed entityId, bytes32 proposedBoardHash);
  event BoardActivated(bytes32 indexed entityId, bytes32 newBoardHash);
  event GovernanceEnabled(bytes32 indexed entityId, uint256 controlTokenId, uint256 dividendTokenId);

  // DEBUG events (remove after debugging)
  event DebugValidateEntity(bytes32 entityId, bytes32 computedHash, bytes32 storedHash, bool isLazy);
  event DebugComputeBoard(uint256 threshold, bytes32 entityId0, bytes32 computedHash);
  event ProposalCancelled(bytes32 indexed entityId, ProposerType cancelledBy);

  constructor() ERC1155("https://xln.com/entity/{id}.json") {
    // Reserve some premium names
    reservedNames["coinbase"] = true;
    reservedNames["ethereum"] = true;
    reservedNames["bitcoin"] = true;
    reservedNames["uniswap"] = true;
    
    // Create foundation entity #1 with governance
    bytes32 foundationQuorum = keccak256("FOUNDATION_INITIAL_QUORUM");
    bytes32 foundationId = bytes32(FOUNDATION_ENTITY);
    
    entities[foundationId] = Entity({
      currentBoardHash: foundationQuorum,
      proposedBoardHash: bytes32(0),
      activateAtBlock: 0,
      registrationBlock: block.number,
      proposerType: ProposerType.BOARD,
      articlesHash: keccak256(abi.encode(EntityArticles({
        controlDelay: 1000,
        dividendDelay: 3000,
        foundationDelay: 0, // Foundation can't replace itself
        controlThreshold: 51
      })))
    });
    
    // Setup governance for foundation entity
    (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(FOUNDATION_ENTITY);
    address foundationAddress = address(uint160(uint256(foundationId)));
    
    _mint(foundationAddress, controlTokenId, TOTAL_CONTROL_SUPPLY, "");
    _mint(foundationAddress, dividendTokenId, TOTAL_DIVIDEND_SUPPLY, "");
    
    totalControlSupply[foundationId] = TOTAL_CONTROL_SUPPLY;
    totalDividendSupply[foundationId] = TOTAL_DIVIDEND_SUPPLY;
    
    emit GovernanceEnabled(foundationId, controlTokenId, dividendTokenId);
    
    nextNumber = 2; // Foundation takes #1, next entity will be #2
  }

  modifier onlyFoundation() {
    // Only foundation entity (via its governance tokens) can call admin functions
    bytes32 foundationId = bytes32(FOUNDATION_ENTITY);
    (uint256 controlTokenId,) = getTokenIds(FOUNDATION_ENTITY);
    require(balanceOf(msg.sender, controlTokenId) > 0, "Only foundation token holders");
    _;
  }

  /**
   * @notice Register a new numbered entity with automatic governance setup
   * @param boardHash Initial board/quorum hash
   * @return entityNumber The assigned entity number
   */
  function registerNumberedEntity(bytes32 boardHash) external returns (uint256 entityNumber) {
    entityNumber = nextNumber++;
    bytes32 entityId = bytes32(entityNumber);

    // Create entity with default governance articles
    EntityArticles memory defaultArticles = EntityArticles({
      controlDelay: 1000,     // Default 1000 blocks for control
      dividendDelay: 3000,    // Default 3000 blocks for dividend
      foundationDelay: 10000, // Default 10000 blocks for foundation
      controlThreshold: 51    // Default 51% threshold
    });

    entities[entityId] = Entity({
      currentBoardHash: boardHash,
      proposedBoardHash: bytes32(0),
      activateAtBlock: 0,
      registrationBlock: block.number,
      proposerType: ProposerType.BOARD,
      articlesHash: keccak256(abi.encode(defaultArticles))
    });

    // Automatically setup governance with fixed supply
    (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(entityNumber);
    address entityAddress = address(uint160(uint256(entityId)));

    _mint(entityAddress, controlTokenId, TOTAL_CONTROL_SUPPLY, "");
    _mint(entityAddress, dividendTokenId, TOTAL_DIVIDEND_SUPPLY, "");

    totalControlSupply[entityId] = TOTAL_CONTROL_SUPPLY;
    totalDividendSupply[entityId] = TOTAL_DIVIDEND_SUPPLY;

    emit EntityRegistered(entityId, entityNumber, boardHash);
    emit GovernanceEnabled(entityId, controlTokenId, dividendTokenId);

    return entityNumber;
  }

  /**
   * @notice Batch register multiple numbered entities in one transaction
   * @param boardHashes Array of board hashes for entities
   * @return entityNumbers Array of assigned entity numbers
   */
  function registerNumberedEntitiesBatch(bytes32[] calldata boardHashes) external returns (uint256[] memory entityNumbers) {
    entityNumbers = new uint256[](boardHashes.length);

    // Default governance articles (reused for all)
    EntityArticles memory defaultArticles = EntityArticles({
      controlDelay: 1000,
      dividendDelay: 3000,
      foundationDelay: 10000,
      controlThreshold: 51
    });
    bytes32 articlesHash = keccak256(abi.encode(defaultArticles));

    for (uint256 i = 0; i < boardHashes.length; i++) {
      uint256 entityNumber = nextNumber++;
      bytes32 entityId = bytes32(entityNumber);

      entities[entityId] = Entity({
        currentBoardHash: boardHashes[i],
        proposedBoardHash: bytes32(0),
        activateAtBlock: 0,
        registrationBlock: block.number,
        proposerType: ProposerType.BOARD,
        articlesHash: articlesHash
      });

      // Setup governance
      (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(entityNumber);
      address entityAddress = address(uint160(uint256(entityId)));

      _mint(entityAddress, controlTokenId, TOTAL_CONTROL_SUPPLY, "");
      _mint(entityAddress, dividendTokenId, TOTAL_DIVIDEND_SUPPLY, "");

      totalControlSupply[entityId] = TOTAL_CONTROL_SUPPLY;
      totalDividendSupply[entityId] = TOTAL_DIVIDEND_SUPPLY;

      emit EntityRegistered(entityId, entityNumber, boardHashes[i]);
      emit GovernanceEnabled(entityId, controlTokenId, dividendTokenId);

      entityNumbers[i] = entityNumber;
    }

    return entityNumbers;
  }

  /**
   * @notice Foundation assigns a name to an existing numbered entity
   * @param name The name to assign (e.g., "coinbase")
   * @param entityNumber The entity number to assign the name to
   */
  function assignName(string memory name, uint256 entityNumber) external onlyFoundation {
    require(bytes(name).length > 0 && bytes(name).length <= 32, "Invalid name length");
    require(entities[bytes32(entityNumber)].currentBoardHash != bytes32(0), "Entity doesn't exist");
    require(nameToNumber[name] == 0, "Name already assigned");
    
    // If entity already has a name, clear it
    string memory oldName = numberToName[entityNumber];
    if (bytes(oldName).length > 0) {
      delete nameToNumber[oldName];
    }
    
    nameToNumber[name] = entityNumber;
    numberToName[entityNumber] = name;
    
    emit NameAssigned(name, entityNumber);
  }

  /**
   * @notice Transfer a name from one entity to another (foundation only)
   * @param name The name to transfer
   * @param newEntityNumber The target entity number
   */
  function transferName(string memory name, uint256 newEntityNumber) external onlyFoundation {
    require(nameToNumber[name] != 0, "Name not assigned");
    require(entities[bytes32(newEntityNumber)].currentBoardHash != bytes32(0), "Target entity doesn't exist");
    
    uint256 oldEntityNumber = nameToNumber[name];
    
    // Clear old mapping
    delete numberToName[oldEntityNumber];
    
    // Set new mapping
    nameToNumber[name] = newEntityNumber;
    numberToName[newEntityNumber] = name;
    
    emit NameTransferred(name, oldEntityNumber, newEntityNumber);
  }

  /**
   * @notice Propose a new board with proper BCD governance
   * @param entityId The entity ID  
   * @param newBoardHash The proposed new board hash
   * @param proposerType Who is proposing (BOARD, CONTROL, DIVIDEND)
   * @param articles Current governance articles (for verification)
   */
  function proposeBoard(
    bytes32 entityId, 
    bytes32 newBoardHash,
    ProposerType proposerType,
    EntityArticles memory articles
  ) external {
    require(entities[entityId].currentBoardHash != bytes32(0), "Entity doesn't exist");
    require(keccak256(abi.encode(articles)) == entities[entityId].articlesHash, "Invalid articles");
    
    // Check permissions and delays
    uint32 delay = _getDelayForProposer(articles, proposerType);
    require(delay > 0, "Proposer type disabled");
    
    // Verify proposer has the right to propose based on type
    if (proposerType == ProposerType.CONTROL) {
      // Control holders can override any proposal
      // TODO: Verify msg.sender has control tokens
    } else if (proposerType == ProposerType.BOARD) {
      // Current board can propose (shortest delay)
      // TODO: Verify msg.sender is current board member
    } else if (proposerType == ProposerType.DIVIDEND) {
      // Dividend holders can propose (longest delay)
      // TODO: Verify msg.sender has dividend tokens
    }
    
    // Cancel any existing proposal that can be overridden
    if (entities[entityId].proposedBoardHash != bytes32(0)) {
      require(_canCancelProposal(proposerType, entities[entityId].proposerType), 
              "Cannot override existing proposal");
    }
    
    uint256 activateAtBlock = block.number + delay;
    
    entities[entityId].proposedBoardHash = newBoardHash;
    entities[entityId].activateAtBlock = activateAtBlock;
    entities[entityId].proposerType = proposerType;
    
    emit BoardProposed(entityId, newBoardHash);
  }

  /**
   * @notice Activate a previously proposed board (with delay enforcement)
   * @param entityId The entity ID
   */
  function activateBoard(bytes32 entityId) external {
    require(entities[entityId].currentBoardHash != bytes32(0), "Entity doesn't exist");
    require(entities[entityId].proposedBoardHash != bytes32(0), "No proposed board");
    require(block.number >= entities[entityId].activateAtBlock, "Delay period not met");
    
    entities[entityId].currentBoardHash = entities[entityId].proposedBoardHash;
    entities[entityId].proposedBoardHash = bytes32(0);
    entities[entityId].activateAtBlock = 0;
    
    emit BoardActivated(entityId, entities[entityId].currentBoardHash);
  }

  /**
   * @notice Cancel a pending board proposal
   * @param entityId The entity ID
   * @param proposerType Who is cancelling (BOARD, CONTROL, DIVIDEND)
   * @param articles Current governance articles (for verification)
   */
  function cancelBoardProposal(
    bytes32 entityId,
    ProposerType proposerType,
    EntityArticles memory articles
  ) external {
    require(entities[entityId].currentBoardHash != bytes32(0), "Entity doesn't exist");
    require(entities[entityId].proposedBoardHash != bytes32(0), "No proposed board");
    require(keccak256(abi.encode(articles)) == entities[entityId].articlesHash, "Invalid articles");
    
    // Check if this proposer type can cancel the existing proposal
    require(_canCancelProposal(proposerType, entities[entityId].proposerType), 
            "Cannot cancel this proposal");
    
    entities[entityId].proposedBoardHash = bytes32(0);
    entities[entityId].activateAtBlock = 0;
    
    emit ProposalCancelled(entityId, proposerType);
  }



  /**
   * @notice Recover entity ID from hanko signature (improved version of isValidSignature)
   * @param encodedBoard The entity's board data
   * @param encodedSignature The entity's signatures  
   * @param hash The hash that was signed
   * @return entityId The entity ID that signed this hash (0 if invalid)
   */
  function recoverEntity(
    bytes calldata encodedBoard, 
    bytes calldata encodedSignature, 
    bytes32 hash
  ) public view returns (uint256 entityId) {
    bytes32 boardHash = keccak256(encodedBoard);
    
    // First try to find registered entity with this board hash
    for (uint256 i = 1; i < nextNumber; i++) {
      bytes32 candidateEntityId = bytes32(i);
      if (entities[candidateEntityId].currentBoardHash != bytes32(0) && entities[candidateEntityId].currentBoardHash == boardHash) {
        // Verify signature for this registered entity
        uint16 boardResult = _verifyBoard(hash, encodedBoard, encodedSignature);
        if (boardResult > 0) {
          return i; // Return entity number
        }
      }
    }
    
    // If no registered entity found, try as lazy entity
    uint16 lazyResult = _verifyBoard(hash, encodedBoard, encodedSignature);
    if (lazyResult > 0) {
      return uint256(boardHash); // Return board hash as entity ID for lazy entities
    }
    
    return 0; // Invalid signature
  }

  /**
   * @notice Simplified board verification (calldata version)
   */
  function _verifyBoard(
    bytes32 _hash,
    bytes calldata encodedBoard,
    bytes calldata encodedSignature
  ) internal pure returns (uint16) {
    Board memory board = abi.decode(encodedBoard, (Board));
    bytes[] memory signatures = abi.decode(encodedSignature, (bytes[]));
    
    require(board.entityIds.length == board.votingPowers.length, "Board arrays length mismatch");
    
    uint16 voteYes = 0;
    uint16 totalVotes = 0;
    
    for (uint i = 0; i < board.entityIds.length && i < signatures.length; i++) {
      bytes32 entityId = board.entityIds[i];
      uint16 votingPower = board.votingPowers[i];
      
      // Check if this is an EOA (20 bytes when cast to address)
      if (uint256(entityId) <= type(uint160).max) {
        // Simple EOA verification
        address signer = address(uint160(uint256(entityId)));
        if (signer == _recoverSigner(_hash, signatures[i])) {
          voteYes += votingPower;
        }
        totalVotes += votingPower;
      }
      // Note: Nested entity verification handled by Hanko system
    }
    
    if (totalVotes == 0) return 0;
    if (voteYes < board.votingThreshold) return 0;
    
    return (voteYes * 100) / totalVotes;
  }



  /**
   * @notice Recover signer from signature
   */
  function _recoverSigner(bytes32 _hash, bytes memory _signature) internal pure returns (address) {
    if (_signature.length != 65) return address(0);
    
    bytes32 r;
    bytes32 s;
    uint8 v;
    
    assembly {
      r := mload(add(_signature, 32))
      s := mload(add(_signature, 64))
      v := byte(0, mload(add(_signature, 96)))
    }
    
    if (v < 27) v += 27;
    if (v != 27 && v != 28) return address(0);
    
    return ecrecover(_hash, v, r, s);
  }

  /**
   * @notice Validate entity exists (registered or lazy)
   * @param entityId The entity ID to validate
   * @param boardHash The board hash for validation
   * @return isLazy Whether this is a lazy entity
   */
  function _validateEntity(bytes32 entityId, bytes32 boardHash) internal returns (bool isLazy) {
    bool isLazyEntity = entities[entityId].currentBoardHash == bytes32(0);
    emit DebugValidateEntity(entityId, boardHash, entities[entityId].currentBoardHash, isLazyEntity);

    if (isLazyEntity) {
      // Lazy entity: entityId must equal boardHash
      require(entityId == boardHash, "Lazy entity: ID must equal board hash");
      return true;
    } else {
      // Registered entity: use stored boardHash
      require(boardHash == entities[entityId].currentBoardHash, "Board hash mismatch");
      return false;
    }
  }



  // Utility functions
  function resolveEntityId(string memory identifier) external view returns (bytes32) {
    // Try to resolve as name first
    uint256 number = nameToNumber[identifier];
    if (number > 0) {
      return bytes32(number);
    }
    
    // Try to parse as number
    // Note: This would need a string-to-uint parser in practice
    return bytes32(0);
  }

  function getEntityInfo(bytes32 entityId) external view returns (
    bool exists,
    bytes32 currentBoardHash,
    bytes32 proposedBoardHash,
    uint256 registrationBlock,
    string memory name
  ) {
    Entity memory entity = entities[entityId];
    exists = entity.currentBoardHash != bytes32(0);
    currentBoardHash = entity.currentBoardHash;
    proposedBoardHash = entity.proposedBoardHash;
    registrationBlock = entity.registrationBlock;
    
    // Get name if it's a numbered entity
    if (uint256(entityId) > 0 && uint256(entityId) < nextNumber) {
      name = numberToName[uint256(entityId)];
    }
  }

  // Admin functions
  function setReservedName(string memory name, bool reserved) external onlyFoundation {
    reservedNames[name] = reserved;
  }

  // === HANKO SIGNATURE VERIFICATION ===
  //
  // ðŸš¨ CRITICAL DESIGN PHILOSOPHY: "ASSUME YES" FLASHLOAN GOVERNANCE ðŸš¨
  //
  // This system INTENTIONALLY allows entities to mutually validate without EOA signatures.
  // This is NOT a bug - it's a feature that enables flexible governance structures.
  //
  // EXAMPLE OF INTENTIONAL "LOOPHOLE":
  // EntityA (threshold: 1) references EntityB at weight 100
  // EntityB (threshold: 1) references EntityA at weight 100
  // â†’ Both pass validation with ZERO EOA signatures!
  //
  // WHY THIS IS INTENDED:
  // 1. UI/Application layer enforces policies (e.g., "require at least 1 EOA")
  // 2. Protocol stays flexible for exotic governance structures
  // 3. Real entities will naturally include EOAs for practical control
  // 4. Alternative would require complex graph analysis â†’ expensive + still gameable
  //
  // POLICY ENFORCEMENT BELONGS IN UI, NOT PROTOCOL!

  struct HankoBytes {
    bytes32[] placeholders;    // Entity IDs that failed to sign (index 0..N-1)  
    bytes packedSignatures;    // EOA signatures â†’ yesEntities (index N..M-1)
    HankoClaim[] claims;       // Entity claims to verify (index M..âˆž)
  }

  struct HankoClaim {
    bytes32 entityId;          // Entity being verified
    uint256[] entityIndexes;   // Indexes into placeholders + yesEntities + claims arrays
    uint256[] weights;         // Voting weights for each entity  
    uint256 threshold;         // Required voting power
  }
  
  // Events
  event HankoVerified(bytes32 indexed entityId, bytes32 indexed hash);
  event HankoClaimProcessed(bytes32 indexed entityId, bool success, uint256 votingPower);

  /**
   * @notice Detect signature count from packed signatures length
   * @dev DESIGN CHOICE: Signature count embedded in byte length, not explicit field
   *      This eliminates potential attack vectors where count != actual signatures
   * 
   * @param packedSignatures Packed rsrsrs...vvv format
   * @return signatureCount Number of signatures in the packed data
   * 
   * EXAMPLES:
   * - 1 sig: 64 bytes (RS) + 1 byte (V) = 65 bytes total
   * - 2 sigs: 128 bytes (RS) + 1 byte (VV in bits) = 129 bytes total  
   * - 8 sigs: 512 bytes (RS) + 1 byte (8 V bits) = 513 bytes total
   * - 9 sigs: 576 bytes (RS) + 2 bytes (9 V bits) = 578 bytes total
   */
  function _detectSignatureCount(bytes memory packedSignatures) internal pure returns (uint256 signatureCount) {
    if (packedSignatures.length == 0) return 0;
    
    // Try different signature counts until we find the right one
    // Formula: length = count * 64 + ceil(count / 8)
    for (uint256 count = 1; count <= 16000; count++) {
      uint256 expectedRSBytes = count * 64;
      uint256 expectedVBytes = (count + 7) / 8; // Ceiling division
      uint256 expectedTotal = expectedRSBytes + expectedVBytes;
      
      if (packedSignatures.length == expectedTotal) {
        return count;
      }
      
      // Early exit if we've exceeded possible length
      if (expectedTotal > packedSignatures.length) {
        break;
      }
    }
    
    revert("Invalid packed signature length - cannot detect count");
  }

  /**
   * @notice Unpack signatures from packed format
   * @param packedSignatures Packed rsrsrs...vvv format
   * @return signatures Array of 65-byte signatures
   */
  function _unpackSignatures(
    bytes memory packedSignatures
  ) internal pure returns (bytes[] memory signatures) {
    uint256 signatureCount = _detectSignatureCount(packedSignatures);
    
    if (signatureCount == 0) {
      return new bytes[](0);
    }
    
    uint256 expectedRSBytes = signatureCount * 64;
    // uint256 expectedVBytes = (signatureCount + 7) / 8; // Ceiling division - unused
    
    signatures = new bytes[](signatureCount);
    
    for (uint256 i = 0; i < signatureCount; i++) {
      // Extract R and S (64 bytes)
      bytes memory rs = new bytes(64);
      for (uint256 j = 0; j < 64; j++) {
        rs[j] = packedSignatures[i * 64 + j];
      }
      
      // Extract V bit
      uint256 vByteIndex = expectedRSBytes + i / 8;
      uint256 vBitIndex = i % 8;
      uint8 vByte = uint8(packedSignatures[vByteIndex]);
      uint8 v = ((vByte >> vBitIndex) & 1) == 0 ? 27 : 28;
      
      // Combine into 65-byte signature
      signatures[i] = new bytes(65);
      for (uint256 j = 0; j < 64; j++) {
        signatures[i][j] = rs[j];
      }
      signatures[i][64] = bytes1(v);
    }
  }

  /**
   * @notice Build and hash a board from actual signers and claim data
   * @param actualSigners Array of recovered signer addresses
   * @param claim The hanko claim with weights and threshold
   * @return boardHash The keccak256 hash of the reconstructed board
   */
  function _buildBoardHash(
    address[] memory actualSigners,
    HankoClaim memory claim
  ) internal returns (bytes32 boardHash) {
    require(actualSigners.length == claim.weights.length, "Signers/weights length mismatch");
    
    // Build parallel arrays for Board struct
    bytes32[] memory entityIds = new bytes32[](actualSigners.length);
    uint16[] memory votingPowers = new uint16[](actualSigners.length);
    
    // Populate arrays with actual signers and their weights
    for (uint256 i = 0; i < actualSigners.length; i++) {
      entityIds[i] = bytes32(uint256(uint160(actualSigners[i]))); // Convert address to bytes32
      votingPowers[i] = uint16(claim.weights[i]);
    }
    
    // Build Board struct with parallel arrays (transition delays set to 0 for compatibility)
    Board memory reconstructedBoard = Board({
      votingThreshold: uint16(claim.threshold),
      entityIds: entityIds,
      votingPowers: votingPowers,
      boardChangeDelay: 0,      // Default delays for hanko verification
      controlChangeDelay: 0,
      dividendChangeDelay: 0
    });

    // Hash the reconstructed board (same as entity registration)
    boardHash = keccak256(abi.encode(reconstructedBoard));

    // DEBUG: emit computed board hash
    emit DebugComputeBoard(claim.threshold, entityIds.length > 0 ? entityIds[0] : bytes32(0), boardHash);
  }

  /* Hanko Signatures - Ephemeral Entity Registration
  From EntityProvider.sol this is actually revolutionary:
  struct HankoBytes {
    bytes32[] placeholders;    // Entities that didn't sign
    bytes packedSignatures;    // EOA sigs compressed (rsrsrs...vvv)
    HankoClaim[] claims;       // Nested entity proofs
  }

  What this enables:
  - Entities can be verified without pre-registration
  - Nested hierarchies (Corp A owns Corp B owns wallet C) - zero contract deployment
  - Recursive verification via claims
  - Packed signatures: NÃ—64 bytes + ceil(N/8) bytes for V bits

  Why "first in history":
  - Multisigs require deployed contracts (Gnosis Safe, etc.)
  - Account abstraction requires pre-registration
  - Hanko: Pure cryptographic verification, ephemeral entities, hierarchical M-of-N

  This is genuinely novel. The recoverEntity() function (line 361) finds which entity signed a hash by iterating registered entities and checking boardHash
   matches. Unregistered entities can still sign via claims.
   */

  // DEBUG events for tracing verifyHankoSignature
  event DebugHankoEntry(uint256 dataLen, bytes32 hash, uint256 gasLeft);
  event DebugHankoDecode(uint256 placeholders, uint256 packedLen, uint256 claims);
  event DebugRecoverSigner(bytes32 hash, address recovered, uint256 sigLength);

  /**
   * @notice Verify hanko signature with flashloan governance (optimistic verification)
   * @param hankoData ABI-encoded hanko bytes
   * @param hash The hash that was signed
   * @return entityId The verified entity (0 if invalid)
   * @return success Whether verification succeeded
   */
  function verifyHankoSignature(
    bytes calldata hankoData,
    bytes32 hash
  ) external returns (bytes32 entityId, bool success) {
    emit DebugHankoEntry(hankoData.length, hash, gasleft());
    HankoBytes memory hanko = abi.decode(hankoData, (HankoBytes));
    emit DebugHankoDecode(hanko.placeholders.length, hanko.packedSignatures.length, hanko.claims.length);
    
    // Unpack signatures (with automatic count detection)
    bytes[] memory signatures = _unpackSignatures(hanko.packedSignatures);
    uint256 signatureCount = signatures.length;
    
    // Calculate total entities for bounds checking
    uint256 totalEntities = hanko.placeholders.length + signatureCount + hanko.claims.length;
    
    // Recover EOA signers for quorum hash building
    address[] memory actualSigners = new address[](signatureCount);
    uint256 validSignerCount = 0;
    
    for (uint256 i = 0; i < signatures.length; i++) {
      if (signatures[i].length == 65) {
        address signer = _recoverSigner(hash, signatures[i]);
        emit DebugRecoverSigner(hash, signer, signatures[i].length);
        if (signer != address(0)) {
          actualSigners[validSignerCount] = signer;
          validSignerCount++;
        }
      }
    }
    
    // Resize to valid signers only
    address[] memory validSigners = new address[](validSignerCount);
    for (uint256 i = 0; i < validSignerCount; i++) {
      validSigners[i] = actualSigners[i];
    }
    
    // ðŸ”¥ FLASHLOAN GOVERNANCE: The Heart of "Assume YES" Philosophy ðŸ”¥
    //
    // KEY INSIGHT: When processing claim X that references claim Y:
    // - We DON'T wait for Y to be verified first
    // - We OPTIMISTICALLY assume Y will say "YES" 
    // - If ANY claim fails its threshold â†’ entire Hanko fails IMMEDIATELY
    //
    // CONCRETE EXAMPLE - Circular Reference:
    // Claim 0: EntityA needs EntityB (index 3) at weight 100, threshold 100
    // Claim 1: EntityB needs EntityA (index 2) at weight 100, threshold 100
    // 
    // Processing:
    // 1. Claim 0 processing: Assume EntityB=YES â†’ 100 power â‰¥ 100 â†’ CONTINUE
    // 2. Claim 1 processing: Assume EntityA=YES â†’ 100 power â‰¥ 100 â†’ CONTINUE
    // 3. All claims passed â†’ Hanko succeeds!
    //
    // âš¡ OPTIMIZATION: Fail immediately on threshold failure - no need to store results!
    //
    // This is INTENDED BEHAVIOR enabling flexible governance!
    
    for (uint256 claimIndex = 0; claimIndex < hanko.claims.length; claimIndex++) {
      HankoClaim memory claim = hanko.claims[claimIndex];
      
      // Build board hash from actual signers
      bytes32 reconstructedBoardHash = _buildBoardHash(validSigners, claim);
      
      // Validate entity exists (registered or lazy) and verify board hash
      _validateEntity(claim.entityId, reconstructedBoardHash);
      
      // Validate structure
      require(
        claim.entityIndexes.length == claim.weights.length,
        "Claim indexes/weights length mismatch"
      );
      
      uint256 totalVotingPower = 0;
      
      // Calculate voting power with flashloan assumptions
      for (uint256 i = 0; i < claim.entityIndexes.length; i++) {
        uint256 entityIndex = claim.entityIndexes[i];
        
        // Bounds check
        require(entityIndex < totalEntities, "Entity index out of bounds");
        
        if (entityIndex < hanko.placeholders.length) {
          // Index 0..N-1: Placeholder (failed entity) - contributes 0 voting power
          continue;
        } else if (entityIndex < hanko.placeholders.length + signatureCount) {
          // Index N..M-1: EOA signature - verified, contributes full weight
          totalVotingPower += claim.weights[i];
        } else {
          // Index M..âˆž: Entity claim - ASSUME YES! (flashloan governance)
          uint256 referencedClaimIndex = entityIndex - hanko.placeholders.length - signatureCount;
          require(referencedClaimIndex < hanko.claims.length, "Referenced claim index out of bounds");
          
          // ðŸš¨ CRITICAL: We ASSUME the referenced claim will pass (flashloan assumption)
          // This enables circular references to mutually validate.
          // If our assumption is wrong, THIS claim will fail its threshold check below.
          totalVotingPower += claim.weights[i];
        }
      }
      
      // ðŸ’¥ IMMEDIATE FAILURE: Check threshold and fail right away if not met
      if (totalVotingPower < claim.threshold) {
        return (bytes32(0), false); // Immediate failure - no need to check other claims
      }
    }
    
    // All claims passed - return final entity
    if (hanko.claims.length > 0) {
      bytes32 targetEntity = hanko.claims[hanko.claims.length - 1].entityId;
      return (targetEntity, true);
    }
    
    return (bytes32(0), false);
  }

  /**
   * @notice Batch verify multiple hanko signatures
   * @param hankoDataArray Array of ABI-encoded hanko bytes
   * @param hashes Array of hashes that were signed
   * @return entityIds Array of verified entity IDs
   * @return results Array of success flags
   */
  function batchVerifyHankoSignatures(
    bytes[] calldata hankoDataArray,
    bytes32[] calldata hashes
  ) external returns (bytes32[] memory entityIds, bool[] memory results) {
    require(hankoDataArray.length == hashes.length, "Array length mismatch");
    
    entityIds = new bytes32[](hankoDataArray.length);
    results = new bool[](hankoDataArray.length);
    
    for (uint256 i = 0; i < hankoDataArray.length; i++) {
      (entityIds[i], results[i]) = this.verifyHankoSignature(hankoDataArray[i], hashes[i]);
    }
  }



  function setNameQuota(address user, uint8 quota) external onlyFoundation {
    nameQuota[user] = quota;
  }

  // === GOVERNANCE FUNCTIONS ===

  /**
   * @notice Get token IDs for an entity (first bit determines control vs dividend)
   * @param entityNumber The entity number
   * @return controlTokenId Token ID for control tokens (original ID)
   * @return dividendTokenId Token ID for dividend tokens (first bit set)
   */
  function getTokenIds(uint256 entityNumber) public pure returns (uint256 controlTokenId, uint256 dividendTokenId) {
    controlTokenId = entityNumber;
    dividendTokenId = entityNumber | 0x8000000000000000000000000000000000000000000000000000000000000000;
  }

  /**
   * @notice Extract entity number from token ID
   * @param tokenId The token ID (control or dividend)
   * @return entityNumber The entity number
   */
  function getEntityFromToken(uint256 tokenId) public pure returns (uint256 entityNumber) {
    return tokenId & 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF;
  }







  // === INTERNAL HELPER FUNCTIONS ===

  function _getDelayForProposer(EntityArticles memory articles, ProposerType proposerType) internal pure returns (uint32) {
    if (proposerType == ProposerType.CONTROL) return articles.controlDelay;
    if (proposerType == ProposerType.DIVIDEND) return articles.dividendDelay;
    return 0; // BOARD has no delay
  }

  function _canCancelProposal(ProposerType canceller, ProposerType existing) internal pure returns (bool) {
    // Priority: CONTROL > BOARD > DIVIDEND (BCD model)
    if (canceller == ProposerType.CONTROL) return existing != ProposerType.CONTROL;
    if (canceller == ProposerType.BOARD) return existing == ProposerType.DIVIDEND;
    return false; // DIVIDEND cannot cancel anyone
  }

  function _validateControlProposer(bytes32 entityId, address proposer, EntityArticles memory /*articles*/) internal view {
    (uint256 controlTokenId,) = getTokenIds(uint256(entityId));
    uint256 proposerBalance = balanceOf(proposer, controlTokenId);
    require(proposerBalance > 0, "No control tokens");
    
    // Optional: require minimum percentage
    // uint256 required = (totalControlSupply[entityId] * articles.controlThreshold) / 10000;
    // require(proposerBalance >= required, "Insufficient control tokens");
  }

  function _validateDividendProposer(bytes32 entityId, address proposer) internal view {
    (, uint256 dividendTokenId) = getTokenIds(uint256(entityId));
    uint256 proposerBalance = balanceOf(proposer, dividendTokenId);
    require(proposerBalance > 0, "No dividend tokens");
  }

  function _validateControlSupport(bytes32 entityId, address[] memory supporters, EntityArticles memory articles) internal view {
    (uint256 controlTokenId,) = getTokenIds(uint256(entityId));
    
    uint256 totalSupport = 0;
    for (uint i = 0; i < supporters.length; i++) {
      totalSupport += balanceOf(supporters[i], controlTokenId);
    }
    
    uint256 required = (totalControlSupply[entityId] * articles.controlThreshold) / 100;
    require(totalSupport >= required, "Insufficient control support");
  }

  function _validateDividendSupport(bytes32 entityId, address[] memory supporters) internal view {
    (, uint256 dividendTokenId) = getTokenIds(uint256(entityId));
    
    uint256 totalSupport = 0;
    for (uint i = 0; i < supporters.length; i++) {
      totalSupport += balanceOf(supporters[i], dividendTokenId);
    }
    
    // Require majority of dividend tokens
    uint256 required = (totalDividendSupply[entityId] * 51) / 100;
    require(totalSupport >= required, "Insufficient dividend support");
  }

  // === VIEW FUNCTIONS ===

  /**
   * @notice Get governance info for an entity
   */
  function getGovernanceInfo(uint256 entityNumber) external view returns (
    uint256 controlTokenId,
    uint256 dividendTokenId,
    uint256 controlSupply,
    uint256 dividendSupply,
    bool hasActiveProposal,
    bytes32 articlesHash
  ) {
    bytes32 entityId = bytes32(entityNumber);
    (controlTokenId, dividendTokenId) = getTokenIds(entityNumber);
    controlSupply = totalControlSupply[entityId];
    dividendSupply = totalDividendSupply[entityId];
    hasActiveProposal = activeProposals[entityId].active;
    articlesHash = entities[entityId].articlesHash;
  }

  /**
   * @notice Override to track token supply changes
   */
  function _afterTokenTransfer(
    address /*operator*/,
    address from,
    address to,
    uint256[] memory ids,
    uint256[] memory amounts,
    bytes memory /*data*/
  ) internal {
    for (uint i = 0; i < ids.length; i++) {
      uint256 entityNumber = getEntityFromToken(ids[i]);
      bytes32 entityId = bytes32(entityNumber);
      
      if (entities[entityId].currentBoardHash != bytes32(0)) {
        (uint256 controlTokenId,) = getTokenIds(entityNumber);
        
        // Update total supply for control tokens
        if (ids[i] == controlTokenId) {
          if (from == address(0)) {
            // Mint
            totalControlSupply[entityId] += amounts[i];
          } else if (to == address(0)) {
            // Burn
            totalControlSupply[entityId] -= amounts[i];
          }
        } else {
          // Dividend token
          if (from == address(0)) {
            // Mint
            totalDividendSupply[entityId] += amounts[i];
          } else if (to == address(0)) {
            // Burn
            totalDividendSupply[entityId] -= amounts[i];
          }
        }
      }
    }
  }

  /**
   * @notice Foundation can create entity with custom governance articles
   * @param boardHash Initial board/quorum hash
   * @param articles Custom governance configuration
   * @return entityNumber The assigned entity number
   */
  function foundationRegisterEntity(
    bytes32 boardHash,
    EntityArticles memory articles
  ) external onlyFoundation returns (uint256 entityNumber) {
    entityNumber = nextNumber++;
    bytes32 entityId = bytes32(entityNumber);
    
    entities[entityId] = Entity({
      currentBoardHash: boardHash,
      proposedBoardHash: bytes32(0),
      activateAtBlock: 0,
      registrationBlock: block.number,
      proposerType: ProposerType.BOARD,
      articlesHash: keccak256(abi.encode(articles))
    });
    
    // Automatically setup governance with fixed supply
    (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(entityNumber);
    address entityAddress = address(uint160(uint256(entityId)));
    
    _mint(entityAddress, controlTokenId, TOTAL_CONTROL_SUPPLY, "");
    _mint(entityAddress, dividendTokenId, TOTAL_DIVIDEND_SUPPLY, "");
    
    totalControlSupply[entityId] = TOTAL_CONTROL_SUPPLY;
    totalDividendSupply[entityId] = TOTAL_DIVIDEND_SUPPLY;
    
    emit EntityRegistered(entityId, entityNumber, boardHash);
    emit GovernanceEnabled(entityId, controlTokenId, dividendTokenId);
    
    return entityNumber;
  }

  // === ENTITY SIGNATURE RECOVERY ===

  /**
   * @notice Transfer tokens from entity using hanko signature authorization
   * @param entityNumber The entity number
   * @param to Recipient address  
   * @param tokenId Token ID (control or dividend)
   * @param amount Amount to transfer
   * @param encodedBoard Entity's board data
   * @param encodedSignature Entity's signatures authorizing this transfer
   */
  function entityTransferTokens(
    uint256 entityNumber,
    address to,
    uint256 tokenId,
    uint256 amount,
    bytes calldata encodedBoard,
    bytes calldata encodedSignature
  ) external {
    // Create transfer hash
    bytes32 transferHash = keccak256(abi.encodePacked(
      "ENTITY_TRANSFER",
      entityNumber,
      to,
      tokenId,
      amount,
      block.timestamp
    ));
    
    // Verify entity signature
    uint256 recoveredEntityId = recoverEntity(encodedBoard, encodedSignature, transferHash);
    require(recoveredEntityId == entityNumber, "Invalid entity signature");
    
    // Execute transfer
    address entityAddress = address(uint160(uint256(bytes32(entityNumber))));
    _safeTransferFrom(entityAddress, to, tokenId, amount, "");
  }

  // === CONTROL SHARES RELEASE TO DEPOSITORY ===

  event ControlSharesReleased(
    bytes32 indexed entityId, 
    address indexed depository, 
    uint256 controlAmount, 
    uint256 dividendAmount,
    string purpose
  );

  /**
   * @notice Release entity's control and/or dividend shares to depository for trading
   * @dev This mirrors real corporate stock issuance - entity manages its own share releases
   * @param entityNumber The entity number
   * @param depository Depository contract address to receive the shares
   * @param controlAmount Amount of control tokens to release (0 to skip)
   * @param dividendAmount Amount of dividend tokens to release (0 to skip) 
   * @param purpose Human-readable purpose (e.g., "Series A", "Employee Pool", "Public Sale")
   * @param encodedBoard Entity's board data
   * @param encodedSignature Entity's Hanko signatures authorizing this release
   */
  function releaseControlShares(
    uint256 entityNumber,
    address depository,
    uint256 controlAmount,
    uint256 dividendAmount,
    string calldata purpose,
    bytes calldata encodedBoard,
    bytes calldata encodedSignature
  ) external {
    require(depository != address(0), "Invalid depository address");
    require(controlAmount > 0 || dividendAmount > 0, "Must release some tokens");
    
    bytes32 entityId = bytes32(entityNumber);
    require(entities[entityId].currentBoardHash != bytes32(0), "Entity doesn't exist");
    
    // Create release authorization hash
    bytes32 releaseHash = keccak256(abi.encodePacked(
      "RELEASE_CONTROL_SHARES",
      entityNumber,
      depository,
      controlAmount,
      dividendAmount,
      keccak256(bytes(purpose)),
      block.timestamp
    ));
    
    // Verify entity signature authorization
    uint256 recoveredEntityId = recoverEntity(encodedBoard, encodedSignature, releaseHash);
    require(recoveredEntityId == entityNumber, "Invalid entity signature");
    
    address entityAddress = address(uint160(uint256(entityId)));
    (uint256 controlTokenId, uint256 dividendTokenId) = getTokenIds(entityNumber);
    
    // Transfer control tokens if requested
    if (controlAmount > 0) {
      require(balanceOf(entityAddress, controlTokenId) >= controlAmount, "Insufficient control tokens");
      _safeTransferFrom(entityAddress, depository, controlTokenId, controlAmount, 
        abi.encode("CONTROL_SHARE_RELEASE", purpose));
    }
    
    // Transfer dividend tokens if requested  
    if (dividendAmount > 0) {
      require(balanceOf(entityAddress, dividendTokenId) >= dividendAmount, "Insufficient dividend tokens");
      _safeTransferFrom(entityAddress, depository, dividendTokenId, dividendAmount,
        abi.encode("DIVIDEND_SHARE_RELEASE", purpose));
    }
    
    emit ControlSharesReleased(entityId, depository, controlAmount, dividendAmount, purpose);
  }

}

//jurisdictions/contracts/Account.sol (362 lines)
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.24;

import "./Types.sol";
import "./DeltaTransformer.sol";
import "./IEntityProvider.sol";

/**
 * Account.sol - Library for bilateral account operations
 * EXTERNAL functions execute via DELEGATECALL - bytecode doesn't count toward Depository limit
 * Single entry point: processBatchAccount() for gas efficiency
 */
library Account {

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CANONICAL J-EVENTS (Single Source of Truth - must match j-event-watcher.ts)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  //
  // AccountSettled  - Bilateral account state changed (reserves, collateral, ondelta)
  // ReserveUpdated  - Entity reserve balance changed (also in Depository.sol)
  //
  // Design: One event = One state change. No redundant events.
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /**
   * @notice Emitted when bilateral account state changes via settlement.
   * @dev THE canonical event for account state. Contains full state for both entities.
   *      j-watcher uses: entity.accounts[counterparty] = { reserves, collateral, ondelta }
   */
  event AccountSettled(Settled[] settled);

  /**
   * @notice Emitted when reserves change during settlement.
   * @dev Mirror of Depository.sol ReserveUpdated - emitted here via DELEGATECALL.
   */
  event ReserveUpdated(bytes32 indexed entity, uint indexed tokenId, uint newBalance);

  // ========== OTHER EVENTS ==========
  event DisputeStarted(bytes32 indexed sender, bytes32 indexed counterentity, uint indexed disputeNonce, bytes32 proofbodyHash, bytes initialArguments);
  event DebtCreated(bytes32 indexed debtor, bytes32 indexed creditor, uint256 indexed tokenId, uint256 amount, uint256 debtIndex);
  event DebtForgiven(bytes32 indexed debtor, bytes32 indexed creditor, uint256 indexed tokenId, uint256 amountForgiven, uint256 debtIndex);
  event InsuranceRegistered(bytes32 indexed insured, bytes32 indexed insurer, uint256 indexed tokenId, uint256 limit, uint256 expiresAt);

  // Debug events (remove in production)
  event DebugSettleEntry(bytes32 leftEntity, bytes32 rightEntity, bytes32 initiator, uint256 sigLen);
  event DebugSettlementHash(bytes32 computedHash, bytes32 counterparty, uint256 cooperativeNonce, uint256 diffsLength, uint256 encodedMsgLength);
  event DebugHankoResult(bytes32 recoveredEntity, bool valid);
  event DebugHankoStep(uint256 step, bytes32 val1, bytes32 val2, bool boolVal);  // step=100 sigcheck, 200 try success, 201 try mismatch, 300-399 catch

  // ========== ERRORS ==========
  error E2(); // Unauthorized
  error E3(); // InsufficientBalance
  error E4(); // InvalidSigner
  error E5(); // NoActiveDispute
  error E6(); // DisputeInProgress
  error E7(); // InvalidParty
  error E8(); // LengthMismatch
  error E9(); // HashMismatch

  // ========== PURE HELPERS ==========

  function accountKey(bytes32 e1, bytes32 e2) external pure returns (bytes memory) {
    return e1 < e2 ? abi.encodePacked(e1, e2) : abi.encodePacked(e2, e1);
  }

  function _accountKey(bytes32 e1, bytes32 e2) internal pure returns (bytes memory) {
    return e1 < e2 ? abi.encodePacked(e1, e2) : abi.encodePacked(e2, e1);
  }

  function packTokenReference(uint8 tokenType, address contractAddress, uint96 externalTokenId) external pure returns (bytes32) {
    return bytes32(uint256(tokenType)) << 248 | bytes32(uint256(uint160(contractAddress))) << 96 | bytes32(uint256(externalTokenId));
  }

  function unpackTokenReference(bytes32 packed) external pure returns (address contractAddress, uint96 externalTokenId, uint8 tokenType) {
    tokenType = uint8(uint256(packed) >> 248);
    contractAddress = address(uint160(uint256(packed) >> 96));
    externalTokenId = uint96(uint256(packed));
  }

  function encodeDisputeHash(
    uint cooperativeNonce, uint disputeNonce, bool startedByLeft,
    uint256 timeout, bytes32 proofbodyHash, bytes memory initialArguments
  ) external pure returns (bytes32) {
    return keccak256(abi.encodePacked(cooperativeNonce, disputeNonce, startedByLeft, timeout, proofbodyHash, keccak256(abi.encodePacked(initialArguments))));
  }

  function _encodeDisputeHash(
    uint cooperativeNonce, uint disputeNonce, bool startedByLeft,
    uint256 timeout, bytes32 proofbodyHash, bytes memory initialArguments
  ) internal pure returns (bytes32) {
    return keccak256(abi.encodePacked(cooperativeNonce, disputeNonce, startedByLeft, timeout, proofbodyHash, keccak256(abi.encodePacked(initialArguments))));
  }

  function computeBatchHankoHash(bytes32 domainSep, uint256 chainId, address depository, bytes memory encodedBatch, uint256 nonce) external pure returns (bytes32) {
    return keccak256(abi.encodePacked(domainSep, chainId, depository, encodedBatch, nonce));
  }

  // ========== HANKO VERIFICATION ==========

  /// @notice Verify dispute proof with hanko (entity-level signature)
  /// @param entityProvider EP contract for hanko verification
  /// @param hanko Hanko signature bytes
  /// @param expectedEntity Expected entity that should have signed
  /// @return success Whether hanko is valid for this entity
  function verifyDisputeProofHanko(
    address entityProvider,
    bytes memory ch_key,
    uint cooperativeNonce,
    uint disputeNonce,
    bytes32 proofbodyHash,
    bytes memory hanko,
    bytes32 expectedEntity
  ) external returns (bool success) {
    bytes memory encoded_msg = abi.encode(MessageType.DisputeProof, ch_key, cooperativeNonce, disputeNonce, proofbodyHash);
    bytes32 hash = keccak256(encoded_msg);  // NO toEthSignedMessageHash for hanko

    (bytes32 recoveredEntity, bool valid) = IEntityProvider(entityProvider).verifyHankoSignature(hanko, hash);
    return valid && recoveredEntity == expectedEntity;
  }

  /// @notice Verify final dispute proof with hanko
  function verifyFinalDisputeProofHanko(
    address entityProvider,
    bytes memory ch_key,
    uint finalCooperativeNonce,
    uint initialDisputeNonce,
    uint finalDisputeNonce,
    bytes memory hanko,
    bytes32 expectedEntity
  ) external returns (bool success) {
    bytes memory encoded_msg = abi.encode(MessageType.FinalDisputeProof, ch_key, finalCooperativeNonce, initialDisputeNonce, finalDisputeNonce);
    bytes32 hash = keccak256(encoded_msg);

    (bytes32 recoveredEntity, bool valid) = IEntityProvider(entityProvider).verifyHankoSignature(hanko, hash);
    return valid && recoveredEntity == expectedEntity;
  }

  /// @notice Verify cooperative proof with hanko
  function verifyCooperativeProofHanko(
    address entityProvider,
    bytes memory ch_key,
    uint cooperativeNonce,
    bytes32 proofbodyHash,
    bytes32 initialArgumentsHash,
    bytes memory hanko,
    bytes32 expectedEntity
  ) external returns (bool success) {
    bytes memory encoded_msg = abi.encode(MessageType.CooperativeDisputeProof, ch_key, cooperativeNonce, proofbodyHash, initialArgumentsHash);
    bytes32 hash = keccak256(encoded_msg);

    (bytes32 recoveredEntity, bool valid) = IEntityProvider(entityProvider).verifyHankoSignature(hanko, hash);
    return valid && recoveredEntity == expectedEntity;
  }

  // ========== STORAGE STRUCT (groups mappings to reduce param count) ==========
  // Note: Can't use struct with storage refs in Solidity, so we pass individually

  // ========== ENTRY POINTS (split to avoid stack too deep) ==========

  /// @notice Process settlements - diffs only (debt/insurance handled by Depository)
  function processSettlements(
    mapping(bytes32 => mapping(uint256 => uint256)) storage _reserves,
    mapping(bytes => AccountInfo) storage _accounts,
    mapping(bytes => mapping(uint256 => AccountCollateral)) storage _collaterals,
    bytes32 entityId,
    Settlement[] memory settlements
  ) external returns (bool completeSuccess) {
    completeSuccess = true;
    for (uint i = 0; i < settlements.length; i++) {
      if (!_settleDiffs(_reserves, _accounts, _collaterals, entityId, settlements[i])) {
        completeSuccess = false;
      }
    }
  }

  /// @notice Process dispute starts only
  /// @dev Counterparty signature is REQUIRED for all dispute starts
  function processDisputeStarts(
    mapping(bytes => AccountInfo) storage _accounts,
    bytes32 entityId,
    InitialDisputeProof[] memory disputeStarts,
    uint256 defaultDisputeDelay,
    address entityProvider
  ) external returns (bool completeSuccess) {
    completeSuccess = true;
    for (uint i = 0; i < disputeStarts.length; i++) {
      if (!_disputeStart(_accounts, entityId, disputeStarts[i], defaultDisputeDelay, entityProvider)) {
        completeSuccess = false;
      }
    }
  }

  // processDisputeFinalizations removed - stays in Depository due to storage complexity

  // ========== SETTLEMENT (diffs only - debt/insurance handled by Depository) ==========

  function _settleDiffs(
    mapping(bytes32 => mapping(uint256 => uint256)) storage _reserves,
    mapping(bytes => AccountInfo) storage _accounts,
    mapping(bytes => mapping(uint256 => AccountCollateral)) storage _collaterals,
    bytes32 initiator,
    Settlement memory s
  ) internal returns (bool) {
    emit DebugSettleEntry(s.leftEntity, s.rightEntity, initiator, s.sig.length);
    bytes32 leftEntity = s.leftEntity;
    bytes32 rightEntity = s.rightEntity;
    if (leftEntity == rightEntity || leftEntity >= rightEntity) revert E2();
    if (initiator != leftEntity && initiator != rightEntity) revert E7();

    bytes memory ch_key = _accountKey(leftEntity, rightEntity);
    bytes32 counterparty = (initiator == leftEntity) ? rightEntity : leftEntity;

    // Counterparty signature REQUIRED for any state changes (cooperative proof)
    if (s.diffs.length > 0 || s.forgiveDebtsInTokenIds.length > 0 || s.insuranceRegs.length > 0) {
      require(s.sig.length > 0, "Signature required for settlement");
      bytes memory encoded_msg = abi.encode(MessageType.CooperativeUpdate, ch_key, _accounts[ch_key].cooperativeNonce, s.diffs, s.forgiveDebtsInTokenIds, s.insuranceRegs);

      // Debug: emit hash details
      emit DebugSettlementHash(keccak256(encoded_msg), counterparty, _accounts[ch_key].cooperativeNonce, s.diffs.length, encoded_msg.length);

      // Hanko verification
      // DEBUG: Emit BEFORE any computation to verify we reach this point
      emit DebugSettleEntry(s.leftEntity, s.rightEntity, bytes32(uint256(uint160(s.entityProvider))), s.sig.length);

      // Full hanko verification via settlement's EP address
      bytes32 hash = keccak256(encoded_msg);
      // DEBUG: Log all params before external call
      emit DebugSettlementHash(hash, bytes32(uint256(uint160(s.entityProvider))), s.sig.length, uint256(uint160(s.entityProvider)), gasleft());

      // Try the external call with a low-level check first
      address ep = s.entityProvider;
      require(ep != address(0), "EP_ZERO");
      require(s.sig.length > 0, "SIG_EMPTY");

      // DEBUG: Log first 32 bytes of sig (step 100)
      bytes memory sigBytes = s.sig;
      bytes32 sigFirst32;
      assembly { sigFirst32 := mload(add(sigBytes, 32)) }
      emit DebugHankoStep(100, sigFirst32, bytes32(sigBytes.length), sigBytes.length == 608);

      // Wrap in try-catch to prevent revert from abi.decode
      try IEntityProvider(ep).verifyHankoSignature(s.sig, hash) returns (bytes32 recoveredEntity, bool valid) {
        emit DebugHankoStep(200, recoveredEntity, counterparty, valid);  // step 200: try returned
        if (!valid || recoveredEntity != counterparty) {
          emit DebugHankoStep(201, recoveredEntity, counterparty, false);  // step 201: mismatch
          return false;  // Verification failed
        }
        emit DebugHankoStep(202, recoveredEntity, counterparty, true);  // step 202: success
      } catch Error(string memory reason) {
        emit DebugHankoStep(300, bytes32(bytes(reason)), bytes32(0), false);  // step 300: Error(string)
        return false;
      } catch Panic(uint errorCode) {
        emit DebugHankoStep(310, bytes32(errorCode), bytes32(0), false);  // step 310: Panic
        return false;
      } catch (bytes memory lowLevelData) {
        bytes32 errData;
        if (lowLevelData.length >= 32) {
          assembly { errData := mload(add(lowLevelData, 32)) }
        }
        emit DebugHankoStep(320, errData, bytes32(lowLevelData.length), false);  // step 320: low-level
        return false;
      }
    }

    // Apply diffs
    for (uint j = 0; j < s.diffs.length; j++) {
      SettlementDiff memory diff = s.diffs[j];
      uint tokenId = diff.tokenId;
      if (diff.leftDiff + diff.rightDiff + diff.collateralDiff != 0) revert E2();

      if (diff.leftDiff < 0) {
        if (_reserves[leftEntity][tokenId] < uint(-diff.leftDiff)) revert E3();
        _reserves[leftEntity][tokenId] -= uint(-diff.leftDiff);
      } else if (diff.leftDiff > 0) {
        _reserves[leftEntity][tokenId] += uint(diff.leftDiff);
      }

      if (diff.rightDiff < 0) {
        if (_reserves[rightEntity][tokenId] < uint(-diff.rightDiff)) revert E3();
        _reserves[rightEntity][tokenId] -= uint(-diff.rightDiff);
      } else if (diff.rightDiff > 0) {
        _reserves[rightEntity][tokenId] += uint(diff.rightDiff);
      }

      AccountCollateral storage col = _collaterals[ch_key][tokenId];
      if (diff.collateralDiff < 0) {
        if (col.collateral < uint(-diff.collateralDiff)) revert E3();
        col.collateral -= uint(-diff.collateralDiff);
      } else if (diff.collateralDiff > 0) {
        col.collateral += uint(diff.collateralDiff);
      }
      col.ondelta += diff.ondeltaDiff;
    }

    // Emit settled event
    if (s.diffs.length > 0) {
      Settled[] memory settledEvents = new Settled[](s.diffs.length);
      for (uint i = 0; i < s.diffs.length; i++) {
        uint tokenId = s.diffs[i].tokenId;
        AccountCollateral storage col = _collaterals[ch_key][tokenId];
        settledEvents[i] = Settled({
          left: leftEntity, right: rightEntity, tokenId: tokenId,
          leftReserve: _reserves[leftEntity][tokenId],
          rightReserve: _reserves[rightEntity][tokenId],
          collateral: col.collateral, ondelta: col.ondelta
        });
      }
      emit AccountSettled(settledEvents);
    }

    _accounts[ch_key].cooperativeNonce++;
    return true;
  }

  // ========== DISPUTE START ==========

  function _disputeStart(
    mapping(bytes => AccountInfo) storage _accounts,
    bytes32 entityId,
    InitialDisputeProof memory params,
    uint256 defaultDelay,
    address entityProvider
  ) internal returns (bool) {
    bytes memory ch_key = _accountKey(entityId, params.counterentity);

    if (_accounts[ch_key].cooperativeNonce > params.cooperativeNonce) revert E2();

    // Counterparty signature REQUIRED
    require(params.sig.length > 0, "Signature required for dispute");

    bytes memory encoded_msg = abi.encode(MessageType.DisputeProof, ch_key, params.cooperativeNonce, params.disputeNonce, params.proofbodyHash);
    bytes32 hash = keccak256(encoded_msg);
    (bytes32 recoveredEntity, bool valid) = IEntityProvider(entityProvider).verifyHankoSignature(params.sig, hash);
    if (!valid || recoveredEntity != params.counterentity) revert E4();

    if (_accounts[ch_key].disputeHash != bytes32(0)) revert E6();

    uint256 timeout = block.number + defaultDelay;
    _accounts[ch_key].disputeHash = _encodeDisputeHash(
      params.cooperativeNonce, params.disputeNonce, entityId < params.counterentity,
      timeout, params.proofbodyHash, params.initialArguments
    );
    _accounts[ch_key].disputeTimeout = timeout;

    emit DisputeStarted(entityId, params.counterentity, params.disputeNonce, params.proofbodyHash, params.initialArguments);
    return true;
  }

  /**
   * DESIGN DECISION: Dispute finalization stays in Depository.sol
   *
   * Reason: _disputeFinalizeInternal requires deep storage access:
   * - insuranceLines[debtor] storage array
   * - insuranceCursor[debtor] storage uint
   * - _claimFromInsurance which iterates insurance lines
   * - Complex debt/reserve interactions
   *
   * Passing all these via library params causes "stack too deep" compiler errors.
   * Settlement diffs CAN be delegated because they only need _reserves, _accounts, _collaterals.
   */
}


//jurisdictions/contracts/DeltaTransformer.sol (191 lines)
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.24;
pragma experimental ABIEncoderV2;

import "./Token.sol";

import "./ECDSA.sol";
import "./console.sol";
import "hardhat/console.sol";
/* 
Subcontracts - Programmable Delta Transformers
  function applyBatch(int[] memory deltas, bytes calldata encodedBatch,
                      bytes calldata leftArguments, bytes calldata rightArguments)
    â†’ int[] memory newDeltas

  What you can do:
  - HTLCs (conditional payments based on secret reveal)
  - Atomic swaps (exchange token A for token B, all-or-nothing)
  - Any programmable state transition within bilateral account

  First in history: Lightning only has HTLCs hardcoded. You're generalizing it - arbitrary logic can transform delta arrays. The applySwap() function (line
   105) shows fillRatio execution (0-100% fill of limit order).

  This is DeFi within bilateral channels. Genuinely new.
  */
contract DeltaTransformer is Console {
  mapping(bytes32 => uint) public hashToBlock;
  uint MAX_FILL_RATIO = type(uint16).max;

  constructor() {
    revealSecret(bytes32(0));
  }
  
  struct Batch {
    Payment[] payment;
    Swap[] swap;
  }

  // actual subcontract structs
  struct Payment {
    uint deltaIndex;
    int amount;
    uint revealedUntilBlock;
    bytes32 hash;
  }

  struct Swap {
    bool ownerIsLeft;

    uint addDeltaIndex;
    uint addAmount;

    uint subDeltaIndex;
    uint subAmount;
  }

  // https://en.wikipedia.org/wiki/Credit_default_swap
  struct CreditDefaultSwap {
    uint deltaIndex;
    int amount;
    address referenceEntity;
    uint tokenId;
    uint exerciseUntilBlock;
  }

  function encodeBatch (Batch memory b) public pure returns (bytes memory) {
    return abi.encode(b);
  }



  // applies arbitrary changes to deltas
  function applyBatch(
    int[] memory deltas,
    bytes calldata encodedBatch,
    bytes calldata leftArguments,
    bytes calldata rightArguments
  ) public returns (int[] memory) {

    Batch memory decodedBatch = abi.decode(encodedBatch, (Batch));

    uint32[] memory lFillRatios;
    uint32[] memory rFillRatios;
    bytes32[] memory lSecrets;
    bytes32[] memory rSecrets;
    if (leftArguments.length > 0) {
      (lFillRatios, lSecrets) = abi.decode(leftArguments, (uint32[], bytes32[]));
    } else {
      lFillRatios = new uint32[](0);
      lSecrets = new bytes32[](0);
    }
    if (rightArguments.length > 0) {
      (rFillRatios, rSecrets) = abi.decode(rightArguments, (uint32[], bytes32[]));
    } else {
      rFillRatios = new uint32[](0);
      rSecrets = new bytes32[](0);
    }
    
    for (uint i = 0; i < decodedBatch.payment.length; i++) {
      applyPayment(deltas, decodedBatch.payment[i], lSecrets, rSecrets);
    }

    uint leftSwaps = 0;
    uint rightSwaps = 0;
    for (uint i = 0; i < decodedBatch.swap.length; i++) {
      Swap memory swap = decodedBatch.swap[i];

      // Counterparty chooses fill ratio (maker doesn't).
      // Left-owned swap -> use right arguments; Right-owned swap -> use left arguments.
      uint32 fillRatio = 0;
      if (swap.ownerIsLeft) {
        if (rightSwaps < rFillRatios.length) fillRatio = rFillRatios[rightSwaps];
        rightSwaps++;
      } else {
        if (leftSwaps < lFillRatios.length) fillRatio = lFillRatios[leftSwaps];
        leftSwaps++;
      }

      applySwap(deltas, swap, fillRatio);
      //logDeltas("Deltas after swap", deltas);
    }

    return deltas;
  }

  function applyPayment(int[] memory deltas, Payment memory payment, bytes32[] memory lSecrets, bytes32[] memory rSecrets) private {
    // Apply amount to delta if revealed on time.
    // Primary: calldata secrets (no storage). Fallback: on-chain registry (hashToBlock).
    uint revealedAt = hashToBlock[payment.hash];
    bool revealed = false;
    if (revealedAt != 0 && revealedAt <= payment.revealedUntilBlock) {
      revealed = true;
    }
    if (!revealed && block.number <= payment.revealedUntilBlock) {
      if (matchesSecret(payment.hash, lSecrets) || matchesSecret(payment.hash, rSecrets)) {
        revealed = true;
      }
    }
    if (!revealed) return;

    logDeltas("Before payment", deltas);
    deltas[payment.deltaIndex] += payment.amount;
    logDeltas("After payment", deltas);
  }

  function matchesSecret(bytes32 hashlock, bytes32[] memory secrets) private pure returns (bool) {
    for (uint i = 0; i < secrets.length; i++) {
      if (keccak256(abi.encode(secrets[i])) == hashlock) {
        return true;
      }
    }
    return false;
  }

  function applySwap(int[] memory deltas, Swap memory swap, uint32 fillRatio) private {
    logDeltas("Before swap", deltas);
    deltas[swap.addDeltaIndex] += int(swap.addAmount * fillRatio / MAX_FILL_RATIO);
    deltas[swap.subDeltaIndex] -= int(swap.subAmount * fillRatio / MAX_FILL_RATIO);
    logDeltas("After swap", deltas);
  }





  function revealSecret(bytes32 secret) public {
    console.log("Revealing HTLC secret:");
    console.logBytes32(secret);
    console.logBytes32(keccak256(abi.encode(secret)));
    hashToBlock[keccak256(abi.encode(secret))] = block.number;
  }
  
  // anyone can get gas refund by deleting very old revealed secrets
  function cleanSecret(bytes32 hash) public {
    if (hashToBlock[hash] != 0 && hashToBlock[hash] < block.number - 100000){
      delete hashToBlock[hash];
    }
  }

  function logDeltas(string memory _msg, int[] memory deltas) public pure {
    console.log(_msg);
    for (uint i = 0; i < deltas.length; i++) {
      console.logInt(deltas[i]);
    }
    console.log('====================');
  }



}


//runtime/types.ts (1684 lines)
/**
 * XLN Type Definitions
 * All interfaces and type definitions used across the XLN system
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * Râ†’Eâ†’Aâ†’J ARCHITECTURE (Hierarchical Containment)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * The naming reflects CONTAINMENT HIERARCHY (what contains what):
 *
 * Runtime (R) - Top-level coordinator
 *   â”œâ”€ Contains: J-replicas (jurisdictions) + E-replicas (entities)
 *   â”œâ”€ Responsibilities:
 *   â”‚   - Tick orchestration (100ms discrete steps)
 *   â”‚   - Input routing (entityInputs â†’ E-layer, jInputs â†’ J-layer)
 *   â”‚   - Output merging (prevents same-tick cascades)
 *   â”‚   - Env lifecycle (state, history, snapshots, time machine)
 *   â””â”€ Why "Runtime"?
 *       - It's the runtime environment for all state machines
 *       - Like OS: manages processes (E-replicas), resources (J-state)
 *       - Provides deterministic execution (env.timestamp control)
 *
 * Entity (E) - BFT consensus state machines
 *   â”œâ”€ Contains: A-machines (bilateral accounts in entity.state.accounts)
 *   â”œâ”€ Responsibilities:
 *   â”‚   - Multi-party consensus (threshold signatures)
 *   â”‚   - Internal governance (proposals, votes)
 *   â”‚   - Account management (owns bilateral relationships)
 *   â”‚   - J-batch accumulation (queue operations for on-chain)
 *   â””â”€ Why Entity-first?
 *       - Entities own accounts (not vice versa)
 *       - Entity = legal/organizational boundary
 *       - Account exists WITHIN entity context
 *
 * Account (A) - Bilateral consensus machines
 *   â”œâ”€ Contains: Per-token deltas (giant table, indexed by tokenId)
 *   â”œâ”€ Responsibilities:
 *   â”‚   - 2-of-2 signatures (both entities must agree)
 *   â”‚   - Frame-based consensus (propose â†’ sign â†’ commit)
 *   â”‚   - Delta transformations (payments, HTLCs, swaps)
 *   â”‚   - Credit limits (left/right perspective)
 *   â””â”€ Why Account-before-Jurisdiction?
 *       - Accounts are off-chain (high frequency)
 *       - J-layer is final settlement (low frequency)
 *       - Aâ†’J not Jâ†’A (accounts settle TO jurisdiction)
 *
 * Jurisdiction (J) - EVM settlement layer
 *   â”œâ”€ Contains: On-chain state (reserves, collaterals, EVM contracts)
 *   â”œâ”€ Responsibilities:
 *   â”‚   - Mempool (batches pending execution)
 *   â”‚   - Block processing (executes batches after blockDelayMs)
 *   â”‚   - FIFO debt enforcement (enforceDebts on reserve updates)
 *   â”‚   - Final truth (on-chain state root)
 *   â””â”€ Why Jurisdiction-last?
 *       - Slowest layer (block time delay)
 *       - Highest finality (on-chain proof)
 *       - Other layers settle TO it (terminal layer)
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * WHY Râ†’Eâ†’Aâ†’J (Not Jâ†’Eâ†’Aâ†’R or Eâ†’Aâ†’Jâ†’R)?
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * 1. CONTAINMENT HIERARCHY:
 *    Runtime contains {jReplicas, eReplicas}
 *    Entity contains {accounts}
 *    Account contains {deltas}
 *    Jurisdiction contains {reserves, collaterals}
 *
 * 2. EXECUTION FLOW MATCHES:
 *    User action â†’ Runtime.process()
 *                â†’ applyEntityInput (E-layer)
 *                  â†’ applyEntityTx (E-machine)
 *                    â†’ processAccountTx (A-machine)
 *                      â†’ jOutputs â†’ J-mempool
 *                        â†’ J-processor â†’ BrowserVM
 *
 * 3. MENTAL MODEL:
 *    "Runtime runs Entities which manage Accounts that settle via Jurisdictions"
 *    Not: "Jurisdictions run Entities..." (backwards)
 *    Not: "Entities run Runtime..." (inverted)
 *
 * 4. ALTERNATIVE ORDERS (Why They're Wrong):
 *    - Jâ†’Eâ†’Aâ†’R: Implies J contains E (wrong - E registers WITH J)
 *    - Eâ†’Aâ†’Jâ†’R: Implies R is innermost (wrong - R is outermost)
 *    - Aâ†’Eâ†’Jâ†’R: Implies A contains E (backwards!)
 *
 * Râ†’Eâ†’Aâ†’J is the NATURAL order: container â†’ contained â†’ contained â†’ terminal.
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * XLN MESSAGE FLOW: Runtime â†’ Entity â†’ Account â†’ Jurisdiction
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * 1. RuntimeInput (External trigger - 100ms tick or user action)
 *    â”œâ”€ runtimeTxs: RuntimeTx[]        // System commands (importReplica, etc.)
 *    â””â”€ entityInputs: EntityInput[]    // Messages to specific entities
 *
 * 2. EntityInput (BFT consensus at entity level)
 *    â”œâ”€ entityTxs: EntityTx[]          // State transitions (chat, payment, vote)
 *    â”œâ”€ precommits: Map<signerId, sig> // BFT signatures from validators
 *    â””â”€ proposedFrame: ProposedEntityFrame // Consensus proposal with merkle root
 *
 * 3. EntityTx (Entity state machine transitions)
 *    â”œâ”€ 'chat' | 'propose' | 'vote'    // Governance layer
 *    â”œâ”€ 'j_event'                      // Blockchain events (reserves, settlements)
 *    â”œâ”€ 'openAccount'                  // Create bilateral account
 *    â”œâ”€ 'directPayment'                // Multi-hop payment through accounts
 *    â””â”€ 'accountInput'                 // Process bilateral consensus message
 *
 * 4. AccountInput (Bilateral consensus between two entities)
 *    â”œâ”€ height: number                 // Which frame we're ACKing
 *    â”œâ”€ prevSignatures: string[]       // ACK their previous frame
 *    â”œâ”€ newAccountFrame: AccountFrame  // Our proposed frame
 *    â”œâ”€ newSignatures: string[]        // Signatures on new frame
 *    â””â”€ counter: number                // Replay protection (CRITICAL)
 *
 * 5. AccountFrame (Agreed bilateral state - like a block)
 *    â”œâ”€ height: number                 // Frame number in bilateral chain
 *    â”œâ”€ accountTxs: AccountTx[]        // State transitions this frame
 *    â”œâ”€ prevFrameHash: string          // Links to previous frame (blockchain)
 *    â”œâ”€ stateHash: string              // Merkle root of current state
 *    â”œâ”€ tokenIds: number[]             // Active tokens in this account
 *    â””â”€ deltas: bigint[]               // Per-token balances (signed integers)
 *
 * 6. AccountTx (Bilateral account state transitions)
 *    â”œâ”€ 'direct_payment'               // Update offdelta (instant settlement)
 *    â”œâ”€ 'add_delta'                    // Add new token to account
 *    â”œâ”€ 'set_credit_limit'             // Set mutual credit limits
 *    â”œâ”€ 'request_withdrawal'           // Phase 2: Câ†’R (collateral to reserve)
 *    â”œâ”€ 'approve_withdrawal'           // ACK/NACK withdrawal request
 *    â””â”€ 'reserve_to_collateral'        // Phase 1: Râ†’C (from j_event)
 *
 * 7. Delta (Per-token bilateral state - the money)
 *    â”œâ”€ collateral: bigint             // Escrowed on-chain funds
 *    â”œâ”€ ondelta: bigint                // On-chain balance delta
 *    â”œâ”€ offdelta: bigint               // Off-chain balance delta (instant)
 *    â”œâ”€ leftCreditLimit: bigint        // Credit extended by left entity
 *    â”œâ”€ rightCreditLimit: bigint       // Credit extended by right entity
 *    â”œâ”€ leftAllowance: bigint          // Left entity's remaining credit
 *    â””â”€ rightAllowance: bigint         // Right entity's remaining credit
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * CONSENSUS GUARANTEES (Byzantine Fault Tolerance)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * Entity Level (BFT):
 *   - Proposer rotates deterministically
 *   - Threshold signatures (t of n validators must sign)
 *   - Precommit-lock prevents double-signing
 *   - Safety: Never finalize conflicting states
 *   - Liveness: Progress if >threshold validators honest
 *
 * Account Level (Bilateral):
 *   - Both sides must sign every frame (2-of-2 consensus)
 *   - Counter prevents replay attacks
 *   - prevSignatures ACK prevents forks
 *   - State hash ensures deterministic state computation
 *   - Dispute resolution via on-chain proof submission
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * EXAMPLE FLOW: Alice pays Bob 100 USDC
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * Step 1: Alice's UI creates RuntimeInput
 *   runtimeInput = {
 *     runtimeTxs: [],
 *     entityInputs: [{
 *       entityId: "Alice",
 *       entityTxs: [{
 *         type: 'directPayment',
 *         data: { targetEntityId: "Bob", tokenId: 1, amount: 100n }
 *       }]
 *     }]
 *   }
 *
 * Step 2: Alice's entity processes payment (entity-consensus.ts)
 *   - Validates Alice has account with Bob
 *   - Creates AccountInput to send to Bob
 *   - Updates Alice's AccountMachine.mempool
 *
 * Step 3: Bob receives AccountInput (account-consensus.ts)
 *   - Validates counter, prevSignatures
 *   - Applies payment tx: Bob.offdelta += 100n, Alice.offdelta -= 100n
 *   - Creates AccountFrame with new state
 *   - Signs frame, sends back to Alice
 *
 * Step 4: Alice receives Bob's signature
 *   - Both sides now have 2-of-2 signed frame
 *   - Payment is FINAL (instant finality)
 *   - No on-chain tx needed (pure off-chain)
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * NAMING CONVENTIONS
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * Consistent terminology prevents confusion when reading/debugging code:
 *
 * **height** (NOT frameId):
 *   - Used everywhere: EntityFrame.height, AccountFrame.height, ServerFrame.height
 *   - Consistent with blockchain terminology (block height)
 *   - Old code used "frameId" but we migrated to "height" for S/E/A consistency
 *
 * **tx** (NOT transition):
 *   - EntityTx, AccountTx, RuntimeTx (transaction = state change request)
 *   - Used for actual state modifications
 *
 * **transition** (NOT tx):
 *   - ackedTransitions, sentTransitions (counter = message sequence number)
 *   - Used for replay protection counters, NOT transaction counts
 *   - Counts message exchanges, not individual transactions
 *   - Example: One message can contain multiple AccountTxs, but only increments counter by 1
 *
 * **counter** (for replay protection):
 *   - AccountInput.counter (sequential message counter, starts at 1)
 *   - CRITICAL: Must be exactly ackedTransitions + 1 (no gaps allowed)
 *   - Different from "transitions" which tracks confirmed message count
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

import type { Profile } from './gossip.js';

export interface JurisdictionConfig {
  address: string;
  name: string;
  entityProviderAddress: string;
  depositoryAddress: string;
  chainId?: number;
}

export interface ConsensusConfig {
  mode: 'proposer-based' | 'gossip-based';
  threshold: bigint;
  validators: string[];
  shares: { [validatorId: string]: bigint };
  jurisdiction?: JurisdictionConfig;
}

export interface RuntimeInput {
  runtimeTxs: RuntimeTx[];
  entityInputs: EntityInput[];
  jInputs?: JInput[]; // J-layer inputs (queue to J-mempool)
}

/** J-layer input - queues JTx to jurisdiction mempool */
export interface JInput {
  jurisdictionName: string; // Which J-machine to queue to
  jTxs: JTx[]; // Transactions to queue
}

export type RuntimeTx =
  | {
      type: 'importReplica';
      entityId: string;
      signerId: string;
      data: {
        config: ConsensusConfig;
        isProposer: boolean;
        position?: { x: number; y: number; z: number };
      };
    }
  | {
      type: 'createXlnomy';
      data: {
        name: string;
        evmType: 'browservm' | 'reth' | 'erigon' | 'monad';
        rpcUrl?: string; // If evmType === RPC-based
        blockTimeMs?: number; // Default: 1000ms
        autoGrid?: boolean; // Auto-create 2x2x2 grid with $1M reserves
      };
    };

export interface EntityInput {
  entityId: string;
  signerId: string;
  entityTxs?: EntityTx[];
  precommits?: Map<string, string>; // signerId -> signature
  proposedFrame?: ProposedEntityFrame;
}

/** Entity output - can include both Eâ†’E messages AND J-layer outputs */
export interface EntityOutput {
  entityInputs: EntityInput[];  // Eâ†’E messages
  jInputs: JInput[];             // Eâ†’J messages (batches to queue)
}

export interface Proposal {
  id: string; // hash of the proposal
  proposer: string;
  action: ProposalAction;
  // Votes: signerId â†’ vote (string for simple votes, object for commented votes)
  // Future: Create VoteData interface for type-safe vote objects
  votes: Map<string, 'yes' | 'no' | 'abstain' | { choice: 'yes' | 'no' | 'abstain'; comment: string }>;
  status: 'pending' | 'executed' | 'rejected';
  created: number; // entity timestamp when proposal was created (deterministic)
}

export interface ProposalAction {
  type: 'collective_message';
  data: {
    message: string;
  };
}

export interface VoteData {
  proposalId: string;
  voter: string;
  choice: 'yes' | 'no' | 'abstain';
  comment?: string;
}

/**
 * Common metadata for all J-events (for JBlock tracking)
 */
interface JEventMetadata {
  blockNumber?: number;      // J-block number where event occurred
  blockHash?: string;        // J-block hash for consensus
  transactionHash?: string;  // On-chain transaction hash
}

/**
 * Jurisdiction event types - discriminated union for type safety
 * Each on-chain event has its own typed data structure
 */
export type JurisdictionEvent =
  | (JEventMetadata & {
      type: 'ReserveUpdated';
      data: {
        entity: string;
        tokenId: number;
        newBalance: string;
        symbol?: string;   // Optional - BrowserVM doesn't have token registry
        decimals?: number; // Optional - use TOKEN_REGISTRY lookup if missing
      };
    })
  | (JEventMetadata & {
      type: 'SecretRevealed';
      data: {
        hashlock: string;
        revealer: string;
        secret: string;
      };
    })
  | (JEventMetadata & {
      type: 'AccountSettled';
      data: {
        leftEntity: string;
        rightEntity: string;
        counterpartyEntityId: string;
        tokenId: number;
        ownReserve: string;
        counterpartyReserve: string;
        collateral: string;
        ondelta: string;
        side: 'left' | 'right';
      };
    })
  | (JEventMetadata & {
      type: 'InsuranceClaimed';
      data: {
        entityId: string;
        counterpartyId: string;
        tokenId: number;
        amount: string;
        claimReason: string;
      };
    })
  | (JEventMetadata & {
      type: 'GovernanceEnabled';
      data: {
        entityId: string;
        proposalThreshold: number;
      };
    });

/**
 * Jurisdiction event data for j_event transactions
 * Now with typed event discriminated union and JBlock consensus info
 */
export interface JurisdictionEventData {
  from: string;
  event: JurisdictionEvent;
  events?: JurisdictionEvent[]; // Batched events from same block
  observedAt: number;
  blockNumber: number;
  blockHash: string;  // Block hash for JBlock consensus
  transactionHash: string;
}

export interface AccountTxInput {
  fromEntityId: string;
  toEntityId: string;
  accountTx: AccountTx; // The actual account transaction to process
  metadata?: {
    purpose?: string;
    description?: string;
  };
}

export type EntityTx =
  | {
      type: 'chat';
      data: { from: string; message: string };
    }
  | {
      type: 'chatMessage';
      data: {
        message: string;
        timestamp: number;
        metadata?: {
          type: string;
          counterpartyId?: string;
          height?: number;
          frameAge?: number;
          tokenId?: number;
          rebalanceAmount?: string;
          [key: string]: any; // Allow additional rebalance metadata
        };
      };
    }
  | {
      type: 'propose';
      data: { action: ProposalAction; proposer: string };
    }
  | {
      type: 'vote';
      data: { proposalId: string; voter: string; choice: 'yes' | 'no'; comment?: string };
    }
  | {
      type: 'profile-update';
      data: { profile: any }; // replace with concrete profile type if available
    }
  | {
      type: 'j_event';
      data: JurisdictionEventData;
    }
  | {
      type: 'accountInput';
      data: AccountInput;
    }
  | {
      type: 'openAccount';
      data: { targetEntityId: string };
    }
  | {
      type: 'j_event_account_claim';
      data: {
        counterpartyEntityId: string; // Which account this observation is for
        jHeight: number;
        jBlockHash: string;
        events: any[];
        observedAt: number;
      };
    }
  | {
      type: 'directPayment';
      data: {
        targetEntityId: string;
        tokenId: number;
        amount: bigint;
        route: string[]; // Full path from source to target
        description?: string;
      };
    }
  | {
      type: 'htlcPayment';
      data: {
        targetEntityId: string;
        tokenId: number;
        amount: bigint;
        route: string[]; // Full path from source to target
        description?: string;
        secret?: string;   // Optional - generated if not provided
        hashlock?: string; // Optional - generated if not provided
      };
    }
  | {
      type: 'requestWithdrawal';
      data: {
        counterpartyEntityId: string;
        tokenId: number;
        amount: bigint;
      };
    }
  | {
      type: 'settleDiffs';
      data: {
        counterpartyEntityId: string;
        diffs: Array<{
          tokenId: number;
          leftDiff: bigint;   // Positive = credit, Negative = debit
          rightDiff: bigint;
          collateralDiff: bigint;
          ondeltaDiff: bigint;
        }>;
        sig: string; // Hanko signature from counterparty
        description?: string; // e.g., "Fund collateral from reserve"
      };
    }
  | {
      type: 'disputeStart';
      data: {
        counterpartyEntityId: string;
        description?: string;
      };
    }
  | {
      type: 'disputeFinalize';
      data: {
        counterpartyEntityId: string;
        cooperative?: boolean;  // If true, use cooperative finalization
        useOnchainRegistry?: boolean; // Optional HTLC reveal via on-chain registry
        description?: string;
      };
    }
  | {
      type: 'deposit_collateral';
      data: {
        counterpartyId: string; // Which account to add collateral to
        tokenId: number;
        amount: bigint;
      };
    }
  | {
      // Reserve-to-reserve: Entity moves reserves to another entity (accumulates in jBatch)
      type: 'reserve_to_reserve';
      data: {
        toEntityId: string; // Recipient entity
        tokenId: number;
        amount: bigint;
      };
    }
  | {
      // J-Broadcast: Entity broadcasts accumulated jBatch to J-machine
      type: 'j_broadcast';
      data: {
        hankoSignature?: string; // Optional hanko seal for the batch
      };
    }
  | {
      // Extend credit to a counterparty in bilateral account
      type: 'extendCredit';
      data: {
        counterpartyEntityId: string;
        tokenId: number;
        amount: bigint;
      };
    }
  | {
      // Place swap offer in bilateral account (user â†’ hub)
      type: 'placeSwapOffer';
      data: {
        counterpartyEntityId: string; // Hub
        offerId: string;
        giveTokenId: number;
        giveAmount: bigint;
        wantTokenId: number;
        wantAmount: bigint;
        minFillRatio: number; // 0-65535
      };
    }
  | {
      // Resolve swap offer in bilateral account (hub â†’ user)
      type: 'resolveSwap';
      data: {
        counterpartyEntityId: string; // User who placed the offer
        offerId: string;
        fillRatio: number; // 0-65535
        cancelRemainder: boolean;
      };
    }
  | {
      // Cancel swap offer (user cancels their own offer)
      type: 'cancelSwap';
      data: {
        counterpartyEntityId: string;
        offerId: string;
      };
    }
  | {
      // Initialize orderbook extension (hub only)
      type: 'initOrderbookExt';
      data: {
        name: string;
        spreadDistribution: {
          makerBps: number;
          takerBps: number;
          hubBps: number;
          makerReferrerBps: number;
          takerReferrerBps: number;
        };
        referenceTokenId: number;
        minTradeSize: bigint;
        supportedPairs: string[];
      };
    }
  | {
      // Mint reserves (admin/test only - creates reserves via J-layer)
      type: 'mintReserves';
      data: {
        tokenId: number;
        amount: bigint;
      };
    }
  | {
      // Create settlement batch (builds settlement in jBatch)
      type: 'createSettlement';
      data: {
        counterpartyEntityId: string;
        diffs: Array<{
          tokenId: number;
          leftDiff: bigint;
          rightDiff: bigint;
          collateralDiff: bigint;
          ondeltaDiff: bigint;
        }>;
        sig: string; // Hanko signature from counterparty (required for cooperative settlement)
      };
    };

export interface AssetBalance {
  amount: bigint; // Balance in smallest unit (wei, cents, shares)
  // Note: symbol, decimals, contractAddress come from token registry, not stored here
}

// Account machine structures for signed and collateralized accounts between entities
export interface AccountDelta {
  tokenId: number;
  delta: bigint; // Positive = we owe them, Negative = they owe us
}

// Simple account state snapshot (for currentFrame)
export interface AccountSnapshot {
  height: number; // Renamed from frameId for S/E/A consistency
  timestamp: number;
  tokenIds: number[]; // Array of token IDs in this account
  deltas: bigint[]; // Array of deltas corresponding to tokenIds
  stateHash?: string; // Optional hash for cryptographic verification
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// HTLC (Hash Time-Locked Contracts)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * HTLC Lock - Conditional payment held until secret reveal or timeout
 * Reference: 2024 StoredSubcontract (ChannelState.ts:4-11)
 */
export interface HtlcLock {
  lockId: string;              // keccak256(hash + height + nonce)
  hashlock: string;            // keccak256(abi.encode(secret)) - 32 bytes hex
  timelock: bigint;            // Expiry timestamp (unix-ms)
  revealBeforeHeight: number;  // J-block height deadline (enforced on-chain)
  amount: bigint;              // Locked amount
  tokenId: number;             // Token being locked
  senderIsLeft: boolean;       // Who initiated (canonical direction)
  createdHeight: number;       // AccountFrame height when created
  createdTimestamp: number;    // When lock was added (for logging)

  // Onion routing envelope (cleartext JSON in Phase 2, encrypted in Phase 3)
  envelope?: import('./htlc-envelope-types').HtlcEnvelope;
}

// Swap offer (limit order) in bilateral account
export interface SwapOffer {
  offerId: string;              // UUID for this offer
  giveTokenId: number;          // Token maker is giving
  giveAmount: bigint;           // Original amount (partial fills reduce this)
  wantTokenId: number;          // Token maker wants in return
  wantAmount: bigint;           // Corresponding want amount (maintains ratio)
  minFillRatio: number;         // 0-65535, minimum acceptable fill
  makerIsLeft: boolean;         // Who created this offer (canonical direction)
  createdHeight: number;        // AccountFrame height when created
  // Quantized amounts for orderbook consistency (set by hub when adding to book)
  // These ensure fill ratios computed from lots match settlement amounts exactly
  quantizedGive?: bigint;       // giveAmount rounded to LOT_SCALE multiple
  quantizedWant?: bigint;       // wantAmount scaled proportionally
}

/**
 * HTLC Routing Context (replaces 2024 User.hashlockMap)
 * Tracks inbound/outbound hops for automatic secret propagation
 */
export interface HtlcRoute {
  hashlock: string;

  // Inbound hop (who sent us this HTLC)
  inboundEntity?: string;
  inboundLockId?: string;

  // Outbound hop (who we forwarded to)
  outboundEntity?: string;
  outboundLockId?: string;

  // Resolution
  secret?: string;
  pendingFee?: bigint; // Fee to accrue on successful reveal (not on forward)
  createdTimestamp: number;
}

export interface AccountMachine {
  // CANONICAL REPRESENTATION (like Channel.ts - both entities store IDENTICAL structure)
  leftEntity: string;   // Lower entity ID (canonical left)
  rightEntity: string;  // Higher entity ID (canonical right)

  mempool: AccountTx[]; // Unprocessed account transactions
  currentFrame: AccountFrame; // Current agreed state (includes full transaction history for replay/audit)
  sentTransitions: number; // Number of transitions sent but not yet confirmed
  ackedTransitions: number; // Number of transitions acknowledged by counterparty

  // Per-token delta states (giant per-token table like old_src)
  deltas: Map<number, Delta>; // tokenId -> Delta

  // HTLC state (conditional payments)
  locks: Map<string, HtlcLock>; // lockId â†’ lock details

  // Swap offers (limit orders)
  swapOffers: Map<string, SwapOffer>; // offerId â†’ offer details

  // Global credit limits (in reference currency - USDC)
  globalCreditLimits: {
    ownLimit: bigint; // How much credit we extend to counterparty (USD)
    peerLimit: bigint; // How much credit counterparty extends to us (USD)
  };

  // Frame-based consensus (like old_src Channel, consistent with entity frames)
  currentHeight: number; // Renamed from currentFrameId for S/E/A consistency
  pendingFrame?: AccountFrame;
  pendingSignatures: string[];

  // Rollback support for bilateral disagreements
  rollbackCount: number;
  lastRollbackFrameHash?: string; // Track last rollback to prevent duplicate increments

  // Bilateral J-event consensus (2-of-2 agreement on jurisdiction events)
  leftJObservations: Array<{ jHeight: number; jBlockHash: string; events: any[]; observedAt: number }>;
  rightJObservations: Array<{ jHeight: number; jBlockHash: string; events: any[]; observedAt: number }>;
  jEventChain: Array<{ jHeight: number; jBlockHash: string; events: any[]; finalizedAt: number }>;
  lastFinalizedJHeight: number;

  // CHANNEL.TS REFERENCE: Proper message counters (NOT timestamps!)
  sendCounter: number;    // Incremented for each outgoing message
  receiveCounter: number; // Incremented for each incoming message
  // Removed isProposer - use isLeft() function like old_src Channel.ts instead

  // Cloned state for validation before committing (replaces dryRun)
  clonedForValidation?: AccountMachine;

  // Proof structures for dispute resolution
  proofHeader: {
    fromEntity: string; // Our entity ID
    toEntity: string; // Counterparty entity ID
    cooperativeNonce: number;
    disputeNonce: number;
  };
  // Simple proofBody for internal use (computed on demand from deltas/locks/swapOffers)
  proofBody: {
    tokenIds: number[];
    deltas: bigint[];
    // HTLC transformers (like 2024 subcontracts - sorted by deltaIndex)
    htlcLocks?: Array<{
      deltaIndex: number;       // Index in tokenIds array
      amount: bigint;
      revealedUntilBlock: number; // revealBeforeHeight
      hash: string;             // hashlock
    }>;
  };
  // ABI-encoded proofBody for on-chain disputes (built by proof-builder.ts)
  abiProofBody?: {
    encodedProofBody: string;   // ABI-encoded bytes for contract call
    proofBodyHash: string;      // keccak256(encodedProofBody) - signed for disputes
    lastUpdatedHeight: number;  // Frame height when last computed
  };
  // Dispute configuration (per-side delay settings)
  disputeConfig: {
    leftDisputeDelay: number;   // uint16 - value * 10 = blocks
    rightDisputeDelay: number;  // uint16 - value * 10 = blocks
  };
  // HANKO SYSTEM: Frame consensus + Dispute proofs
  currentFrameHanko?: HankoString;           // My hanko on current frame (bilateral consensus)
  counterpartyFrameHanko?: HankoString;      // Their hanko on current frame (bilateral consensus)

  currentDisputeProofHanko?: HankoString;              // My hanko on dispute proof (for J-machine enforcement)
  currentDisputeProofCooperativeNonce?: number;        // Cooperative nonce used in currentDisputeProofHanko
  currentDisputeProofBodyHash?: string;                // ProofBodyHash used in currentDisputeProofHanko
  counterpartyDisputeProofHanko?: HankoString;         // Their hanko on dispute proof (ready for disputes)
  counterpartyDisputeProofCooperativeNonce?: number;   // Cooperative nonce used in counterpartyDisputeProofHanko
  counterpartyDisputeProofBodyHash?: string;           // ProofBodyHash that counterparty signed (MUST match dispute)
  disputeProofNoncesByHash?: Record<string, number>;   // ProofBodyHash â†’ cooperative nonce (local + counterparty)
  disputeProofBodiesByHash?: Record<string, any>;      // ProofBodyHash â†’ ProofBodyStruct (for dispute finalize)

  // SETTLEMENT HANKO: Cooperative state updates (for j-batch settlements)
  currentSettlementHanko?: HankoString;
  currentSettlementDiffs?: Array<{
    tokenId: number;
    leftDiff: bigint;
    rightDiff: bigint;
    collateralDiff: bigint;
    ondeltaDiff: bigint;
  }>;
  counterpartySettlementHanko?: HankoString;
  counterpartySettlementDiffs?: Array<{
    tokenId: number;
    leftDiff: bigint;
    rightDiff: bigint;
    collateralDiff: bigint;
    ondeltaDiff: bigint;
  }>;

  // Active dispute state (set after disputeStart, needed for disputeFinalize)
  activeDispute?: {
    startedByLeft: boolean;           // Who initiated dispute (from on-chain)
    initialProofbodyHash: string;     // Hash committed in disputeStart
    initialDisputeNonce: number;      // Dispute nonce from disputeStart
    disputeTimeout: number;           // Block number when timeout expires
    initialCooperativeNonce: number;  // Cooperative nonce PASSED to disputeStart (for hash match)
    onChainCooperativeNonce: number;  // On-chain nonce (may differ from initial)
    initialArguments?: string;        // On-chain initialArguments from disputeStart
  };

  hankoSignature?: string; // LEGACY - will be removed

  // Historical frame log - grows until manually pruned by entity
  frameHistory: AccountFrame[]; // All confirmed bilateral frames in chronological order

  // Payment routing: temporary storage for multi-hop payments
  pendingForward?: {
    tokenId: number;
    amount: bigint;
    route: string[];
    description?: string;
  };

  // Withdrawal tracking (Phase 2: Câ†’R)
  pendingWithdrawals: Map<string, {
    requestId: string;
    tokenId: number;
    amount: bigint;
    requestedAt: number; // Timestamp
    direction: 'outgoing' | 'incoming'; // Did we request, or did they?
    status: 'pending' | 'approved' | 'rejected' | 'timed_out';
    signature?: string; // If approved
  }>;

  // Rebalancing hints (Phase 3: Hub coordination)
  requestedRebalance: Map<number, bigint>; // tokenId â†’ amount entity wants rebalanced (creditâ†’collateral)
}

// Account frame structure for bilateral consensus (renamed from AccountBlock)
export interface AccountFrame {
  height: number; // Renamed from frameId for S/E/A consistency
  timestamp: number;
  jHeight: number; // J-machine height agreed for HTLC deadline checks
  accountTxs: AccountTx[]; // Renamed from transitions
  prevFrameHash: string; // Hash of previous frame (creates chain linkage, not state linkage)
  stateHash: string;
  byLeft?: boolean; // Who proposed this frame (left or right entity)
  tokenIds: number[]; // Array of token IDs in this frame
  deltas: bigint[]; // Array of deltas corresponding to tokenIds (ondelta+offdelta for quick access)
  fullDeltaStates?: Delta[]; // OPTIONAL: Full delta objects (includes credit limits, allowances, collateral)
}

// AccountInput - Maps 1:1 to Channel.ts FlushMessage (frame-level consensus ONLY)
export interface AccountInput {
  fromEntityId: string;
  toEntityId: string;

  // Frame-level consensus (matches Channel.ts FlushMessage structure)
  height?: number;                   // Which frame we're ACKing or referencing (renamed from frameId)

  // HANKO SYSTEM:
  prevHanko?: HankoString;                // ACK hanko for their frame
  newAccountFrame?: AccountFrame;         // Our new proposed frame (like block in Channel.ts)
  newHanko?: HankoString;                 // Hanko on newAccountFrame
  newDisputeHanko?: HankoString;          // Hanko on dispute proof (for J-machine enforcement)
  newDisputeProofBodyHash?: string;       // ProofBodyHash that newDisputeHanko signs
  newSettlementHanko?: HankoString;
  newSettlementDiffs?: Array<{
    tokenId: number;
    leftDiff: bigint;
    rightDiff: bigint;
    collateralDiff: bigint;
    ondeltaDiff: bigint;
  }>;

  // LEGACY (will be removed):
  prevSignatures?: string[];         // ACK for their frame (LEGACY)
  newSignatures?: string[];          // Signatures on new frame (LEGACY)

  counter?: number;                  // Message counter for replay protection (like Channel.ts line 620)
}

// Delta structure for per-token account state (based on old_src)
export interface Delta {
  tokenId: number;
  collateral: bigint;
  ondelta: bigint; // On-chain delta
  offdelta: bigint; // Off-chain delta
  leftCreditLimit: bigint;
  rightCreditLimit: bigint;
  leftAllowance: bigint;
  rightAllowance: bigint;

  // HTLC holds (capacity locked in pending HTLCs)
  leftHtlcHold?: bigint;  // Left's outgoing HTLC holds
  rightHtlcHold?: bigint; // Right's outgoing HTLC holds

  // Swap holds (capacity locked in pending swap offers)
  leftSwapHold?: bigint;  // Left's locked swap offer amounts
  rightSwapHold?: bigint; // Right's locked swap offer amounts
}

// Derived account balance information per token
export interface DerivedDelta {
  delta: bigint;
  collateral: bigint;
  inCollateral: bigint;
  outCollateral: bigint;
  inOwnCredit: bigint;
  outPeerCredit: bigint;
  inAllowance: bigint;
  outAllowance: bigint;
  totalCapacity: bigint;
  ownCreditLimit: bigint;
  peerCreditLimit: bigint;
  inCapacity: bigint;
  outCapacity: bigint;
  outOwnCredit: bigint;
  inPeerCredit: bigint;
  ascii: string; // ASCII visualization from deriveDelta (like old_src)
}

/**
 * Account Events - Bubbled up from A-layer to E-layer
 * Used for routing (HTLC secrets) and matching (swap offers)
 */
export type AccountEvent =
  | { type: 'htlc_revealed'; hashlock: string; secret: string }
  | { type: 'swap_offer_created'; offerId: string; makerId: string; accountId: string; giveTokenId: number; giveAmount: bigint; wantTokenId: number; wantAmount: bigint; minFillRatio: number }
  | { type: 'swap_offer_cancelled'; offerId: string; accountId: string };

// Account transaction types
export type AccountTx =
  | { type: 'account_payment'; data: { tokenId: number; amount: bigint } }
  | { type: 'direct_payment'; data: { tokenId: number; amount: bigint; route?: string[]; description?: string; fromEntityId?: string; toEntityId?: string } }
  | { type: 'add_delta'; data: { tokenId: number } }
  | { type: 'set_credit_limit'; data: { tokenId: number; amount: bigint; side: 'left' | 'right' } }
  | { type: 'account_frame'; data: { frame: AccountFrame; processedTransactions: number; fromEntity: string } }
  | {
      type: 'account_settle';
      data: {
        tokenId: number;
        ownReserve: string;
        counterpartyReserve: string;
        collateral: string;
        ondelta: string;
        side: 'left' | 'right';
        blockNumber: number;
        transactionHash: string;
      };
    }
  | {
      type: 'reserve_to_collateral';
      data: {
        tokenId: number;
        collateral: string; // Absolute collateral value from contract
        ondelta: string;    // Absolute ondelta value from contract
        side: 'receiving' | 'counterparty';
        blockNumber: number;
        transactionHash: string;
      };
    }
  | {
      type: 'request_withdrawal';
      data: {
        tokenId: number;
        amount: bigint;
        requestId: string; // Unique ID for matching ACK/NACK
      };
    }
  | {
      type: 'approve_withdrawal';
      data: {
        tokenId: number;
        amount: bigint;
        requestId: string; // Matches request_withdrawal.requestId
        approved: boolean; // true = ACK, false = NACK
        signature?: string; // If approved: signature for on-chain submission
      };
    }
  | {
      type: 'request_rebalance';
      data: {
        tokenId: number;
        amount: bigint; // How much collateral requested for insurance
      };
    }
  // === HTLC TRANSACTION TYPES ===
  | {
      type: 'htlc_lock';
      data: {
        lockId: string;
        hashlock: string;
        timelock: bigint;
        revealBeforeHeight: number;
        amount: bigint;
        tokenId: number;
        envelope?: import('./htlc-envelope-types').HtlcEnvelope; // Onion routing envelope
      };
    }
  | {
      type: 'htlc_reveal';
      data: {
        lockId: string;
        secret: string;
      };
    }
  | {
      type: 'htlc_timeout';
      data: {
        lockId: string;
      };
    }
  // === SWAP TRANSACTION TYPES ===
  | {
      type: 'swap_offer';
      data: {
        offerId: string;          // UUID, not array index
        giveTokenId: number;
        giveAmount: bigint;
        wantTokenId: number;
        wantAmount: bigint;       // at this ratio
        minFillRatio: number;     // 0-65535 (uint16), minimum partial fill
      };
    }
  | {
      type: 'swap_cancel';
      data: {
        offerId: string;
      };
    }
  | {
      type: 'swap_resolve';
      data: {
        offerId: string;
        fillRatio: number;        // 0-65535 (uint16)
        cancelRemainder: boolean; // true = fill + cancel, false = fill + keep open
      };
    }
  | {
      type: 'j_sync';
      data: {
        jBlockNumber: number;  // Block number from j-machine (both sides must match)
        tokenId: number;
        collateral: bigint;    // Absolute collateral from j-event
        ondelta: bigint;       // Absolute ondelta from j-event
      };
    };

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// J-BLOCK CONSENSUS (Multi-signer agreement on J-machine state)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// Each signer independently observes J-machine blocks and submits observations.
// Entity finalizes a JBlock when threshold signers agree on (jHeight, jBlockHash).
// This ensures Byzantine-tolerant J-machine state tracking without extra signatures.
//
// Flow:
// 1. Signer observes J-block N with events relevant to entity
// 2. Signer submits JBlockObservation as EntityTx
// 3. Entity collects observations from all signers
// 4. When threshold agree on same (jHeight, jBlockHash) â†’ finalize
// 5. Apply events from finalized JBlock to entity state
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Observation of a J-block by a single signer.
 * Submitted as j_event EntityTx, aggregated by entity consensus.
 */
export interface JBlockObservation {
  signerId: string;              // Who observed this
  jHeight: number;               // J-machine block number
  jBlockHash: string;            // EVM block hash (or BrowserVM frame hash)
  events: JurisdictionEvent[];   // Events relevant to this entity in this block
  observedAt: number;            // When signer observed this (for timeout detection)
}

/**
 * Finalized J-block after threshold agreement.
 * Events from this block can be safely applied to entity state.
 */
export interface JBlockFinalized {
  jHeight: number;
  jBlockHash: string;
  events: JurisdictionEvent[];
  finalizedAt: number;           // When consensus was reached
  signerCount: number;           // How many signers agreed (for audit)
}

/**
 * Liveness sync - empty block observation to prove chain is alive.
 * Required every JBLOCK_LIVENESS_INTERVAL blocks even if no events.
 */
export const JBLOCK_LIVENESS_INTERVAL = 100;

export interface EntityState {
  entityId: string; // The entity ID this state belongs to
  height: number;
  timestamp: number;
  nonces: Map<string, number>;
  messages: string[];
  proposals: Map<string, Proposal>;
  config: ConsensusConfig;

  // ðŸ’° Financial state
  reserves: Map<string, bigint>; // tokenId -> amount only, metadata from TOKEN_REGISTRY
  accounts: Map<string, AccountMachine>; // canonicalKey "left:right" -> account state
  // Account frame scheduling (accounts blocked by pendingFrame, retried on next ACK)
  deferredAccountProposals?: Map<string, true>;
  // ðŸ”­ J-machine tracking (JBlock consensus)
  lastFinalizedJHeight: number;           // Last finalized J-block height
  jBlockObservations: JBlockObservation[]; // Pending observations from signers
  jBlockChain: JBlockFinalized[];          // Finalized J-blocks (prunable)

  // ðŸ”— Account machine integration
  accountInputQueue?: AccountInput[]; // Queue of settlement events to be processed by a-machine

  // â° Crontab system - periodic task execution (typed in entity-crontab.ts)
  crontabState?: any; // CrontabState - avoid circular import

  // ðŸ“¦ J-Batch system - accumulates operations for on-chain submission (typed in j-batch.ts)
  jBatchState?: any; // JBatchState - avoid circular import

  // ðŸ›¡ï¸ Insurance - coverage lines from insurers
  insuranceLines?: Array<{
    insurer: string;
    tokenId: number;
    remaining: bigint;
    expiresAt: bigint;
  }>;

  // ðŸ” Cryptography - RSA-OAEP keys for HTLC envelope encryption
  cryptoPublicKey?: string;  // Base64 RSA-OAEP public key (shareable)
  cryptoPrivateKey?: string; // Base64 RSA-OAEP private key (secret, encrypt at rest in prod)

  // ðŸ”’ HTLC Routing - Multi-hop payment tracking (like 2024 hashlockMap)
  htlcRoutes: Map<string, HtlcRoute>; // hashlock â†’ routing context
  htlcFeesEarned: bigint; // Running total of HTLC routing fees collected

  // ðŸ’³ Debts - amounts owed to creditors (from FIFO queue)
  debts?: Array<{
    creditor: string;
    tokenId: number;
    amount: bigint;
    index: number;
  }>;

  // ðŸ“Š Orderbook Extension - Hub matching engine (typed in orderbook/types.ts)
  orderbookExt?: any; // OrderbookExtState - avoid circular import

  // ðŸ“– Aggregated Books - E-Machine view of all A-Machine positions
  // Mirrors A-Machine state for easy UI access, updated on frame commits
  swapBook: Map<string, SwapBookEntry>;  // offerId â†’ entry
  lockBook: Map<string, LockBookEntry>;  // lockId â†’ entry

  // ðŸ“ˆ Pending swap fill ratios (orderbook â†’ dispute arguments)
  pendingSwapFillRatios?: Map<string, number>; // key = "accountId:offerId"
}

/** Aggregated swap order entry at E-Machine level */
export interface SwapBookEntry {
  offerId: string;
  accountId: string;        // counterparty entity ID where order lives
  giveTokenId: number;
  giveAmount: bigint;       // remaining amount
  wantTokenId: number;
  wantAmount: bigint;       // remaining want
  minFillRatio: number;
  createdAt: bigint;
}

/** Aggregated HTLC lock entry at E-Machine level */
export interface LockBookEntry {
  lockId: string;
  accountId: string;        // counterparty entity ID where lock lives
  tokenId: number;
  amount: bigint;
  hashlock: string;
  timelock: bigint;
  direction: 'outgoing' | 'incoming';
  createdAt: bigint;
}

export interface ProposedEntityFrame {
  height: number;
  txs: EntityTx[];
  hash: string;
  newState: EntityState;

  // NEW HANKO SYSTEM:
  hashes?: string[];         // Sorted lexicographically - all objects signed in this frame
  signatures?: string[][];   // [validator_i][hash_j] - partial sigs during collection
  hankos?: HankoString[];    // After merge: one HankoBytes per hash (hex-encoded ABI)

  // LEGACY (will be removed after hanko migration):
  signatures_legacy?: Map<string, string>; // signerId -> signature (old system)
}

export interface EntityReplica {
  entityId: string;
  signerId: string;
  state: EntityState;
  mempool: EntityTx[];
  proposal?: ProposedEntityFrame;
  lockedFrame?: ProposedEntityFrame; // Frame this validator is locked/precommitted to
  isProposer: boolean;
  sentTransitions?: number; // Number of txs sent to proposer but not yet committed (Channel.ts pattern)
  // Position is RELATIVE to j-machine (jurisdiction)
  // Frontend calculates: worldPos = jMachine.position + relativePosition
  position?: {
    x: number;      // Relative X offset from j-machine center
    y: number;      // Relative Y offset from j-machine center
    z: number;      // Relative Z offset from j-machine center
    jurisdiction?: string; // Which j-machine this entity belongs to (defaults to activeJurisdiction)
    xlnomy?: string; // DEPRECATED: Use jurisdiction instead
  };
}

// =============================================================================
// STRUCTURED LOGGING SYSTEM
// =============================================================================

/** Log severity levels - ordered by priority */
export type LogLevel = 'trace' | 'debug' | 'info' | 'warn' | 'error';

/** Log categories for filtering */
export type LogCategory =
  | 'consensus'     // BFT entity consensus
  | 'account'       // Bilateral account consensus
  | 'jurisdiction'  // J-machine events
  | 'evm'           // Blockchain interactions
  | 'network'       // Routing/messaging
  | 'ui'            // UI events
  | 'system';       // System-level

/** Single log entry attached to a frame */
export interface FrameLogEntry {
  id: number;
  timestamp: number;
  level: LogLevel;
  category: LogCategory;
  message: string;
  entityId?: string;              // Associated entity (if applicable)
  data?: Record<string, unknown>; // Structured data
}

export interface BrowserVMState {
  stateRoot: string;
  trieData: Array<[string, string]>;
  nonce: string;
  addresses: { depository: string; entityProvider: string };
}

export interface Env {
  eReplicas: Map<string, EntityReplica>;  // Entity replicas (E-layer state machines)
  jReplicas: Map<string, JReplica>;       // Jurisdiction replicas (J-layer EVM state)
  height: number;
  timestamp: number;
  runtimeSeed?: string; // BrainVault seed backing this runtime (plaintext, dev mode)
  runtimeId?: string; // Runtime identity (usually signer1 address)
  runtimeInput: RuntimeInput; // Persistent storage for merged inputs
  history: EnvSnapshot[]; // Time machine snapshots - single source of truth
  gossip: any; // Gossip layer for network profiles

  // Isolated BrowserVM instance per runtime (prevents cross-runtime state leakage)
  browserVM?: any; // BrowserVMProvider instance for this runtime
  browserVMState?: BrowserVMState; // Serialized BrowserVM state for time travel

  // Active jurisdiction
  activeJurisdiction?: string; // Currently active J-replica name

  // Scenario mode: deterministic time control (scenarios set env.timestamp manually)
  scenarioMode?: boolean; // When true, runtime doesn't auto-update timestamp
  strictScenario?: boolean; // When true, runtime asserts invariants per frame
  strictScenarioLabel?: string; // Optional label for strict scenario errors

  // Frame stepping: stop at specific frame for debugging
  stopAtFrame?: number; // When set, process() stops at this frame and dumps state

  // Frame display duration hint (for time-travel visualization)
  frameDisplayMs?: number; // How long to display this frame (default: 100ms)

  // Snapshot extras for scenarios (set before process(), consumed by captureSnapshot)
  extra?: {
    subtitle?: {
      title: string;
      what?: string;
      why?: string;
      tradfiParallel?: string;
      keyMetrics?: string[];
    };
    expectedSolvency?: bigint;
    description?: string;
  };

  // Eâ†’E message queue (always spans ticks - no same-tick cascade)
  pendingOutputs?: EntityInput[]; // Outputs queued for next tick
  skipPendingForward?: boolean;   // Temp flag to defer forwarding to next frame
  networkInbox?: EntityInput[];   // Inbound network messages queued for next tick
  pendingNetworkOutputs?: EntityInput[]; // Outputs waiting for runtimeId gossip before routing
  lockRuntimeSeed?: boolean;      // Prevent runtime seed updates during scenarios

  // Frame-scoped structured logs (captured into snapshot, then reset)
  frameLogs: FrameLogEntry[];

  // HANKO SYSTEM: Hash collection during frame creation
  currentFrameHashes?: string[]; // Hashes accumulated during applyEntityFrame (cleared after)
  currentFrameEntityId?: string; // EntityId for current frame being built (for signAsEntity)

  // Event emission methods (EVM-style - like Ethereum block logs)
  log: (message: string) => void;
  info: (category: LogCategory, message: string, data?: Record<string, unknown>, entityId?: string) => void;
  warn: (category: LogCategory, message: string, data?: Record<string, unknown>, entityId?: string) => void;
  error: (category: LogCategory, message: string, data?: Record<string, unknown>, entityId?: string) => void;
  emit: (eventName: string, data: Record<string, unknown>) => void; // Generic event emission
}

/**
 * JReplica = Jurisdiction replica (J-Machine EVM state)
 * Contains stateRoot for time travel + decoded contracts for UI
 */
export interface JReplica {
  name: string;                           // "ethereum", "base", "simnet"
  blockNumber: bigint;                    // Current J-block height
  stateRoot: Uint8Array;                  // 32 bytes - for time travel via setStateRoot()
  mempool: JTx[];                         // Pending settlement txs

  // Block creation delay (ms-based for universal timing)
  // Creates visual delay where batches sit in mempool as yellow cubes
  blockDelayMs: number;                   // Delay in ms before processing mempool (default: 300)
  lastBlockTimestamp: number;             // Timestamp (ms) of last block creation
  blockReady?: boolean;                   // True when mempool has items and blockDelayMs elapsed

  // Visual position (for 3D rendering)
  position: { x: number; y: number; z: number };

  // Contract addresses (primary)
  depositoryAddress?: string; // Primary depository address (for replay protection)
  entityProviderAddress?: string; // Primary entity provider address

  // Decoded contract addresses for UI (deprecated - use depositoryAddress/entityProviderAddress)
  contracts?: {
    depository?: string;
    entityProvider?: string;
    account?: string;
  };

  // === SYNCED FROM DEPOSITORY.SOL ===
  // mapping(bytes32 => mapping(uint => uint)) _reserves
  reserves?: Map<string, Map<number, bigint>>;  // entityId -> tokenId -> amount

  // mapping(bytes => mapping(uint => AccountCollateral)) _collaterals
  collaterals?: Map<string, Map<number, { collateral: bigint; ondelta: bigint }>>; // accountKey -> tokenId -> {collateral, ondelta}

  // mapping(bytes32 => InsuranceLine[]) insuranceLines
  insuranceLines?: Map<string, Array<{ insurer: string; tokenId: number; remaining: bigint; expiresAt: bigint }>>;

  // === SYNCED FROM ENTITYPROVIDER.SOL ===
  // mapping(bytes32 => Entity) entities
  registeredEntities?: Map<string, { name: string; quorum: string[]; threshold: number }>;
}

/** J-Machine transaction (settlement layer) */
export interface JTx {
  type: 'batch'; // ALL J-operations go through batch (matches Depository.processBatch)
  entityId: string;
  data: {
    batch: any; // JBatch structure from j-batch.ts
    hankoSignature?: string;
    batchSize: number;
    signerId?: string;
  };
  timestamp: number;
  expectedJBlock?: number; // Expected j-block height (for replay protection)
}

export interface RuntimeSnapshot {
  height: number;
  entities: Record<string, EntityState>;
  gossip: {
    profiles: Record<string, Profile>;
  };
}

export interface EnvSnapshot {
  height: number;
  timestamp: number;
  runtimeSeed?: string;
  runtimeId?: string;
  eReplicas: Map<string, EntityReplica>;  // E-layer state
  jReplicas: JReplica[];                   // J-layer state (with stateRoot for time travel)
  browserVMState?: BrowserVMState;
  runtimeInput: RuntimeInput;
  runtimeOutputs: EntityInput[];
  description: string;
  gossip?: {
    profiles: Profile[];
  };
  // Interactive storytelling narrative
  title?: string; // Short headline (e.g., "Bank Run Begins")
  narrative?: string; // Detailed explanation of what's happening in this frame
  // Fed Chair educational subtitles (AHB demo)
  subtitle?: {
    title: string;           // Technical summary (e.g., "Reserve-to-Reserve Transfer")
    what: string;            // What's happening
    why: string;             // Why it matters
    tradfiParallel: string;  // Traditional finance equivalent
    keyMetrics?: string[];   // Bullet points of key numbers
  };
  // Cinematic view state for scenario playback
  viewState?: {
    camera?: 'orbital' | 'overview' | 'follow' | 'free';
    zoom?: number;
    focus?: string; // Entity ID to center on
    panel?: 'accounts' | 'transactions' | 'consensus' | 'network';
    speed?: number; // Playback speed multiplier
    position?: { x: number; y: number; z: number }; // Camera position
    rotation?: { x: number; y: number; z: number }; // Camera rotation
  };
  // Frame-specific structured logs
  logs?: FrameLogEntry[];
  // Display duration hint for time-travel visualization (default: 100ms)
  displayMs?: number;
}

// Entity types - canonical definition in ids.ts
export { type EntityType } from './ids';

// Constants
export const ENC = 'hex' as const;

// === HANKO BYTES SYSTEM (Final Design) ===
export interface HankoBytes {
  placeholders: Buffer[]; // Entity IDs that failed to sign (index 0..N-1)
  packedSignatures: Buffer; // EOA signatures â†’ yesEntities (index N..M-1)
  claims: HankoClaim[]; // Entity claims to verify (index M..âˆž)
}

export interface HankoClaim {
  entityId: Buffer;
  entityIndexes: number[];
  weights: number[];
  threshold: number;
  // NOTE: NO expectedQuorumHash - EP.sol reconstructs board hash from recovered signers
}

// Hanko in string format (hex-encoded ABI bytes)
export type HankoString = string;

export interface HankoVerificationResult {
  valid: boolean;
  entityId: Buffer;
  signedHash: Buffer;
  yesEntities: Buffer[];
  noEntities: Buffer[];
  completionPercentage: number; // 0-100% completion
  errors?: string[];
}

export interface HankoMergeResult {
  merged: HankoBytes;
  addedSignatures: number;
  completionBefore: number;
  completionAfter: number;
  log: string[];
}

/**
 * Context for hanko verification
 */
export interface HankoContext {
  timestamp: number;
  blockNumber?: number;
  networkId?: number;
}

// === PROFILE & NAME RESOLUTION TYPES ===

/**
 * Entity profile stored in gossip layer
 */
export interface EntityProfile {
  entityId: string;
  name: string; // Human-readable name e.g., "Alice Corp", "Bob's DAO"
  avatar?: string; // Custom avatar URL (fallback to generated identicon)
  bio?: string; // Short description
  website?: string; // Optional website URL
  lastUpdated: number; // Timestamp of last update
  hankoSignature: string; // Signature proving entity ownership
}

/**
 * Profile update transaction data
 */
export interface ProfileUpdateTx {
  name?: string;
  avatar?: string;
  bio?: string;
  website?: string;
}

/**
 * Name index for autocomplete
 */
export interface NameIndex {
  [name: string]: string; // name -> entityId mapping
}

/**
 * Autocomplete search result
 */
export interface NameSearchResult {
  entityId: string;
  name: string;
  avatar: string;
  relevance: number; // Search relevance score 0-1
}

// === XLNOMY (JURISDICTION) SYSTEM ===

/**
 * Economic Topology Types
 * Defines how central bank, commercial banks, and customers interact
 */
export type TopologyType = 'star' | 'mesh' | 'tiered' | 'correspondent' | 'hybrid';

export interface TopologyLayer {
  name: string;              // "Federal Reserve", "Tier 1 Banks", "Customers"
  yPosition: number;         // Vertical position in 3D space
  entityCount: number;       // How many entities in this layer
  xzSpacing: number;         // Horizontal spread between entities

  // Visual properties
  color: string;             // Hex color (#FFD700 for Fed)
  size: number;              // Size multiplier (10.0 for Fed, 1.0 for banks, 0.5 for customers)
  emissiveIntensity: number; // Glow intensity

  // Economic properties
  initialReserves: bigint;   // Starting balance
  canMintMoney: boolean;     // Only central bank = true
}

export interface ConnectionRules {
  // Who can create accounts with whom
  allowedPairs: Array<{ from: string; to: string }>;

  // Routing
  allowDirectInterbank: boolean;  // Banks can trade P2P?
  requireHubRouting: boolean;     // All payments through central hub?
  maxHops: number;                // Max routing path length

  // Credit limits (per layer pair)
  defaultCreditLimits: Map<string, bigint>;
}

export interface XlnomyTopology {
  type: TopologyType;
  layers: TopologyLayer[];
  rules: ConnectionRules;

  // Crisis management (for HYBRID)
  crisisThreshold: number;        // 0.20 = reserves < 20% deposits triggers crisis
  crisisMode: 'star' | 'mesh';    // Morph to this during crisis
}

/**
 * Xlnomy = J-Machine (court/jurisdiction) + Entities + Contracts
 * Self-contained economy where J-Machine IS the jurisdiction
 */
export interface Xlnomy {
  name: string; // e.g., "Simnet", "GameEconomy"
  evmType: 'browservm' | 'reth' | 'erigon' | 'monad';
  blockTimeMs: number; // Block time in milliseconds (1000ms default)

  // NEW: Economic topology configuration
  topology?: XlnomyTopology;

  // J-Machine = Jurisdiction machine (court that entities anchor to)
  jMachine: {
    position: { x: number; y: number; z: number }; // Visual position (0, 100, 0)
    capacity: number; // Broadcast threshold (default: 3)
    jHeight: number; // Current block height in jurisdiction
    mempool: any[]; // Pending transactions in J-Machine queue
  };

  // Deployed contracts
  contracts: {
    entityProviderAddress: string;
    depositoryAddress: string;
    deltaTransformerAddress?: string;
  };

  // EVM instance (BrowserVM in-browser, or Reth/Erigon RPC)
  evm: JurisdictionEVM;

  // Entity registry
  entities: string[]; // Entity IDs registered in this Xlnomy

  // Metadata
  created: number; // Timestamp
  version: string; // e.g., "1.0.0"
}

/**
 * Abstract jurisdiction EVM (BrowserVM or RPC to Reth/Erigon/Monad)
 * Allows swapping execution layer without changing runtime code
 */
export interface JurisdictionEVM {
  type: 'browservm' | 'reth' | 'erigon' | 'monad';

  // Contract deployment
  deployContract(bytecode: string, args?: any[]): Promise<string>;

  // Contract calls
  call(to: string, data: string, from?: string): Promise<string>;
  send(to: string, data: string, value?: bigint): Promise<string>;

  // State queries
  getBlock(): Promise<number>;
  getBalance(address: string): Promise<bigint>;

  // Serialization for persistence
  serialize(): Promise<XlnomySnapshot>;

  // Address getters
  getEntityProviderAddress(): string;
  getDepositoryAddress(): string;

  // Time travel (optional - only BrowserVM supports this)
  captureStateRoot?(): Promise<Uint8Array>;
  timeTravel?(stateRoot: Uint8Array): Promise<void>;
  getBlockNumber?(): bigint;
}

/**
 * Persisted Xlnomy snapshot (stored in Level/IndexedDB)
 * Can be exported as JSON and shared/imported
 */
export interface XlnomySnapshot {
  name: string;
  version: string;
  created: number;
  evmType: 'browservm' | 'reth' | 'erigon' | 'monad';
  blockTimeMs: number;

  // J-Machine config
  jMachine: {
    position: { x: number; y: number; z: number };
    capacity: number;
    jHeight: number;
  };

  // Deployed contracts
  contracts: {
    entityProviderAddress: string;
    depositoryAddress: string;
    deltaTransformerAddress?: string;
  };

  // EVM-specific state
  evmState: {
    rpcUrl?: string; // If RPC EVM (Reth/Erigon/Monad)
    vmState?: any; // If BrowserVM - serialized @ethereumjs/vm state
  };

  // Entity registry
  entities: string[];

  // Runtime state (replicas + history)
  runtimeState?: {
    replicas: any; // Serialized Map<string, EntityReplica>
    history: EnvSnapshot[];
  };
}


//runtime/ids.ts (519 lines)
/**
 * XLN Identity System
 *
 * Canonical addressing for entities and replicas across jurisdictions.
 * Runtime is single source of truth - frontend imports from here.
 *
 * URI Format: xln://{host}:{port}/{jId}/{epAddress}/{entityId}/{signerId}
 *
 * Entity Types:
 * - Numbered: entityId < 1,000,000 (display as #1, #2, etc.)
 * - Lazy: entityId = keccak256(governance_structure) (display as abc123...)
 */

// =============================================================================
// BRANDED TYPES - Compile-time type safety
// =============================================================================

declare const EntityIdBrand: unique symbol;
declare const SignerIdBrand: unique symbol;
declare const JIdBrand: unique symbol;
declare const EntityProviderAddressBrand: unique symbol;

/** Entity identifier - 32-byte hex string (0x + 64 chars) */
export type EntityId = string & { readonly [EntityIdBrand]: typeof EntityIdBrand };

/** Signer identifier - wallet address or named signer */
export type SignerId = string & { readonly [SignerIdBrand]: typeof SignerIdBrand };

/** Jurisdiction ID - EVM chainId or lazy hash for local jurisdictions */
export type JId = string & { readonly [JIdBrand]: typeof JIdBrand };

/** EntityProvider contract address - 20-byte hex (0x + 40 chars) */
export type EntityProviderAddress = string & { readonly [EntityProviderAddressBrand]: typeof EntityProviderAddressBrand };

// =============================================================================
// CONSTANTS
// =============================================================================

/** Maximum entity number for "numbered" entities (vs lazy hash entities) */
export const MAX_NUMBERED_ENTITY = 1_000_000n;

/** URI scheme for XLN addresses */
export const XLN_URI_SCHEME = 'xln://';

/** Default runtime host (for local single-runtime setup) */
export const DEFAULT_RUNTIME_HOST = 'localhost:8080';

/** Coordinator for cross-runtime messaging (future) */
export const XLN_COORDINATOR = 'xln.finance';

/** Well-known EVM chain IDs */
export const CHAIN_IDS = {
  mainnet: '1',
  sepolia: '11155111',
  polygon: '137',
  arbitrum: '42161',
  local: 'local', // For local dev/testing
} as const;

// =============================================================================
// REPLICA KEY - Structured, type-safe
// =============================================================================

/** Structured replica key - NO MORE string splitting! */
export interface ReplicaKey {
  readonly entityId: EntityId;
  readonly signerId: SignerId;
}

/** Full address including jurisdiction context */
export interface FullReplicaAddress extends ReplicaKey {
  readonly jId: JId;
  readonly epAddress: EntityProviderAddress;
}

/** Complete URI with runtime host for networking */
export interface ReplicaUri extends FullReplicaAddress {
  readonly runtimeHost: string; // host:port
}

// =============================================================================
// TYPE GUARDS & VALIDATORS
// =============================================================================

/** Check if string is valid EntityId format (0x + 64 hex chars) */
export const isValidEntityId = (s: string): s is EntityId => {
  return typeof s === 'string' && /^0x[a-fA-F0-9]{64}$/.test(s);
};

/** Check if string is valid SignerId (non-empty string) */
export const isValidSignerId = (s: string): s is SignerId => {
  return typeof s === 'string' && s.length > 0;
};

/** Check if string is valid JId (chainId number or hash) */
export const isValidJId = (s: string): s is JId => {
  return typeof s === 'string' && s.length > 0;
};

/** Check if string is valid EntityProviderAddress (0x + 40 hex chars) */
export const isValidEpAddress = (s: string): s is EntityProviderAddress => {
  return typeof s === 'string' && /^0x[a-fA-F0-9]{40}$/i.test(s);
};

// =============================================================================
// CONSTRUCTORS - Validate at source, trust at use
// =============================================================================

/** Create validated EntityId - throws if invalid */
export const toEntityId = (s: string): EntityId => {
  if (!isValidEntityId(s)) {
    throw new Error(`FINTECH-SAFETY: Invalid EntityId format: ${s}`);
  }
  return s;
};

/** Create validated SignerId - throws if invalid */
export const toSignerId = (s: string): SignerId => {
  if (!isValidSignerId(s)) {
    throw new Error(`FINTECH-SAFETY: Invalid SignerId: ${s}`);
  }
  return s;
};

/** Create validated JId - throws if invalid */
export const toJId = (s: string): JId => {
  if (!isValidJId(s)) {
    throw new Error(`FINTECH-SAFETY: Invalid JId: ${s}`);
  }
  return s;
};

/** Create validated EntityProviderAddress - throws if invalid */
export const toEpAddress = (s: string): EntityProviderAddress => {
  if (!isValidEpAddress(s)) {
    throw new Error(`FINTECH-SAFETY: Invalid EntityProviderAddress: ${s}`);
  }
  return s;
};

// =============================================================================
// REPLICA KEY OPERATIONS - Replace all split(':') patterns
// =============================================================================

/**
 * Parse legacy replica key string "entityId:signerId" â†’ ReplicaKey
 * This is the ONLY place string splitting should happen!
 */
export const parseReplicaKey = (keyString: string): ReplicaKey => {
  const colonIndex = keyString.indexOf(':');
  if (colonIndex === -1) {
    throw new Error(`FINTECH-SAFETY: Invalid replica key format (no colon): ${keyString}`);
  }

  const entityIdRaw = keyString.slice(0, colonIndex);
  const signerIdRaw = keyString.slice(colonIndex + 1);

  if (!entityIdRaw || !signerIdRaw) {
    throw new Error(`FINTECH-SAFETY: Invalid replica key format (empty parts): ${keyString}`);
  }

  return {
    entityId: toEntityId(entityIdRaw),
    signerId: toSignerId(signerIdRaw),
  };
};

/**
 * Format ReplicaKey â†’ legacy string "entityId:signerId"
 * Use for IndexedDB keys and Map lookups (temporary until full migration)
 */
export const formatReplicaKey = (key: ReplicaKey): string => {
  return `${key.entityId}:${key.signerId}`;
};

/**
 * Create ReplicaKey from parts (validates at construction)
 */
export const createReplicaKey = (entityId: string, signerId: string): ReplicaKey => ({
  entityId: toEntityId(entityId),
  signerId: toSignerId(signerId),
});

/**
 * Extract just entityId from legacy key string
 * Convenience for cases where only entityId is needed
 */
export const extractEntityId = (keyString: string): EntityId => {
  return parseReplicaKey(keyString).entityId;
};

/**
 * Extract just signerId from legacy key string
 * Convenience for cases where only signerId is needed
 */
export const extractSignerId = (keyString: string): SignerId => {
  return parseReplicaKey(keyString).signerId;
};

// =============================================================================
// ENTITY TYPE DETECTION
// =============================================================================

export type EntityType = 'numbered' | 'lazy' | 'named';

/**
 * Detect entity type from entityId
 * - numbered: small integers (1-999,999) stored as 0x-padded hex
 * - lazy: keccak256 hashes of governance structure
 * - named: reserved for future on-chain name registry
 */
export const detectEntityType = (entityId: EntityId): EntityType => {
  try {
    const num = BigInt(entityId);
    if (num > 0n && num < MAX_NUMBERED_ENTITY) {
      return 'numbered';
    }
    return 'lazy';
  } catch {
    return 'lazy';
  }
};

/**
 * Check if entityId is a numbered entity
 */
export const isNumberedEntity = (entityId: EntityId): boolean => {
  return detectEntityType(entityId) === 'numbered';
};

/**
 * Check if entityId is a lazy entity (hash-based)
 */
export const isLazyEntity = (entityId: EntityId): boolean => {
  return detectEntityType(entityId) === 'lazy';
};

// =============================================================================
// DISPLAY FORMATTING
// =============================================================================

/**
 * Format entityId for display
 * - Numbered: "#42"
 * - Lazy: "a1b2c3d4..." (first 8 chars of hash)
 */
export const formatEntityDisplay = (entityId: EntityId): string => {
  const type = detectEntityType(entityId);

  if (type === 'numbered') {
    const num = Number(BigInt(entityId));
    return `#${num}`;
  }

  // Lazy: show truncated hash (skip 0x, take first 8 chars)
  return entityId.slice(2, 10) + '...';
};

/**
 * Get numeric representation for display/sorting
 * - Numbered: actual number (1, 2, 3...)
 * - Lazy: deterministic number from hash suffix (for consistent display)
 */
export const getEntityDisplayNumber = (entityId: EntityId): number => {
  try {
    const num = BigInt(entityId);

    if (num > 0n && num < MAX_NUMBERED_ENTITY) {
      return Number(num);
    }

    // Lazy: use last 4 bytes for deterministic display number
    const hashSuffix = entityId.slice(-8);
    return (parseInt(hashSuffix, 16) % 9000000) + 1000000; // 1M-10M range
  } catch {
    throw new Error(`FINTECH-SAFETY: Invalid entityId for display: ${entityId}`);
  }
};

/**
 * Format signerId for display
 * - Wallet address: truncated "0x1234...abcd"
 * - Named signer: as-is "alice_proposer"
 */
export const formatSignerDisplay = (signerId: SignerId): string => {
  if (signerId.startsWith('0x') && signerId.length === 42) {
    return `${signerId.slice(0, 6)}...${signerId.slice(-4)}`;
  }
  return signerId;
};

/**
 * Format full ReplicaKey for display
 * Example: "#42:alice" or "a1b2c3d4...:0x1234...abcd"
 */
export const formatReplicaDisplay = (key: ReplicaKey): string => {
  return `${formatEntityDisplay(key.entityId)}:${formatSignerDisplay(key.signerId)}`;
};

// =============================================================================
// URI OPERATIONS (For future networking)
// =============================================================================

/**
 * Format full URI for cross-runtime addressing
 * xln://localhost:8080/1/0x5FbD.../0x0000...0001/alice
 */
export const formatReplicaUri = (uri: ReplicaUri): string => {
  return `${XLN_URI_SCHEME}${uri.runtimeHost}/${uri.jId}/${uri.epAddress}/${uri.entityId}/${uri.signerId}`;
};

/**
 * Parse URI string into ReplicaUri
 */
export const parseReplicaUri = (uriString: string): ReplicaUri => {
  if (!uriString.startsWith(XLN_URI_SCHEME)) {
    throw new Error(`FINTECH-SAFETY: Invalid URI scheme: ${uriString}`);
  }

  const rest = uriString.slice(XLN_URI_SCHEME.length);
  const parts = rest.split('/');

  if (parts.length < 5) {
    throw new Error(`FINTECH-SAFETY: Invalid URI format: ${uriString}`);
  }

  const [runtimeHost, jId, epAddress, entityId, signerId] = parts;

  return {
    runtimeHost: runtimeHost!,
    jId: toJId(jId!),
    epAddress: toEpAddress(epAddress!),
    entityId: toEntityId(entityId!),
    signerId: toSignerId(signerId!),
  };
};

/**
 * Create local URI (uses default runtime host)
 */
export const createLocalUri = (
  jId: JId,
  epAddress: EntityProviderAddress,
  entityId: EntityId,
  signerId: SignerId,
): ReplicaUri => ({
  runtimeHost: DEFAULT_RUNTIME_HOST,
  jId,
  epAddress,
  entityId,
  signerId,
});

// =============================================================================
// TYPE-SAFE COLLECTIONS
// =============================================================================

/**
 * Type-safe Map for replicas keyed by ReplicaKey
 * Uses string keys internally for IndexedDB compatibility
 */
export class ReplicaMap<T> {
  private readonly map = new Map<string, T>();

  get(key: ReplicaKey): T | undefined {
    return this.map.get(formatReplicaKey(key));
  }

  set(key: ReplicaKey, value: T): this {
    this.map.set(formatReplicaKey(key), value);
    return this;
  }

  has(key: ReplicaKey): boolean {
    return this.map.has(formatReplicaKey(key));
  }

  delete(key: ReplicaKey): boolean {
    return this.map.delete(formatReplicaKey(key));
  }

  get size(): number {
    return this.map.size;
  }

  *entries(): IterableIterator<[ReplicaKey, T]> {
    for (const [keyString, value] of this.map.entries()) {
      yield [parseReplicaKey(keyString), value];
    }
  }

  *keys(): IterableIterator<ReplicaKey> {
    for (const keyString of this.map.keys()) {
      yield parseReplicaKey(keyString);
    }
  }

  *values(): IterableIterator<T> {
    yield* this.map.values();
  }

  forEach(callback: (value: T, key: ReplicaKey, map: ReplicaMap<T>) => void): void {
    this.map.forEach((value, keyString) => {
      callback(value, parseReplicaKey(keyString), this);
    });
  }

  /** Get underlying Map for serialization */
  toMap(): Map<string, T> {
    return new Map(this.map);
  }

  /** Create from existing Map */
  static fromMap<T>(map: Map<string, T>): ReplicaMap<T> {
    const rm = new ReplicaMap<T>();
    for (const [k, v] of map.entries()) {
      rm.map.set(k, v);
    }
    return rm;
  }
}

/**
 * Type-safe Map for entities keyed by EntityId
 */
export class EntityMap<T> {
  private readonly map = new Map<EntityId, T>();

  get(key: EntityId): T | undefined {
    return this.map.get(key);
  }

  set(key: EntityId, value: T): this {
    this.map.set(key, value);
    return this;
  }

  has(key: EntityId): boolean {
    return this.map.has(key);
  }

  delete(key: EntityId): boolean {
    return this.map.delete(key);
  }

  get size(): number {
    return this.map.size;
  }

  *entries(): IterableIterator<[EntityId, T]> {
    yield* this.map.entries();
  }

  *keys(): IterableIterator<EntityId> {
    yield* this.map.keys();
  }

  *values(): IterableIterator<T> {
    yield* this.map.values();
  }

  forEach(callback: (value: T, key: EntityId, map: EntityMap<T>) => void): void {
    this.map.forEach((value, key) => callback(value, key, this));
  }
}

// =============================================================================
// JURISDICTION HELPERS
// =============================================================================

/** Well-known jurisdiction configurations */
export interface JurisdictionInfo {
  jId: JId;
  name: string;
  chainId?: number; // For EVM chains
  rpcUrl?: string;
}

/** Create JId from EVM chainId */
export const jIdFromChainId = (chainId: number): JId => {
  return toJId(chainId.toString());
};

/** Create lazy JId for local/test jurisdictions */
export const createLazyJId = (name: string): JId => {
  // Simple hash for now - could use keccak256 for stronger uniqueness
  let hash = 0;
  for (let i = 0; i < name.length; i++) {
    hash = ((hash << 5) - hash + name.charCodeAt(i)) | 0;
  }
  return toJId(`lazy_${Math.abs(hash).toString(16)}`);
};

// =============================================================================
// MIGRATION HELPERS (temporary - remove after full migration)
// =============================================================================

/**
 * Safely parse replica key with fallback for invalid data
 * Use ONLY during migration - prefer parseReplicaKey for validated code paths
 */
export const safeParseReplicaKey = (keyString: string): ReplicaKey | null => {
  try {
    return parseReplicaKey(keyString);
  } catch {
    console.warn(`[ids] Invalid replica key during migration: ${keyString}`);
    return null;
  }
};

/**
 * Extract entityId from legacy key string with fallback
 * Use ONLY during migration
 */
export const safeExtractEntityId = (keyString: string): EntityId | null => {
  const key = safeParseReplicaKey(keyString);
  return key?.entityId ?? null;
};


//runtime/runtime.ts (2252 lines)
// for regular use > bun run runtime/runtime.ts
// for debugging > bun repl
// await import('./debug.js');
// FORCE AUTO-REBUILD: Fixed signerId consistency and fintech type safety

// Import utilities and types
// High-level database using Level polyfill (works in both Node.js and browser)
import { Level } from 'level';

// Bump this when you need to confirm the browser picked up a new runtime bundle.
const RUNTIME_BUILD_ID = '2025-02-16-22:50Z';
console.log(`ðŸš€ RUNTIME.JS BUILD: ${RUNTIME_BUILD_ID}`);

import { getPerfMs, getWallClockMs } from './time';
import { applyEntityInput, mergeEntityInputs } from './entity-consensus';
import { isLeftEntity } from './entity-id-utils';
import {
  createLazyEntity,
  createNumberedEntity,
  createNumberedEntitiesBatch,
  detectEntityType,
  encodeBoard,
  generateLazyEntityId,
  generateNamedEntityId,
  generateNumberedEntityId,
  hashBoard,
  isEntityRegistered,
  requestNamedEntity,
  resolveEntityIdentifier,
} from './entity-factory';
import {
  assignNameOnChain,
  connectToEthereum,
  debugFundReserves,
  getAvailableJurisdictions,
  getEntityInfoFromChain,
  getJurisdictionByAddress,
  getNextEntityNumber,
  registerNumberedEntityOnChain,
  setBrowserVMJurisdiction,
  getBrowserVMInstance,
  submitProcessBatch,
  submitPrefundAccount,
  submitSettle,
  submitReserveToReserve,
  transferNameBetweenEntities,
} from './evm';
import { createGossipLayer } from './gossip';
import { attachEventEmitters } from './env-events';
import { deriveSignerAddressSync, deriveSignerKeySync, getSignerPrivateKey, getSignerPublicKey, registerSignerKey, setRuntimeSeed as setCryptoRuntimeSeed } from './account-crypto';
import { buildEntityProfile } from './gossip-helper';
import { RuntimeP2P, type P2PConfig } from './p2p';
import {
  parseReplicaKey,
  extractEntityId,
  extractSignerId,
  formatReplicaKey,
  createReplicaKey,
  formatEntityDisplay as formatEntityDisplayIds,
  formatSignerDisplay as formatSignerDisplayIds,
  formatReplicaDisplay,
  // Types for re-export
  type EntityId,
  type SignerId,
  type JId,
  type EntityProviderAddress,
  type ReplicaKey,
  type FullReplicaAddress,
  type ReplicaUri,
  // Constants
  XLN_URI_SCHEME,
  DEFAULT_RUNTIME_HOST,
  XLN_COORDINATOR,
  CHAIN_IDS,
  MAX_NUMBERED_ENTITY,
  // Type guards
  isValidEntityId,
  isValidSignerId,
  isValidJId,
  isValidEpAddress,
  // Constructors
  toEntityId,
  toSignerId,
  toJId,
  toEpAddress,
  // Entity type detection (re-export from ids.ts)
  detectEntityType as detectEntityTypeIds,
  isNumberedEntity,
  isLazyEntity,
  getEntityDisplayNumber,
  // URI operations
  formatReplicaUri,
  parseReplicaUri,
  createLocalUri,
  // Type-safe collections
  ReplicaMap,
  EntityMap,
  // Jurisdiction helpers
  type JurisdictionInfo,
  jIdFromChainId,
  createLazyJId,
  // Migration helpers
  safeParseReplicaKey,
  safeExtractEntityId,
} from './ids';
import { type Profile, loadPersistedProfiles } from './gossip.js';
import { setupJEventWatcher, JEventWatcher } from './j-event-watcher';
import {
  createProfileUpdateTx,
  getEntityDisplayInfo as getEntityDisplayInfoFromProfileOriginal,
  resolveEntityName as resolveEntityNameOriginal,
  searchEntityNames as searchEntityNamesOriginal,
} from './name-resolution';
// import { runDemo } from './rundemo'; // REMOVED: Legacy demo replaced by scenarios/ahb
import { decode, encode } from './snapshot-coder'; // encode used in exports
import { deriveDelta, isLeft, getTokenInfo, formatTokenAmount, createDemoDelta, getDefaultCreditLimit } from './account-utils';
import { classifyBilateralState, getAccountBarVisual } from './account-consensus-state';
import {
  formatTokenAmount as formatTokenAmountEthers,
  parseTokenAmount,
  convertTokenPrecision,
  calculatePercentage as calculatePercentageEthers,
  formatAssetAmount as formatAssetAmountEthers,
  BigIntMath,
  FINANCIAL_CONSTANTS
} from './financial-utils';
import { captureSnapshot, cloneEntityReplica } from './state-helpers';
import { getEntityShortId, getEntityNumber, formatEntityId, HEAVY_LOGS } from './utils';
import { safeStringify } from './serialization-utils';
import { validateDelta, validateAccountDeltas, createDefaultDelta, isDelta, validateEntityInput, validateEntityOutput } from './validation-utils';
import { EntityInput, EntityReplica, Env, RuntimeInput, JReplica } from './types';
import {
  clearDatabase,
  DEBUG,
  formatEntityDisplay,
  formatSignerDisplay,
  generateEntityAvatar,
  generateSignerAvatar,
  getEntityDisplayInfo,
  getSignerDisplayInfo,
  isBrowser,
  log,
} from './utils';
import { logError } from './logger';

// --- Clean Log Capture (for debugging without file:line noise) ---
const cleanLogs: string[] = [];
const MAX_CLEAN_LOGS = 2000;

// Wrap console to capture clean logs (browser only)
if (isBrowser) {
  const originalLog = console.log;
  const originalWarn = console.warn;
  const originalError = console.error;
  const originalDebug = console.debug;

  const formatArgs = (args: any[]): string => {
    return args.map(a => {
      if (typeof a === 'string') return a;
      if (typeof a === 'bigint') return a.toString() + 'n';
      try { return JSON.stringify(a); } catch { return String(a); }
    }).join(' ');
  };

  const addCleanLog = (level: string, msg: string) => {
    const ts = new Date().toLocaleTimeString('en-US', { hour12: false, hour: '2-digit', minute: '2-digit', second: '2-digit', fractionalSecondDigits: 3 });
    cleanLogs.push(`[${ts}] ${level}: ${msg}`);
    if (cleanLogs.length > MAX_CLEAN_LOGS) cleanLogs.shift();
  };

  console.log = function(...args: any[]) {
    originalLog.apply(console, args);
    addCleanLog('LOG', formatArgs(args));
  };
  console.warn = function(...args: any[]) {
    originalWarn.apply(console, args);
    addCleanLog('WARN', formatArgs(args));
  };
  console.error = function(...args: any[]) {
    originalError.apply(console, args);
    addCleanLog('ERR', formatArgs(args));
  };
  console.debug = function(...args: any[]) {
    originalDebug.apply(console, args);
    addCleanLog('DBG', formatArgs(args));
  };
}

/** Get all clean logs as text (no file:line references) */
export const getCleanLogs = (): string => cleanLogs.join('\n');

/** Clear clean logs buffer */
export const clearCleanLogs = (): void => { cleanLogs.length = 0; };

/** Copy clean logs to clipboard (returns text if clipboard fails) */
export const copyCleanLogs = async (): Promise<string> => {
  const text = getCleanLogs();
  if (isBrowser && navigator.clipboard) {
    try {
      await navigator.clipboard.writeText(text);
      console.log(`âœ… Copied ${cleanLogs.length} log entries to clipboard`);
    } catch {
      // Clipboard fails when devtools focused - just return text
    }
  }
  return text;
};

// --- Database Setup ---
// Level polyfill: Node.js uses filesystem, Browser uses IndexedDB
const nodeProcess =
  !isBrowser && typeof globalThis.process !== 'undefined'
    ? globalThis.process
    : undefined;
const defaultDbPath = nodeProcess ? 'db-tmp/runtime' : 'db';
const dbPath = nodeProcess?.env?.XLN_DB_PATH || defaultDbPath;
export const db: Level<Buffer, Buffer> = new Level(dbPath, {
  valueEncoding: 'buffer',
  keyEncoding: 'binary',
});

// Helper: Race promise with timeout
async function withTimeout<T>(promise: Promise<T>, ms: number): Promise<T> {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(() => reject(new Error('TIMEOUT')), ms)
    )
  ]);
}

// Database availability check
let dbOpenPromise: Promise<boolean> | null = null;

async function tryOpenDb(): Promise<boolean> {
  if (!dbOpenPromise) {
    dbOpenPromise = (async () => {
      try {
        await db.open();
        console.log('âœ… Database opened');
        return true;
      } catch (error) {
        // Check if IndexedDB is completely blocked (Safari incognito)
        const isBlocked = error instanceof Error &&
          (error.message?.includes('blocked') ||
           error.name === 'SecurityError' ||
           error.name === 'InvalidStateError');

        if (isBlocked) {
          console.log('âš ï¸ IndexedDB blocked (incognito/private mode) - running in-memory');
          return false;
        }

        // Other errors - log but assume DB is available
        console.warn('âš ï¸ DB open warning:', error instanceof Error ? error.message : error);
        return true;
      }
    })();
  }
  return dbOpenPromise;
}

// === ETHEREUM INTEGRATION ===

// === SVELTE REACTIVITY INTEGRATION ===
// Callback that Svelte can register to get notified of env changes
let envChangeCallback: ((env: Env) => void) | null = null;

// Module-level environment variable
let env: Env;
let runtimeSeed: string | null = null;
let runtimeId: string | null = null;
let p2pOverlay: RuntimeP2P | null = null;
let pendingP2PConfig: { env: Env; config: P2PConfig } | null = null;
let networkProcessScheduled = false;
let lastP2PConfig: P2PConfig | null = null;

// Module-level j-watcher instance - prevent multiple instances
let jWatcher: JEventWatcher | null = null;
let jWatcherStarted = false;

export const registerEnvChangeCallback = (callback: (env: Env) => void) => {
  envChangeCallback = callback;
};

/**
 * Get the module-level env (used for j-watcher and runtime tick)
 * CRITICAL: This returns the SAME env that the runtime tick processes!
 * View.svelte should use this instead of createEmptyEnv() for proper event routing.
 */
export const getEnv = (): Env | null => {
  return env || null;
};

export const setRuntimeSeed = (seed: string | null): void => {
  if (env?.lockRuntimeSeed) {
    console.warn('âš ï¸ Runtime seed update blocked (scenario lock enabled)');
    return;
  }
  const normalized = seed && seed.length > 0 ? seed : null;
  runtimeSeed = normalized;
  setCryptoRuntimeSeed(normalized);
  if (normalized) {
    try {
      runtimeId = deriveSignerAddressSync(normalized, '1');
    } catch (error) {
      console.warn('âš ï¸ Failed to derive runtimeId from seed:', error);
      runtimeId = null;
    }
  } else {
    runtimeId = null;
  }
  if (env) {
    env.runtimeSeed = normalized || undefined;
    env.runtimeId = runtimeId || undefined;
  }
  if (pendingP2PConfig && runtimeId) {
    const { env: pendingEnv, config } = pendingP2PConfig;
    pendingP2PConfig = null;
    startP2P(pendingEnv, config);
  }
  if (env && p2pOverlay && lastP2PConfig && runtimeId) {
    startP2P(env, lastP2PConfig);
  }
};

export const setRuntimeId = (id: string | null): void => {
  runtimeId = id && id.length > 0 ? id : null;
  if (env) {
    env.runtimeId = runtimeId || undefined;
  }
};

const scheduleNetworkProcess = (env: Env) => {
  if (networkProcessScheduled) return;
  networkProcessScheduled = true;
  const defer =
    typeof setImmediate === 'function'
      ? setImmediate
      : (cb: () => void) => {
          if (typeof queueMicrotask === 'function') {
            queueMicrotask(cb);
          } else {
            setTimeout(cb, 0);
          }
        };
  defer(async () => {
    networkProcessScheduled = false;
    if (!env.networkInbox || env.networkInbox.length === 0) return;
    if (processing) {
      scheduleNetworkProcess(env);
      return;
    }
    try {
      await process(env);
    } catch (error) {
      logError('NETWORK', 'Failed to process network inbox', error);
    }
  });
};

const resolveRuntimeIdForEntity = (env: Env, entityId: string): string | null => {
  if (!env.gossip?.getProfiles) return null;
  const profiles = env.gossip.getProfiles();
  const profile = profiles.find((p: Profile) => p.entityId === entityId);
  return profile?.runtimeId || null;
};

const routeEntityOutputs = (env: Env, outputs: EntityInput[]): EntityInput[] => {
  if (!p2pOverlay) return outputs;
  const localEntityIds = new Set<string>();
  for (const replicaKey of env.eReplicas.keys()) {
    try {
      localEntityIds.add(extractEntityId(replicaKey));
    } catch {
      // Skip malformed replica keys
    }
  }

  const localOutputs: EntityInput[] = [];
  const pendingOutputs = env.pendingNetworkOutputs ? [...env.pendingNetworkOutputs] : [];
  env.pendingNetworkOutputs = [];
  const allOutputs = [...pendingOutputs, ...outputs];
  const deferredOutputs: EntityInput[] = [];

  for (const output of allOutputs) {
    if (localEntityIds.has(output.entityId)) {
      localOutputs.push(output);
      continue;
    }
    const targetRuntimeId = resolveRuntimeIdForEntity(env, output.entityId);
    console.log(`ðŸ”€ ROUTE: Output for entity ${output.entityId.slice(-4)} â†’ runtimeId=${targetRuntimeId?.slice(0,10) || 'UNKNOWN'}`);

    if (!targetRuntimeId) {
      console.warn(`âš ï¸ ROUTE-DEFER: No runtimeId for entity ${output.entityId.slice(-4)} - deferring output`);
      env.warn('network', 'Missing runtimeId for entity output (queued)', { entityId: output.entityId });
      deferredOutputs.push(output);
      continue;
    }

    console.log(`ðŸ“¤ P2P-SEND: Enqueueing to runtimeId ${targetRuntimeId.slice(0, 10)} for entity ${output.entityId.slice(-4)}`);
    p2pOverlay.enqueueEntityInput(targetRuntimeId, output);
  }

  if (deferredOutputs.length > 0) {
    env.pendingNetworkOutputs = deferredOutputs;
  }

  return localOutputs;
};

export const startP2P = (env: Env, config: P2PConfig = {}): RuntimeP2P | null => {
  lastP2PConfig = config;
  const resolvedRuntimeId = config.runtimeId || env.runtimeId;
  if (!resolvedRuntimeId) {
    pendingP2PConfig = { env, config };
    return null;
  }

  if (p2pOverlay) {
    if (p2pOverlay.matchesIdentity(resolvedRuntimeId, config.signerId)) {
      p2pOverlay.updateConfig(config);
      return p2pOverlay;
    }
    p2pOverlay.close();
  }

  p2pOverlay = new RuntimeP2P({
    env,
    runtimeId: resolvedRuntimeId,
    signerId: config.signerId,
    relayUrls: config.relayUrls,
    seedRuntimeIds: config.seedRuntimeIds,
    advertiseEntityIds: config.advertiseEntityIds,
    isHub: config.isHub,
    profileName: config.profileName,
    onEntityInput: (from, input) => {
      const txTypes = input.entityTxs?.map(tx => tx.type).join(',') || 'none';
      console.log(`ðŸ“¨ P2P-RECEIVE: from=${from.slice(0,10)} entity=${input.entityId.slice(-4)} txTypes=[${txTypes}]`);
      env.networkInbox = env.networkInbox || [];
      env.networkInbox.push(input);
      console.log(`ðŸ“¥ NETWORK-INBOX: Added, size=${env.networkInbox.length}`);
      env.info('network', 'INBOUND_ENTITY_INPUT', { fromRuntimeId: from, entityId: input.entityId }, input.entityId);
      scheduleNetworkProcess(env);
    },
    onGossipProfiles: (from, profiles) => {
      console.log(`ðŸ“¥ onGossipProfiles: Received ${profiles.length} profiles from ${from.slice(0,10)}`);
      console.log(`ðŸ“¥ Profile details:`, profiles.map(p => `${p.entityId?.slice(-4) || '????'}:${p.accounts?.length || 0}acc`).join(', '));

      if (!env.gossip?.announce) {
        console.warn(`âš ï¸ No env.gossip.announce!`);
        return;
      }

      console.log(`ðŸ“¥ Starting announce loop for ${profiles.length} profiles...`);
      for (let i = 0; i < profiles.length; i++) {
        const profile = profiles[i];
        console.log(`  [${i}] Announcing ${profile.entityId.slice(-4)} accounts=${profile.accounts?.length || 0} ts=${profile.metadata?.lastUpdated}`);
        env.gossip.announce(profile);
      }
      console.log(`ðŸ“¥ Announce loop complete`);
      env.info('network', 'GOSSIP_SYNC', { fromRuntimeId: from, profiles: profiles.length });
    },
  });

  p2pOverlay.connect();
  return p2pOverlay;
};

export const stopP2P = (): void => {
  if (p2pOverlay) {
    p2pOverlay.close();
    p2pOverlay = null;
  }
  lastP2PConfig = null;
};

export const getP2P = (): RuntimeP2P | null => p2pOverlay;

/**
 * Initialize module-level env if not already set
 * Call this early in frontend initialization before prepopulate
 */
export const initEnv = (): Env => {
  if (!env) {
    env = createEmptyEnv(runtimeSeed);
    if (env.runtimeSeed) {
      setCryptoRuntimeSeed(env.runtimeSeed);
    }
    console.log('ðŸŒ Runtime env initialized (module-level)');
  }
  return env;
};

const notifyEnvChange = (env: Env) => {
  if (envChangeCallback) {
    envChangeCallback(env);
  }
};

/**
 * Process any pending j-events after j-block finalization
 * Called automatically after each BrowserVM batch execution
 * This is the R-machine routing j-events from jReplicas to eReplicas
 */
export const processJBlockEvents = async (): Promise<void> => {
  if (!env) {
    console.warn('âš ï¸ processJBlockEvents: No env available');
    return;
  }

  const pending = env.runtimeInput.entityInputs.length;
  if (pending === 0) return;

  console.log(`ðŸ”— J-BLOCK: ${pending} j-events queued â†’ routing to eReplicas`);
  const toProcess = [...env.runtimeInput.entityInputs];
  env.runtimeInput.entityInputs = [];

  await applyRuntimeInput(env, {
    runtimeTxs: [],
    entityInputs: toProcess,
  });
  console.log(`   âœ“ ${toProcess.length} j-events processed`);
};

// J-Watcher initialization
const startJEventWatcher = async (env: Env): Promise<void> => {
  // BrowserVM is the default - it handles events synchronously via processJBlockEvents()
  // External RPC watcher is disabled until we support remote jurisdictions
  const browserVM = getBrowserVMInstance(env);
  if (browserVM) {
    console.log('ðŸ”­ J-WATCHER: Using BrowserVM (external RPC not needed)');
    return;
  }

  // External RPC mode (future - not yet supported)
  try {
    const arrakis = await getJurisdictionByAddress('arrakis');
    if (!arrakis) {
      console.warn('âš ï¸ Arrakis jurisdiction not found, skipping j-watcher');
      return;
    }

    jWatcher = await setupJEventWatcher(
      env,
      arrakis.address,
      arrakis.entityProviderAddress,
      arrakis.depositoryAddress
    );

    console.log('âœ… J-Event Watcher started (external RPC)');
    console.log(`ðŸ”­ Monitoring: ${arrakis.address}`);

    setInterval(async () => {
      if (env.runtimeInput.entityInputs.length > 0) {
        const pendingInputs = [...env.runtimeInput.entityInputs];
        env.runtimeInput.entityInputs = [];
        await applyRuntimeInput(env, { runtimeTxs: [], entityInputs: pendingInputs });
      }
    }, 100);

  } catch (error) {
    logError("RUNTIME_TICK", 'âŒ Failed to start J-Event Watcher:', error);
  }
};

// Note: History is now stored in env.history (no global variable needed)

// === SNAPSHOT UTILITIES ===
// All cloning utilities now moved to state-helpers.ts

// All snapshot functionality now moved to state-helpers.ts

// === UTILITY FUNCTIONS ===

const applyRuntimeInput = async (
  env: Env,
  runtimeInput: RuntimeInput,
): Promise<{ entityOutbox: EntityInput[]; mergedInputs: EntityInput[] }> => {
  const startTime = getPerfMs();

  try {
    // SECURITY: Validate runtime input
    if (!runtimeInput) {
      log.error('âŒ Null runtime input provided');
      return { entityOutbox: [], mergedInputs: [] };
    }
    if (!Array.isArray(runtimeInput.runtimeTxs)) {
      log.error(`âŒ Invalid runtimeTxs: expected array, got ${typeof runtimeInput.runtimeTxs}`);
      return { entityOutbox: [], mergedInputs: [] };
    }
    if (!Array.isArray(runtimeInput.entityInputs)) {
      log.error(`âŒ Invalid entityInputs: expected array, got ${typeof runtimeInput.entityInputs}`);
      return { entityOutbox: [], mergedInputs: [] };
    }

    // Process J-layer inputs (queue to J-mempool)
    if (runtimeInput.jInputs && Array.isArray(runtimeInput.jInputs)) {
      if (HEAVY_LOGS) console.log(`ðŸ” J-Input processing: ${runtimeInput.jInputs.length} jInputs`);
      for (const jInput of runtimeInput.jInputs) {
        const jReplica = env.jReplicas?.get(jInput.jurisdictionName);
        if (!jReplica) {
          console.error(`âŒ J-Input: Jurisdiction "${jInput.jurisdictionName}" not found`);
          continue;
        }

        if (HEAVY_LOGS) console.log(`ðŸ” J-Input has ${jInput.jTxs.length} JTxs for ${jInput.jurisdictionName}`);
        // Queue all JTxs to J-mempool with queuedAt timestamp
        for (const jTx of jInput.jTxs) {
          // Mark when added (for minimum 1-tick delay visualization)
          const jTxWithQueueTime = { ...jTx, queuedAt: env.timestamp };
          jReplica.mempool.push(jTxWithQueueTime);
          console.log(`ðŸ“¥ J-Input: Queued ${jTx.type} from ${jTx.entityId.slice(-4)} to ${jInput.jurisdictionName} mempool (mempool size now: ${jReplica.mempool.length})`);
        }

        console.log(`âœ… J-Input: ${jInput.jTxs.length} txs queued (mempool: ${jReplica.mempool.length})`);
      }
    }

    // Capture queued inputs and clear to allow new ones during processing
    const queuedRuntimeTxs = [...env.runtimeInput.runtimeTxs];
    const queuedEntityInputs = [...env.runtimeInput.entityInputs];
    env.runtimeInput.runtimeTxs = [];
    env.runtimeInput.entityInputs = [];

    // SECURITY: Resource limits (include queued + new inputs)
    if (queuedRuntimeTxs.length + runtimeInput.runtimeTxs.length > 1000) {
      log.error(`âŒ Too many runtime transactions: ${queuedRuntimeTxs.length + runtimeInput.runtimeTxs.length} > 1000`);
      return { entityOutbox: [], mergedInputs: [] };
    }
    if (queuedEntityInputs.length + runtimeInput.entityInputs.length > 10000) {
      log.error(`âŒ Too many entity inputs: ${queuedEntityInputs.length + runtimeInput.entityInputs.length} > 10000`);
      return { entityOutbox: [], mergedInputs: [] };
    }

    // FINTECH-LEVEL TYPE SAFETY: Validate all inputs BEFORE mutating env
    // Clone inputs to avoid mutating caller's data
    const validatedRuntimeTxs = [...runtimeInput.runtimeTxs];
    const validatedEntityInputs = [...runtimeInput.entityInputs];
    
    // Validate entity inputs before merging
    validatedEntityInputs.forEach((input, i) => {
      try {
        validateEntityInput(input);
      } catch (error) {
        logError("RUNTIME_TICK", `ðŸš¨ CRITICAL FINANCIAL ERROR: Invalid EntityInput[${i}] before merge!`, {
          error: (error as Error).message,
          input
        });
        throw error; // Fail fast
      }
    });

    const mergedRuntimeTxs = [...queuedRuntimeTxs, ...validatedRuntimeTxs];
    const mergedEntityInputs = [...queuedEntityInputs, ...validatedEntityInputs];

    // Merge all entityInputs (already validated above)
    const mergedInputs = mergeEntityInputs(mergedEntityInputs);

    const entityOutbox: EntityInput[] = [];
    const jOutbox: JInput[] = []; // Collect J-outputs from entities

    // Process runtime transactions (handle async operations properly)
    for (const runtimeTx of mergedRuntimeTxs) {
      if (runtimeTx.type === 'createXlnomy') {
        console.log(`[Runtime] Creating Xlnomy "${runtimeTx.data.name}"...`);

        try {
          const { createXlnomy } = await import('./jurisdiction-factory.js');
          const xlnomy = await createXlnomy({
            name: runtimeTx.data.name,
            evmType: runtimeTx.data.evmType,
            rpcUrl: runtimeTx.data.rpcUrl,
            blockTimeMs: runtimeTx.data.blockTimeMs,
            autoGrid: runtimeTx.data.autoGrid,
            env, // Pass env so grid entities get added to runtime
          });

          if (xlnomy.evmType === 'browservm' && xlnomy.contracts?.depositoryAddress) {
            setBrowserVMJurisdiction(xlnomy.contracts.depositoryAddress, xlnomy.evm);
          }

          // Initialize jReplicas Map if it doesn't exist
          if (!env.jReplicas) {
            env.jReplicas = new Map();
          }

          // Capture initial stateRoot from EVM (for time travel)
          let stateRoot = new Uint8Array(32);
          if (xlnomy.evm?.captureStateRoot) {
            try {
              stateRoot = await xlnomy.evm.captureStateRoot();
              console.log(`[Runtime] Captured initial stateRoot: ${Buffer.from(stateRoot).toString('hex').slice(0, 16)}...`);
            } catch (e) {
              console.warn(`[Runtime] Could not capture stateRoot: ${e}`);
            }
          }

          // Create JReplica from Xlnomy
          const jReplica: JReplica = {
            name: xlnomy.name,
            blockNumber: BigInt(xlnomy.jMachine.jHeight),
            stateRoot,
            mempool: xlnomy.jMachine.mempool || [],
            blockDelayMs: 300,             // 300ms delay before processing mempool
            lastBlockTimestamp: env.timestamp,  // Use env.timestamp for determinism
            position: xlnomy.jMachine.position,
            contracts: xlnomy.contracts ? {
              depository: xlnomy.contracts.depositoryAddress || (xlnomy.contracts as any).depository,
              entityProvider: xlnomy.contracts.entityProviderAddress || (xlnomy.contracts as any).entityProvider,
            } : undefined,
          };
          env.jReplicas.set(xlnomy.name, jReplica);

          // Set as active if it's the first one
          if (!env.activeJurisdiction) {
            env.activeJurisdiction = xlnomy.name;
          }

          console.log(`[Runtime] âœ… JReplica "${xlnomy.name}" created`);
          console.log(`[Runtime] Grid entities queued in runtimeInput: ${mergedRuntimeTxs.length} txs`);
          console.log(`[Runtime] Active Jurisdiction: ${env.activeJurisdiction}`);
        } catch (error) {
          console.error(`[Runtime] âŒ Failed to create Xlnomy:`, error);
        }
      } else if (runtimeTx.type === 'importReplica') {
        if (DEBUG)
          console.log(
            `Importing replica Entity #${formatEntityDisplay(runtimeTx.entityId)}:${formatSignerDisplay(runtimeTx.signerId)} (proposer: ${runtimeTx.data.isProposer})`,
          );

        const replicaKey = `${runtimeTx.entityId}:${runtimeTx.signerId}`;
        const replica: EntityReplica = {
          entityId: runtimeTx.entityId,
          signerId: runtimeTx.signerId,
          mempool: [],
          isProposer: runtimeTx.data.isProposer,
          state: {
            entityId: runtimeTx.entityId, // Store entityId in state
            height: 0,
            timestamp: env.timestamp,
            nonces: new Map(),
            messages: [],
            proposals: new Map(),
            config: runtimeTx.data.config,
            // ðŸ’° Initialize financial state
            reserves: new Map(), // tokenId -> bigint amount
            accounts: new Map(), // counterpartyEntityId -> AccountMachine
            deferredAccountProposals: new Map(),

            // ðŸ”­ J-machine tracking (JBlock consensus)
            lastFinalizedJHeight: 0,
            jBlockObservations: [],
            jBlockChain: [],

            // â° Crontab system - will be initialized on first use
            crontabState: undefined,

            // ðŸ“¦ J-Batch system - will be initialized on first use
            jBatchState: undefined,

            // ðŸ”’ HTLC routing and fee tracking
            htlcRoutes: new Map(),
            htlcFeesEarned: 0n,

            // ðŸ“– Aggregated books (E-Machine view of A-Machine positions)
            swapBook: new Map(),
            lockBook: new Map(),
            pendingSwapFillRatios: new Map(),
          },
        };

        // ðŸ” Generate crypto keys for HTLC envelope encryption
        const { NobleCryptoProvider } = await import('./crypto-noble');
        const crypto = new NobleCryptoProvider();
        const { publicKey, privateKey } = await crypto.generateKeyPair();
        replica.state.cryptoPublicKey = publicKey;
        replica.state.cryptoPrivateKey = privateKey;

        // Only add position if it exists (exactOptionalPropertyTypes compliance)
        if (runtimeTx.data.position) {
          replica.position = {
            ...runtimeTx.data.position,
            jurisdiction: runtimeTx.data.position.jurisdiction || runtimeTx.data.position.xlnomy || env.activeJurisdiction || 'default',
          };
        }

        env.eReplicas.set(replicaKey, replica);

        const browserVM = getBrowserVMInstance(env);
        if (browserVM) {
          const validators = runtimeTx.data.config.validators;
          const threshold = runtimeTx.data.config.threshold;
          if (validators.length === 1 && threshold === 1n) {
            const signerId = validators[0];
            try {
              const privateKey = getSignerPrivateKey(env, signerId);
              const privateKeyHex = `0x${Array.from(privateKey).map(b => b.toString(16).padStart(2, '0')).join('')}`;
              if (typeof browserVM.registerEntityWallet === 'function') {
                browserVM.registerEntityWallet(runtimeTx.entityId, privateKeyHex);
              } else {
                console.warn(`âš ï¸ BrowserVM missing registerEntityWallet - skipping wallet registration for ${runtimeTx.entityId.slice(0, 10)}...`);
              }
            } catch (error) {
              console.warn(`âš ï¸ Cannot derive private key for signer ${signerId} (no env.runtimeSeed), skipping BrowserVM wallet registration`);
            }
          }
        }

        // Ensure entity-level signing key exists for this runtime (needed for gossip public key)
        if (runtimeSeed) {
          try {
            const seedBytes = new TextEncoder().encode(runtimeSeed);
            const entityKey = deriveSignerKeySync(seedBytes, runtimeTx.entityId);
            registerSignerKey(runtimeTx.entityId, entityKey);
          } catch (error) {
            console.warn(`âš ï¸ Failed to derive entity key for ${runtimeTx.entityId.slice(0, 10)}:`, error);
          }
        }

        // Validate jBlock immediately after creation
        const createdReplica = env.eReplicas.get(replicaKey);
        const actualJBlock = createdReplica?.state.lastFinalizedJHeight;
        // REPLICA-DEBUG removed

        // Broadcast initial profile to gossip layer
        if (env.gossip && createdReplica) {
          const entityPublicKey = getSignerPublicKey(env, runtimeTx.entityId);
          const publicKeyHex = entityPublicKey ? `0x${Buffer.from(entityPublicKey).toString('hex')}` : undefined;
          const profile = buildEntityProfile(createdReplica.state, undefined, env.timestamp);
          profile.runtimeId = env.runtimeId;
          if (publicKeyHex) {
            profile.metadata = { ...(profile.metadata || {}), entityPublicKey: publicKeyHex };
          }
          env.gossip.announce(profile);
        }

        if (typeof actualJBlock !== 'number') {
          logError("RUNTIME_TICK", `ðŸ’¥ ENTITY-CREATION-BUG: Just created entity with invalid jBlock!`);
          logError("RUNTIME_TICK", `ðŸ’¥   Expected: 0 (number), Got: ${typeof actualJBlock}, Value: ${actualJBlock}`);
          // Force fix immediately
          if (createdReplica) {
            createdReplica.state.lastFinalizedJHeight = 0;
            console.log(`ðŸ’¥   FIXED: Set jBlock to 0 for replica ${replicaKey}`);
          }
        }
      }
    }
    // REPLICA-DEBUG and SERVER-PROCESSING logs removed
    for (const entityInput of mergedInputs) {
      // Track j-events in this input - entityInput.entityTxs guaranteed by validateEntityInput above
      // J-EVENT logging removed - too verbose

      // Handle empty signerId for AccountInputs - auto-route to proposer
      let actualSignerId = entityInput.signerId;
      if (!actualSignerId || actualSignerId === '') {
        // Check if this is an AccountInput that needs auto-routing
        const hasAccountInput = entityInput.entityTxs!.some(tx => tx.type === 'accountInput');
        if (hasAccountInput) {
          // Find the proposer for this entity
          const entityReplicaKeys = Array.from(env.eReplicas.keys()).filter(key => key.startsWith(entityInput.entityId + ':'));
          if (entityReplicaKeys.length > 0) {
            const firstReplicaKey = entityReplicaKeys[0];
            if (!firstReplicaKey) {
              logError("RUNTIME_TICK", `âŒ Invalid replica key for entity ${entityInput.entityId}`);
              continue;
            }
            const firstReplica = env.eReplicas.get(firstReplicaKey);
            if (firstReplica?.state.config.validators[0]) {
              actualSignerId = firstReplica.state.config.validators[0];
              // AUTO-ROUTE log removed
            }
          }
        }

        // Fallback if still no signerId
        if (!actualSignerId || actualSignerId === '') {
          console.warn(`âš ï¸ No signerId and unable to determine proposer for entity ${entityInput.entityId.slice(0,10)}...`);
          continue; // Skip this input
        }
      }

      const replicaKey = `${entityInput.entityId}:${actualSignerId}`;
      const entityReplica = env.eReplicas.get(replicaKey);

      // REPLICA-LOOKUP logs removed - not consensus-critical

      if (entityReplica) {
        if (DEBUG) {
          console.log(`Processing input for ${replicaKey}:`);
          if (entityInput.entityTxs?.length) console.log(`  â†’ ${entityInput.entityTxs.length} transactions`);
          if (entityInput.proposedFrame) console.log(`  â†’ Proposed frame: ${entityInput.proposedFrame.hash}`);
          if (entityInput.precommits?.size) console.log(`  â†’ ${entityInput.precommits.size} precommits`);
        }

        const { newState, outputs, jOutputs, workingReplica } = await applyEntityInput(env, entityReplica, entityInput);
        // APPLY-ENTITY-INPUT-RESULT removed - too noisy

        // IMMUTABILITY: Update replica with new state from applyEntityInput
        // CRITICAL: Preserve proposal/lockedFrame from workingReplica (multi-signer consensus)
        // Only cleared when threshold reached and frame committed (handled in entity-consensus.ts)
        env.eReplicas.set(replicaKey, {
          ...entityReplica,
          state: newState,
          mempool: workingReplica.mempool, // Preserve mempool state
          proposal: workingReplica.proposal, // CRITICAL: Preserve for multi-signer threshold
          lockedFrame: workingReplica.lockedFrame, // CRITICAL: Preserve validator locks
          sentTransitions: workingReplica.sentTransitions ?? 0, // Preserve counter
        });

        // FINTECH-LEVEL TYPE SAFETY: Validate all entity outputs before routing
        outputs.forEach((output, index) => {
          try {
            validateEntityOutput(output);
          } catch (error) {
            logError("RUNTIME_TICK", `ðŸš¨ CRITICAL FINANCIAL ERROR: Invalid EntityOutput[${index}] from ${replicaKey}!`, {
              error: (error as Error).message,
              output
            });
            throw error; // Fail fast to prevent financial routing corruption
          }
        });

        entityOutbox.push(...outputs);

        // Collect J-outputs (batch broadcasts)
        if (jOutputs && jOutputs.length > 0) {
          console.log(`ðŸ“¦ [2/6] Collecting ${jOutputs.length} jOutputs from ${replicaKey.slice(-10)}`);
          jOutbox.push(...jOutputs);
        }
        // ENTITY-OUTBOX log removed - too noisy
      }
    }

    // Process J-outputs BEFORE creating frame (queue to J-mempool)
    if (jOutbox.length > 0) {
      console.log(`ðŸ“¤ [3/6] J-OUTPUTS: ${jOutbox.length} J-outputs collected â†’ routing to J-mempools`);

      for (const jInput of jOutbox) {
        const jReplica = env.jReplicas?.get(jInput.jurisdictionName);
        if (!jReplica) {
          console.error(`âŒ J-Output: Jurisdiction "${jInput.jurisdictionName}" not found`);
          continue;
        }

        // Queue JTxs to J-mempool (PROPER ROUTING)
        for (const jTx of jInput.jTxs) {
          // Mark when queued (for minimum 1-tick visualization delay)
          const jTxWithQueueTime = { ...jTx, queuedAt: env.timestamp };
          jReplica.mempool.push(jTxWithQueueTime);
          console.log(`ðŸ“¥ [4/6] J-Output: Queued ${jTx.type} from ${jTx.entityId.slice(-4)} to ${jInput.jurisdictionName} mempool (queuedAt: ${env.timestamp}, mempool.length: ${jReplica.mempool.length})`);

          // Emit event when actually queued
          env.emit('JBatchQueued', {
            entityId: jTx.entityId,
            batchSize: jTx.data.batchSize,
            mempoolSize: jReplica.mempool.length,
            jurisdictionName: jInput.jurisdictionName,
          });
        }

        console.log(`âœ… J-Output: ${jInput.jTxs.length} txs queued to ${jInput.jurisdictionName} (mempool: ${jReplica.mempool.length})`);
      }
    }

    // Only create runtime frame if there's actual work to do
    const hasRuntimeTxs = mergedRuntimeTxs.length > 0;
    const hasEntityInputs = mergedInputs.length > 0;
    const hasOutputs = entityOutbox.length > 0;
    const hasJOutputs = jOutbox.length > 0;

    if (hasRuntimeTxs || hasEntityInputs || hasOutputs || hasJOutputs) {
      // Emit runtime tick event
      env.emit('RuntimeTick', {
        height: env.height + 1,
        runtimeTxs: mergedRuntimeTxs.length,
        entityInputs: mergedInputs.length,
        outputs: entityOutbox.length,
      });

      // Update env (mutable)
      env.height++;
      // Don't overwrite timestamp in scenario mode (deterministic time control)
      if (!env.scenarioMode) {
        env.timestamp = getWallClockMs();
      }

      // Capture snapshot BEFORE clearing (to show what was actually processed)
      const inputDescription = `Tick ${env.height - 1}: ${mergedRuntimeTxs.length} runtimeTxs, ${mergedInputs.length} merged entityInputs â†’ ${entityOutbox.length} outputs`;
      const processedInput = {
        runtimeTxs: [...mergedRuntimeTxs],
        entityInputs: [...mergedInputs], // Use merged inputs instead of raw inputs
      };

      // CRITICAL: Update JReplica stateRoots from BrowserVM BEFORE snapshot
      // Without this, time-travel shows stale EVM state from xlnomy creation
      const browserVM = getBrowserVMInstance(env);
      if (browserVM?.captureStateRoot && env.jReplicas) {
        try {
          const freshStateRoot = await browserVM.captureStateRoot();
          for (const [name, jReplica] of env.jReplicas.entries()) {
            jReplica.stateRoot = freshStateRoot;
          }
        } catch (e) {
          // Silent fail - stateRoot capture is optional for time-travel
        }
      }

      // CRITICAL: Sync collaterals and blockNumber from BrowserVM BEFORE snapshot
      if (browserVM?.syncAllCollaterals && env.jReplicas && env.eReplicas) {
        try {
          // Collect all account pairs from all entities
          const accountPairs: Array<{ entityId: string; counterpartyId: string }> = [];
          for (const [replicaKey, replica] of env.eReplicas.entries()) {
            if (replica.state.accounts) {
              for (const [counterpartyId, _account] of replica.state.accounts) {
                const entityId = replicaKey.split(':')[0];
                accountPairs.push({ entityId, counterpartyId });
              }
            }
          }

          // Sync all collaterals from BrowserVM (for now, just tokenId 1 = USDC)
          const collaterals = await browserVM.syncAllCollaterals(accountPairs, 1);

          // Get current block height from BrowserVM
          const blockHeight = browserVM.getBlockHeight ? browserVM.getBlockHeight() : 0;

          // Update JReplica with synced data
          for (const [name, jReplica] of env.jReplicas.entries()) {
            jReplica.collaterals = collaterals;
            jReplica.blockNumber = BigInt(blockHeight);
          }
        } catch (e) {
          // Silent fail - collaterals sync is optional for debugging
          console.warn('[Runtime] Failed to sync BrowserVM state:', e);
        }
      }

      // NOTE: Snapshot creation moved to process() - single entry point
      // applyRuntimeInput just processes inputs, process() handles snapshotting
    } else {
      console.log(`âšª SKIP-FRAME: No runtimeTxs, entityInputs, or outputs`);
      // Clear env.extra even when skipping frame to prevent stale solvency expectations
      env.extra = undefined;
    }

    // Notify Svelte about environment changes
    // REPLICA-DEBUG and GOSSIP-DEBUG removed
    
    // CRITICAL FIX: Initialize gossip layer if missing
    if (!env.gossip) {
      console.log(`ðŸš¨ CRITICAL: gossip layer missing from environment, creating new one`);
      env.gossip = createGossipLayer();
      console.log(`âœ… Gossip layer created and added to environment`);
    }

    // Compare old vs new entities
    const oldEntityKeys = Array.from(env.eReplicas.keys()).filter(
      key =>
        key.startsWith('0x0000000000000000000000000000000000000000000000000000000000000001:') ||
        key.startsWith('0x0000000000000000000000000000000000000000000000000000000000000002:'),
    );
    const newEntityKeys = Array.from(env.eReplicas.keys()).filter(
      key =>
        !key.startsWith('0x0000000000000000000000000000000000000000000000000000000000000001:') &&
        !key.startsWith('0x0000000000000000000000000000000000000000000000000000000000000002:') &&
        !key.startsWith('0x57e360b00f393ea6d898d6119f71db49241be80aec0fbdecf6358b0103d43a31:'),
    );

    // OLD/NEW-ENTITY-DEBUG removed - too noisy

    if (oldEntityKeys.length > 0 && newEntityKeys.length > 0) {
      const oldReplicaKey = oldEntityKeys[0];
      const newReplicaKey = newEntityKeys[0];
      if (!oldReplicaKey || !newReplicaKey) {
        logError("RUNTIME_TICK", `âŒ Invalid replica keys: old=${oldReplicaKey}, new=${newReplicaKey}`);
        // Continue with empty outbox instead of crashing
      } else {
      // REPLICA-STRUCTURE logs removed - not consensus-critical
      }
    }

    notifyEnvChange(env);

    if (DEBUG && entityOutbox.length > 0) {
      console.log(`ðŸ“¤ Outputs: ${entityOutbox.length} messages`);
      entityOutbox.forEach((output, i) => {
        console.log(
          `  ${i + 1}. â†’ ${output.signerId} (${output.entityTxs ? `${output.entityTxs.length} txs` : ''}${output.proposedFrame ? ` proposal: ${output.proposedFrame.hash.slice(0, 10)}...` : ''}${output.precommits ? ` ${output.precommits.size} precommits` : ''})`,
        );
      });
    } else if (DEBUG && entityOutbox.length === 0) {
      console.log(`ðŸ“¤ No outputs generated`);
    }

    // Replica states dump removed - too verbose

    // Always notify UI after processing a frame (this is the discrete simulation step)
    notifyEnvChange(env);

    // Performance logging
    const endTime = getPerfMs();
    if (DEBUG) {
      console.log(`â±ï¸  Tick ${env.height - 1} completed in ${endTime - startTime}ms`);
    }

    // APPLY-SERVER-INPUT-FINAL-RETURN removed
    return { entityOutbox, mergedInputs };
  } catch (error) {
    console.error(`âŒ CRITICAL: applyRuntimeInput failed!`, error);
    throw error; // Don't swallow - fail fast and loud
  }
};

// This is the new, robust main function that replaces the old one.
const main = async (): Promise<Env> => {
  console.log(`ðŸš€ RUNTIME.JS VERSION: ${RUNTIME_BUILD_ID}`);

  // Open database before any operations
  const dbReady = await tryOpenDb();

  // DEBUG: Log jurisdictions content on startup using centralized loader
  if (!isBrowser) {
    try {
      const { loadJurisdictions } = await import('./jurisdiction-loader');
      const jurisdictions = loadJurisdictions();
      console.log('ðŸ” STARTUP: Current jurisdictions content (from centralized loader):');
      console.log('ðŸ“ Arrakis Depository:', jurisdictions.jurisdictions['arrakis']?.contracts?.depository);
      console.log('ðŸ“ Arrakis EntityProvider:', jurisdictions.jurisdictions['arrakis']?.contracts?.entityProvider);
      console.log('ðŸ“ Last updated:', jurisdictions.lastUpdated);
      console.log('ðŸ“ Full Arrakis config:', safeStringify(jurisdictions.jurisdictions['arrakis']));
    } catch (error) {
      console.log('âš ï¸ Failed to load jurisdictions:', (error as Error).message);
    }
  }

  // Initialize gossip layer
  console.log('ðŸ•¸ï¸ Initializing gossip layer...');
  const gossipLayer = createGossipLayer();
  console.log('âœ… Gossip layer initialized');

  // Load persisted profiles from database into gossip layer
  console.log('ðŸ“¡ Loading persisted profiles from database...');
  await loadPersistedProfiles(db, gossipLayer);

  // First, create default environment with gossip layer and event emitters
  env = createEmptyEnv(runtimeSeed);
  env.gossip = gossipLayer; // Override default gossip with persisted profiles

  // Try to load saved state from database
  try {
    if (!dbReady) {
      console.log('ðŸ’¾ Database unavailable - starting fresh');
      throw new Error('DB_UNAVAILABLE');
    }

    console.log('ðŸ“¥ Loading state from database...');
    const latestHeightBuffer = await withTimeout(db.get(Buffer.from('latest_height')), 2000);

    const latestHeight = parseInt(latestHeightBuffer.toString(), 10);
    console.log(`ðŸ“Š BROWSER-DEBUG: Found latest height in DB: ${latestHeight}`);

    console.log(`ðŸ“Š Found latest height: ${latestHeight}, loading ${latestHeight + 1} snapshots...`);

    // Load snapshots starting from 1 (height 0 is initial state, no snapshot saved)
    console.log(`ðŸ“¥ Loading snapshots: 1 to ${latestHeight}...`);
    const snapshots = [];

    // Start from 1 since height 0 is initial state with no snapshot
    for (let i = 1; i <= latestHeight; i++) {
      try {
        const buffer = await db.get(Buffer.from(`snapshot:${i}`));
        const snapshot = decode(buffer);
        snapshots.push(snapshot);
        console.log(`ðŸ“¦ Snapshot ${i}: loaded ${buffer.length} bytes`);
      } catch (error) {
        logError("RUNTIME_TICK", `âŒ Failed to load snapshot ${i}:`, error);
        console.warn(`âš ï¸ Snapshot ${i} missing, continuing with available data...`);
      }
    }

    if (snapshots.length === 0) {
      console.log(`ðŸ“¦ No snapshots found (latestHeight: ${latestHeight}), using fresh environment`);
      throw new Error('LEVEL_NOT_FOUND');
    }

    console.log(`ðŸ“Š Successfully loaded ${snapshots.length}/${latestHeight} snapshots (starting from height 1)`);
    env.history = snapshots;

    if (snapshots.length > 0) {
      const latestSnapshot = snapshots[snapshots.length - 1];

      // CRITICAL: Validate snapshot has proper eReplicas data
      if (!latestSnapshot.eReplicas) {
        console.warn('âš ï¸ Latest snapshot missing eReplicas data, using fresh environment');
        throw new Error('LEVEL_NOT_FOUND');
      }

      // Restore gossip profiles from snapshot
      const gossipLayer = createGossipLayer();
      if (latestSnapshot.gossip?.profiles) {
        for (const [id, profile] of Object.entries(latestSnapshot.gossip.profiles)) {
          gossipLayer.profiles.set(id, profile as Profile);
        }
        console.log(`ðŸ“¡ Restored gossip profiles: ${Object.keys(latestSnapshot.gossip.profiles).length} entries`);
      }

      // CRITICAL: Convert eReplicas to proper Map if needed (handle deserialization from DB)
      let eReplicasMap: Map<string, EntityReplica>;
      try {
        if (latestSnapshot.eReplicas instanceof Map) {
          eReplicasMap = latestSnapshot.eReplicas;
        } else if (latestSnapshot.eReplicas && typeof latestSnapshot.eReplicas === 'object') {
          // Deserialized from DB - convert object to Map
          eReplicasMap = new Map(Object.entries(latestSnapshot.eReplicas));
        } else {
          console.warn('âš ï¸ Invalid eReplicas format in snapshot, using fresh environment');
          throw new Error('LEVEL_NOT_FOUND');
        }
      } catch (conversionError) {
        logError("RUNTIME_TICK", 'âŒ Failed to convert eReplicas to Map:', conversionError);
        console.warn('âš ï¸ Falling back to fresh environment');
        throw new Error('LEVEL_NOT_FOUND');
      }

      // Convert jReplicas array to Map
      const jReplicasMap = new Map<string, JReplica>();
      if (latestSnapshot.jReplicas) {
        for (const jr of latestSnapshot.jReplicas) {
          jReplicasMap.set(jr.name, {
            ...jr,
            stateRoot: new Uint8Array(jr.stateRoot), // Ensure proper Uint8Array
          });
        }
      }

      // Create env with proper event emitters, then populate from snapshot
      const snapshotSeed = latestSnapshot.runtimeSeed || null;
      env = createEmptyEnv(snapshotSeed);
      if (snapshotSeed) {
        runtimeSeed = snapshotSeed;
        setCryptoRuntimeSeed(runtimeSeed);
      }
      if (latestSnapshot.runtimeId) {
        runtimeId = latestSnapshot.runtimeId;
        env.runtimeId = runtimeId;
      } else if (runtimeSeed) {
        try {
          runtimeId = deriveSignerAddressSync(runtimeSeed, '1');
          env.runtimeId = runtimeId;
        } catch (error) {
          console.warn('âš ï¸ Failed to derive runtimeId on restore:', error);
        }
      }
      // CRITICAL: Clone the eReplicas Map to avoid mutating snapshot data!
      env.eReplicas = new Map(Array.from(eReplicasMap).map(([key, replica]): [string, EntityReplica] => {
        return [key, cloneEntityReplica(replica)];
      }));
      env.jReplicas = jReplicasMap;
      env.height = latestSnapshot.height;
      env.timestamp = latestSnapshot.timestamp;
      // CRITICAL: runtimeInput must start EMPTY on restore!
      // The snapshot's runtimeInput was already processed
      env.runtimeInput = {
        runtimeTxs: [],
        entityInputs: []
      };
      env.history = snapshots; // Include the loaded history
      env.gossip = gossipLayer; // Use restored gossip layer
      env.frameLogs = [];
      console.log(`âœ… History restored. Runtime is at height ${env.height} with ${env.history.length} snapshots.`);
      console.log(`ðŸ“ˆ Snapshot details:`, {
        height: env.height,
        replicaCount: env.eReplicas.size,
        timestamp: new Date(env.timestamp).toISOString(),
        runtimeInputs: env.runtimeInput.entityInputs.length,
      });
    }
  } catch (error) {
    const isTimeout = error instanceof Error && error.message === 'TIMEOUT';
    const isNotFound = error instanceof Error &&
      (error.name === 'NotFoundError' ||
       error.message?.includes('NotFoundError') ||
       error.message?.includes('Entry not found'));

    if (isTimeout || isNotFound) {
      console.log('ðŸ“¦ No saved state found - starting fresh');
    } else if (error instanceof Error && error.message === 'DB_UNAVAILABLE') {
      // Already logged above
    } else {
      console.warn('âš ï¸ Error loading state:', error instanceof Error ? error.message : error);
      console.log('ðŸ“¦ Starting fresh');
    }
  }

  // Demo profiles are only initialized during runDemo - not by default

  // Only run demos in Node.js environment, not browser
  if (!isBrowser) {
    // DISABLED: Hanko tests during development
    console.log('\nðŸš€ Hanko tests disabled during development - focusing on core functionality');
    
    // // Add hanko demo to the main execution
    // console.log('\nðŸ–‹ï¸  Testing Complete Hanko Implementation...');
    // await demoCompleteHanko();

    // // ðŸ§ª Run basic Hanko functionality tests first
    // console.log('\nðŸ§ª Running basic Hanko functionality tests...');
    // await runBasicHankoTests();

    // // ðŸ§ª Run comprehensive Depository-Hanko integration tests
    // console.log('\nðŸ§ª Running comprehensive Depository-Hanko integration tests...');
    // try {
    //   await runDepositoryHankoTests();
    // } catch (error) {
    //   console.log(
    //     'â„¹ï¸  Depository integration tests skipped (contract setup required):',
    //     (error as Error).message?.substring(0, 100) || 'Unknown error',
    //   );
    // }
  } else {
    console.log('ðŸŒ Browser environment: Demos available via UI buttons, not auto-running');
  }

  log.info(`ðŸŽ¯ Runtime startup complete. Height: ${env.height}, Entities: ${env.eReplicas.size}`);

  // Debug final state before starting j-watcher
  if (isBrowser) {
    if (HEAVY_LOGS) console.log(`ðŸ” BROWSER-DEBUG: Final state before j-watcher start:`);
    if (HEAVY_LOGS) console.log(`ðŸ”   Environment height: ${env.height}`);
    if (HEAVY_LOGS) console.log(`ðŸ”   Total replicas: ${env.eReplicas.size}`);
    for (const [replicaKey, replica] of env.eReplicas.entries()) {
      const { entityId, signerId } = parseReplicaKey(replicaKey);
      if (HEAVY_LOGS) console.log(`ðŸ”   Entity ${entityId.slice(0,10)}... (${signerId}): jBlock=${replica.state.lastFinalizedJHeight}, isProposer=${replica.isProposer}`);
    }
  }

  // DISABLED: J-watcher temporarily disabled (external RPC not needed for demo)
  // Re-enable by uncommenting this block when blockchain integration is needed
  /*
  if (!jWatcherStarted) {
    console.log('ðŸ”­ STARTING-JWATCHER: Snapshots loaded, starting j-watcher (non-blocking)...');

    Promise.race([
      startJEventWatcher(env),
      new Promise((_, reject) => setTimeout(() => reject(new Error('J-watcher startup timeout (3s)')), 3000))
    ])
      .then(() => {
        jWatcherStarted = true;
        console.log('ðŸ”­ JWATCHER-READY: J-watcher started successfully');
      })
      .catch((error) => {
        console.warn('âš ï¸  J-Event Watcher startup failed or timed out (non-critical):', error.message);
        console.warn('    UI will load anyway. Blockchain sync will retry in background.');
      });
  } else {
    console.log('ðŸ”­ JWATCHER-SKIP: J-watcher already started, skipping');
  }
  */
  console.log('ðŸ”­ J-WATCHER: Disabled (external RPC not needed for simnet demo)');

  return env;
};

// === TIME MACHINE API ===
const getHistory = () => env.history || [];
const getSnapshot = (index: number) => {
  const history = env.history || [];
  return index >= 0 && index < history.length ? history[index] : null;
};
const getCurrentHistoryIndex = () => (env.history || []).length - 1;

// === SYSTEM SOLVENCY CHECK ===
// Total tokens in system: reserves + collateral must equal minted supply
interface Solvency {
  reserves: bigint;
  collateral: bigint;
  total: bigint;
  byToken: Map<number, { reserves: bigint; collateral: bigint; total: bigint }>;
}

const calculateSolvency = (snapshot?: Env): Solvency => {
  const targetEnv = snapshot || env;
  const byToken = new Map<number, { reserves: bigint; collateral: bigint; total: bigint }>();

  let reserves = 0n;
  let collateral = 0n;

  for (const [_replicaKey, replica] of targetEnv.eReplicas) {
    // Sum reserves
    for (const [tokenId, amount] of replica.state.reserves) {
      reserves += amount;
      const existing = byToken.get(tokenId) || { reserves: 0n, collateral: 0n, total: 0n };
      existing.reserves += amount;
      existing.total = existing.reserves + existing.collateral;
      byToken.set(tokenId, existing);
    }

    // Sum collateral (left entity only to avoid double-counting)
    for (const [counterpartyId, account] of replica.state.accounts) {
      if (isLeftEntity(replica.state.entityId, counterpartyId)) {
        for (const [tokenId, delta] of account.deltas) {
          collateral += delta.collateral;
          const existing = byToken.get(tokenId) || { reserves: 0n, collateral: 0n, total: 0n };
          existing.collateral += delta.collateral;
          existing.total = existing.reserves + existing.collateral;
          byToken.set(tokenId, existing);
        }
      }
    }
  }

  return { reserves, collateral, total: reserves + collateral, byToken };
};

const verifySolvency = (expected?: bigint, label?: string): boolean => {
  const s = calculateSolvency();
  const prefix = label ? `[${label}] ` : '';

  if (expected !== undefined && s.total !== expected) {
    console.error(`âŒ ${prefix}SOLVENCY VIOLATION: Expected ${expected}, got ${s.total}`);
    console.error(`   Reserves: ${s.reserves}, Collateral: ${s.collateral}`);
    throw new Error(`Solvency check failed: ${s.total} !== ${expected}`);
  }

  console.log(`âœ… ${prefix}Solvency: ${s.total} (R:${s.reserves} + C:${s.collateral})`);
  return true;
};

// Server-specific clearDatabase that also resets history
const clearDatabaseAndHistory = async () => {
  console.log('ðŸ—‘ï¸ Clearing database and resetting runtime history...');

  // Clear the Level database
  await clearDatabase(db);

  // Reset the runtime environment to initial state (including history)
  env = {
    eReplicas: new Map(),
    jReplicas: new Map(),
    height: 0,
    timestamp: 0,
    ...(runtimeSeed ? { runtimeSeed } : {}),
    ...(runtimeId ? { runtimeId } : {}),
    runtimeInput: { runtimeTxs: [], entityInputs: [] },
    history: [],
    gossip: createGossipLayer(),
    frameLogs: [],
  };

  console.log('âœ… Database and runtime history cleared');
};

// Export j-watcher status for frontend display
export const getJWatcherStatus = () => {
  if (!jWatcher || !env) return null;
  return {
    isWatching: jWatcher.getStatus().isWatching,
    proposers: Array.from(env.eReplicas.entries())
      .filter(([, replica]) => replica.isProposer)
      .map(([key, replica]) => {
        const { entityId, signerId } = parseReplicaKey(key);
        return {
          entityId: entityId.slice(0,10) + '...',
          signerId,
          lastFinalizedJHeight: replica.state.lastFinalizedJHeight,
        };
      }),
    nextSyncIn: Math.floor((1000 - ((env.timestamp || 0) % 1000)) / 100) / 10, // Seconds until next 1s sync
  };
};

export {
  applyRuntimeInput,
  assignNameOnChain,
  clearDatabase,
  classifyBilateralState,
  getAccountBarVisual,
  clearDatabaseAndHistory,
  // Clean logs: getCleanLogs, clearCleanLogs, copyCleanLogs - exported at definition
  connectToEthereum,
  // Entity creation functions
  createLazyEntity,
  createNumberedEntity,
  createNumberedEntitiesBatch,
  createProfileUpdateTx,
  demoCompleteHanko,
  detectEntityType,
  encodeBoard,
  // Display and avatar functions
  formatEntityDisplay,
  formatSignerDisplay,
  generateEntityAvatar,
  // Entity utility functions
  generateLazyEntityId,
  generateNamedEntityId,
  generateNumberedEntityId,
  generateSignerAvatar,
  getAvailableJurisdictions,
  getCurrentHistoryIndex,
  getEntityDisplayInfo,
  getEntityDisplayInfoFromProfile,
  getEntityInfoFromChain,
  getHistory,
  getJurisdictionByAddress,
  getNextEntityNumber,
  getSignerDisplayInfo,
  getSnapshot,
  hashBoard,
  isEntityRegistered,
  main,
  startJEventWatcher,
  // Blockchain registration functions
  registerNumberedEntityOnChain,
  requestNamedEntity,
  resolveEntityIdentifier,
  resolveEntityName,
  // Name resolution functions
  searchEntityNames,
  setBrowserVMJurisdiction,
  getBrowserVMInstance,
  // getEnv, initEnv, processJBlockEvents - already exported inline above
  submitProcessBatch,
  submitPrefundAccount,
  submitSettle,
  submitReserveToReserve,
  debugFundReserves,
  transferNameBetweenEntities,
  // Account utilities (destructured from AccountUtils)
  deriveDelta,
  isLeft,
  getTokenInfo,
  formatTokenAmount,
  createDemoDelta,
  getDefaultCreditLimit,

  // Entity utilities (from entity-helpers and serialization-utils)
  getEntityShortId,
  getEntityNumber, // deprecated, use getEntityShortId
  formatEntityId,
  safeStringify,

  // Financial utilities (ethers.js-based, precision-safe)
  formatTokenAmountEthers,
  parseTokenAmount,
  convertTokenPrecision,
  calculatePercentageEthers,
  formatAssetAmountEthers,
  BigIntMath,
  FINANCIAL_CONSTANTS,

  // Validation utilities (strict typing for financial data)
  validateDelta,
  validateAccountDeltas,
  createDefaultDelta,
  isDelta,

  // Snapshot utilities
  encode,
  decode,

  // System solvency (conservation of tokens)
  calculateSolvency,
  verifySolvency,

  // Identity system (from ids.ts) - replaces split(':') patterns
  parseReplicaKey,
  extractEntityId,
  extractSignerId,
  formatReplicaKey,
  createReplicaKey,
  formatReplicaDisplay,
  // Type guards
  isValidEntityId,
  isValidSignerId,
  isValidJId,
  isValidEpAddress,
  // Constructors
  toEntityId,
  toSignerId,
  toJId,
  toEpAddress,
  // Entity type detection
  isNumberedEntity,
  isLazyEntity,
  getEntityDisplayNumber,
  // URI operations (for future networking)
  formatReplicaUri,
  parseReplicaUri,
  createLocalUri,
  // Type-safe collections
  ReplicaMap,
  EntityMap,
  // Jurisdiction helpers
  jIdFromChainId,
  createLazyJId,
  // Migration helpers
  safeParseReplicaKey,
  safeExtractEntityId,
  // Constants
  XLN_URI_SCHEME,
  DEFAULT_RUNTIME_HOST,
  XLN_COORDINATOR,
  CHAIN_IDS,
  MAX_NUMBERED_ENTITY,

  // Account messaging: Using bilateral frame-based consensus instead of direct messaging
  // (Old direct messaging functions removed - replaced with AccountInput flow)
};

// Re-export types from ids.ts for frontend use
export type {
  EntityId,
  SignerId,
  JId,
  EntityProviderAddress,
  ReplicaKey,
  FullReplicaAddress,
  ReplicaUri,
  JurisdictionInfo,
} from './ids';

// Runtime is a pure library - no auto-execution side effects.
// Use xln.ts as CLI entry point: `bun run xln.ts`
// Browser: index.html calls xln.main() explicitly

// === HANKO DEMO FUNCTION ===

const demoCompleteHanko = async (): Promise<void> => {
  try {
    // Check if running in browser environment
    const isBrowser = typeof window !== 'undefined';

    if (isBrowser) {
      console.log('ðŸŽ¯ Browser environment detected - running simplified Hanko demo...');
      console.log('âœ… Basic signature verification available');
      console.log('ðŸ’¡ Full test suite available in Node.js environment');
      console.log('âœ… Hanko browser demo completed!');
      return;
    }

    console.log('ðŸŽ¯ Complete Hanko test suite disabled during strict TypeScript mode');
    // await runCompleteHankoTests();
    console.log('âœ… Complete Hanko tests skipped!');
  } catch (error) {
    logError("RUNTIME_TICK", 'âŒ Complete Hanko tests failed:', error);
    throw error;
  }
};

// Demo wrapper removed - use scenarios.ahb(env) or scenarios.grid(env) instead

// === ENVIRONMENT UTILITIES ===
// Global reference to current env for log capturing
let currentEnvForLogs: Env | null = null;

export const createEmptyEnv = (seed?: Uint8Array | string | null): Env => {
  // Convert seed to proper format
  const seedBytes = seed !== undefined && seed !== null
    ? (typeof seed === 'string' ? new TextEncoder().encode(seed) : seed)
    : null;

  const env: Env = {
    eReplicas: new Map(),
    jReplicas: new Map(),
    height: 0,
    timestamp: 0,
    ...(seedBytes ? { runtimeSeed: seedBytes } : {}),
    ...(runtimeId ? { runtimeId } : {}),
    runtimeInput: { runtimeTxs: [], entityInputs: [] },
    history: [],
    gossip: createGossipLayer(),
    frameLogs: [],
    networkInbox: [],
    pendingNetworkOutputs: [],
    // Event emitters will be attached below
    log: () => {},
    info: () => {},
    warn: () => {},
    error: () => {},
    emit: () => {},
    // BrowserVM will be lazily initialized on first use (see evm.ts)
    browserVM: null,
  };

  // Attach event emission methods (EVM-style)
  attachEventEmitters(env);

  // Set as current env for log capturing
  currentEnvForLogs = env;

  return env;
};

// Intercept console for frame log capturing (browser only)
// TEMPORARILY DISABLED - debugging solvency regression
if (false && isBrowser) {
  const originalLog = console.log;
  const originalWarn = console.warn;
  const originalError = console.error;

  console.log = function(...args: any[]) {
    originalLog.apply(console, args);
    if (currentEnvForLogs) {
      try {
        const msg = args.map(a => {
          if (typeof a === 'string') return a;
          if (typeof a === 'bigint') return a.toString() + 'n';
          try { return JSON.stringify(a); } catch { return String(a); }
        }).join(' ');
        currentEnvForLogs.frameLogs.push({
          level: 'info',
          category: detectLogCategory(msg),
          message: msg,
          timestamp: currentEnvForLogs?.timestamp ?? 0,
        });
      } catch (e) {
        // Silently fail log capture - don't break runtime
      }
    }
  };

  console.warn = function(...args: any[]) {
    originalWarn.apply(console, args);
    if (currentEnvForLogs) {
      try {
        const msg = args.map(a => {
          if (typeof a === 'string') return a;
          if (typeof a === 'bigint') return a.toString() + 'n';
          try { return JSON.stringify(a); } catch { return String(a); }
        }).join(' ');
        currentEnvForLogs.frameLogs.push({
          level: 'warn',
          category: detectLogCategory(msg),
          message: msg,
          timestamp: currentEnvForLogs?.timestamp ?? 0,
        });
      } catch (e) {
        // Silently fail
      }
    }
  };

  console.error = function(...args: any[]) {
    originalError.apply(console, args);
    if (currentEnvForLogs) {
      try {
        const msg = args.map(a => {
          if (typeof a === 'string') return a;
          if (typeof a === 'bigint') return a.toString() + 'n';
          try { return JSON.stringify(a); } catch { return String(a); }
        }).join(' ');
        currentEnvForLogs.frameLogs.push({
          level: 'error',
          category: detectLogCategory(msg),
          message: msg,
          timestamp: currentEnvForLogs?.timestamp ?? 0,
        });
      } catch (e) {
        // Silently fail
      }
    }
  };
}

function detectLogCategory(msg: string): 'consensus' | 'account' | 'jurisdiction' | 'evm' | 'network' | 'ui' | 'system' {
  if (msg.includes('CONSENSUS') || msg.includes('E-MACHINE') || msg.includes('PROPOSE')) return 'consensus';
  if (msg.includes('ACCOUNT') || msg.includes('A-MACHINE') || msg.includes('BILATERAL')) return 'account';
  if (msg.includes('J-MACHINE') || msg.includes('JURISDICTION')) return 'jurisdiction';
  if (msg.includes('EVM') || msg.includes('BrowserVM')) return 'evm';
  if (msg.includes('GOSSIP') || msg.includes('NETWORK')) return 'network';
  if (msg.includes('[View]') || msg.includes('[Graph3D]')) return 'ui';
  return 'system';
}

// === CONSENSUS PROCESSING ===
// ONE TICK = ONE ITERATION. No cascade. Eâ†’E communication always requires new tick.
let processing = false;

export const process = async (
  env: Env,
  inputs?: EntityInput[],
  runtimeDelay = 0
) => {
  // Frame stepping: check if we should stop and dump state
  if (env.stopAtFrame !== undefined && env.height >= env.stopAtFrame) {
    console.log(`\nâ¸ï¸  FRAME STEPPING: Stopped at frame ${env.height}`);
    console.log('â•'.repeat(80));
    const { formatRuntime } = await import('./runtime-ascii');
    console.log(formatRuntime(env, { maxAccounts: 10, maxLocks: 20, maxSwaps: 20 }));
    console.log('â•'.repeat(80) + '\n');
    console.log('ðŸ’¾ State captured - use jq on /tmp/{scenario}-runtime.json for deep queries');
    throw new Error(`FRAME_STEP: Stopped at frame ${env.height} for debugging`);
  }

  // Lock: prevent interleaving
  if (processing) {
    console.warn('â¸ï¸ SKIP: Previous tick still processing');
    return env;
  }

  processing = true;

  // Merge pending outputs from previous tick with new inputs
  const allInputs = [
    ...(env.pendingOutputs || []),
    ...(env.networkInbox || []),
    ...(inputs || []),
  ];
  env.pendingOutputs = [];
  env.networkInbox = [];

  // Validate inputs
  allInputs.forEach(o => {
    try {
      validateEntityInput(o);
    } catch (error) {
      logError("RUNTIME_TICK", `ðŸš¨ CRITICAL: Invalid EntityInput!`, {
        error: (error as Error).message,
        entityId: o.entityId.slice(0, 10),
        signerId: o.signerId,
      });
      throw error;
    }
  });

  try {
    // Update timestamp
    // In scenario mode, advance by 100ms per tick (deterministic)
    // In live mode, use real time
    if (env.scenarioMode) {
      env.timestamp = (env.timestamp ?? 0) + 100; // Advance 100ms per frame
    } else {
      env.timestamp = getWallClockMs();
    }
    getBrowserVMInstance(env)?.setBlockTimestamp?.(env.timestamp);

    if (allInputs.length > 0) {
      console.log(`ðŸ“¥ TICK: Processing ${allInputs.length} inputs for [${allInputs.map(o => o.entityId.slice(-4)).join(',')}]`);

      const result = await applyRuntimeInput(env, { runtimeTxs: [], entityInputs: allInputs });

      // DEBUG: Log what applyRuntimeInput returned
      if (HEAVY_LOGS) console.log(`ðŸ” PROCESS-DEBUG: applyRuntimeInput returned entityOutbox.length=${result.entityOutbox.length}`);

      // Store outputs for NEXT tick
      const routedOutputs = routeEntityOutputs(env, result.entityOutbox);
      env.pendingOutputs = routedOutputs;

      if (routedOutputs.length > 0) {
        console.log(`ðŸ“¤ TICK: ${routedOutputs.length} outputs queued for next tick â†’ [${routedOutputs.map(o => o.entityId.slice(-4)).join(',')}]`);
      }
    } else {
      // No inputs to process - retry routing any pending network outputs
      if (env.pendingNetworkOutputs && env.pendingNetworkOutputs.length > 0) {
        const routedOutputs = routeEntityOutputs(env, []);
        if (routedOutputs.length > 0) {
          env.pendingOutputs = [...(env.pendingOutputs || []), ...routedOutputs];
          console.log(`ðŸ“¤ TICK: ${routedOutputs.length} local outputs queued from pending network outputs`);
        }
      } else {
        // No inputs to process - keep env.extra so narrative-only frames still render
      }
    }

    // === J-MACHINE BLOCK PROCESSING ===
    // Process J-machine mempools when blockDelayMs has elapsed
    if (env.jReplicas) {
      for (const [jName, jReplica] of env.jReplicas.entries()) {
        const mempool = jReplica.mempool || [];
        const blockDelayMs = jReplica.blockDelayMs || 300;
        const lastBlockTs = jReplica.lastBlockTimestamp || 0;
        const elapsed = env.timestamp - lastBlockTs;

        // Debug logging
        if (mempool.length > 0) {
          if (HEAVY_LOGS) console.log(`ðŸ” [J-Machine ${jName}] mempool=${mempool.length}, elapsed=${elapsed}ms, blockDelay=${blockDelayMs}ms, ready=${elapsed >= blockDelayMs}`);
        }

        // Check if mempool items are ready (minimum 1 tick delay for visualization)
        const oldestTxAge = mempool.length > 0 && mempool[0].queuedAt ? env.timestamp - mempool[0].queuedAt : 999999;
        const mempoolReady = mempool.length > 0 && oldestTxAge >= blockDelayMs;

        if (mempool.length > 0 && !mempoolReady) {
          console.log(`â³ [J-Machine] ${mempool.length} pending (age: ${oldestTxAge}ms < ${blockDelayMs}ms) - waiting...`);
        }

        // If mempool ready AND block delay passed â†’ PROCESS
        if (mempoolReady) {
          console.log(`âš¡ [5/6] J-Machine ${jReplica.name}: Processing ${mempool.length} txs (oldest: ${oldestTxAge}ms >= ${blockDelayMs}ms)`);
          console.log(`   Mempool BEFORE execution:`, mempool.map(tx => `${tx.entityId.slice(-4)}:${tx.data.batchSize || '?'}`));

          // Emit J-block event
          env.emit('JBlockProcessing', {
            jurisdictionName: jName,
            txCount: mempool.length,
            blockNumber: Number(jReplica.blockNumber) + 1,
          });

          // Process each JTx in mempool
          const { broadcastBatch } = await import('./j-batch');
          const { getBrowserVMInstance } = await import('./evm');
          const browserVM = getBrowserVMInstance(env);

          if (browserVM?.beginJurisdictionBlock) {
            browserVM.beginJurisdictionBlock(env.timestamp);
          }

          for (const jTx of mempool) {
            if (jTx.type === 'batch' && jTx.data?.batch) {
              console.log(`ðŸ”¨ [J-Machine] Executing batch from ${jTx.entityId.slice(-4)}`);
              console.log(`   Batch size: ${jTx.data.batchSize || 'unknown'}`);
              console.log(`   Batch.reserveToReserve:`, jTx.data.batch.reserveToReserve);
              let batchSummary: string | undefined;
              try {
                const { summarizeBatch } = await import('./j-batch');
                batchSummary = safeStringify(summarizeBatch(jTx.data.batch));
                console.log(`   Batch.summary: ${batchSummary}`);
              } catch {
                // best-effort debug only
              }

              // Create temporary jBatchState for broadcastBatch call
              const tempJBatchState = {
                batch: jTx.data.batch,
                jurisdiction: null,
                lastBroadcast: jTx.timestamp,
                broadcastCount: 1,
                failedAttempts: 0,
              };

              // Execute batch on BrowserVM
              const result = await broadcastBatch(
                env,
                jTx.entityId,
                tempJBatchState,
                null, // jurisdiction not needed for BrowserVM
                browserVM || undefined,
                jTx.timestamp ?? env.timestamp,
                jTx.data?.signerId
              );

              if (result.success) {
                console.log(`   âœ… Batch executed successfully`);
                console.log(`   ðŸ“¡ ${result.events?.length || 0} events will route back to entities`);
              } else {
                console.error(`   âŒ Batch execution failed: ${result.error}`);
                if (!batchSummary) {
                  try {
                    const { summarizeBatch } = await import('./j-batch');
                    batchSummary = safeStringify(summarizeBatch(jTx.data.batch));
                    console.error(`   âŒ Failed batch summary: ${batchSummary}`);
                  } catch {
                    // best-effort debug only
                  }
                } else {
                  console.error(`   âŒ Failed batch summary: ${batchSummary}`);
                }
                if (env.scenarioMode) {
                  throw new Error(`J-BATCH FAILED: ${result.error || 'unknown error'}`);
                }
              }
            }
          }

          if (browserVM?.endJurisdictionBlock) {
            browserVM.endJurisdictionBlock();
          }

          // Clear mempool immediately after processing (all txs executed)
          const processedCount = mempool.length;
          const successCount = processedCount; // Failures would throw in scenario mode
          const failCount = 0;

          // CRITICAL: Clear mempool immediately (txs already executed)
          console.log(`ðŸ§¹ [J-Machine] Clearing mempool (before: ${jReplica.mempool.length} items)...`);
          jReplica.mempool = [];
          console.log(`ðŸ§¹ [J-Machine] Mempool AFTER clear: ${jReplica.mempool.length} items (should be 0)`);

          jReplica.lastBlockTimestamp = env.timestamp; // Reset timer for next block
          jReplica.blockNumber = jReplica.blockNumber + 1n; // Increment ONLY when block processed
          jReplica.blockReady = false; // Block created, mempool empty

          console.log(`âœ… [J-Machine ${jReplica.name}] Block #${jReplica.blockNumber} finalized (${successCount}/${processedCount} batches)`);
          if (failCount > 0) {
            console.warn(`   âš ï¸ ${failCount} batches failed, queued for retry`);
          }
          console.log(`   Next block in ${blockDelayMs}ms`);

          // Emit J-block finalized event
          env.emit('JBlockFinalized', {
            jurisdictionName: jName,
            blockNumber: Number(jReplica.blockNumber),
            txCount: mempool.length,
          });
        } else if (mempool.length > 0) {
          // Mempool has items but delay not elapsed yet (yellow cube visible, waiting)
          jReplica.blockReady = true;
        } else {
          jReplica.blockReady = false;
        }
      }
    }

    // ALWAYS snapshot after tick (full frame chain)
    // env.extra only adds metadata (subtitle, description) - optional
    let browserVMState: any = undefined;
    const browserVMStateSource = getBrowserVMInstance(env);
    if (browserVMStateSource?.serializeState) {
      try {
        browserVMState = await browserVMStateSource.serializeState();
        env.browserVMState = browserVMState;
      } catch (error) {
        console.warn('[Runtime] Failed to serialize BrowserVM state:', error);
        if (env.scenarioMode) {
          throw error;
        }
      }
    }

    const snapshot: any = {
      height: env.height,
      timestamp: env.timestamp,
      ...(env.runtimeSeed ? { runtimeSeed: env.runtimeSeed } : {}),
      ...(env.runtimeId ? { runtimeId: env.runtimeId } : {}),
      eReplicas: new Map(env.eReplicas),
      jReplicas: env.jReplicas ? Array.from(env.jReplicas.values()).map(jr => ({
        ...jr,
        mempool: [...jr.mempool], // Deep clone mempool array
        stateRoot: new Uint8Array(jr.stateRoot), // Clone Uint8Array
      })) : [],
      runtimeInput: env.runtimeInput,
      runtimeOutputs: env.pendingOutputs || [],
      frameLogs: env.frameLogs || [],
      title: `Frame ${env.history?.length || 0}`, // Default title
      ...(browserVMState ? { browserVMState } : {}),
    };

    // Add metadata if provided via snap()
    if (env.extra) {
      const { subtitle, description } = env.extra;
      if (subtitle) {
        snapshot.subtitle = subtitle;
        snapshot.title = subtitle.title || snapshot.title; // Override title
      }
      if (description) snapshot.description = description;
      env.extra = undefined; // Clear after use
    }

    if (!env.history) env.history = [];
    env.history.push(snapshot);

    console.log(`ðŸ“¸ Snapshot: ${snapshot.title} (${env.history.length} total)`);

    // Auto-persist
    await saveEnvToDB(env);

    if (env.strictScenario) {
      const { assertRuntimeStateStrict } = await import('./strict-assertions');
      await assertRuntimeStateStrict(env);
    }
    return env;
  } finally {
    processing = false;
  }
};

// === LEVELDB PERSISTENCE ===
export const saveEnvToDB = async (env: Env): Promise<void> => {
  if (!isBrowser) return; // Only persist in browser

  try {
    const dbReady = await tryOpenDb();
    if (!dbReady) return;

    // Save latest height pointer
    await db.put(Buffer.from('latest_height'), Buffer.from(String(env.height)));

    // Save environment snapshot (jReplicas with stateRoot are serializable)
    // CRITICAL: Exclude 'history' to prevent exponential growth (history contains all previous snapshots)
    const seen = new WeakSet();
    const snapshot = JSON.stringify(env, (k, v) => {
      if (k === 'history') return undefined; // Skip history - it's rebuilt from individual snapshots
      if (k === 'browserVM') return undefined; // BrowserVM is non-serializable (circular refs)
      if (k === 'log' || k === 'info' || k === 'warn' || k === 'error' || k === 'emit') return undefined;
      if (k === 'gossip' && v && typeof v === 'object') {
        return {
          profiles: v.profiles instanceof Map ? Array.from(v.profiles.entries()) : v.profiles,
        };
      }
      if (typeof v === 'bigint') return String(v);
      if (v instanceof Uint8Array) return Array.from(v);
      if (v instanceof Map) return Array.from(v.entries());
      if (v instanceof Set) return Array.from(v);
      if (typeof v === 'function') return undefined;
      if (v && typeof v === 'object') {
        if (seen.has(v)) return '[Circular]';
        seen.add(v);
      }
      return v;
    });
    await db.put(Buffer.from(`snapshot:${env.height}`), Buffer.from(snapshot));
  } catch (err) {
    console.error('âŒ Failed to save to LevelDB:', err);
    if (env.scenarioMode) {
      throw err;
    }
  }
};

export const loadEnvFromDB = async (): Promise<Env | null> => {
  if (!isBrowser) return null;

  try {
    const dbReady = await tryOpenDb();
    if (!dbReady) return null;

    const latestHeightBuffer = await db.get(Buffer.from('latest_height'));
    const latestHeight = parseInt(latestHeightBuffer.toString());

    // Load all snapshots to build history
    const history: Env[] = [];
    for (let i = 0; i <= latestHeight; i++) {
      const buffer = await db.get(Buffer.from(`snapshot:${i}`));
      const data = JSON.parse(buffer.toString());

      // Hydrate Maps/BigInts
      const env = createEmptyEnv(data.runtimeSeed || null);
      env.height = BigInt(data.height || 0);
      env.timestamp = BigInt(data.timestamp || 0);
      if (data.browserVMState) {
        env.browserVMState = data.browserVMState;
      }
      if (data.runtimeSeed) {
        setCryptoRuntimeSeed(data.runtimeSeed);
      }
      if (data.runtimeId) {
        env.runtimeId = data.runtimeId;
      } else if (data.runtimeSeed) {
        try {
          env.runtimeId = deriveSignerAddressSync(data.runtimeSeed, '1');
        } catch (error) {
          console.warn('âš ï¸ Failed to derive runtimeId from DB snapshot:', error);
        }
      }
      // Support both old (replicas) and new (eReplicas) format
      env.eReplicas = new Map(data.eReplicas || data.replicas || []);
      // Load jReplicas if present
      if (data.jReplicas) {
        env.jReplicas = new Map(data.jReplicas.map((jr: JReplica) => [jr.name, jr]));
      }
      if (data.gossip?.profiles) {
        env.gossip.profiles = new Map(data.gossip.profiles);
      }
      history.push(env);
    }

    const latestEnv = history[history.length - 1];
    if (latestEnv) {
      latestEnv.history = history;
    }

    return latestEnv;
  } catch (err) {
    console.log('No persisted state found');
    return null;
  }
};

export const clearDB = async (): Promise<void> => {
  if (!isBrowser) return;

  try {
    const dbReady = await tryOpenDb();
    if (!dbReady) return;

    await db.clear();
    console.log('âœ… LevelDB cleared');
  } catch (err) {
    console.error('âŒ Failed to clear LevelDB:', err);
  }
};

// === PREPOPULATE FUNCTION ===
// REMOVED: Legacy prepopulate functions replaced by scenarios namespace below

// Scenarios namespace for better organization
export const scenarios = {
  ahb: async (env: Env): Promise<Env> => {
    const { ahb } = await import('./scenarios/ahb');
    await ahb(env);
    return env;
  },
  lockAhb: async (env: Env): Promise<Env> => {
    const { lockAhb } = await import('./scenarios/lock-ahb');
    await lockAhb(env);
    return env;
  },
  swap: async (env: Env): Promise<Env> => {
    const { swap, swapWithOrderbook, multiPartyTrading } = await import('./scenarios/swap');
    // Run all 3 phases for complete swap demo (Alice, Hub, Bob, Carol, Dave)
    await swap(env);             // Phase 1: Alice + Hub basic bilateral swaps
    await swapWithOrderbook(env); // Phase 2: Add Bob, orderbook matching
    await multiPartyTrading(env); // Phase 3: Add Carol + Dave, multi-party
    return env;
  },
  swapMarket: async (env: Env): Promise<Env> => {
    const { swapMarket } = await import('./scenarios/swap-market');
    await swapMarket(env);
    return env;
  },
  rapidFire: async (env: Env): Promise<Env> => {
    const { rapidFire } = await import('./scenarios/rapid-fire');
    await rapidFire(env);
    return env;
  },
  grid: async (env: Env): Promise<Env> => {
    const { grid } = await import('./scenarios/grid');
    await grid(env);
    return env;
  },
  fullMechanics: async (env: Env): Promise<Env> => {
    await prepopulateFullMechanicsImpl(env);
    return env;
  },
};

// Deprecated aliases (backwards compatibility - will be removed)
export const prepopulateAHB = scenarios.ahb;
export const prepopulateFullMechanics = scenarios.fullMechanics;

// === SCENARIO SYSTEM ===
export { parseScenario, mergeAndSortEvents } from './scenarios/parser.js';
export { executeScenario } from './scenarios/executor.js';
export { loadScenarioFromFile, loadScenarioFromText } from './scenarios/loader.js';
export { SCENARIOS, getScenario, getScenariosByTag, type ScenarioMetadata } from './scenarios/index.js';

// === CRYPTOGRAPHIC SIGNATURES ===
export { deriveSignerKey, deriveSignerKeySync, registerSignerKey, registerSignerPublicKey, registerTestKeys, clearSignerKeys, signAccountFrame, verifyAccountSignature, getSignerPublicKey } from './account-crypto.js';

// === NAME RESOLUTION WRAPPERS (override imports) ===
const searchEntityNames = (query: string, limit?: number) => searchEntityNamesOriginal(db, query, limit);
const resolveEntityName = (entityId: string) => resolveEntityNameOriginal(db, entityId);
const getEntityDisplayInfoFromProfile = (entityId: string) => getEntityDisplayInfoFromProfileOriginal(db, entityId);

// Avatar functions are already imported and exported above
export { BrowserEVM } from './evms/browser-evm.js';

// ASCII visualization exports
export { formatRuntime, formatEntity, formatAccount, formatOrderbook, formatSummary } from './runtime-ascii';


//runtime/entity-consensus.ts (1209 lines)
/**
 * XLN Entity Consensus and State Management
 * Core entity processing logic, consensus, proposals, and state transitions
 */

import { applyEntityTx } from './entity-tx';
import { isLeftEntity } from './entity-id-utils';
import { ConsensusConfig, EntityInput, EntityReplica, EntityState, EntityTx, Env } from './types';
import { DEBUG, HEAVY_LOGS, formatEntityDisplay, formatSignerDisplay, log } from './utils';
import { safeStringify } from './serialization-utils';
import { logError } from './logger';
import { addMessages, cloneEntityReplica, canonicalAccountKey, getAccountPerspective, emitScopedEvents, resolveEntityProposerId } from './state-helpers';
import { LIMITS } from './constants';
import { signAccountFrame as signFrame, verifyAccountSignature as verifyFrame } from './account-crypto';

// === SECURITY VALIDATION ===

/**
 * Validates entity input to prevent malicious or corrupted data
 */
const validateEntityInput = (input: EntityInput): boolean => {
  try {
    // Basic required fields
    if (!input.entityId || typeof input.entityId !== 'string') {
      log.error(`âŒ Invalid entityId: ${input.entityId}`);
      return false;
    }
    if (!input.signerId || typeof input.signerId !== 'string') {
      log.error(`âŒ Invalid signerId: ${input.signerId}`);
      return false;
    }

    // EntityTx validation
    if (input.entityTxs) {
      if (!Array.isArray(input.entityTxs)) {
        log.error(`âŒ EntityTxs must be array, got: ${typeof input.entityTxs}`);
        return false;
      }
      if (input.entityTxs.length > 1000) {
        log.error(`âŒ Too many transactions: ${input.entityTxs.length} > 1000`);
        return false;
      }
      for (const tx of input.entityTxs) {
        if (!tx.type || !tx.data) {
          log.error(`âŒ Invalid transaction: ${safeStringify(tx)}`);
          return false;
        }
        if (typeof tx.type !== 'string') {
          log.error(`âŒ Transaction type must be string: ${typeof tx.type}`);
          return false;
        }
        // No whitelist - trust the type system
      }
    }

    // Precommits validation
    if (input.precommits) {
      if (!(input.precommits instanceof Map)) {
        log.error(`âŒ Precommits must be Map, got: ${typeof input.precommits}`);
        return false;
      }
      if (input.precommits.size > 100) {
        log.error(`âŒ Too many precommits: ${input.precommits.size} > 100`);
        return false;
      }
      for (const [signerId, signature] of input.precommits) {
        if (typeof signerId !== 'string' || typeof signature !== 'string') {
          log.error(`âŒ Invalid precommit format: ${signerId} -> ${signature}`);
          return false;
        }
      }
    }

    // ProposedFrame validation
    if (input.proposedFrame) {
      const frame = input.proposedFrame;
      if (typeof frame.height !== 'number' || frame.height < 0) {
        log.error(`âŒ Invalid frame height: ${frame.height}`);
        return false;
      }
      if (!Array.isArray(frame.txs)) {
        log.error(`âŒ Frame txs must be array`);
        return false;
      }
      if (!frame.hash || typeof frame.hash !== 'string') {
        log.error(`âŒ Invalid frame hash: ${frame.hash}`);
        return false;
      }
    }

    return true;
  } catch (error) {
    log.error(`âŒ Input validation error: ${error}`);
    return false;
  }
};

/**
 * Validates entity replica to prevent corrupted state
 */
const validateEntityReplica = (replica: EntityReplica): boolean => {
  try {
    if (!replica.entityId || !replica.signerId) {
      log.error(`âŒ Invalid replica IDs: ${replica.entityId}:${replica.signerId}`);
      return false;
    }
    if (replica.state.height < 0) {
      log.error(`âŒ Invalid state height: ${replica.state.height}`);
      return false;
    }
    if (replica.mempool.length > LIMITS.MEMPOOL_SIZE) {
      log.error(`âŒ Mempool overflow: ${replica.mempool.length} > ${LIMITS.MEMPOOL_SIZE}`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`âŒ Replica validation error: ${error}`);
    return false;
  }
};

/**
 * Detects Byzantine faults like double-signing
 */
const detectByzantineFault = (signatures: Map<string, string>, signerId: string, newSignature: string): boolean => {
  try {
    const existingSig = signatures.get(signerId);
    if (existingSig && existingSig !== newSignature) {
      log.error(`âŒ BYZANTINE FAULT: Double-sign detected from ${signerId}`);
      log.error(`âŒ Existing: ${existingSig}`);
      log.error(`âŒ New: ${newSignature}`);
      return true;
    }
    return false;
  } catch (error) {
    log.error(`âŒ Byzantine detection error: ${error}`);
    return false;
  }
};

/**
 * Validates voting power to prevent overflow attacks
 */
const validateVotingPower = (power: bigint): boolean => {
  try {
    if (power < 0n) {
      log.error(`âŒ Negative voting power: ${power}`);
      return false;
    }
    // Check for overflow (2^53 - 1 in bigint)
    if (power > BigInt(Number.MAX_SAFE_INTEGER)) {
      log.error(`âŒ Voting power overflow: ${power} > ${Number.MAX_SAFE_INTEGER}`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`âŒ Voting power validation error: ${error}`);
    return false;
  }
};

// === CORE ENTITY PROCESSING ===

/**
 * Main entity input processor - handles consensus, proposals, and state transitions
 */
export const applyEntityInput = async (
  env: Env,
  entityReplica: EntityReplica,
  entityInput: EntityInput,
): Promise<{ newState: EntityState, outputs: EntityInput[], jOutputs: JInput[], workingReplica: EntityReplica }> => {
  // IMMUTABILITY: Clone replica at function start (fintech-safe, hacker-proof)
  // Prevents state mutations from escaping function scope
  const workingReplica = cloneEntityReplica(entityReplica);

  // Debug: Log every input being processed with deterministic timestamp
  const entityDisplay = formatEntityDisplay(entityInput.entityId);
  const timestamp = env.timestamp; // Use deterministic env.timestamp, not Date.now()
  const currentProposalHash = workingReplica.proposal?.hash?.slice(0, 10) || 'none';
  const frameHash = entityInput.proposedFrame?.hash?.slice(0, 10) || 'none';

  console.log(
    `ðŸ” INPUT-RECEIVED: [${timestamp}] Processing input for Entity #${entityDisplay}:${formatSignerDisplay(entityInput.signerId)}`,
  );
  console.log(
    `ðŸ” INPUT-STATE: Current proposal: ${currentProposalHash}, Mempool: ${workingReplica.mempool.length}, isProposer: ${workingReplica.isProposer}`,
  );
  console.log(
    `ðŸ” INPUT-DETAILS: txs=${entityInput.entityTxs?.length || 0}, precommits=${entityInput.precommits?.size || 0}, frame=${frameHash}`,
  );
  if (entityInput.precommits?.size) {
    const precommitSigners = Array.from(entityInput.precommits.keys());
    if (HEAVY_LOGS) console.log(`ðŸ” INPUT-PRECOMMITS: Received precommits from: ${precommitSigners.join(', ')}`);
    // Track exactly which proposal these precommits are for
    const firstPrecommit = entityInput.precommits.values().next().value;
    const proposalHashFromSig = firstPrecommit ? firstPrecommit.split('_')[2]?.slice(0, 10) : 'unknown';
    if (HEAVY_LOGS) console.log(`ðŸ” PRECOMMIT-PROPOSAL: These precommits are for proposal: ${proposalHashFromSig}`);
  }

  // SECURITY: Validate all inputs
  if (!validateEntityInput(entityInput)) {
    log.error(`âŒ Invalid input for ${entityInput.entityId}:${entityInput.signerId}`);
    return { newState: workingReplica.state, outputs: [], jOutputs: [], workingReplica };
  }
  if (!validateEntityReplica(workingReplica)) {
    log.error(`âŒ Invalid replica state for ${workingReplica.entityId}:${workingReplica.signerId}`);
    return { newState: workingReplica.state, outputs: [], jOutputs: [], workingReplica };
  }

  const entityOutbox: EntityInput[] = [];
  const jOutbox: JInput[] = []; // J-layer outputs

  // â° Execute crontab tasks (periodic checks like account timeouts)
  const { executeCrontab, initCrontab } = await import('./entity-crontab');

  // Initialize crontab on first use
  if (!workingReplica.state.crontabState) {
    workingReplica.state.crontabState = initCrontab();
  }

  const hasManualBroadcast = Boolean(entityInput.entityTxs?.some(tx => tx.type === 'j_broadcast'));
  if (hasManualBroadcast) {
    const broadcastTask = workingReplica.state.crontabState.tasks.get('broadcastBatch');
    if (broadcastTask) {
      // Avoid auto-broadcast clobbering explicit j_broadcast in this tick.
      broadcastTask.lastRun = workingReplica.state.timestamp;
    }
  }

  const crontabOutputs = await executeCrontab(workingReplica, workingReplica.state.crontabState);
  if (crontabOutputs.length > 0) {
    console.log(`â° CRONTAB: Generated ${crontabOutputs.length} outputs from periodic tasks`);
    entityOutbox.push(...crontabOutputs);
  }

  // Add transactions to mempool (mutable for performance)
  if (entityInput.entityTxs?.length) {
    // DEBUG: Track vote transactions specifically
    const voteTransactions = entityInput.entityTxs.filter(tx => tx.type === 'vote');
    if (voteTransactions.length > 0) {
      console.log(`ðŸ—³ï¸ VOTE-MEMPOOL: ${workingReplica.signerId} receiving ${voteTransactions.length} vote transactions`);
      voteTransactions.forEach(tx => {
        console.log(`ðŸ—³ï¸ VOTE-TX:`, tx);
      });
    }

    if (workingReplica.signerId === 'alice') {
      console.log(`ðŸ”¥ ALICE-RECEIVES: Alice receiving ${entityInput.entityTxs.length} txs from input`);
      console.log(
        `ðŸ”¥ ALICE-RECEIVES: Transaction types:`,
        entityInput.entityTxs.map(tx => tx.type),
      );
      console.log(
        `ðŸ”¥ ALICE-RECEIVES: Alice isProposer=${workingReplica.isProposer}, current mempool=${workingReplica.mempool.length}`,
      );
    }
    // Log details of each EntityTx
    for (const tx of entityInput.entityTxs) {
      console.log(`ðŸ›ï¸ E-MACHINE: - EntityTx type="${tx.type}", data=`, safeStringify(tx.data, 2));
    }
    workingReplica.mempool.push(...entityInput.entityTxs);
    if (DEBUG)
      console.log(
        `    â†’ Added ${entityInput.entityTxs.length} txs to mempool (total: ${workingReplica.mempool.length})`,
      );
    if (DEBUG && entityInput.entityTxs.length > 3) {
      console.log(`    âš ï¸  CORNER CASE: Large batch of ${entityInput.entityTxs.length} transactions`);
    }
  } else if (entityInput.entityTxs && entityInput.entityTxs.length === 0) {
    // DEBUG removed: âš ï¸  CORNER CASE: Empty transaction array received - no mempool changes`);
  }

  // CRITICAL: Forward transactions to proposer BEFORE processing commits
  // This prevents race condition where commits clear mempool before forwarding
  if (!workingReplica.isProposer && workingReplica.mempool.length > 0) {
    // Send mempool to proposer
    const proposerId = workingReplica.state.config.validators[0];
    if (!proposerId) {
      logError("FRAME_CONSENSUS", `âŒ No proposer found in validators: ${workingReplica.state.config.validators}`);
      return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica };
    }

    const txCount = workingReplica.mempool.length;
    console.log(`ðŸ”¥ BOB-TO-ALICE: Bob sending ${txCount} txs to proposer ${proposerId}`);
    console.log(
      `ðŸ”¥ BOB-TO-ALICE: Transaction types:`,
      workingReplica.mempool.map(tx => tx.type),
    );
    entityOutbox.push({
      entityId: entityInput.entityId,
      signerId: proposerId,
      entityTxs: [...workingReplica.mempool],
    });

    // CHANNEL.TS PATTERN: Track sent txs, DON'T clear mempool yet
    // Only clear after receiving commit confirmation (like Channel.ts line 217)
    workingReplica.sentTransitions = txCount;
    console.log(`ðŸ“Š Tracked ${txCount} sent transitions (will clear on commit)`);
  }

  // Handle commit notifications AFTER forwarding (when receiving finalized frame from proposer)
  if (entityInput.precommits?.size && entityInput.proposedFrame && !workingReplica.proposal) {
    const signers = Array.from(entityInput.precommits.keys());
    const totalPower = calculateQuorumPower(workingReplica.state.config, signers);

    if (totalPower >= workingReplica.state.config.threshold) {
      // This is a commit notification from proposer, apply the frame

      // SECURITY: Validate commit matches our locked frame (if we have one)
      if (workingReplica.lockedFrame) {
        if (workingReplica.lockedFrame.hash !== entityInput.proposedFrame.hash) {
          logError("FRAME_CONSENSUS", `âŒ BYZANTINE: Commit frame doesn't match locked frame!`);
          logError("FRAME_CONSENSUS", `   Locked: ${workingReplica.lockedFrame.hash}`);
          logError("FRAME_CONSENSUS", `   Commit: ${entityInput.proposedFrame.hash}`);
          return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica };
        }
        console.log(`âœ… Commit validation: matches locked frame ${workingReplica.lockedFrame.hash.slice(0,10)}`);
      }

      // SECURITY: Verify signatures are for the correct frame hash
      for (const [signerId, signature] of entityInput.precommits) {
        if (!verifyFrame(env, signerId, entityInput.proposedFrame.hash, signature)) {
          logError("FRAME_CONSENSUS", `âŒ BYZANTINE: Invalid signature from ${signerId}`);
          logError("FRAME_CONSENSUS", `   Frame hash: ${entityInput.proposedFrame.hash.slice(0,30)}...`);
          logError("FRAME_CONSENSUS", `   Signature: ${signature.slice(0,30)}...`);
          return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica };
        }
      }
      console.log(`âœ… All ${entityInput.precommits.size} signatures validated for frame ${entityInput.proposedFrame.hash.slice(0,10)}`);

      // Emit frame commit event
      env.emit('EntityFrameCommitted', {
        entityId: entityInput.entityId,
        signerId: workingReplica.signerId,
        height: workingReplica.state.height + 1,
        frameHash: entityInput.proposedFrame.hash,
        txCount: entityInput.proposedFrame.txs.length,
        signatures: entityInput.precommits.size,
      });

      // Apply the committed frame with incremented height
      workingReplica.state = {
        ...entityInput.proposedFrame.newState,
        entityId: workingReplica.state.entityId, // PRESERVE: Never lose entityId
        height: workingReplica.state.height + 1,
      };

      // CHANNEL.TS PATTERN: Clear only the committed txs, keep any new txs
      // This avoids dropping fresh inputs merged into the same tick (e.g., accountInput ACKs).
      const committedTxCount = entityInput.proposedFrame.txs.length;
      if (committedTxCount > 0) {
        console.log(`ðŸ“Š Clearing ${committedTxCount} committed txs from mempool (${workingReplica.mempool.length} total)`);
        workingReplica.mempool.splice(0, committedTxCount);
        workingReplica.sentTransitions = 0;
        console.log(`ðŸ“Š Mempool after commit: ${workingReplica.mempool.length} txs remaining`);
      } else {
        // No txs committed - leave mempool as-is
        workingReplica.sentTransitions = 0;
      }

      delete workingReplica.lockedFrame; // Release lock after commit
      if (DEBUG)
        console.log(
          `    â†’ Applied commit, new state: ${workingReplica.state.messages.length} messages, height: ${workingReplica.state.height}`,
        );

      // Return early - commit notifications don't trigger further processing
      return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica };
    }
  }

  // Handle proposed frame (PROPOSE phase) - only if not a commit notification
  if (
    entityInput.proposedFrame &&
    (!workingReplica.proposal || (workingReplica.state.config.mode === 'gossip-based' && workingReplica.isProposer))
  ) {
    const frameSignature = signFrame(env, workingReplica.signerId, entityInput.proposedFrame.hash);
    const config = workingReplica.state.config;

    // Lock to this frame (CometBFT style)
    workingReplica.lockedFrame = entityInput.proposedFrame;
    // DEBUG removed: â†’ Validator locked to frame ${entityInput.proposedFrame.hash.slice(0, 10)}...`);

    if (config.mode === 'gossip-based') {
      // Send precommit to all validators
      config.validators.forEach(validatorId => {
        console.log(
          `ðŸ” GOSSIP: [${timestamp}] ${workingReplica.signerId} sending precommit to ${validatorId} for entity ${entityInput.entityId.slice(0, 10)}, proposal ${frameHash}, sig: ${frameSignature.slice(0, 20)}...`,
        );
        entityOutbox.push({
          entityId: entityInput.entityId,
          signerId: validatorId,
          precommits: new Map([[workingReplica.signerId, frameSignature]]),
        });
      });
      // DEBUG removed: â†’ Signed proposal, gossiping precommit to ${config.validators.length} validators`);
    } else {
      // Send precommit to proposer only
      const proposerId = config.validators[0];
      if (!proposerId) {
        logError("FRAME_CONSENSUS", `âŒ No proposer found in validators: ${config.validators}`);
        return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica };
      }
      console.log(
        `ðŸ” PROPOSER: [${timestamp}] ${workingReplica.signerId} sending precommit to ${proposerId} for entity ${entityInput.entityId.slice(0, 10)}, proposal ${frameHash}, sig: ${frameSignature.slice(0, 20)}...`,
      );
      console.log(
        `ðŸ” PROPOSER-REASON: Signed new proposal, current state: proposal=${currentProposalHash}, locked=${workingReplica.lockedFrame?.hash?.slice(0, 10) || 'none'}`,
      );
      entityOutbox.push({
        entityId: entityInput.entityId,
        signerId: proposerId,
        precommits: new Map([[workingReplica.signerId, frameSignature]]),
      });
      // DEBUG removed: â†’ Signed proposal, sending precommit to ${proposerId}`);
    }
  }

  // Handle precommits (SIGN phase)
  if (entityInput.precommits?.size && workingReplica.proposal) {
    // SECURITY: Check for Byzantine faults before collecting signatures
    for (const [signerId, signature] of entityInput.precommits) {
      if (detectByzantineFault(workingReplica.proposal.signatures, signerId, signature)) {
        log.error(`âŒ Rejecting Byzantine input from ${signerId}`);
        return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica }; // Return early, don't process malicious input
      }
      workingReplica.proposal.signatures.set(signerId, signature);
    }
    if (DEBUG)
      console.log(
        `    â†’ Collected ${entityInput.precommits.size} signatures (total: ${workingReplica.proposal.signatures.size})`,
      );

    // Check threshold using shares
    const signers = Array.from(workingReplica.proposal.signatures.keys());
    const totalPower = calculateQuorumPower(workingReplica.state.config, signers);

    // SECURITY: Validate voting power
    if (!validateVotingPower(totalPower)) {
      log.error(`âŒ Invalid voting power calculation: ${totalPower}`);
      return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica };
    }

    if (DEBUG) {
      const totalShares = Object.values(workingReplica.state.config.shares).reduce((sum, val) => sum + val, BigInt(0));
      const percentage = ((Number(totalPower) / Number(workingReplica.state.config.threshold)) * 100).toFixed(1);
      log.info(
        `    ðŸ” Threshold check: ${totalPower} / ${totalShares} [${percentage}% threshold${Number(totalPower) >= Number(workingReplica.state.config.threshold) ? '+' : ''}]`,
      );
      if (workingReplica.state.config.mode === 'gossip-based') {
        console.log(`    âš ï¸  CORNER CASE: Gossip mode - all validators receive precommits`);
      }
    }

    if (totalPower >= workingReplica.state.config.threshold) {
      // Commit phase - use pre-computed state with incremented height
      workingReplica.state = {
        ...workingReplica.proposal.newState,
        entityId: workingReplica.state.entityId, // PRESERVE: Never lose entityId
        height: workingReplica.state.height + 1,
      };
      // DEBUG removed: â†’ Threshold reached! Committing frame, height: ${workingReplica.state.height}`);

      // Save proposal data before clearing
      const sortedSignatures = sortSignatures(workingReplica.proposal.signatures, workingReplica.state.config);
      const committedFrame = workingReplica.proposal;

      // Clear only committed txs; keep any new txs merged into this tick
      const committedTxCount = committedFrame.txs.length;
      if (committedTxCount > 0) {
        workingReplica.mempool.splice(0, committedTxCount);
      }
      delete workingReplica.proposal;
      delete workingReplica.lockedFrame; // Release lock after commit

      // Only send commit notifications in proposer-based mode
      // In gossip mode, everyone already has all precommits via gossip
      if (workingReplica.state.config.mode === 'proposer-based') {
        const committedProposalHash = committedFrame.hash.slice(0, 10);
        console.log(
          `ðŸ” COMMIT-START: [${timestamp}] ${workingReplica.signerId} reached threshold for proposal ${committedProposalHash}, sending commit notifications...`,
        );

        // Notify all validators (except self - proposer already has all precommits)
        workingReplica.state.config.validators.forEach(validatorId => {
          if (validatorId !== workingReplica.signerId) {
            const precommitSigners = Array.from(sortedSignatures.keys());
            console.log(
              `ðŸ” COMMIT: [${timestamp}] ${workingReplica.signerId} sending commit notification to ${validatorId} for entity ${entityInput.entityId.slice(0, 10)}, proposal ${committedProposalHash} (${sortedSignatures.size} precommits from: ${precommitSigners.join(', ')})`,
            );
            entityOutbox.push({
              entityId: entityInput.entityId,
              signerId: validatorId,
              precommits: sortedSignatures,
              proposedFrame: committedFrame,
            });
          }
        });
        // const notifiedCount = workingReplica.state.config.validators.length - 1; // excluding self
        // DEBUG removed: â†’ Sending commit notifications to ${notifiedCount} validators (excluding self)`);
      } else {
        console.log(
          `ðŸ” GOSSIP-COMMIT: [${timestamp}] ${workingReplica.signerId} NOT sending commit notifications (gossip mode) for entity ${entityInput.entityId.slice(0, 10)}...`,
        );
        if (DEBUG)
          console.log(`    â†’ Gossip mode: No commit notifications needed (everyone has precommits via gossip)`);
      }
    }
  }

  // Commit notifications are now handled at the top of the function

  // Debug consensus trigger conditions
  console.log(`ðŸŽ¯ CONSENSUS-CHECK: Entity ${workingReplica.entityId}:${workingReplica.signerId}`);
  console.log(`ðŸŽ¯   isProposer: ${workingReplica.isProposer}`);
  console.log(`ðŸŽ¯   mempool.length: ${workingReplica.mempool.length}`);
  console.log(`ðŸŽ¯   hasProposal: ${!!workingReplica.proposal}`);
  if (workingReplica.mempool.length > 0) {
    console.log(
      `ðŸŽ¯   mempoolTypes:`,
      workingReplica.mempool.map(tx => tx.type),
    );
  }

  // Auto-propose logic: ONLY proposer can propose (BFT requirement)
  if (workingReplica.isProposer && workingReplica.mempool.length > 0 && !workingReplica.proposal) {
    console.log(`ðŸ”¥ ALICE-PROPOSES: Alice auto-propose triggered!`);
    console.log(
      `ðŸ”¥ ALICE-PROPOSES: mempool=${workingReplica.mempool.length}, isProposer=${workingReplica.isProposer}, hasProposal=${!!workingReplica.proposal}`,
    );
    console.log(
      `ðŸ”¥ ALICE-PROPOSES: Mempool transaction types:`,
      workingReplica.mempool.map(tx => tx.type),
    );

    // Check if this is a single signer entity (threshold = 1, only 1 validator)
    const isSingleSigner =
      workingReplica.state.config.validators.length === 1 && workingReplica.state.config.threshold === BigInt(1);

    if (isSingleSigner) {
      console.log(`ðŸš€ SINGLE-SIGNER: Direct execution without consensus for single signer entity`);
      // For single signer entities, directly apply transactions without consensus
      const { newState: newEntityState, outputs: frameOutputs, jOutputs: frameJOutputs } = await applyEntityFrame(env, workingReplica.state, workingReplica.mempool);
      workingReplica.state = {
        ...newEntityState,
        entityId: workingReplica.state.entityId, // PRESERVE: Never lose entityId
        height: workingReplica.state.height + 1,
      };

      // Add any outputs generated by entity transactions to the outbox
      entityOutbox.push(...frameOutputs);
      jOutbox.push(...frameJOutputs); // CRITICAL: Collect J-outputs!

      // Clear mempool after direct application
      workingReplica.mempool.length = 0;

      if (DEBUG)
        console.log(
          `    âš¡ Single signer entity: transactions applied directly, height: ${workingReplica.state.height}`,
        );
      // SINGLE-SIGNER-RETURN removed - too noisy
      console.log(`ðŸ”¥ SINGLE-SIGNER RETURN: entityOutbox=${entityOutbox.length}, jOutbox=${jOutbox.length}`);
      return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica }; // Skip the full consensus process
    }

    if (DEBUG)
      console.log(
        `    ðŸš€ Auto-propose triggered: mempool=${workingReplica.mempool.length}, isProposer=${workingReplica.isProposer}, hasProposal=${!!workingReplica.proposal}`,
      );
    // Compute new state once during proposal
    const { newState: newEntityState, outputs: proposalOutputs } = await applyEntityFrame(env, workingReplica.state, workingReplica.mempool);

    // Add any outputs generated during proposal to the outbox
    entityOutbox.push(...proposalOutputs);

    // Proposer creates new timestamp for this frame (DETERMINISTIC: use runtime timestamp)
    const newTimestamp = env.timestamp;

    // NOTE: Timestamp validation removed - comparing env.timestamp to itself was meaningless
    // For peer proposals, validation happens during signature verification

    // TODO(bft-hardening): Replace weak placeholder hash with cryptographic commitment
    // Current: height + timestamp only - validators don't sign actual state content
    // Required: Merkle root over transactions + keccak256(orderbookExt + accountStates)
    // Impact: Without this, equivocation attacks possible in multi-validator setup
    // See: docs/htlc-hardening.md for full security audit
    const frameHash = `frame_${workingReplica.state.height + 1}_${newTimestamp}`;
    const selfSignature = signFrame(env, workingReplica.signerId, frameHash);

    workingReplica.proposal = {
      height: workingReplica.state.height + 1,
      txs: [...workingReplica.mempool],
      hash: frameHash,
      newState: {
        ...newEntityState,
        entityId: workingReplica.state.entityId, // PRESERVE: Never lose entityId in proposal
        height: workingReplica.state.height + 1,
        timestamp: newTimestamp, // Set new deterministic timestamp in proposed state
      },
      signatures: new Map<string, string>([[workingReplica.signerId, selfSignature]]), // Proposer signs immediately
    };

    if (DEBUG)
      console.log(
        `    â†’ Auto-proposing frame ${workingReplica.proposal.hash} with ${workingReplica.proposal.txs.length} txs and self-signature.`,
      );

    // Send proposal to all validators (except self)
    workingReplica.state.config.validators.forEach(validatorId => {
      if (validatorId !== workingReplica.signerId) {
        entityOutbox.push({
          entityId: entityInput.entityId,
          signerId: validatorId,
          proposedFrame: workingReplica.proposal!,
          // Note: Don't send entityTxs separately - they're already in proposedFrame.txs
        });
      }
    });
  } else if (workingReplica.isProposer && workingReplica.mempool.length === 0 && !workingReplica.proposal) {
    // DEBUG removed: âš ï¸  CORNER CASE: Proposer with empty mempool - no auto-propose`);
  } else if (!workingReplica.isProposer && workingReplica.mempool.length > 0) {
    // DEBUG removed: â†’ Non-proposer sending ${workingReplica.mempool.length} txs to proposer`);
    // Send mempool to proposer
    const proposerId = workingReplica.state.config.validators[0];
    if (!proposerId) {
      logError("FRAME_CONSENSUS", `âŒ No proposer found in validators: ${workingReplica.state.config.validators}`);
      return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica };
    }
    console.log(`ðŸ”¥ BOB-TO-ALICE: Bob sending ${workingReplica.mempool.length} txs to proposer ${proposerId}`);
    console.log(
      `ðŸ”¥ BOB-TO-ALICE: Transaction types:`,
      workingReplica.mempool.map(tx => tx.type),
    );
    entityOutbox.push({
      entityId: entityInput.entityId,
      signerId: proposerId,
      entityTxs: [...workingReplica.mempool],
    });
    // Clear mempool after sending
    workingReplica.mempool.length = 0;
  } else if (workingReplica.isProposer && workingReplica.proposal) {
    // DEBUG removed: âš ï¸  CORNER CASE: Proposer already has pending proposal - no new auto-propose`);
  }

  // Debug: Log outputs being generated with detailed analysis
  console.log(
    `ðŸ” OUTPUT-GENERATED: [${timestamp}] Entity #${entityDisplay}:${formatSignerDisplay(workingReplica.signerId)} generating ${entityOutbox.length} outputs`,
  );
  console.log(
    `ðŸ” OUTPUT-FINAL-STATE: proposal=${workingReplica.proposal?.hash?.slice(0, 10) || 'none'}, mempool=${workingReplica.mempool.length}, locked=${workingReplica.lockedFrame?.hash?.slice(0, 10) || 'none'}`,
  );

  entityOutbox.forEach((output, index) => {
    const targetDisplay = formatEntityDisplay(output.entityId);
    const outputFrameHash = output.proposedFrame?.hash?.slice(0, 10) || 'none';
    console.log(
      `ðŸ” OUTPUT-${index + 1}: [${timestamp}] To Entity #${targetDisplay}:${formatSignerDisplay(output.signerId)} - txs=${output.entityTxs?.length || 0}, precommits=${output.precommits?.size || 0}, frame=${outputFrameHash}`,
    );

    if (output.precommits?.size) {
      const precommitSigners = Array.from(output.precommits.keys());
      if (HEAVY_LOGS) console.log(`ðŸ” OUTPUT-${index + 1}-PRECOMMITS: Sending precommits from: ${precommitSigners.join(', ')}`);

      // Show the actual signature content to track duplicates
      output.precommits.forEach((sig, signer) => {
        const sigShort = sig.slice(0, 20);
        const proposalFromSig = sig.split('_')[2]?.slice(0, 10) || 'unknown';
        if (HEAVY_LOGS) console.log(`ðŸ” OUTPUT-${index + 1}-SIG-DETAIL: ${signer} -> ${sigShort}... (proposal: ${proposalFromSig})`);
      });
    }

    // Classify output type for clarity
    if (output.proposedFrame && output.precommits?.size) {
      if (HEAVY_LOGS) console.log(`ðŸ” OUTPUT-${index + 1}-TYPE: COMMIT_NOTIFICATION (frame + precommits)`);
    } else if (output.precommits?.size) {
      if (HEAVY_LOGS) console.log(`ðŸ” OUTPUT-${index + 1}-TYPE: PRECOMMIT_VOTE (precommits only)`);
    } else if (output.proposedFrame) {
      if (HEAVY_LOGS) console.log(`ðŸ” OUTPUT-${index + 1}-TYPE: PROPOSAL (frame only)`);
    } else if (output.entityTxs?.length) {
      if (HEAVY_LOGS) console.log(`ðŸ” OUTPUT-${index + 1}-TYPE: TRANSACTION_FORWARD (txs only)`);
    } else {
      if (HEAVY_LOGS) console.log(`ðŸ” OUTPUT-${index + 1}-TYPE: UNKNOWN (empty output)`);
    }
  });

  return { newState: workingReplica.state, outputs: entityOutbox, jOutputs: jOutbox, workingReplica };
};

export const applyEntityFrame = async (
  env: Env,
  entityState: EntityState,
  entityTxs: EntityTx[],
): Promise<{ newState: EntityState, outputs: EntityInput[], jOutputs: JInput[] }> => {
  console.log(`ðŸŽ¯ APPLY-ENTITY-FRAME: Processing ${entityTxs.length} transactions`);
  entityTxs.forEach((tx, index) => {
    console.log(`ðŸŽ¯ Transaction ${index}: type="${tx.type}", data=`, tx.data);
  });

  let currentEntityState = entityState;
  const allOutputs: EntityInput[] = [];
  const allJOutputs: JInput[] = []; // Collect J-outputs

  // Track accounts that need frame proposals during this processing round
  const proposableAccounts = new Set<string>();

  // === AGGREGATE PURE EVENTS FROM ALL HANDLERS ===
  const allMempoolOps: Array<{ accountId: string; tx: any }> = [];
  const allSwapOffersCreated: Array<any> = [];
  const allSwapOffersCancelled: Array<any> = [];

  for (const entityTx of entityTxs) {
    const { newState, outputs, jOutputs, mempoolOps, swapOffersCreated, swapOffersCancelled } = await applyEntityTx(env, currentEntityState, entityTx);
    currentEntityState = newState;

    // DEBUG: Check account mempools IMMEDIATELY after entityTx
    if (entityTx.type === 'j_event') {
      for (const [cpId, acct] of currentEntityState.accounts) {
        if (acct.mempool.length > 0) {
          if (HEAVY_LOGS) console.log(`ðŸ” [Frame ${env.height}] AFTER-ENTITY-TX(j_event): Account ${cpId.slice(-4)} mempool:`, acct.mempool.map((tx: any) => tx.type));
        }
      }
    }

    allOutputs.push(...outputs);
    if (jOutputs) allJOutputs.push(...jOutputs);

    // CRITICAL FIX: Apply mempoolOps IMMEDIATELY instead of batching
    // This ensures directPayment can detect newly-added mempool items in the same tick
    if (mempoolOps && mempoolOps.length > 0) {
      console.log(`ðŸ“¦ ENTITY-ORCHESTRATOR: Applying ${mempoolOps.length} mempoolOps (inline)`);
      for (const { accountId, tx } of mempoolOps) {
        const account = currentEntityState.accounts.get(accountId);
        if (account) {
          account.mempool.push(tx);
          proposableAccounts.add(accountId);
          console.log(`ðŸ“¦   â†’ ${accountId.slice(-8)}: ${tx.type} (mempool now: ${account.mempool.length} txs, pendingFrame=${!!account.pendingFrame ? 'h'+account.pendingFrame.height : 'none'})`);
        } else {
          console.warn(`ðŸ“¦   âš ï¸ Account ${accountId.slice(-8)} not found for mempoolOp`);
        }
      }
    }

    if (swapOffersCreated) allSwapOffersCreated.push(...swapOffersCreated);
    if (swapOffersCancelled) allSwapOffersCancelled.push(...swapOffersCancelled);

    // Debug: Log all account mempools after each tx
    if (entityTx.type === 'extendCredit') {
      console.log(`ðŸ’³ POST-EXTEND-CREDIT: Checking all account mempools:`);
      for (const [cpId, acctMachine] of currentEntityState.accounts) {
        console.log(`ðŸ’³   Account with ${cpId.slice(0,10)}: mempool=${acctMachine.mempool.length}, pendingFrame=${acctMachine.pendingFrame ? `height=${acctMachine.pendingFrame.height}` : 'none'}, currentHeight=${acctMachine.currentHeight}`);
        if (acctMachine.mempool.length > 0) {
          console.log(`ðŸ’³   Mempool txs:`, acctMachine.mempool.map(tx => tx.type));
        }
        if (acctMachine.pendingFrame) {
          console.log(`ðŸ’³   âš ï¸ BLOCKING: pendingFrame exists - no new proposals until ACKed!`);
        }
      }
    }

    // Track which accounts need proposals based on transaction type
    if (entityTx.type === 'accountInput' && entityTx.data) {
      const fromEntity = entityTx.data.fromEntityId;
      // Account keyed by counterparty ID (fromEntity is our counterparty)
      const accountMachine = currentEntityState.accounts.get(fromEntity);

      if (accountMachine) {
        // Add to proposable if:
        // - We have pending mempool items and no pending frame
        const isAck = entityTx.data.height && entityTx.data.prevHanko;
        const hasPendingTxs = accountMachine.mempool.length > 0;

        // Only propose if we have something to send:
        // - Have transactions in mempool
        if (hasPendingTxs && !accountMachine.pendingFrame) {
          proposableAccounts.add(fromEntity); // counterparty ID
          console.log(`ðŸ”„ Added ${fromEntity.slice(0,10)} to proposable - Pending:${hasPendingTxs}`);
        } else if (isAck) {
          console.log(`âœ… Received ACK from ${fromEntity.slice(0,10)}, no action needed (mempool empty)`);
        }
      }
    } else if (entityTx.type === 'directPayment' && entityTx.data) {
      if (HEAVY_LOGS) console.log(`ðŸ” DIRECT-PAYMENT detected in applyEntityFrame`);
      if (HEAVY_LOGS) console.log(`ðŸ” Payment data:`, {
        targetEntityId: entityTx.data.targetEntityId,
        route: entityTx.data.route,
        amount: entityTx.data.amount
      });
      if (HEAVY_LOGS) console.log(`ðŸ” Current entity has ${currentEntityState.accounts.size} accounts`);

      // Payment was added to mempool in applyEntityTx
      // We need to find which account got the payment and mark it for frame proposal

      // Check all accounts to see which one has new mempool items
      // Note: accountKey is counterparty ID (e.g., "alice", "bob")
      if (HEAVY_LOGS) console.log(`ðŸ” DIRECT-PAYMENT-SCAN: Entity ${currentEntityState.entityId.slice(-4)} has ${currentEntityState.accounts.size} accounts`);
      for (const [counterpartyId, accountMachine] of currentEntityState.accounts) {
        const isLeft = isLeftEntity(accountMachine.proofHeader.fromEntity, accountMachine.proofHeader.toEntity);
        if (HEAVY_LOGS) console.log(`ðŸ” Checking account ${counterpartyId.slice(-10)}: mempool=${accountMachine.mempool.length}, isLeft=${isLeft}, pendingFrame=${!!accountMachine.pendingFrame}, mempoolTxs=[${accountMachine.mempool.map((t: any) => t.type).join(',')}]`);
        if (accountMachine.mempool.length > 0 && !accountMachine.pendingFrame) {
          proposableAccounts.add(counterpartyId);
          console.log(`ðŸ”„ âœ… Added ${counterpartyId.slice(-10)} to proposableAccounts (has ${accountMachine.mempool.length} mempool items)`);
        } else if (accountMachine.pendingFrame) {
          console.log(`ðŸ”„ â¸ï¸  SKIP: ${counterpartyId.slice(-10)} has pendingFrame h${accountMachine.pendingFrame.height} - will propose after ACK`);
        }
      }
    } else if (entityTx.type === 'openAccount' && entityTx.data) {
      // Account opened - may need initial frame
      const targetEntity = entityTx.data.targetEntityId;
      // Account keyed by counterparty ID
      const accountMachine = currentEntityState.accounts.get(targetEntity);
      if (accountMachine) {
        const isLeft = isLeftEntity(accountMachine.proofHeader.fromEntity, accountMachine.proofHeader.toEntity);
        if (isLeft && accountMachine.mempool.length > 0 && !accountMachine.pendingFrame) {
          proposableAccounts.add(targetEntity);
          console.log(`ðŸ”„ Added ${targetEntity.slice(0,10)} to proposable (new account opened)`);
        }
      }
    } else if (entityTx.type === 'extendCredit' && entityTx.data) {
      // Credit extension - mark account for proposal
      const counterpartyId = entityTx.data.counterpartyEntityId;
      // Account keyed by counterparty ID
      const accountMachine = currentEntityState.accounts.get(counterpartyId);
      console.log(`ðŸ’³ EXTEND-CREDIT: Checking account ${counterpartyId.slice(0,10)} for proposal`);
      console.log(`ðŸ’³ EXTEND-CREDIT: accountMachine exists: ${!!accountMachine}, mempool: ${accountMachine?.mempool?.length || 0}`);
      if (accountMachine && accountMachine.mempool.length > 0) {
        proposableAccounts.add(counterpartyId);
        console.log(`ðŸ’³ âœ… Added ${counterpartyId.slice(0,10)} to proposableAccounts (credit extension)`);
      }
    }
  }

  // === APPLY AGGREGATED PURE EVENTS ===

  // 1. MempoolOps now applied inline (see above in the loop) to fix simultaneous payment bug
  // This section removed - mempoolOps are applied immediately after each applyEntityTx

  // 2. Run orderbook matching on aggregated swap offers (batch matching)
  if (allSwapOffersCreated.length > 0 && currentEntityState.orderbookExt) {
    console.log(`ðŸ“Š ENTITY-ORCHESTRATOR: Batch matching ${allSwapOffersCreated.length} swap offers`);

    // AUDIT FIX (CRITICAL-1): Enrich SwapOfferEvent with accountId from Hub's perspective
    // Hub is running this code, so accountId = the counterparty's entityId (the Map key)
    // For Hub processing Alice's offer: fromEntity=Hub, toEntity=Alice (from Hub's A-Machine)
    // So accountId = Alice's entityId (the counterparty who placed the offer)
    const enrichedOffers = allSwapOffersCreated.map(offer => {
      // The offer comes from an account where the account's proofHeader has
      // fromEntity = entity running this code (Hub) and toEntity = counterparty
      // BUT offers are created by the MAKER, who may be fromEntity or toEntity
      // depending on makerIsLeft
      //
      // SIMPLE RULE: Hub's Map key = counterparty ID
      // The counterparty is whoever is NOT Hub in this account
      // Since we're Hub and we're processing, accountId = whichever entity is NOT us
      const hubId = currentEntityState.entityId;
      const counterparty = offer.fromEntity === hubId ? offer.toEntity : offer.fromEntity;
      return { ...offer, accountId: counterparty };
    });
    console.log(`ðŸ“Š ENTITY-ORCHESTRATOR: Enriched ${enrichedOffers.length} offers with accountId`);

    const { processOrderbookSwaps } = await import('./entity-tx/handlers/account');
    const matchResult = processOrderbookSwaps(currentEntityState, enrichedOffers);

    // Apply match results to account mempools
    for (const { accountId, tx } of matchResult.mempoolOps) {
      const account = currentEntityState.accounts.get(accountId);
      if (account) {
        account.mempool.push(tx);
        proposableAccounts.add(accountId);
        console.log(`ðŸ“Š   â†’ ${accountId.slice(-8)}: ${tx.type}`);
      }

      if (tx.type === 'swap_resolve') {
        currentEntityState.pendingSwapFillRatios ||= new Map();
        const key = `${accountId}:${tx.data.offerId}`;
        currentEntityState.pendingSwapFillRatios.set(key, tx.data.fillRatio);
      }
    }

    // Apply book updates
    const ext = currentEntityState.orderbookExt as any;
    for (const { pairId, book } of matchResult.bookUpdates) {
      ext.books.set(pairId, book);
    }
  }

  // 3. Process swap cancellations
  if (allSwapOffersCancelled.length > 0 && currentEntityState.orderbookExt) {
    console.log(`ðŸ“Š ENTITY-ORCHESTRATOR: Processing ${allSwapOffersCancelled.length} swap cancels`);
    const { processOrderbookCancels } = await import('./entity-tx/handlers/account');
    const bookUpdates = processOrderbookCancels(currentEntityState, allSwapOffersCancelled);

    const ext = currentEntityState.orderbookExt as any;
    for (const { pairId, book } of bookUpdates) {
      ext.books.set(pairId, book);
    }
  }

  // AUTO-PROPOSE: Propose account frames for touched accounts (Channel.ts pattern)
  const { proposeAccountFrame } = await import('./account-consensus');

  // CRITICAL: Deterministic ordering
  // Simple filter: propose if ready (mempool non-empty, no pendingFrame)
  // If pendingFrame exists, skip - will be handled by BATCH-CHECK when ACK arrives
  const accountsToProposeFrames = Array.from(proposableAccounts)
    .filter(accountId => {
      const accountMachine = currentEntityState.accounts.get(accountId);
      if (!accountMachine) {
        if (HEAVY_LOGS) console.log(`ðŸ” FILTER: Account ${accountId.slice(-8)} not found - skip`);
        return false;
      }
      if (accountMachine.mempool.length === 0) {
        if (HEAVY_LOGS) console.log(`ðŸ” FILTER: Account ${accountId.slice(-8)} mempool empty - skip`);
        return false;
      }
      if (accountMachine.pendingFrame) {
        if (HEAVY_LOGS) console.log(`ðŸ” FILTER: Account ${accountId.slice(-8)} has pendingFrame h${accountMachine.pendingFrame.height} - SKIP (will batch on ACK)`);
        return false;
      }
      if (HEAVY_LOGS) console.log(`ðŸ” FILTER: Account ${accountId.slice(-8)} READY - proposing (mempool: ${accountMachine.mempool.length})`);
      return true;
    })
    .sort();

  if (accountsToProposeFrames.length > 0) {

    for (const accountKey of accountsToProposeFrames) {
      const accountMachine = currentEntityState.accounts.get(accountKey);
      const { counterparty: cpId } = accountMachine ? getAccountPerspective(accountMachine, currentEntityState.entityId) : { counterparty: 'unknown' };
      if (HEAVY_LOGS) console.log(`ðŸ” [Frame ${env.height}] BEFORE-PROPOSE: Getting account for ${cpId.slice(-4)}`);
      if (accountMachine) {
        console.log(`ðŸ“‹ [Frame ${env.height}] PROPOSE-FRAME for ${cpId.slice(-4)}: mempool=${accountMachine.mempool.length} txs:`, accountMachine.mempool.map(tx => tx.type));
        console.log(`ðŸ“‹ [Frame ${env.height}] PROPOSE-FRAME: leftJObs=${accountMachine.leftJObservations?.length || 0}, rightJObs=${accountMachine.rightJObservations?.length || 0}`);
        console.log(`ðŸ“‹ [Frame ${env.height}] PROPOSE-FRAME: Full mempool details:`, accountMachine.mempool.map((tx, i) => `${i}:${tx.type}`).join(', '));
        const proposal = await proposeAccountFrame(env, accountMachine, false, currentEntityState.lastFinalizedJHeight);

        console.log(`ðŸ“¤ PROPOSE-RESULT for ${cpId.slice(-4)}: success=${proposal.success}, hasAccountInput=${!!proposal.accountInput}, error=${proposal.error || 'none'}`);

        if (proposal.success && proposal.accountInput) {
          // Get the proposer of the target entity from env
          // IMPORTANT: AccountInput sent only to PROPOSER (bilateral consensus between entity proposers)
          // Multi-validator entities share account state via entity-level consensus
          const targetProposerId = resolveEntityProposerId(
            env,
            proposal.accountInput!.toEntityId,
            'accountInput.propose'
          );

          // Convert AccountInput to EntityInput for routing
          const outputEntityInput: EntityInput = {
            entityId: proposal.accountInput.toEntityId,
            signerId: targetProposerId, // Route to target entity's proposer
            entityTxs: [{
              type: 'accountInput' as const,
              data: proposal.accountInput
            }]
          };
          allOutputs.push(outputEntityInput);

          console.log(`ðŸ“® ACCOUNT-FRAME-OUTPUT: frame ${proposal.accountInput.height} â†’ Entity ${proposal.accountInput.toEntityId.slice(-4)} (${accountKey.slice(-8)} account)`);

          // Add events to entity messages with size limiting
          addMessages(currentEntityState, proposal.events);
          emitScopedEvents(
            env,
            'account',
            `E/A/${currentEntityState.entityId.slice(-4)}:${cpId.slice(-4)}/propose`,
            proposal.events,
            {
              entityId: currentEntityState.entityId,
              counterpartyId: cpId,
              frameHeight: proposal.accountInput.height,
              accountKey,
            },
            currentEntityState.entityId,
          );
        }
      }
    }
  }

  return { newState: currentEntityState, outputs: allOutputs, jOutputs: allJOutputs };
};

// === HELPER FUNCTIONS ===

/**
 * Calculate quorum power based on validator shares
 */
export const calculateQuorumPower = (config: ConsensusConfig, signers: string[]): bigint => {
  return signers.reduce((total, signerId) => {
    const shares = config.shares[signerId];
    if (shares === undefined) {
      throw new Error(`CONSENSUS-SAFETY: Unknown validator ${signerId} - cannot calculate quorum power`);
    }
    return total + shares;
  }, 0n);
};

export const sortSignatures = (signatures: Map<string, string>, config: ConsensusConfig): Map<string, string> => {
  const sortedEntries = Array.from(signatures.entries()).sort(([a], [b]) => {
    const indexA = config.validators.indexOf(a);
    const indexB = config.validators.indexOf(b);
    return indexA - indexB;
  });
  return new Map(sortedEntries);
};

// === ENTITY UTILITIES (existing) ===

/**
 * Merges duplicate entity inputs to reduce processing overhead
 */
const mergeJEventTxs = (txs: EntityTx[]): EntityTx[] => {
  const merged: EntityTx[] = [];

  for (const tx of txs) {
    if (tx.type !== 'j_event' || !tx.data) {
      merged.push(tx);
      continue;
    }

    const data = tx.data as any;
    const blockNumber = data.blockNumber;
    const blockHash = data.blockHash;

    const existing = merged.find(
      candidate =>
        candidate.type === 'j_event' &&
        candidate.data &&
        (candidate.data as any).blockNumber === blockNumber &&
        (candidate.data as any).blockHash === blockHash,
    );

    if (!existing || !existing.data) {
      merged.push(tx);
      continue;
    }

    const existingData = existing.data as any;
    const existingEvents = existingData.events || (existingData.event ? [existingData.event] : []);
    const incomingEvents = data.events || (data.event ? [data.event] : []);

    const seen = new Set<string>();
    const mergedEvents: any[] = [];
    for (const event of [...existingEvents, ...incomingEvents]) {
      const key = `${event?.type ?? 'unknown'}:${safeStringify(event?.data ?? event)}`;
      if (seen.has(key)) continue;
      seen.add(key);
      mergedEvents.push(event);
    }

    existingData.events = mergedEvents;
    existingData.event = mergedEvents[0];

    if (typeof data.observedAt === 'number') {
      if (typeof existingData.observedAt !== 'number' || data.observedAt < existingData.observedAt) {
        existingData.observedAt = data.observedAt;
      }
    }

    if (HEAVY_LOGS) {
      console.log(
        `ðŸ” MERGE-J-EVENTS: block ${blockNumber} ${blockHash?.slice(0, 10)}... now ${mergedEvents.length} events`,
      );
    }
  }

  return merged;
};

export const mergeEntityInputs = (inputs: EntityInput[]): EntityInput[] => {
  const merged = new Map<string, EntityInput>();
  const conflicts: EntityInput[] = [];
  let duplicateCount = 0;

  // Look for potential Carol duplicates specifically
  const carolInputs = inputs.filter(input => input.signerId.includes('carol'));
  if (carolInputs.length > 1) {
    if (HEAVY_LOGS) console.log(`ðŸ” MERGE-CAROL-ALERT: Found ${carolInputs.length} inputs from Carol - potential duplicate source!`);
    carolInputs.forEach((input, i) => {
      const entityShort = input.entityId.slice(0, 10);
      const precommitSigners = input.precommits ? Array.from(input.precommits.keys()).join(',') : 'none';
      if (HEAVY_LOGS) console.log(`ðŸ” MERGE-CAROL-${i + 1}: ${entityShort}:${input.signerId} - precommits: ${precommitSigners}`);
    });
  }

  for (const input of inputs) {
    const key = `${input.entityId}:${input.signerId}`;
    const entityShort = input.entityId.slice(0, 10);

    if (merged.has(key)) {
      const existing = merged.get(key)!;
      duplicateCount++;

      const existingFrameHash = existing.proposedFrame?.hash;
      const incomingFrameHash = input.proposedFrame?.hash;
      if (existingFrameHash && incomingFrameHash && existingFrameHash !== incomingFrameHash) {
        const existingHasPrecommits = !!existing.precommits && existing.precommits.size > 0;
        const incomingHasPrecommits = !!input.precommits && input.precommits.size > 0;
        console.warn(
          `âš ï¸  MERGE-CONFLICT: ${key} has different proposedFrame hashes (${existingFrameHash.slice(0, 10)} vs ${incomingFrameHash.slice(0, 10)}) - keeping both inputs`,
        );
        if (incomingHasPrecommits && !existingHasPrecommits) {
          merged.set(key, { ...input });
          conflicts.push(existing);
        } else {
          conflicts.push(input);
        }
        continue;
      }

      if (HEAVY_LOGS) console.log(`ðŸ” DUPLICATE-FOUND: Merging duplicate input ${duplicateCount} for ${entityShort}:${input.signerId}`);

      // Merge entity transactions
      if (input.entityTxs) {
        existing.entityTxs = [...(existing.entityTxs || []), ...input.entityTxs];
        if (existing.entityTxs) {
          existing.entityTxs = mergeJEventTxs(existing.entityTxs);
        }
        if (HEAVY_LOGS) console.log(`ðŸ” MERGE-TXS: Added ${input.entityTxs.length} transactions`);
      }

      // Merge precommits
      if (input.precommits) {
        const existingPrecommits = existing.precommits || new Map();
        console.log(
          `ðŸ” MERGE-PRECOMMITS: Merging ${input.precommits.size} precommits into existing ${existingPrecommits.size} for ${entityShort}:${input.signerId}`,
        );
        input.precommits.forEach((signature, signerId) => {
          if (HEAVY_LOGS) console.log(`ðŸ” MERGE-DETAIL: Adding precommit from ${signerId} (sig: ${signature.slice(0, 20)}...)`);
          existingPrecommits.set(signerId, signature);
        });
        existing.precommits = existingPrecommits;
        if (HEAVY_LOGS) console.log(`ðŸ” MERGE-RESULT: Total ${existingPrecommits.size} precommits after merge`);
      }

      // Keep the latest frame (simplified)
      if (input.proposedFrame) existing.proposedFrame = input.proposedFrame;

      console.log(
        `    ðŸ”„ Merging inputs for ${key}: txs=${input.entityTxs?.length || 0}, precommits=${input.precommits?.size || 0}, frame=${!!input.proposedFrame}`,
      );
    } else {
      merged.set(key, { ...input });
    }
  }

  if (duplicateCount > 0) {
    console.log(`    âš ï¸  CORNER CASE: Merged ${duplicateCount} duplicate inputs (${inputs.length} â†’ ${merged.size})`);
  }

  const mergedInputs = Array.from(merged.values());
  return [...mergedInputs, ...conflicts].map(input => {
    if (input.entityTxs && input.entityTxs.length > 1) {
      return { ...input, entityTxs: mergeJEventTxs(input.entityTxs) };
    }
    return input;
  });
};

/**
 * Gets entity state summary for debugging
 */
export const getEntityStateSummary = (replica: EntityReplica): string => {
  const hasProposal = replica.proposal ? 'âœ“' : 'âœ—';
  return `mempool=${replica.mempool.length}, messages=${replica.state.messages.length}, proposal=${hasProposal}`;
};

/**
 * Checks if entity should auto-propose (simplified version)
 */
export const shouldAutoPropose = (replica: EntityReplica, _config: ConsensusConfig): boolean => {
  const hasMempool = replica.mempool.length > 0;
  const isProposer = replica.isProposer;
  const hasProposal = replica.proposal !== undefined;

  return hasMempool && isProposer && !hasProposal;
};

/**
 * Processes empty transaction arrays (corner case)
 */
export const handleEmptyTransactions = (): void => {
  console.log(`    âš ï¸  CORNER CASE: Empty transaction array received - no mempool changes`);
};

/**
 * Logs large transaction batches (corner case)
 */
export const handleLargeBatch = (txCount: number): void => {
  if (txCount >= 8) {
    console.log(`    âš ï¸  CORNER CASE: Large batch of ${txCount} transactions`);
  }
};

/**
 * Handles gossip mode precommit distribution
 */
export const handleGossipMode = (): void => {
  console.log(`    âš ï¸  CORNER CASE: Gossip mode - all validators receive precommits`);
};

/**
 * Logs proposer with empty mempool corner case
 */
export const handleEmptyMempoolProposer = (): void => {
  console.log(`    âš ï¸  CORNER CASE: Proposer with empty mempool - no auto-propose`);
};


//runtime/account-consensus.ts (1377 lines)
/**
 * XLN Account Consensus System
 *
 * Implements bilateral consensus between two entities for off-chain account settlement.
 * Based on old_src Channel.ts but adapted for entity-deterministic architecture.
 *
 * Key Concepts:
 * - AccountMachine: Bilateral state machine between two entities
 * - Giant Per-Token Table: Map<tokenId, Delta> like old_src channels
 * - Global Credit Limits: USD-denominated credit limits (simplified)
 * - Frame-Based Consensus: Bilateral agreement on account state changes
 * - Event Bubbling: Account events bubble up to E-Machine for entity messages
 */

import { AccountMachine, AccountFrame, AccountTx, AccountInput, Env, EntityState, Delta } from './types';
import { cloneAccountMachine, getAccountPerspective } from './state-helpers';
import { isLeft } from './account-utils';
import { signAccountFrame, verifyAccountSignature } from './account-crypto';
import { cryptoHash as hash, formatEntityId, HEAVY_LOGS } from './utils';
import { logError } from './logger';
import { safeStringify } from './serialization-utils';
import { validateAccountFrame as validateAccountFrameStrict } from './validation-utils';
import { processAccountTx } from './account-tx/apply';
import { buildSettlementDiffs, createSettlementHash } from './proof-builder.js';

// Removed createValidAccountSnapshot - using simplified AccountSnapshot interface

// === CONSTANTS ===
const MEMPOOL_LIMIT = 1000;
const MAX_MESSAGE_COUNTER = 1000000;

/**
 * Get depositoryAddress from environment (BrowserVM or active J-replica)
 * CRITICAL for replay protection - domain separator for signatures
 */
function getDepositoryAddress(env: Env): string {
  // Try BrowserVM first (most common)
  if (env.browserVM) {
    const browserVM = env.browserVM;
    const getAddress = browserVM.getDepositoryAddress?.() || browserVM.browserVM?.getDepositoryAddress?.();
    if (getAddress && getAddress !== '0x0000000000000000000000000000000000000000') {
      return getAddress;
    }
  }

  // Try active jurisdiction
  if (env.activeJurisdiction) {
    const jReplica = env.jReplicas.get(env.activeJurisdiction);
    if (jReplica?.depositoryAddress) {
      return jReplica.depositoryAddress;
    }
    // Fallback to legacy contracts.depository
    if (jReplica?.contracts?.depository) {
      return jReplica.contracts.depository;
    }
  }

  // Fallback: first J-replica with depositoryAddress
  for (const jReplica of env.jReplicas.values()) {
    if (jReplica.depositoryAddress) {
      return jReplica.depositoryAddress;
    }
    // Fallback to legacy contracts.depository
    if (jReplica.contracts?.depository) {
      return jReplica.contracts.depository;
    }
  }

  // Last resort: return zero address (will fail verification but won't crash)
  console.warn('[account-consensus] âš ï¸ No depositoryAddress found in env - using zero address (signatures will fail!)');
  return '0x0000000000000000000000000000000000000000';
}
const MAX_FRAME_TIMESTAMP_DRIFT_MS = 300000; // 5 minutes
const MAX_FRAME_SIZE_BYTES = 1048576; // 1MB frame size limit (Bitcoin block size standard)

function shouldIncludeToken(delta: Delta, totalDelta: bigint): boolean {
  const hasHolds = (delta.leftHtlcHold || 0n) !== 0n ||
                   (delta.rightHtlcHold || 0n) !== 0n ||
                   (delta.leftSwapHold || 0n) !== 0n ||
                   (delta.rightSwapHold || 0n) !== 0n;

  return !(totalDelta === 0n &&
           delta.leftCreditLimit === 0n &&
           delta.rightCreditLimit === 0n &&
           !hasHolds);
}

// === VALIDATION ===

/**
 * Validate account frame (frame-level validation)
 */
export function validateAccountFrame(
  frame: AccountFrame,
  currentTimestamp?: number,
  previousFrameTimestamp?: number
): boolean {
  if (frame.height < 0) return false;
  if (typeof frame.jHeight !== 'number' || frame.jHeight < 0) return false;
  if (frame.accountTxs.length > 100) return false;
  if (frame.tokenIds.length !== frame.deltas.length) return false;

  // CRITICAL: Timestamp validation for HTLC safety
  if (currentTimestamp !== undefined) {
    // Check drift (prevent clock manipulation)
    if (Math.abs(frame.timestamp - currentTimestamp) > MAX_FRAME_TIMESTAMP_DRIFT_MS) {
      console.log(`âŒ Frame timestamp drift too large: ${frame.timestamp} vs ${currentTimestamp}`);
      return false;
    }

    // Ensure non-decreasing timestamps (prevent time-travel attacks on HTLCs)
    // Allow equal timestamps (batched frames), but reject backwards movement
    if (previousFrameTimestamp !== undefined && frame.timestamp < previousFrameTimestamp - 1000) {
      console.log(`âŒ Frame timestamp went backwards significantly: ${frame.timestamp} < ${previousFrameTimestamp} (delta: ${previousFrameTimestamp - frame.timestamp}ms)`);
      return false;
    }
  }

  return true;
}

/**
 * Validate message counter (strict replay protection)
 * Counter must be EXACTLY ackedTransitions + 1 (sequential, no gaps allowed)
 */
export function validateMessageCounter(accountMachine: AccountMachine, counter: number): boolean {
  if (counter <= 0 || counter > MAX_MESSAGE_COUNTER) {
    console.log(`âŒ Counter out of range: ${counter} (must be 1-${MAX_MESSAGE_COUNTER})`);
    return false;
  }

  // CRITICAL: Enforce STRICT sequential increment (no gaps, no replays, no skips)
  const expectedCounter = accountMachine.ackedTransitions + 1;
  if (counter !== expectedCounter) {
    console.log(`âŒ Counter violation: got ${counter}, expected ${expectedCounter} (ackedTransitions=${accountMachine.ackedTransitions})`);
    return false;
  }

  return true;
}

// === FRAME HASH COMPUTATION ===

async function createFrameHash(frame: AccountFrame): Promise<string> {
  // CRITICAL: Use keccak256 for EVM compatibility (Channel.ts:585, 744)
  // Include prevFrameHash to chain frames together (prevents signature replay)
  const { ethers } = await import('ethers');

  // Encode FULL frame structure including all delta fields (2024 pattern)
  const frameData = {
    height: frame.height,
    timestamp: frame.timestamp,
    jHeight: frame.jHeight,
    prevFrameHash: frame.prevFrameHash, // Chain linkage
    accountTxs: frame.accountTxs.map(tx => ({
      type: tx.type,
      data: tx.data
    })),
    tokenIds: frame.tokenIds,
    deltas: frame.deltas.map(d => d.toString()), // Quick access sums
    // AUDIT FIX: Include FULL delta state (credit limits, allowances, collateral, HTLC holds)
    fullDeltaStates: frame.fullDeltaStates?.map(delta => ({
      tokenId: delta.tokenId,
      collateral: delta.collateral.toString(),
      ondelta: delta.ondelta.toString(),
      offdelta: delta.offdelta.toString(),
      leftCreditLimit: delta.leftCreditLimit.toString(),
      rightCreditLimit: delta.rightCreditLimit.toString(),
      leftAllowance: delta.leftAllowance.toString(),
      rightAllowance: delta.rightAllowance.toString(),
      leftHtlcHold: (delta.leftHtlcHold || 0n).toString(),   // HTLC holds
      rightHtlcHold: (delta.rightHtlcHold || 0n).toString(), // HTLC holds
      leftSwapHold: (delta.leftSwapHold || 0n).toString(),   // Swap holds
      rightSwapHold: (delta.rightSwapHold || 0n).toString(), // Swap holds
    }))
  };

  // Use keccak256 like 2024 Channel.ts (not truncated hash20)
  const encoded = safeStringify(frameData); // Deterministic JSON encoding
  return ethers.keccak256(ethers.toUtf8Bytes(encoded));
}

export async function computeFrameHash(frame: AccountFrame): Promise<string> {
  return createFrameHash(frame);
}

// === TRANSACTION PROCESSING ===

// Transaction processing now delegated to account-tx/apply.ts (modular handlers)
// See: src/account-tx/handlers/* for individual transaction handlers

// === FRAME CONSENSUS ===

/**
 * Propose account frame (like old_src Channel consensus)
 */
export async function proposeAccountFrame(
  env: Env,
  accountMachine: AccountMachine,
  skipCounterIncrement: boolean = false,
  entityJHeight?: number // Optional: J-height from entity state for HTLC consensus
): Promise<{
  success: boolean;
  accountInput?: AccountInput;
  events: string[];
  error?: string;
  revealedSecrets?: Array<{ secret: string; hashlock: string }>;
  swapOffersCreated?: Array<{
    offerId: string;
    makerIsLeft: boolean;
    fromEntity: string;
    toEntity: string;
    accountId?: string;
    giveTokenId: number;
    giveAmount: bigint;
    wantTokenId: number;
    wantAmount: bigint;
    minFillRatio: number;
  }>;
  swapOffersCancelled?: Array<{ offerId: string; accountId: string }>;
}> {
  // Derive counterparty from canonical left/right
  const myEntityId = accountMachine.proofHeader.fromEntity;
  const { counterparty } = getAccountPerspective(accountMachine, myEntityId);
  console.log(`ðŸš€ E-MACHINE: Proposing account frame for ${counterparty.slice(-4)}`);
  console.log(`ðŸš€ E-MACHINE: Account state - mempool=${accountMachine.mempool.length}, pendingFrame=${!!accountMachine.pendingFrame}, currentHeight=${accountMachine.currentHeight}`);
  console.log(`ðŸš€ E-MACHINE: Mempool contents:`, accountMachine.mempool.map(tx => tx.type));

  const events: string[] = [];

  // Mempool size validation
  if (accountMachine.mempool.length > MEMPOOL_LIMIT) {
    console.log(`âŒ E-MACHINE: Mempool overflow ${accountMachine.mempool.length} > ${MEMPOOL_LIMIT}`);
    return { success: false, error: `Mempool overflow: ${accountMachine.mempool.length} > ${MEMPOOL_LIMIT}`, events };
  }

  if (accountMachine.mempool.length === 0) {
    console.log(`âŒ E-MACHINE: No transactions in mempool to propose`);
    return { success: false, error: 'No transactions to propose', events };
  }

  // Check if we have a pending frame waiting for ACK
  if (accountMachine.pendingFrame) {
    console.log(`â³ E-MACHINE: Still waiting for ACK on pending frame #${accountMachine.pendingFrame.height}`);
    return { success: false, error: 'Waiting for ACK on pending frame', events };
  }

  console.log(`âœ… E-MACHINE: Creating frame with ${accountMachine.mempool.length} transactions...`);
  if (HEAVY_LOGS) console.log(`ðŸ” PROOF-HEADER: from=${formatEntityId(accountMachine.proofHeader.fromEntity)}, to=${formatEntityId(accountMachine.proofHeader.toEntity)}`);

  // Clone account machine for validation
  const clonedMachine = cloneAccountMachine(accountMachine);
  // Dispute nonce tracks committed frame height for counter-dispute support
  clonedMachine.proofHeader.disputeNonce = accountMachine.currentHeight + 1;

  // Get entity's synced J-height for deterministic HTLC validation
  const ourEntityId = accountMachine.proofHeader.fromEntity;
  const ourReplica = Array.from(env.eReplicas.values()).find(r => r.state.entityId === ourEntityId);
  const currentJHeight = ourReplica?.state.lastFinalizedJHeight || 0;
  const frameJHeight = entityJHeight ?? currentJHeight;

  // Process all transactions on the clone
  const allEvents: string[] = [];
  const revealedSecrets: Array<{ secret: string; hashlock: string }> = [];
  // AUDIT FIX (CRITICAL-1): SwapOfferEvent carries makerIsLeft + fromEntity/toEntity
  // Entity handler will enrich with accountId based on its own perspective
  const swapOffersCreated: Array<{
    offerId: string;
    makerIsLeft: boolean;
    fromEntity: string;
    toEntity: string;
    accountId?: string;  // Enriched by entity handler
    giveTokenId: number;
    giveAmount: bigint;
    wantTokenId: number;
    wantAmount: bigint;
    minFillRatio: number;
  }> = [];
  const swapOffersCancelled: Array<{ offerId: string; accountId: string }> = [];

  if (HEAVY_LOGS) console.log(`ðŸ” MEMPOOL-BEFORE-PROCESS: ${accountMachine.mempool.length} txs:`, accountMachine.mempool.map(tx => tx.type));

  for (const accountTx of accountMachine.mempool) {
    console.log(`   ðŸ” Processing accountTx type=${accountTx.type}`);
    const result = await processAccountTx(
      clonedMachine,
      accountTx,
      true, // Processing our own transactions
      env.timestamp, // Will be replaced by frame.timestamp during commit
      frameJHeight,  // Entity's synced J-height
      true // isValidation = true (on clone, skip persistent state updates)
    );

    if (!result.success) {
      // CRITICAL: Remove failed tx from mempool to prevent blocking future proposals
      const failedIndex = accountMachine.mempool.indexOf(accountTx);
      if (failedIndex >= 0) {
        accountMachine.mempool.splice(failedIndex, 1);
        console.log(`âš ï¸ Removed failed tx from mempool: ${accountTx.type} (${result.error})`);
      }
      return { success: false, error: `Tx validation failed: ${result.error}`, events: allEvents };
    }

    allEvents.push(...result.events);

    // Collect revealed secrets for backward propagation
    if (HEAVY_LOGS) console.log(`ðŸ” TX-RESULT: type=${accountTx.type}, hasSecret=${!!result.secret}, hasHashlock=${!!result.hashlock}`);
    if (result.secret && result.hashlock) {
      console.log(`âœ… Collected secret from ${accountTx.type}`);
      revealedSecrets.push({ secret: result.secret, hashlock: result.hashlock });
    }

    // Collect swap offers for orderbook integration
    if (result.swapOfferCreated) {
      console.log(`ðŸ“Š Collected swap offer: ${result.swapOfferCreated.offerId}`);
      swapOffersCreated.push(result.swapOfferCreated);
    }

    // Collect cancelled offers for orderbook cleanup
    if (result.swapOfferCancelled) {
      console.log(`ðŸ“Š Collected swap cancel: ${result.swapOfferCancelled.offerId}`);
      swapOffersCancelled.push(result.swapOfferCancelled);
    }
  }

  // CRITICAL FIX: Extract FULL delta state from clonedMachine.deltas (after processing)
  // Include ALL fields (credit limits, allowances, collateral) for dispute proofs
  const finalTokenIds: number[] = [];
  const finalDeltas: bigint[] = [];
  const fullDeltaStates: import('./types').Delta[] = [];

  // Sort by tokenId for deterministic ordering
  const sortedTokens = Array.from(clonedMachine.deltas.entries()).sort((a, b) => a[0] - b[0]);

  for (const [tokenId, delta] of sortedTokens) {
    // CONSENSUS FIX: Only include tokens that were actually used in transactions
    // This prevents mismatch when one side creates empty delta entries
    const totalDelta = delta.ondelta + delta.offdelta;

    // Skip tokens with zero delta AND zero limits AND zero holds (never used)
    // CRITICAL: Include tokens with HTLC/swap holds even if delta/limits/collateral are zero
    // NOTE: Collateral changes from j_events are included separately in frame validation
    // Only skip if delta, limits, AND holds are all zero
    // Collateral is omitted here because j_events can set it during frame processing
    if (!shouldIncludeToken(delta, totalDelta)) {
      console.log(`â­ï¸  Skipping unused token ${tokenId} from frame (zero delta/limits/holds)`);
      continue;
    }

    finalTokenIds.push(tokenId);
    finalDeltas.push(totalDelta);
    // AUDIT FIX: Store FULL delta state (collateral, credit limits, allowances)
    fullDeltaStates.push({ ...delta });
  }

  console.log(`ðŸ“Š Frame state after processing: ${finalTokenIds.length} tokens`);
  console.log(`ðŸ“Š TokenIds: [${finalTokenIds.join(', ')}]`);
  console.log(`ðŸ“Š Deltas: [${finalDeltas.map(d => d.toString()).join(', ')}]`);
  console.log(`ðŸ“Š FullDeltaStates:`, fullDeltaStates.map(d => ({
    tokenId: d.tokenId,
    collateral: d.collateral?.toString(),
    leftCreditLimit: d.leftCreditLimit?.toString(),
    rightCreditLimit: d.rightCreditLimit?.toString(),
  })));

  // Determine if we're left entity (for byLeft field)
  const weAreLeft = isLeft(accountMachine.proofHeader.fromEntity, accountMachine.proofHeader.toEntity);

  // Ensure monotonic timestamps within account (HTLC safety + multi-runtime compatibility)
  // In multi-runtime P2P scenarios, different runtimes may have different clock rates
  // We ensure frames always have increasing timestamps within an account chain
  const previousTimestamp = accountMachine.currentFrame?.timestamp ?? 0;
  const frameTimestamp = Math.max(env.timestamp, previousTimestamp + 1);
  if (frameTimestamp > env.timestamp) {
    console.log(`âš¡ TIMESTAMP-SYNC: Using monotonic timestamp ${frameTimestamp} (prev=${previousTimestamp}, env=${env.timestamp})`);
  }

  // Create account frame matching the real AccountFrame interface
  // CRITICAL: Deep-copy accountTxs to prevent mutation issues (j_event_claim data can be modified later)
  // Use structuredClone to preserve BigInt values
  const accountTxsCopy = structuredClone([...accountMachine.mempool]);
  const frameData = {
    height: accountMachine.currentHeight + 1,
    timestamp: frameTimestamp, // MONOTONIC: max(env.timestamp, prev+1) for multi-runtime safety
    jHeight: frameJHeight, // CRITICAL: J-height for HTLC consensus
    accountTxs: accountTxsCopy,
    // CRITICAL: Use stored stateHash from currentFrame (set during commit)
    prevFrameHash: accountMachine.currentHeight === 0
      ? 'genesis'
      : accountMachine.currentFrame.stateHash || '',
    stateHash: '', // Will be filled after hash calculation
    byLeft: weAreLeft, // Who proposed this frame
    tokenIds: finalTokenIds, // Use computed state from clonedMachine.deltas
    deltas: finalDeltas,      // Quick access: ondelta+offdelta sums
    fullDeltaStates          // AUDIT FIX: Full Delta objects for dispute proofs
  };

  // Calculate state hash (frameData is properly typed AccountFrame)
  frameData.stateHash = await createFrameHash(frameData as AccountFrame);

  // Debug: log what's being hashed at creation time
  if (HEAVY_LOGS) {
    console.log(`[HASH-DEBUG] Frame creation for ${accountMachine.proofHeader.toEntity.slice(-4)}:`);
    console.log(`  height: ${frameData.height}`);
    console.log(`  timestamp: ${frameData.timestamp}`);
    console.log(`  jHeight: ${frameData.jHeight}`);
    console.log(`  prevFrameHash: ${frameData.prevFrameHash?.slice(0,20)}...`);
    console.log(`  accountTxs count: ${frameData.accountTxs.length}`);
    console.log(`  accountTxs types: [${frameData.accountTxs.map(tx => tx.type).join(', ')}]`);
    console.log(`  tokenIds: [${frameData.tokenIds.join(', ')}]`);
    console.log(`  deltas: [${frameData.deltas.map(d => d.toString()).join(', ')}]`);
    console.log(`  fullDeltaStates count: ${fullDeltaStates.length}`);
    console.log(`  byLeft: ${frameData.byLeft}`);
    console.log(`  stateHash: ${frameData.stateHash}`);
  }

  // VALIDATE AT SOURCE: Guaranteed type safety from this point forward
  let newFrame: AccountFrame;
  try {
    newFrame = validateAccountFrameStrict(frameData, 'proposeAccountFrame');
  } catch (error) {
    console.warn(`âš ï¸ Frame validation failed: ${error instanceof Error ? error.message : String(error)}`);
    return {
      success: false,
      error: `Frame validation failed: ${(error as Error).message}`,
      events,
    };
  }

  // Validate frame size (Bitcoin 1MB block limit)
  const frameSize = safeStringify(newFrame).length;
  if (frameSize > MAX_FRAME_SIZE_BYTES) {
    console.warn(`âš ï¸ Frame too large: ${frameSize} bytes`);
    return {
      success: false,
      error: `Frame exceeds 1MB limit: ${frameSize} bytes`,
      events,
    };
  }
  console.log(`âœ… Frame size: ${frameSize} bytes (${(frameSize / MAX_FRAME_SIZE_BYTES * 100).toFixed(2)}% of 1MB limit)`);

  // Generate HANKO signature - CRITICAL: Use signerId, not entityId
  // For single-signer entities, build hanko with single EOA signature
  const signingEntityId = accountMachine.proofHeader.fromEntity;
  const signingReplica = Array.from(env.eReplicas.values()).find(r => r.state.entityId === signingEntityId);
  if (!signingReplica) {
    return { success: false, error: `Cannot find replica for entity ${signingEntityId.slice(-4)}`, events, accountInput: null };
  }
  const signingSignerId = signingReplica.state.config.validators[0]; // Single-signer: use first validator
  if (!signingSignerId) {
    return { success: false, error: `Entity ${signingEntityId.slice(-4)} has no validators`, events, accountInput: null };
  }

  console.log(`ðŸ” HANKO-SIGN: entityId=${signingEntityId.slice(-4)} â†’ signerId=${signingSignerId.slice(-4)}`);

  // Build hanko for account frame
  const { signHashesAsSingleEntity } = await import('./hanko-signing');
  // Sign frame hash for bilateral consensus
  const hankos = await signHashesAsSingleEntity(env, signingEntityId, signingSignerId, [newFrame.stateHash]);
  const frameHanko = hankos[0];
  if (!frameHanko) {
    return { success: false, error: 'Failed to build frame hanko', events, accountInput: null };
  }
  accountMachine.currentFrameHanko = frameHanko;

  // Build dispute proof and sign it (CRITICAL: always sign dispute proof with every frame)
  // BUG FIX: Use clonedMachine (has NEW state after txs) NOT accountMachine (old state)
  const { buildAccountProofBody, createDisputeProofHash } = await import('./proof-builder');
  const depositoryAddress = getDepositoryAddress(env);
  const proofResult = buildAccountProofBody(clonedMachine);
  const disputeHash = createDisputeProofHash(clonedMachine, proofResult.proofBodyHash, depositoryAddress);

  const disputeHankos = await signHashesAsSingleEntity(env, signingEntityId, signingSignerId, [disputeHash]);
  const disputeHanko = disputeHankos[0];
  if (!disputeHanko) {
    return { success: false, error: 'Failed to build dispute hanko', events, accountInput: null };
  }
  accountMachine.currentDisputeProofHanko = disputeHanko;
  accountMachine.currentDisputeProofCooperativeNonce = clonedMachine.proofHeader.cooperativeNonce;
  accountMachine.currentDisputeProofBodyHash = proofResult.proofBodyHash;
  if (!accountMachine.disputeProofNoncesByHash) {
    accountMachine.disputeProofNoncesByHash = {};
  }
  accountMachine.disputeProofNoncesByHash[proofResult.proofBodyHash] = clonedMachine.proofHeader.cooperativeNonce;
  if (!accountMachine.disputeProofBodiesByHash) {
    accountMachine.disputeProofBodiesByHash = {};
  }
  accountMachine.disputeProofBodiesByHash[proofResult.proofBodyHash] = proofResult.proofBodyStruct;

  // Sign settlement for current state (bilateral signature exchange)
  const settlementDiffs = buildSettlementDiffs(clonedMachine);
  const settlementHash = createSettlementHash(clonedMachine, settlementDiffs, depositoryAddress);
  const settlementHankos = await signHashesAsSingleEntity(env, signingEntityId, signingSignerId, [settlementHash]);
  const settlementHanko = settlementHankos[0];
  accountMachine.currentSettlementHanko = settlementHanko;
  accountMachine.currentSettlementDiffs = settlementDiffs;

  console.log(`âœ… Signed frame + dispute proof + settlement for account ${accountMachine.proofHeader.toEntity.slice(-4)}`);

  // Set pending state (no longer storing clone - re-execution on commit)
  accountMachine.pendingFrame = newFrame;
  accountMachine.sentTransitions = accountMachine.mempool.length;
  console.log(`ðŸ”’ PROPOSE: Account ${accountMachine.proofHeader.fromEntity.slice(-4)}:${accountMachine.proofHeader.toEntity.slice(-4)} pendingFrame=${newFrame.height}, txs=${newFrame.accountTxs.length}`);

  // Clear mempool
  accountMachine.mempool = [];

  events.push(`ðŸš€ Proposed frame ${newFrame.height} with ${newFrame.accountTxs.length} transactions`);

  const accountInput: AccountInput = {
    fromEntityId: accountMachine.proofHeader.fromEntity,
    toEntityId: accountMachine.proofHeader.toEntity,
    height: newFrame.height,
    newAccountFrame: newFrame,
    newHanko: frameHanko,         // Hanko on frame stateHash
    newDisputeHanko: disputeHanko, // Hanko on dispute proof hash
    newDisputeProofBodyHash: proofResult.proofBodyHash, // ProofBodyHash that disputeHanko signs
    newSettlementHanko: settlementHanko,
    newSettlementDiffs: settlementDiffs,
    counter: skipCounterIncrement ? accountMachine.proofHeader.cooperativeNonce : ++accountMachine.proofHeader.cooperativeNonce,
  };

  return { success: true, accountInput, events, revealedSecrets, swapOffersCreated, swapOffersCancelled };
}

/**
 * Handle received AccountInput (bilateral consensus)
 */
export async function handleAccountInput(
  env: Env,
  accountMachine: AccountMachine,
  input: AccountInput
): Promise<{
  success: boolean;
  response?: AccountInput;
  events: string[];
  error?: string;
  approvalNeeded?: AccountTx;
  revealedSecrets?: Array<{ secret: string; hashlock: string }>;
  swapOffersCreated?: Array<{
    offerId: string;
    makerIsLeft: boolean;
    fromEntity: string;
    toEntity: string;
    accountId?: string;
    giveTokenId: number;
    giveAmount: bigint;
    wantTokenId: number;
    wantAmount: bigint;
    minFillRatio: number;
  }>;
  swapOffersCancelled?: Array<{ offerId: string; accountId: string }>;
  timedOutHashlocks?: string[];
}> {
  console.log(`ðŸ“¨ A-MACHINE: Received AccountInput from ${input.fromEntityId.slice(-4)}, pendingFrame=${accountMachine.pendingFrame ? `h${accountMachine.pendingFrame.height}` : 'none'}, currentHeight=${accountMachine.currentHeight}`);
  console.log(`ðŸ“¨ A-MACHINE INPUT: height=${input.height || 'none'}, hasACK=${!!input.prevHanko}, hasNewFrame=${!!input.newAccountFrame}, counter=${input.counter}`);

  const events: string[] = [];
  const timedOutHashlocks: string[] = [];
  let ackProcessed = false;

  // CRITICAL: Counter validation (replay protection) - ALWAYS enforce, no frame 0 exemption
  if (input.counter !== undefined) {
    // SPECIAL CASE: If this is an ACK for our pendingFrame, allow counter flexibility
    // When we proposed pendingFrame, we incremented cooperativeNonce (counter), but ackedTransitions
    // hasn't been updated yet (only updated when ACK arrives). So ACK counter can be > ackedTransitions+1.
    const isACKForPendingFrame = accountMachine.pendingFrame
      && input.height === accountMachine.pendingFrame.height
      && !!input.prevHanko;

    let counterValid: boolean;
    if (isACKForPendingFrame) {
      // For ACKs, counter should match or exceed ackedTransitions (to account for our proposal increment)
      // Just validate it's in valid range and not going backwards
      counterValid = input.counter > 0 && input.counter <= MAX_MESSAGE_COUNTER && input.counter >= accountMachine.ackedTransitions;
      if (HEAVY_LOGS) console.log(`ðŸ” Counter validation (ACK for pendingFrame): ${input.counter} vs acked=${accountMachine.ackedTransitions}, valid=${counterValid}`);
    } else {
      counterValid = validateMessageCounter(accountMachine, input.counter);
      if (HEAVY_LOGS) console.log(`ðŸ” Counter validation: ${input.counter} vs acked=${accountMachine.ackedTransitions}, height=${accountMachine.currentHeight}, valid=${counterValid}`);
    }

    if (!counterValid) {
      return { success: false, error: `Replay attack detected: counter ${input.counter} invalid (expected ${accountMachine.ackedTransitions + 1})`, events };
    }

    // DoS FIX: Update counter AFTER signature verification (moved below)
    // If we update here, attacker can desync counters with invalid signatures
  } else {
    // Counter is REQUIRED for all messages (replay protection)
    return { success: false, error: 'Missing counter - replay protection requires sequential counter', events };
  }

  // Handle pending frame confirmation
  if (accountMachine.pendingFrame && input.height === accountMachine.pendingFrame.height && input.prevHanko) {
    console.log(`âœ… Received confirmation for pending frame ${input.height}`);
    console.log(`âœ… ACK-DEBUG: fromEntity=${input.fromEntityId.slice(-4)}, toEntity=${input.toEntityId.slice(-4)}, counter=${input.counter}`);

    const frameHash = accountMachine.pendingFrame.stateHash;

    // HANKO ACK VERIFICATION: Verify hanko instead of single signature
    const ackHanko = input.prevHanko;
    if (!ackHanko) {
      return { success: false, error: 'Missing ACK hanko', events };
    }

    console.log(`ðŸ” HANKO-ACK-VERIFY: Verifying ACK hanko for our pending frame`);

    const { verifyHankoForHash } = await import('./hanko-signing');
    const expectedAckEntity = accountMachine.proofHeader.toEntity;
    const { valid, entityId: recoveredEntityId } = await verifyHankoForHash(ackHanko, frameHash, expectedAckEntity, env);

    if (!valid) {
      return { success: false, error: 'Invalid ACK hanko signature', events };
    }

    if (!recoveredEntityId || recoveredEntityId.toLowerCase() !== expectedAckEntity.toLowerCase()) {
      return { success: false, error: `ACK hanko entityId mismatch: got ${recoveredEntityId?.slice(-4)}, expected ${expectedAckEntity.slice(-4)}`, events };
    }

    console.log(`âœ… HANKO-ACK-VERIFIED: ACK from ${recoveredEntityId.slice(-4)}`);

    // ACK is valid - proceed
    if (true) {
      ackProcessed = true;
      // DoS FIX: Update counter AFTER signature verified (prevents counter desync attacks)
      if (input.counter !== undefined) {
        accountMachine.ackedTransitions = input.counter;
        console.log(`âœ… ACK-BLOCK COUNTER-UPDATE: ackedTransitions now ${accountMachine.ackedTransitions} (from ACK processing)`);
      }

      // CRITICAL DEBUG: Log what we're committing
      console.log(`ðŸ”’ COMMIT: Frame ${accountMachine.pendingFrame.height}`);
      console.log(`  Transactions: ${accountMachine.pendingFrame.accountTxs.length}`);
      console.log(`  Transactions detail:`, accountMachine.pendingFrame.accountTxs);
      console.log(`  TokenIds: ${accountMachine.pendingFrame.tokenIds.join(',')}`);
      console.log(`  Deltas: ${accountMachine.pendingFrame.deltas.map(d => `${d}`).join(',')}`);
      console.log(`  StateHash: ${frameHash.slice(0,16)}...`);

      // PROPOSER COMMIT: Re-execute txs on REAL state (Channel.ts pattern)
      // This eliminates fragile manual field copying
      {
        const { counterparty: cpForLog } = getAccountPerspective(accountMachine, accountMachine.proofHeader.fromEntity);
        console.log(`ðŸ”“ PROPOSER-COMMIT: Re-executing ${accountMachine.pendingFrame.accountTxs.length} txs for ${cpForLog.slice(-4)}`);

        // Re-execute all frame txs on REAL accountMachine (deterministic)
        // CRITICAL: Use frame.timestamp for determinism (HTLC validation must use agreed consensus time)
        const pendingJHeight = accountMachine.pendingFrame.jHeight ?? accountMachine.currentHeight;
        for (const tx of accountMachine.pendingFrame.accountTxs) {
          const commitResult = await processAccountTx(accountMachine, tx, true, accountMachine.pendingFrame.timestamp, pendingJHeight);
          if (!commitResult.success) {
            console.error(`âŒ PROPOSER-COMMIT FAILED for tx type=${tx.type}: ${commitResult.error}`);
            throw new Error(`Frame ${accountMachine.pendingFrame.height} commit failed: ${tx.type} - ${commitResult.error}`);
          }
          if (commitResult.timedOutHashlock) {
            timedOutHashlocks.push(commitResult.timedOutHashlock);
          }
        }

        console.log(`ðŸ’³ PROPOSER-COMMIT COMPLETE: Deltas after re-execution for ${cpForLog.slice(-4)}:`,
          Array.from(accountMachine.deltas.entries()).map(([tokenId, delta]) => ({
            tokenId,
            collateral: delta.collateral?.toString(),
            ondelta: delta.ondelta?.toString(),
            offdelta: delta.offdelta?.toString(),
            leftCreditLimit: delta.leftCreditLimit?.toString(),
            rightCreditLimit: delta.rightCreditLimit?.toString(),
          })));

        // Clean up clone (no longer needed with re-execution)
        delete accountMachine.clonedForValidation;

        // CRITICAL: Deep-copy entire pendingFrame to prevent mutation issues
        accountMachine.currentFrame = structuredClone(accountMachine.pendingFrame);
        accountMachine.currentHeight = accountMachine.pendingFrame.height;
        accountMachine.proofHeader.disputeNonce = accountMachine.currentHeight;

        if (input.newDisputeHanko) {
          accountMachine.counterpartyDisputeProofHanko = input.newDisputeHanko;
          const signedCooperativeNonce = input.counter !== undefined
            ? input.counter - 1
            : accountMachine.proofHeader.cooperativeNonce;
          accountMachine.counterpartyDisputeProofCooperativeNonce = signedCooperativeNonce;
          if (input.newDisputeProofBodyHash) {
            accountMachine.counterpartyDisputeProofBodyHash = input.newDisputeProofBodyHash;
            if (!accountMachine.disputeProofNoncesByHash) {
              accountMachine.disputeProofNoncesByHash = {};
            }
            accountMachine.disputeProofNoncesByHash[input.newDisputeProofBodyHash] = signedCooperativeNonce;
          }
          console.log(`âœ… Stored counterparty dispute hanko from ACK`);
        }

        // Store counterparty settlement signature
        if (input.newSettlementHanko) {
          accountMachine.counterpartySettlementHanko = input.newSettlementHanko;
          if (input.newSettlementDiffs) {
            accountMachine.counterpartySettlementDiffs = input.newSettlementDiffs;
          }
          console.log(`âœ… Stored counterparty settlement hanko from ACK`);
        }

        // Add confirmed frame to history
        accountMachine.frameHistory.push({...accountMachine.pendingFrame});
        // Cap history at 10 frames to prevent snapshot bloat
        if (accountMachine.frameHistory.length > 10) {
          accountMachine.frameHistory.shift();
        }
        console.log(`ðŸ“š Frame ${accountMachine.pendingFrame.height} added to history (total: ${accountMachine.frameHistory.length})`);
      }

      // Clear pending state
      delete accountMachine.pendingFrame;
      accountMachine.sentTransitions = 0;
      delete accountMachine.clonedForValidation;
      accountMachine.rollbackCount = Math.max(0, accountMachine.rollbackCount - 1); // Successful confirmation reduces rollback
      if (accountMachine.rollbackCount === 0) {
        delete accountMachine.lastRollbackFrameHash; // Reset deduplication on full resolution
      }

      console.log(`âœ… PENDING-CLEARED: Frame ${input.height} confirmed, mempool now has ${accountMachine.mempool.length} txs: [${accountMachine.mempool.map(tx => tx.type).join(',')}]`);
      events.push(`âœ… Frame ${input.height} confirmed and committed`);

      // CRITICAL FIX: Chained Proposal - if mempool has items (e.g. j_event_claim), propose immediately
      if (!input.newAccountFrame) {
        if (accountMachine.mempool.length > 0) {
          console.log(`ðŸš€ CHAINED-PROPOSAL: ACK received, mempool has ${accountMachine.mempool.length} txs - proposing next frame immediately`);
          const proposeResult = await proposeAccountFrame(env, accountMachine);
          if (proposeResult.success && proposeResult.accountInput) {
            return {
              success: true,
              response: proposeResult.accountInput,
              events: [...events, ...proposeResult.events],
              revealedSecrets: proposeResult.revealedSecrets,
              swapOffersCreated: proposeResult.swapOffersCreated,
              swapOffersCancelled: proposeResult.swapOffersCancelled,
              timedOutHashlocks
            };
          }
        }
        if (HEAVY_LOGS) console.log(`ðŸ” RETURN-ACK-ONLY: frame ${input.height} ACKed, no new frame bundled`);
        return { success: true, events, timedOutHashlocks };
      }
      // Fall through to process newAccountFrame below
      console.log(`ðŸ“¦ BATCHED-MESSAGE: ACK processed, now processing bundled new frame...`);
    } else {
      return { success: false, error: 'Invalid confirmation signature', events };
    }
  }

  // Handle new frame proposal
  if (input.newAccountFrame) {
    const receivedFrame = input.newAccountFrame;

    // Validate frame with timestamp checks (HTLC safety)
    const previousTimestamp = accountMachine.currentFrame?.timestamp;
    if (!validateAccountFrame(receivedFrame, env.timestamp, previousTimestamp)) {
      return { success: false, error: 'Invalid frame structure', events };
    }

    // CRITICAL: Verify prevFrameHash links to our current frame (prevent state fork)
    const expectedPrevFrameHash = accountMachine.currentHeight === 0
      ? 'genesis'
      : accountMachine.currentFrame.stateHash || '';

    if (receivedFrame.prevFrameHash !== expectedPrevFrameHash) {
      console.warn(`âš ï¸ FRAME-CHAIN: prevHash mismatch at height ${accountMachine.currentHeight}`);
      return {
        success: false,
        error: `Frame chain broken: prevFrameHash mismatch (expected ${expectedPrevFrameHash.slice(0, 16)}...)`,
        events
      };
    }

    console.log(`âœ… Frame chain verified: prevFrameHash matches frame ${accountMachine.currentHeight}`);

    // CHANNEL.TS REFERENCE: Lines 138-165 - Proper rollback logic for simultaneous proposals
    // Handle simultaneous proposals when both sides send same height
    if (accountMachine.pendingFrame && receivedFrame.height === accountMachine.pendingFrame.height) {
      console.log(`ðŸ”„ SIMULTANEOUS-PROPOSALS: Both proposed frame ${receivedFrame.height}`);

      // Deterministic tiebreaker: Left always wins (CHANNEL.TS REFERENCE: Line 140-157)
      const isLeftEntity = isLeft(accountMachine.proofHeader.fromEntity, accountMachine.proofHeader.toEntity);
      if (HEAVY_LOGS) console.log(`ðŸ” TIEBREAKER: fromEntity=${accountMachine.proofHeader.fromEntity.slice(-4)}, toEntity=${accountMachine.proofHeader.toEntity.slice(-4)}, isLeft=${isLeftEntity}`);

      if (isLeftEntity) {
        // We are LEFT - ignore their frame, keep ours (deterministic tiebreaker)
        console.log(`ðŸ“¤ LEFT-WINS: Ignoring right's frame ${receivedFrame.height}, waiting for them to accept ours`);

        // EMIT EVENT: Track LEFT wins tiebreaker
        events.push(`ðŸ“¤ LEFT-WINS: Ignored RIGHT's frame ${receivedFrame.height} (waiting for their ACK)`);
        env.info('consensus', 'LEFT-WINS', {
          fromEntity: accountMachine.proofHeader.fromEntity,
          toEntity: accountMachine.proofHeader.toEntity,
          height: receivedFrame.height,
        }, accountMachine.proofHeader.fromEntity);

        // CRITICAL FIX: Even though we ignore their frame, check mempool and send update if we have new txs
        // This prevents j_event_claims from getting stuck when both sides propose simultaneously
        if (accountMachine.mempool.length > 0) {
          console.log(`ðŸ“¤ LEFT-WINS-BUT-HAS-MEMPOOL: ${accountMachine.mempool.length} txs waiting - notifying counterparty`);
          events.push(`âš ï¸ LEFT has ${accountMachine.mempool.length} pending txs while waiting for RIGHT's ACK`);
          // Send a message with just mempool status so they know we have pending work
          // TODO: Determine if we should send frames or just signal
        }
        // This is NOT an error - it's correct consensus behavior (Channel.ts handlePendingBlock)
        return { success: true, events };
      } else {
        // We are RIGHT - rollback our frame, accept theirs
        // DEDUPLICATION: Check if we already rolled back this exact frame
        const receivedHash = receivedFrame.stateHash;
        if (accountMachine.lastRollbackFrameHash === receivedHash) {
          console.log(`âš ï¸ ROLLBACK-DEDUPE: Already rolled back for frame ${receivedHash.slice(0, 16)}... - ignoring duplicate`);
          // Don't increment rollbackCount again, just process their frame
        } else if (accountMachine.rollbackCount === 0) {
          // First rollback - restore transactions to mempool before discarding frame
          let restoredTxCount = 0;
          if (accountMachine.pendingFrame) {
            restoredTxCount = accountMachine.pendingFrame.accountTxs.length;
            console.log(`ðŸ“¥ RIGHT-ROLLBACK: Restoring ${restoredTxCount} txs to mempool`);
            // CRITICAL: Re-add transactions to mempool (Channel.ts pattern)
            accountMachine.mempool.unshift(...accountMachine.pendingFrame.accountTxs);
            console.log(`ðŸ“¥ Mempool now has ${accountMachine.mempool.length} txs after rollback restore`);

            // EMIT EVENT: Track rollback for debugging
            events.push(`ðŸ”„ ROLLBACK: Discarded our frame ${accountMachine.pendingFrame.height}, restored ${restoredTxCount} txs to mempool`);
            env.info('consensus', 'ROLLBACK', {
              fromEntity: accountMachine.proofHeader.fromEntity,
              toEntity: accountMachine.proofHeader.toEntity,
              height: accountMachine.pendingFrame.height,
              restoredTxCount,
            }, accountMachine.proofHeader.fromEntity);
          }

          accountMachine.sentTransitions = 0;
          delete accountMachine.pendingFrame;
          delete accountMachine.clonedForValidation;
          accountMachine.rollbackCount++;
          accountMachine.lastRollbackFrameHash = receivedHash; // Track this rollback
          console.log(`ðŸ“¥ RIGHT-ROLLBACK: Accepting left's frame (rollbacks: ${accountMachine.rollbackCount})`);

          // EMIT EVENT: Track that we accepted LEFT's frame
          events.push(`ðŸ“¥ Accepted LEFT's frame ${receivedFrame.height} (we are RIGHT, deterministic tiebreaker)`);

          // Continue to process their frame below
        } else {
          // Should never rollback twice (unless duplicate messages)
          console.warn(`âš ï¸ ROLLBACK-LIMIT: ${accountMachine.rollbackCount}x - consensus stalled`);
          return { success: false, error: 'Multiple rollbacks detected - consensus failure', events };
        }
      }
    }

    // NOTE: rollbackCount decrement happens in ACK block (line 547) when pendingFrame confirmed
    // This ensures we only decrement once per rollback resolution (no double-decrement)

    // Verify frame sequence
    if (HEAVY_LOGS) console.log(`ðŸ” SEQUENCE-CHECK: receivedFrame.height=${receivedFrame.height}, currentHeight=${accountMachine.currentHeight}, expected=${accountMachine.currentHeight + 1}`);
    if (receivedFrame.height !== accountMachine.currentHeight + 1) {
      console.log(`âŒ Frame sequence mismatch: expected ${accountMachine.currentHeight + 1}, got ${receivedFrame.height}`);
      return { success: false, error: `Frame sequence mismatch: expected ${accountMachine.currentHeight + 1}, got ${receivedFrame.height}`, events };
    }

    // SECURITY: Verify signatures (REQUIRED for all frames)
    // HANKO VERIFICATION: Require hanko for all frames
    const hankoToVerify = input.newHanko;
    if (!hankoToVerify) {
      return { success: false, error: 'SECURITY: Frame must have hanko signature', events };
    }

    console.log(`ðŸ” HANKO-VERIFY: Verifying hanko for frame ${receivedFrame.height} from ${input.fromEntityId.slice(-4)}`);

    // Verify hanko - CRITICAL: Must verify fromEntityId is the signer with board validation
    const { verifyHankoForHash } = await import('./hanko-signing');
    const { valid, entityId: recoveredEntityId } = await verifyHankoForHash(hankoToVerify, receivedFrame.stateHash, input.fromEntityId, env);

    if (!valid || !recoveredEntityId) {
      return { success: false, error: `Invalid hanko signature from ${input.fromEntityId.slice(-4)}`, events };
    }

    console.log(`âœ… HANKO-VERIFIED: Frame from ${recoveredEntityId.slice(-4)}`);

    // Store counterparty's frame hanko
    accountMachine.counterpartyFrameHanko = hankoToVerify;

    // Store counterparty's dispute proof hanko ONLY if verified and frame will commit
    // Don't update yet - will update when frame COMMITS (not just received)
    // This prevents storing dispute hanko for pending/rolled-back frames
    if (input.newDisputeHanko && !ackProcessed) {
      // Store temporarily - will be moved to counterpartyDisputeProofHanko on commit
      (accountMachine as any).pendingCounterpartyDisputeHanko = input.newDisputeHanko;
      const signedCooperativeNonce = input.counter !== undefined
        ? input.counter - 1
        : accountMachine.proofHeader.cooperativeNonce;
      (accountMachine as any).pendingCounterpartyDisputeProofCooperativeNonce = signedCooperativeNonce;
      if (input.newDisputeProofBodyHash) {
        (accountMachine as any).pendingCounterpartyDisputeProofBodyHash = input.newDisputeProofBodyHash;
      }
      console.log(`ðŸ“ Stored pending counterparty dispute hanko (will commit with frame)`);
    }

    // Get entity's synced J-height for deterministic HTLC validation
    const ourEntityId = accountMachine.proofHeader.fromEntity;
    const ourReplica = Array.from(env.eReplicas.values()).find(r => r.state.entityId === ourEntityId);
    const currentJHeight = ourReplica?.state.lastFinalizedJHeight || 0;
    const frameJHeight = receivedFrame.jHeight ?? currentJHeight;

    // Apply frame transactions to clone (as receiver)
    const clonedMachine = cloneAccountMachine(accountMachine);
    const processEvents: string[] = [];
    const revealedSecrets: Array<{ secret: string; hashlock: string }> = [];
    // AUDIT FIX (CRITICAL-1): SwapOfferEvent carries makerIsLeft + fromEntity/toEntity
    const swapOffersCreated: Array<{
      offerId: string;
      makerIsLeft: boolean;
      fromEntity: string;
      toEntity: string;
      accountId?: string;
      giveTokenId: number;
      giveAmount: bigint;
      wantTokenId: number;
      wantAmount: bigint;
      minFillRatio: number;
    }> = [];
    const swapOffersCancelled: Array<{ offerId: string; accountId: string }> = [];

    for (const accountTx of receivedFrame.accountTxs) {
      // When receiving a frame, we process transactions from counterparty's perspective (incoming)
      // CRITICAL: Use receivedFrame.timestamp for determinism (HTLC validation must use agreed consensus time)
      const result = await processAccountTx(
        clonedMachine,
        accountTx,
        false, // Processing their transactions = incoming
        receivedFrame.timestamp, // DETERMINISTIC: Use frame's consensus timestamp
        frameJHeight,  // Frame's consensus J-height
        true // isValidation = true (on clone, skip bilateral finalization)
      );
      if (!result.success) {
        return { success: false, error: `Frame application failed: ${result.error}`, events };
      }
      processEvents.push(...result.events);

      if (HEAVY_LOGS) console.log(`ðŸ” TX-PROCESSED: ${accountTx.type}, success=${result.success}`);
      // Collect revealed secrets (CRITICAL for multi-hop)
      if (result.secret && result.hashlock) {
        revealedSecrets.push({ secret: result.secret, hashlock: result.hashlock });
      }
      if (result.timedOutHashlock) {
        timedOutHashlocks.push(result.timedOutHashlock);
      }

      // Collect swap offers for orderbook integration
      if (result.swapOfferCreated) {
        swapOffersCreated.push(result.swapOfferCreated);
      }
      if (result.swapOfferCancelled) {
        swapOffersCancelled.push(result.swapOfferCancelled);
      }
    }

    // STATE VERIFICATION: Compare deltas directly (both sides compute identically)
    // Extract final state from clonedMachine after processing ALL transactions
    const ourFinalTokenIds: number[] = [];
    const ourFinalDeltas: bigint[] = [];

    const sortedOurTokens = Array.from(clonedMachine.deltas.entries()).sort((a, b) => a[0] - b[0]);
    for (const [tokenId, delta] of sortedOurTokens) {
      const totalDelta = delta.ondelta + delta.offdelta;

      // CONSENSUS FIX: Apply SAME filtering as proposer
      // Skip tokens with zero delta AND zero limits (never used)
      if (!shouldIncludeToken(delta, totalDelta)) {
        console.log(`â­ï¸  RECEIVER: Skipping unused token ${tokenId} from validation (zero delta/limits/holds)`);
        continue;
      }

      ourFinalTokenIds.push(tokenId);
      ourFinalDeltas.push(totalDelta);
    }

    if (HEAVY_LOGS) console.log(`ðŸ” RECEIVER: Computed ${ourFinalTokenIds.length} tokens after filtering: [${ourFinalTokenIds.join(', ')}]`);

    // CRITICAL: Extract FULL delta states for hash verification (same as proposer does)
    // This ensures hash verification includes credit limits, collateral, allowances
    const ourFullDeltaStates: import('./types').Delta[] = [];
    for (const [tokenId, delta] of sortedOurTokens) {
      const totalDelta = delta.ondelta + delta.offdelta;
      // Apply SAME filtering as proposer (skip unused tokens)
      if (!shouldIncludeToken(delta, totalDelta)) {
        continue;
      }
      ourFullDeltaStates.push({ ...delta });
    }

    const ourComputedState = Buffer.from(ourFinalDeltas.map(d => d.toString()).join(',')).toString('hex');
    const theirClaimedState = Buffer.from(receivedFrame.deltas.map(d => d.toString()).join(',')).toString('hex');

    if (HEAVY_LOGS) console.log(`ðŸ” STATE-VERIFY Frame ${receivedFrame.height}:`);
    console.log(`  Our computed:  ${ourComputedState.slice(0, 32)}...`);
    console.log(`  Their claimed: ${theirClaimedState.slice(0, 32)}...`);

    if (ourComputedState !== theirClaimedState) {
      // Compact error - full dump only if DEBUG enabled
      console.warn(`âš ï¸ CONSENSUS: Frame ${receivedFrame.height} - state mismatch (our: ${ourComputedState.slice(0,16)}... vs their: ${theirClaimedState.slice(0,16)}...)`);
      return { success: false, error: `Bilateral consensus failure - states don't match`, events };
    }

    if (HEAVY_LOGS) console.log(`ðŸ” ABOUT-TO-VERIFY-HASH: Computing frame hash...`);
    // SECURITY: Verify full frame hash (tokenIds + fullDeltaStates + deltas)
    // This prevents accepting frames with poisoned dispute proofs
    if (HEAVY_LOGS) console.log(`ðŸ” COMPUTING-HASH: Creating hash for frame ${receivedFrame.height}...`);
    const recomputedHash = await createFrameHash({
      height: receivedFrame.height,
      timestamp: receivedFrame.timestamp,
      jHeight: receivedFrame.jHeight,
      accountTxs: receivedFrame.accountTxs,
      prevFrameHash: receivedFrame.prevFrameHash,
      tokenIds: ourFinalTokenIds,
      deltas: ourFinalDeltas,
      fullDeltaStates: ourFullDeltaStates, // CRITICAL FIX: Compute from clonedMachine like proposer does
      stateHash: '', // Computed by createFrameHash
      byLeft: receivedFrame.byLeft,
    });

    if (recomputedHash !== receivedFrame.stateHash) {
      console.warn(`âš ï¸ SECURITY: Frame hash mismatch after validation`);
      console.warn(`   Recomputed: ${recomputedHash.slice(0,16)}...`);
      console.warn(`   Claimed:    ${receivedFrame.stateHash.slice(0,16)}...`);
      return { success: false, error: `Frame hash verification failed - dispute proof mismatch`, events };
    }

    console.log(`âœ… CONSENSUS-SUCCESS: Both sides computed identical state for frame ${receivedFrame.height}`);

    // Emit bilateral consensus event
    env.emit('BilateralFrameCommitted', {
      fromEntity: input.fromEntityId,
      toEntity: accountMachine.proofHeader.fromEntity,
      height: receivedFrame.height,
      txCount: receivedFrame.accountTxs.length,
      tokenIds: receivedFrame.tokenIds,
      stateHash: receivedFrame.stateHash,
    });

    // RECEIVER COMMIT: Re-execute txs on REAL state (Channel.ts pattern)
    // This eliminates fragile manual field copying
    const { counterparty: cpForCommitLog } = getAccountPerspective(accountMachine, ourEntityId);
    if (HEAVY_LOGS) console.log(`ðŸ” RECEIVER-COMMIT: Re-executing ${receivedFrame.accountTxs.length} txs for ${cpForCommitLog.slice(-4)}`);

    // Re-execute all frame txs on REAL accountMachine (deterministic)
    // CRITICAL: Use receivedFrame.timestamp for determinism (HTLC validation must use agreed consensus time)
    for (const tx of receivedFrame.accountTxs) {
      // CRITICAL: Use frame.jHeight for HTLC checks (consensus-aligned height)
      const jHeightForCommit = receivedFrame.jHeight || accountMachine.currentHeight;
      const commitResult = await processAccountTx(accountMachine, tx, false, receivedFrame.timestamp, jHeightForCommit);

      // CRITICAL: Verify commit succeeded (Codex: prevent silent divergence)
      if (!commitResult.success) {
        console.error(`âŒ RECEIVER-COMMIT FAILED for tx type=${tx.type}: ${commitResult.error}`);
        throw new Error(`Frame ${receivedFrame.height} commit failed: ${tx.type} - ${commitResult.error}`);
      }
    }

    console.log(`ðŸ’³ RECEIVER-COMMIT COMPLETE: Deltas after re-execution for ${cpForCommitLog.slice(-4)}:`,
      Array.from(accountMachine.deltas.entries()).map(([tokenId, delta]) => ({
        tokenId,
        collateral: delta.collateral?.toString(),
        leftCreditLimit: delta.leftCreditLimit?.toString(),
        rightCreditLimit: delta.rightCreditLimit?.toString(),
        ondelta: delta.ondelta?.toString(),
        offdelta: delta.offdelta?.toString(),
      })));

    // CRITICAL: Copy pendingForward for multi-hop routing
    if (clonedMachine.pendingForward) {
      accountMachine.pendingForward = clonedMachine.pendingForward;
      console.log(`ðŸ”€ Copied pendingForward for multi-hop: route=[${clonedMachine.pendingForward.route.map(r => r.slice(-4)).join(',')}]`);
    }

    // CRITICAL: Use receivedFrame.fullDeltaStates from proposer to maintain hash consistency
    // The proposer's fullDeltaStates was used to compute the stateHash
    // CRITICAL: Deep-copy to prevent mutation issues
    accountMachine.currentFrame = structuredClone({
      height: receivedFrame.height,
      timestamp: receivedFrame.timestamp,
      jHeight: receivedFrame.jHeight,
      accountTxs: receivedFrame.accountTxs,
      prevFrameHash: receivedFrame.prevFrameHash,
      tokenIds: receivedFrame.tokenIds,
      deltas: receivedFrame.deltas,
      stateHash: receivedFrame.stateHash,
      byLeft: receivedFrame.byLeft, // Copy proposer info
      fullDeltaStates: receivedFrame.fullDeltaStates || [], // Use proposer's fullDeltaStates for hash consistency
    });
    accountMachine.currentHeight = receivedFrame.height;
    accountMachine.proofHeader.disputeNonce = accountMachine.currentHeight;

    // COMMIT counterparty dispute hanko (frame accepted and committed)
    if ((accountMachine as any).pendingCounterpartyDisputeHanko) {
      accountMachine.counterpartyDisputeProofHanko = (accountMachine as any).pendingCounterpartyDisputeHanko;
      delete (accountMachine as any).pendingCounterpartyDisputeHanko;
      if ((accountMachine as any).pendingCounterpartyDisputeProofCooperativeNonce !== undefined) {
        accountMachine.counterpartyDisputeProofCooperativeNonce = (accountMachine as any).pendingCounterpartyDisputeProofCooperativeNonce;
        delete (accountMachine as any).pendingCounterpartyDisputeProofCooperativeNonce;
      }
      if ((accountMachine as any).pendingCounterpartyDisputeProofBodyHash) {
        accountMachine.counterpartyDisputeProofBodyHash = (accountMachine as any).pendingCounterpartyDisputeProofBodyHash;
        if (!accountMachine.disputeProofNoncesByHash) {
          accountMachine.disputeProofNoncesByHash = {};
        }
        if (accountMachine.counterpartyDisputeProofCooperativeNonce !== undefined) {
          accountMachine.disputeProofNoncesByHash[accountMachine.counterpartyDisputeProofBodyHash] = accountMachine.counterpartyDisputeProofCooperativeNonce;
        }
        delete (accountMachine as any).pendingCounterpartyDisputeProofBodyHash;
      }
      console.log(`âœ… Committed counterparty dispute hanko (frame ${receivedFrame.height} accepted)`);
    }

    // Add accepted frame to history
    accountMachine.frameHistory.push({...receivedFrame});
    // Cap history at 10 frames to prevent snapshot bloat
    if (accountMachine.frameHistory.length > 10) {
      accountMachine.frameHistory.shift();
    }
    console.log(`ðŸ“š Frame ${receivedFrame.height} accepted and added to history (total: ${accountMachine.frameHistory.length})`);

    // CRITICAL: Update ackedTransitions after successfully processing incoming frame
    if (input.counter !== undefined) {
      accountMachine.ackedTransitions = input.counter;
      console.log(`âœ… COUNTER-UPDATE: ackedTransitions now ${accountMachine.ackedTransitions} (next expected: ${accountMachine.ackedTransitions + 1})`);
    }

    events.push(...processEvents);
    events.push(`ðŸ¤ Accepted frame ${receivedFrame.height} from Entity ${input.fromEntityId.slice(-4)}`);

    // Send confirmation (ACK) using HANKO
    const ackEntityId = accountMachine.proofHeader.fromEntity;
    const ackReplica = Array.from(env.eReplicas.values()).find(r => r.state.entityId === ackEntityId);
    const ackSignerId = ackReplica?.state.config.validators[0];
    if (!ackSignerId) {
      return { success: false, error: `Cannot find signerId for ACK from ${ackEntityId.slice(-4)}`, events };
    }

    console.log(`ðŸ” HANKO-ACK: entityId=${ackEntityId.slice(-4)} â†’ signerId=${ackSignerId.slice(-4)}`);

    // Build ACK hanko
    const { signHashesAsSingleEntity } = await import('./hanko-signing');
    const ackHankos = await signHashesAsSingleEntity(env, ackEntityId, ackSignerId, [receivedFrame.stateHash]);
    const confirmationHanko = ackHankos[0];
    if (!confirmationHanko) {
      return { success: false, error: 'Failed to build ACK hanko', events };
    }

    console.log(`ðŸ“¤ ACK-SEND: Preparing ACK for frame ${receivedFrame.height} from ${accountMachine.proofHeader.fromEntity.slice(-4)} to ${input.fromEntityId.slice(-4)}`);

    // CHANNEL.TS PATTERN (Lines 576-612): Batch ACK + new frame in same message!
    // Check if we should batch BEFORE incrementing counter
    let batchedWithNewFrame = false;
    let proposeResult: Awaited<ReturnType<typeof proposeAccountFrame>> | undefined;
    // Build dispute proof hanko for ACK response (always include current state's dispute proof)
    const { buildAccountProofBody: buildProof, createDisputeProofHash: createHash } = await import('./proof-builder');
    const ackDepositoryAddress = getDepositoryAddress(env);
    const ackProofResult = buildProof(accountMachine);
    const ackDisputeHash = createHash(accountMachine, ackProofResult.proofBodyHash, ackDepositoryAddress);
    const ackDisputeHankos = await signHashesAsSingleEntity(env, ackEntityId, ackSignerId, [ackDisputeHash]);
    const ackDisputeHanko = ackDisputeHankos[0];
    const ackSignedCooperativeNonce = accountMachine.proofHeader.cooperativeNonce;
    if (!accountMachine.disputeProofNoncesByHash) {
      accountMachine.disputeProofNoncesByHash = {};
    }
    accountMachine.disputeProofNoncesByHash[ackProofResult.proofBodyHash] = ackSignedCooperativeNonce;
    if (!accountMachine.disputeProofBodiesByHash) {
      accountMachine.disputeProofBodiesByHash = {};
    }
    accountMachine.disputeProofBodiesByHash[ackProofResult.proofBodyHash] = ackProofResult.proofBodyStruct;

    const response: AccountInput = {
      fromEntityId: accountMachine.proofHeader.fromEntity,
      toEntityId: input.fromEntityId,
      height: receivedFrame.height,
      prevHanko: confirmationHanko,       // Hanko ACK on their frame
      newDisputeHanko: ackDisputeHanko,   // My dispute proof hanko (current state)
      newDisputeProofBodyHash: ackProofResult.proofBodyHash, // ProofBodyHash that ackDisputeHanko signs
      counter: 0, // Will be set below after batching decision
    };

    if (HEAVY_LOGS) console.log(`ðŸ” BATCH-CHECK for account ${input.fromEntityId.slice(-4)}: mempool=${accountMachine.mempool.length}, pendingFrame=${!!accountMachine.pendingFrame}, mempoolTxs=[${accountMachine.mempool.map(tx => tx.type).join(',')}]`);
    if (accountMachine.mempool.length > 0 && !accountMachine.pendingFrame) {
      console.log(`ðŸ“¦ BATCH-OPTIMIZATION: Sending ACK + new frame in single message (Channel.ts pattern)`);

      // Pass skipCounterIncrement=true since we'll increment for the whole batch below
      proposeResult = await proposeAccountFrame(env, accountMachine, true);

      if (proposeResult.success && proposeResult.accountInput) {
        batchedWithNewFrame = true;
        // Merge ACK and new proposal into same AccountInput
        if (proposeResult.accountInput.newAccountFrame) {
          response.newAccountFrame = proposeResult.accountInput.newAccountFrame;
        }
        if (proposeResult.accountInput.newHanko) {
          response.newHanko = proposeResult.accountInput.newHanko;
        }
        // DON'T overwrite response.newDisputeHanko (it's ACK's dispute hanko for current committed state)
        // Proposal's newDisputeHanko will be delivered when proposal commits, not now
        // This preserves ACK's dispute hanko for last agreed state

        const newFrameId = proposeResult.accountInput.newAccountFrame?.height || 0;
        console.log(`âœ… Batched ACK for frame ${receivedFrame.height} + proposal for frame ${newFrameId}`);
        events.push(`ðŸ“¤ Batched ACK + frame ${newFrameId}`);
      }
    }

    if (!batchedWithNewFrame) {
      accountMachine.currentDisputeProofHanko = ackDisputeHanko;
      accountMachine.currentDisputeProofCooperativeNonce = ackSignedCooperativeNonce;
      accountMachine.currentDisputeProofBodyHash = ackProofResult.proofBodyHash;
    }

    // Increment counter ONCE per message (whether batched or not)
    response.counter = ++accountMachine.proofHeader.cooperativeNonce;
    console.log(`ðŸ”¢ Message counter: ${response.counter} (batched=${batchedWithNewFrame})`);

    // Merge revealed secrets from BOTH incoming frame AND proposed frame
    const allRevealedSecrets = [
      ...revealedSecrets, // From incoming frame (line 493)
      ...(proposeResult?.revealedSecrets || []) // From our proposed frame (if batched)
    ];

    // Merge swap offers from BOTH incoming frame AND proposed frame
    const allSwapOffersCreated = [
      ...swapOffersCreated,
      ...(proposeResult?.swapOffersCreated || [])
    ];
    const allSwapOffersCancelled = [
      ...swapOffersCancelled,
      ...(proposeResult?.swapOffersCancelled || [])
    ];

    if (HEAVY_LOGS) console.log(`ðŸ” RETURN-RESPONSE: h=${response.height} prevHanko=${!!response.prevHanko} newFrame=${!!response.newAccountFrame}`);
    return { success: true, response, events, revealedSecrets: allRevealedSecrets, swapOffersCreated: allSwapOffersCreated, swapOffersCancelled: allSwapOffersCancelled, timedOutHashlocks };
  }

  if (HEAVY_LOGS) console.log(`ðŸ” RETURN-NO-RESPONSE: No response object`);
  return { success: true, events, swapOffersCreated: [], swapOffersCancelled: [], timedOutHashlocks };
}

// === E-MACHINE INTEGRATION ===

/**
 * Add transaction to account mempool with limits
 */
export function addToAccountMempool(accountMachine: AccountMachine, accountTx: AccountTx): boolean {
  if (accountMachine.mempool.length >= MEMPOOL_LIMIT) {
    console.log(`âŒ Mempool full: ${accountMachine.mempool.length} >= ${MEMPOOL_LIMIT}`);
    return false;
  }

  accountMachine.mempool.push(accountTx);
  console.log(`ðŸ“¥ Added ${accountTx.type} to mempool (${accountMachine.mempool.length}/${MEMPOOL_LIMIT})`);
  return true;
}

/**
 * Check if account should auto-propose frame
 */
export function shouldProposeFrame(accountMachine: AccountMachine): boolean {
  // Should propose if:
  // 1. Has transactions in mempool
  // 2. No pending frame waiting for confirmation
  const should = accountMachine.mempool.length > 0 && !accountMachine.pendingFrame;
  console.error(`   shouldProposeFrame: mempool=${accountMachine.mempool.length}, pending=${!!accountMachine.pendingFrame}, result=${should}`);
  return should;
}

/**
 * Get accounts that should propose frames (for E-Machine auto-propose)
 * @param entityState - Entity state containing accounts to check
 */
export function getAccountsToProposeFrames(entityState: EntityState): string[] {
  const accountsToProposeFrames: string[] = [];

  // Check if accounts exists and is iterable
  if (!entityState.accounts || !(entityState.accounts instanceof Map)) {
    console.log(`âš ï¸ No accounts or accounts not a Map: ${typeof entityState.accounts}`);
    return accountsToProposeFrames;
  }

  for (const [accountKey, accountMachine] of entityState.accounts) {
    if (shouldProposeFrame(accountMachine)) {
      accountsToProposeFrames.push(accountKey);
    }
  }

  return accountsToProposeFrames;
}

// === PROOF GENERATION (for future J-Machine integration) ===

/**
 * Generate account proof for dispute resolution (like old_src Channel.getSubchannelProofs)
 * Must be ABI-compatible with Depository contract
 *
 * DUAL-TRACK APPROACH:
 * - proofBody: Simple internal representation (tokenIds + deltas)
 * - abiProofBody: ABI-encoded for on-chain disputes (includes transformers)
 */
export async function generateAccountProof(accountMachine: AccountMachine): Promise<{
  proofHash: string;
  signature: string;
  abiEncodedProofBody?: string;
  abiProofBodyHash?: string;
}> {
  // Update simple proofBody with current state (like old_src does before signing)
  accountMachine.proofBody = {
    tokenIds: Array.from(accountMachine.deltas.keys()).sort((a, b) => a - b), // Deterministic order
    deltas: Array.from(accountMachine.deltas.keys())
      .sort((a, b) => a - b)
      .map(tokenId => {
        const delta = accountMachine.deltas.get(tokenId);
        if (!delta) {
          console.warn(`Missing delta for token ${tokenId}`);
          throw new Error(`Critical financial data missing: delta for token ${tokenId}`);
        }
        return delta.ondelta + delta.offdelta; // Total delta for each token
      }),
  };

  // Build ABI-encoded proofBody for on-chain disputes
  const { buildAccountProofBody } = await import('./proof-builder.js');
  const abiResult = buildAccountProofBody(accountMachine);

  // Store ABI-encoded proofBody for later dispute submission
  accountMachine.abiProofBody = {
    encodedProofBody: abiResult.encodedProofBody,
    proofBodyHash: abiResult.proofBodyHash,
    lastUpdatedHeight: accountMachine.currentHeight,
  };

  // Create proof structure compatible with Depository.sol (legacy format)
  const proofData = {
    fromEntity: accountMachine.proofHeader.fromEntity,
    toEntity: accountMachine.proofHeader.toEntity,
    cooperativeNonce: accountMachine.proofHeader.cooperativeNonce,
    disputeNonce: accountMachine.proofHeader.disputeNonce,
    tokenIds: accountMachine.proofBody.tokenIds,
    deltas: accountMachine.proofBody.deltas.map(d => d.toString()), // Convert BigInt for JSON
  };

  // Create deterministic proof hash using browser-compatible crypto
  const proofContent = safeStringify(proofData);
  const fullHash = await hash(proofContent);
  const proofHash = fullHash.slice(2); // Remove 0x prefix for compatibility

  // Generate hanko signature - CRITICAL: Use signerId, not entityId
  const proofEntityId = accountMachine.proofHeader.fromEntity;
  const proofReplica = Array.from(env.eReplicas.values()).find(r => r.state.entityId === proofEntityId);
  const proofSignerId = proofReplica?.state.config.validators[0];
  if (!proofSignerId) {
    throw new Error(`Cannot find signerId for proof from ${proofEntityId.slice(-4)}`);
  }
  console.log(`ðŸ” PROOF-SIGN: entityId=${proofEntityId.slice(-4)} â†’ signerId=${proofSignerId.slice(-4)}`);
  const signature = signAccountFrame(env, proofSignerId, `0x${proofHash}`);

  // Store signature for later use
  accountMachine.hankoSignature = signature;

  console.log(`Generated account proof: ${accountMachine.proofBody.tokenIds.length} tokens`);
  console.log(`  Simple hash: 0x${proofHash.slice(0, 20)}...`);
  console.log(`  ABI hash: ${abiResult.proofBodyHash.slice(0, 20)}...`);
  console.log(`  Locks: ${accountMachine.locks.size}, Swaps: ${accountMachine.swapOffers.size}`);

  return {
    proofHash: `0x${proofHash}`,
    signature,
    abiEncodedProofBody: abiResult.encodedProofBody,
    abiProofBodyHash: abiResult.proofBodyHash,
  };
}


//runtime/account-consensus-state.ts (171 lines)
/**
 * Bilateral Consensus State Classification
 * Determines visual state of account for rendering uncommitted frames
 *
 * KISS principle: 3 states (mempool, proposed, committed)
 * Right-wins rule: On simultaneous proposals, LEFT rolls back
 */

import type { AccountMachine } from './types';

export type BilateralState =
  | 'committed'    // Both sides synced
  | 'mempool'      // Local transactions not yet proposed
  | 'proposed'     // Frame sent to peer, awaiting ACK
  | 'conflict';    // Simultaneous proposals detected

export interface BilateralVisualizationState {
  state: BilateralState;
  isLeftEntity: boolean;
  shouldRollback: boolean;  // True if LEFT in conflict (Right wins)
  pendingHeight: number | null;
  mempoolCount: number;
}

/**
 * Classify bilateral consensus state for ONE side of the account
 * @param myAccount - My view of the bilateral account
 * @param peerCurrentHeight - Peer's committed frame height (from their replica)
 * @param isLeft - Am I the left entity? (for conflict resolution)
 */
export function classifyBilateralState(
  myAccount: AccountMachine | undefined,
  peerCurrentHeight: number | undefined,
  isLeft: boolean
): BilateralVisualizationState {
  if (!myAccount) {
    return {
      state: 'committed',
      isLeftEntity: isLeft,
      shouldRollback: false,
      pendingHeight: null,
      mempoolCount: 0,
    };
  }

  const myHeight = myAccount.currentFrame?.height ?? 0;
  const myPendingHeight = myAccount.pendingFrame?.height ?? null;
  const peerHeight = peerCurrentHeight ?? 0;
  const mempoolCount = myAccount.mempool?.length ?? 0;

  console.log(`ðŸ” BILATERAL-STATE: isLeft=${isLeft}, myHeight=${myHeight}, myPending=${myPendingHeight}, peerHeight=${peerHeight}, mempool=${mempoolCount}`);

  // CONFLICT: Both sides have pendingFrame at same height
  // RIGHT wins, LEFT must rollback (deterministic tie-breaker)
  const hasPendingFrame = myPendingHeight !== null;
  const peerAhead = peerHeight > myHeight;

  if (hasPendingFrame && peerAhead && peerHeight === myPendingHeight) {
    return {
      state: 'conflict',
      isLeftEntity: isLeft,
      shouldRollback: isLeft, // LEFT rolls back, RIGHT wins
      pendingHeight: myPendingHeight,
      mempoolCount,
    };
  }

  // PROPOSED: I sent frame, peer hasn't applied yet
  if (hasPendingFrame && peerHeight < (myPendingHeight ?? 0)) {
    return {
      state: 'proposed',
      isLeftEntity: isLeft,
      shouldRollback: false,
      pendingHeight: myPendingHeight,
      mempoolCount,
    };
  }

  // MEMPOOL: Have transactions but haven't proposed yet
  if (mempoolCount > 0 && !hasPendingFrame) {
    return {
      state: 'mempool',
      isLeftEntity: isLeft,
      shouldRollback: false,
      pendingHeight: null,
      mempoolCount,
    };
  }

  // COMMITTED: No pending frames, peer is synced
  return {
    state: 'committed',
    isLeftEntity: isLeft,
    shouldRollback: false,
    pendingHeight: null,
    mempoolCount: 0,
  };
}

/**
 * Get visual properties for account bar rendering
 */
export interface AccountBarVisual {
  glowColor: 'yellow' | 'blue' | 'red' | null;
  glowSide: 'left' | 'right' | 'both' | null;
  glowIntensity: number; // 0.0 to 1.0
  isDashed: boolean;     // True for uncommitted state
  pulseSpeed: number;    // ms per pulse cycle (0 = no pulse)
}

export function getAccountBarVisual(
  leftState: BilateralVisualizationState,
  rightState: BilateralVisualizationState
): AccountBarVisual {
  console.log(`ðŸŽ¨ BAR-VISUAL: left=${leftState.state}, right=${rightState.state}`);

  // CONFLICT: Both proposed simultaneously
  if (leftState.state === 'conflict' || rightState.state === 'conflict') {
    return {
      glowColor: 'red',
      glowSide: 'both',
      glowIntensity: 0.8,
      isDashed: true,
      pulseSpeed: 500, // Fast pulse indicates conflict
    };
  }

  // PROPOSED from left
  if (leftState.state === 'proposed') {
    return {
      glowColor: 'yellow',
      glowSide: 'left',
      glowIntensity: 0.6,
      isDashed: true,
      pulseSpeed: 1000,
    };
  }

  // PROPOSED from right
  if (rightState.state === 'proposed') {
    return {
      glowColor: 'yellow',
      glowSide: 'right',
      glowIntensity: 0.6,
      isDashed: true,
      pulseSpeed: 1000,
    };
  }

  // MEMPOOL on either side (subtle indication)
  if (leftState.state === 'mempool' || rightState.state === 'mempool') {
    const side = leftState.state === 'mempool' ? 'left' : 'right';
    return {
      glowColor: 'yellow',
      glowSide: side,
      glowIntensity: 0.2, // Very subtle
      isDashed: false,
      pulseSpeed: 2000,   // Slow pulse
    };
  }

  // COMMITTED: Both sides synced
  return {
    glowColor: null,
    glowSide: null,
    glowIntensity: 0,
    isDashed: false,
    pulseSpeed: 0,
  };
}


//runtime/j-batch.ts (807 lines)
/**
 * J-Batch Aggregator System
 *
 * Accumulates entity operations into batches for atomic on-chain submission.
 * Pattern from 2019src.txt lines 3309-3399 (sharedState.batch + broadcastBatch)
 *
 * Design:
 * - Each entity accumulates operations in their jBatch
 * - Server periodically broadcasts batches (every 5s or when full)
 * - Batch is cleared after successful submission
 * - Failed batches are retried (with exponential backoff)
 */

import { ethers } from 'ethers';
import { isLeftEntity, normalizeEntityId, compareEntityIds } from './entity-id-utils';
import type { JurisdictionConfig } from './types';
import { safeStringify } from './serialization-utils';

/**
 * Batch structure matching Depository.sol (lines 203-231)
 */
export interface JBatch {
  // Reserve â†” External Token (deposits/withdrawals to/from blockchain)
  reserveToExternalToken: Array<{
    receivingEntity: string;
    tokenId: number;
    amount: bigint;
  }>;
  externalTokenToReserve: Array<{
    entity: string;
    packedToken: string;
    internalTokenId: number;
    amount: bigint;
  }>;

  // Reserve â†” Reserve (entity-to-entity transfers)
  reserveToReserve: Array<{
    receivingEntity: string;
    tokenId: number;
    amount: bigint;
  }>;

  // Reserve â†’ Collateral (fund account)
  reserveToCollateral: Array<{
    tokenId: number;
    receivingEntity: string; // Which entity is depositing
    pairs: Array<{
      entity: string; // Counterparty in the account
      amount: bigint;
    }>;
  }>;

  // Settlements - MUST match Solidity Settlement struct exactly
  settlements: Array<{
    leftEntity: string;
    rightEntity: string;
    diffs: Array<{
      tokenId: number;
      leftDiff: bigint;
      rightDiff: bigint;
      collateralDiff: bigint;
      ondeltaDiff: bigint;
    }>;
    forgiveDebtsInTokenIds: number[];
    insuranceRegs: Array<{
      insured: string;
      insurer: string;
      tokenId: number;
      limit: bigint;
      expiresAt: bigint;
    }>;
    sig: string; // Hanko signature (required when there are changes)
    entityProvider: string; // EntityProvider address
    hankoData: string; // Hanko signature data
    nonce: number; // Settlement nonce
  }>;

  // Dispute proofs (active in Depository.sol)
  cooperativeUpdate: never[];  // Legacy - not used
  cooperativeDisputeProof: never[];  // Legacy - not used
  disputeStarts: Array<{
    counterentity: string;
    cooperativeNonce: number;
    disputeNonce: number;
    proofbodyHash: string;
    sig: string;
    initialArguments: string;
  }>;
  disputeFinalizations: Array<{
    counterentity: string;
    initialCooperativeNonce: number;
    finalCooperativeNonce: number;
    initialDisputeNonce: number;
    finalDisputeNonce: number;
    initialProofbodyHash: string;
    finalProofbody: any;  // ProofBody struct
    finalArguments: string;
    initialArguments: string;
    sig: string;
    startedByLeft: boolean;
    disputeUntilBlock: number;
    cooperative: boolean;
  }>;

  // Flashloans (for atomic batch execution)
  flashloans: Array<{
    tokenId: number;
    amount: bigint;
  }>;

  // HTLC secret reveals (on-chain hashlock unlocks)
  revealSecrets: Array<{
    transformer: string;
    secret: string;
  }>;

  // Hub ID (for gas tracking)
  hub_id: number;
}

/**
 * JBatch state for an entity
 */
export interface JBatchState {
  batch: JBatch;
  jurisdiction: JurisdictionConfig | null; // Cached jurisdiction for this entity
  lastBroadcast: number; // Timestamp of last broadcast
  broadcastCount: number; // Total broadcasts
  failedAttempts: number; // Failed broadcast attempts (for exponential backoff)
}

/**
 * Create empty batch (2019src.txt line 3368)
 */
export function createEmptyBatch(): JBatch {
  return {
    flashloans: [],
    reserveToReserve: [],
    reserveToCollateral: [],
    settlements: [],
    cooperativeUpdate: [],
    cooperativeDisputeProof: [],
    disputeStarts: [], // Match Solidity: InitialDisputeProof[]
    disputeFinalizations: [], // Match Solidity: FinalDisputeProof[]
    externalTokenToReserve: [],
    reserveToExternalToken: [],
    revealSecrets: [],
    hub_id: 0,
  };
}

const DEPOSITORY_BATCH_ABI =
  'tuple(' +
    'tuple(uint256 tokenId, uint256 amount)[] flashloans,' +
    'tuple(bytes32 receivingEntity, uint256 tokenId, uint256 amount)[] reserveToReserve,' +
    'tuple(uint256 tokenId, bytes32 receivingEntity, tuple(bytes32 entity, uint256 amount)[] pairs)[] reserveToCollateral,' +
    'tuple(bytes32 leftEntity, bytes32 rightEntity, tuple(uint256 tokenId, int256 leftDiff, int256 rightDiff, int256 collateralDiff, int256 ondeltaDiff)[] diffs, uint256[] forgiveDebtsInTokenIds, tuple(bytes32 insured, bytes32 insurer, uint256 tokenId, uint256 limit, uint64 expiresAt)[] insuranceRegs, bytes sig, address entityProvider, bytes hankoData, uint256 nonce)[] settlements,' +
    'tuple(bytes32 counterentity, uint256 cooperativeNonce, uint256 disputeNonce, bytes32 proofbodyHash, bytes sig, bytes initialArguments)[] disputeStarts,' +
    'tuple(bytes32 counterentity, uint256 initialCooperativeNonce, uint256 finalCooperativeNonce, uint256 initialDisputeNonce, uint256 finalDisputeNonce, bytes32 initialProofbodyHash, tuple(int256[] offdeltas, uint256[] tokenIds, tuple(address transformerAddress, bytes encodedBatch, tuple(uint256 deltaIndex, uint256 rightAllowance, uint256 leftAllowance)[] allowances)[] transformers) finalProofbody, bytes finalArguments, bytes initialArguments, bytes sig, bool startedByLeft, uint256 disputeUntilBlock, bool cooperative)[] disputeFinalizations,' +
    'tuple(bytes32 entity, bytes32 packedToken, uint256 internalTokenId, uint256 amount)[] externalTokenToReserve,' +
    'tuple(bytes32 receivingEntity, uint256 tokenId, uint256 amount)[] reserveToExternalToken,' +
    'tuple(address transformer, bytes32 secret)[] revealSecrets,' +
    'uint256 hub_id' +
  ')';

const BATCH_DOMAIN_SEPARATOR = ethers.keccak256(ethers.toUtf8Bytes('XLN_DEPOSITORY_HANKO_V1'));

export function encodeJBatch(batch: JBatch): string {
  const abiCoder = ethers.AbiCoder.defaultAbiCoder();
  return abiCoder.encode([DEPOSITORY_BATCH_ABI as any], [batch]);
}

export function decodeJBatch(encodedBatch: string): JBatch {
  const abiCoder = ethers.AbiCoder.defaultAbiCoder();
  const decoded = abiCoder.decode([DEPOSITORY_BATCH_ABI as any], encodedBatch);
  return decoded[0] as JBatch;
}

export function summarizeBatch(batch: JBatch): Record<string, unknown> {
  const sample = <T>(arr: T[]) => (arr.length > 0 ? arr[0] : null);
  return {
    flashloans: { count: batch.flashloans.length, sample: sample(batch.flashloans) },
    reserveToReserve: { count: batch.reserveToReserve.length, sample: sample(batch.reserveToReserve) },
    reserveToCollateral: { count: batch.reserveToCollateral.length, sample: sample(batch.reserveToCollateral) },
    settlements: {
      count: batch.settlements.length,
      sample: batch.settlements.length
        ? {
            left: batch.settlements[0]?.leftEntity,
            right: batch.settlements[0]?.rightEntity,
            diffs: batch.settlements[0]?.diffs.length ?? 0,
            forgive: batch.settlements[0]?.forgiveDebtsInTokenIds.length ?? 0,
            insurance: batch.settlements[0]?.insuranceRegs.length ?? 0,
            sigLen: batch.settlements[0]?.sig?.length ?? 0,
          }
        : null,
    },
    disputeStarts: { count: batch.disputeStarts.length, sample: sample(batch.disputeStarts) },
    disputeFinalizations: { count: batch.disputeFinalizations.length, sample: sample(batch.disputeFinalizations) },
    externalTokenToReserve: { count: batch.externalTokenToReserve.length, sample: sample(batch.externalTokenToReserve) },
    reserveToExternalToken: { count: batch.reserveToExternalToken.length, sample: sample(batch.reserveToExternalToken) },
    revealSecrets: { count: batch.revealSecrets.length, sample: sample(batch.revealSecrets) },
    hub_id: batch.hub_id,
  };
}

export function preflightBatchForE2(
  entityId: string,
  batch: JBatch,
  blockTimestampSec?: number
): string[] {
  const issues: string[] = [];
  const normalizedEntityId = normalizeEntityId(entityId);
  const nowSec = blockTimestampSec ?? 0;

  const zeroEntity = '0x0000000000000000000000000000000000000000000000000000000000000000';
  for (const op of batch.externalTokenToReserve) {
    const target = op.entity ? normalizeEntityId(op.entity) : zeroEntity;
    if (target !== zeroEntity && target !== normalizedEntityId) {
      issues.push(`externalTokenToReserve entity mismatch: ${target.slice(-4)} != ${normalizedEntityId.slice(-4)}`);
    }
  }

  for (const op of batch.revealSecrets) {
    if (!op.transformer || op.transformer === '0x0000000000000000000000000000000000000000') {
      issues.push(`revealSecrets transformer=0`);
    }
  }

  for (const op of batch.reserveToReserve) {
    const receiving = normalizeEntityId(op.receivingEntity);
    if (receiving === normalizedEntityId) {
      issues.push(`reserveToReserve to self (${op.receivingEntity.slice(-4)})`);
    }
  }

  for (const s of batch.settlements) {
    if (compareEntityIds(s.leftEntity, s.rightEntity) >= 0) {
      issues.push(`settlement left>=right: ${s.leftEntity.slice(-4)} >= ${s.rightEntity.slice(-4)}`);
    }
    const hasChanges = s.diffs.length > 0 || s.forgiveDebtsInTokenIds.length > 0 || s.insuranceRegs.length > 0;
    if (hasChanges && (!s.sig || s.sig === '0x')) {
      issues.push(`settlement missing sig: ${s.leftEntity.slice(-4)}â†”${s.rightEntity.slice(-4)}`);
    }
    for (const reg of s.insuranceRegs) {
      if (normalizeEntityId(reg.insured) === normalizeEntityId(reg.insurer)) {
        issues.push(`insuranceReg insured==insurer (${reg.insured.slice(-4)})`);
      }
      if (reg.limit <= 0n) {
        issues.push(`insuranceReg limit=0 (${reg.insured.slice(-4)})`);
      }
      if (nowSec > 0 && reg.expiresAt <= BigInt(nowSec)) {
        issues.push(`insuranceReg expired (${reg.insured.slice(-4)})`);
      }
    }
  }

  for (const f of batch.disputeFinalizations) {
    if (f.cooperative && (!f.sig || f.sig === '0x')) {
      issues.push(`cooperative dispute finalize missing sig (${f.counterentity.slice(-4)})`);
    }
    if (!f.cooperative && f.sig && f.sig !== '0x') {
      const initialNonce = typeof f.initialDisputeNonce === 'bigint' ? f.initialDisputeNonce : BigInt(f.initialDisputeNonce);
      const finalNonce = typeof f.finalDisputeNonce === 'bigint' ? f.finalDisputeNonce : BigInt(f.finalDisputeNonce);
      if (initialNonce >= finalNonce) {
        issues.push(`counterdispute nonce order (${f.counterentity.slice(-4)})`);
      }
    }
  }

  return issues;
}

export function computeBatchHankoHash(
  chainId: bigint,
  depositoryAddress: string,
  encodedBatch: string,
  nonce: bigint
): string {
  return ethers.keccak256(ethers.solidityPacked(
    ['bytes32', 'uint256', 'address', 'bytes', 'uint256'],
    [BATCH_DOMAIN_SEPARATOR, chainId, depositoryAddress, encodedBatch, nonce]
  ));
}

/**
 * Initialize jBatch state for entity
 */
export function initJBatch(): JBatchState {
  return {
    batch: createEmptyBatch(),
    jurisdiction: null, // Will be set when first operation is added
    lastBroadcast: 0,
    broadcastCount: 0,
    failedAttempts: 0,
  };
}

/**
 * Check if batch has any operations
 */
export function isBatchEmpty(batch: JBatch): boolean {
  return (
    batch.flashloans.length === 0 &&
    batch.reserveToReserve.length === 0 &&
    batch.reserveToCollateral.length === 0 &&
    batch.settlements.length === 0 &&
    batch.disputeStarts.length === 0 &&
    batch.disputeFinalizations.length === 0 &&
    batch.externalTokenToReserve.length === 0 &&
    batch.reserveToExternalToken.length === 0 &&
    batch.revealSecrets.length === 0
  );
}

/**
 * Add reserve â†’ collateral operation to batch
 */
export function batchAddReserveToCollateral(
  jBatchState: JBatchState,
  entityId: string,
  counterpartyId: string,
  tokenId: number,
  amount: bigint
): void {
  // Check if we already have an Râ†’C entry for this entity+counterparty+token
  // If yes, aggregate amounts
  const existing = jBatchState.batch.reserveToCollateral.find(
    op => op.receivingEntity === entityId && op.tokenId === tokenId
  );

  if (existing) {
    // Find the pair entry
    const pair = existing.pairs.find(p => p.entity === counterpartyId);
    if (pair) {
      pair.amount += amount; // Aggregate
    } else {
      existing.pairs.push({ entity: counterpartyId, amount });
    }
  } else {
    // Create new entry
    jBatchState.batch.reserveToCollateral.push({
      tokenId,
      receivingEntity: entityId,
      pairs: [{ entity: counterpartyId, amount }],
    });
  }

  console.log(`ðŸ“¦ jBatch: Added Râ†’C ${amount} token ${tokenId} for ${entityId.slice(-4)}â†’${counterpartyId.slice(-4)}`);
}

/**
 * Insurance registration for settlement
 */
export interface InsuranceReg {
  insured: string;
  insurer: string;
  tokenId: number;
  limit: bigint;
  expiresAt: bigint;
}

/**
 * Add settlement operation to batch
 */
export function batchAddSettlement(
  jBatchState: JBatchState,
  leftEntity: string,
  rightEntity: string,
  diffs: Array<{
    tokenId: number;
    leftDiff: bigint;
    rightDiff: bigint;
    collateralDiff: bigint;
    ondeltaDiff: bigint;
  }>,
  forgiveDebtsInTokenIds: number[] = [],
  insuranceRegs: InsuranceReg[] = [],
  sig?: string,
  entityProvider: string = '0x0000000000000000000000000000000000000000',
  hankoData: string = '0x',
  nonce: number = 0
): void {
  // Validate entities are in canonical order
  if (leftEntity >= rightEntity) {
    throw new Error(`Settlement entities must be ordered: ${leftEntity} >= ${rightEntity}`);
  }

  const hasChanges = diffs.length > 0 ||
    forgiveDebtsInTokenIds.length > 0 ||
    insuranceRegs.length > 0;

  if (hasChanges && (!sig || sig === '0x')) {
    throw new Error(`Settlement ${leftEntity.slice(-4)}â†”${rightEntity.slice(-4)} missing hanko signature`);
  }

  // Check if we already have a settlement for this pair
  const existing = jBatchState.batch.settlements.find(
    s => s.leftEntity === leftEntity && s.rightEntity === rightEntity
  );

  if (existing) {
    if (existing.diffs.length > 0 && hasChanges) {
      throw new Error(`Settlement ${leftEntity.slice(-4)}â†”${rightEntity.slice(-4)} already queued - refuse to merge diffs without a fresh signature`);
    }
    // Aggregate diffs by token
    for (const newDiff of diffs) {
      const existingDiff = existing.diffs.find(d => d.tokenId === newDiff.tokenId);
      if (existingDiff) {
        existingDiff.leftDiff += newDiff.leftDiff;
        existingDiff.rightDiff += newDiff.rightDiff;
        existingDiff.collateralDiff += newDiff.collateralDiff;
        existingDiff.ondeltaDiff += newDiff.ondeltaDiff;
      } else {
        existing.diffs.push(newDiff);
      }
    }
    // Append new insurance registrations
    existing.insuranceRegs.push(...insuranceRegs);
    // Append debt forgiveness (dedup)
    for (const tokenId of forgiveDebtsInTokenIds) {
      if (!existing.forgiveDebtsInTokenIds.includes(tokenId)) {
        existing.forgiveDebtsInTokenIds.push(tokenId);
      }
    }
    if (hasChanges) {
      existing.sig = sig || existing.sig;
      existing.entityProvider = entityProvider;
      existing.hankoData = hankoData;
      existing.nonce = nonce;
    }
  } else {
    jBatchState.batch.settlements.push({
      leftEntity,
      rightEntity,
      diffs,
      forgiveDebtsInTokenIds,
      insuranceRegs,
      sig: sig || '',
      entityProvider,
      hankoData,
      nonce,
    });
  }

  const insuranceMsg = insuranceRegs.length > 0 ? `, ${insuranceRegs.length} insurance regs` : '';
  console.log(`ðŸ“¦ jBatch: Added settlement ${leftEntity.slice(-4)}â†”${rightEntity.slice(-4)}, ${diffs.length} tokens${insuranceMsg}`);
}

/**
 * Add insurance registration to existing settlement (or create new settlement)
 */
export function batchAddInsurance(
  jBatchState: JBatchState,
  leftEntity: string,
  rightEntity: string,
  insuranceReg: InsuranceReg
): void {
  // Validate entities are in canonical order
  const [left, right] = isLeftEntity(leftEntity, rightEntity) ? [leftEntity, rightEntity] : [rightEntity, leftEntity];

  // Find or create settlement
  let existing = jBatchState.batch.settlements.find(
    s => s.leftEntity === left && s.rightEntity === right
  );

  if (!existing) {
    // Create empty settlement just for insurance
    existing = {
      leftEntity: left,
      rightEntity: right,
      diffs: [],
      forgiveDebtsInTokenIds: [],
      insuranceRegs: [],
      sig: '',
      entityProvider: '0x0000000000000000000000000000000000000000',
      hankoData: '0x',
      nonce: 0,
    };
    jBatchState.batch.settlements.push(existing);
  }

  if (!existing) {
    throw new Error('Failed to create settlement for insurance registration');
  }

  existing.insuranceRegs.push(insuranceReg);
  console.log(`ðŸ“¦ jBatch: Added insurance ${insuranceReg.insurer.slice(-4)}â†’${insuranceReg.insured.slice(-4)}, ${insuranceReg.limit} limit`);
}

/**
 * Add reserve â†’ reserve transfer to batch
 */
export function batchAddReserveToReserve(
  jBatchState: JBatchState,
  receivingEntity: string,
  tokenId: number,
  amount: bigint
): void {
  jBatchState.batch.reserveToReserve.push({
    receivingEntity,
    tokenId,
    amount,
  });

  console.log(`ðŸ“¦ jBatch: Added Râ†’R ${amount} token ${tokenId} to ${receivingEntity.slice(-4)}`);
}

/**
 * Add HTLC secret reveal to batch (idempotent per transformer+secret)
 */
export function batchAddRevealSecret(
  jBatchState: JBatchState,
  transformer: string,
  secret: string
): void {
  const exists = jBatchState.batch.revealSecrets.find(
    r => r.transformer === transformer && r.secret === secret
  );
  if (exists) {
    return;
  }
  jBatchState.batch.revealSecrets.push({ transformer, secret });
  console.log(`ðŸ“¦ jBatch: Added secret reveal ${secret.slice(0, 10)}... via ${transformer.slice(0, 10)}...`);
}

/**
 * Get batch size (total operations)
 */
export function getBatchSize(batch: JBatch): number {
  return (
    batch.flashloans.length +
    batch.reserveToReserve.length +
    batch.reserveToCollateral.length +
    batch.settlements.length +
    batch.disputeStarts.length +
    batch.disputeFinalizations.length +
    batch.externalTokenToReserve.length +
    batch.reserveToExternalToken.length +
    batch.revealSecrets.length
  );
}

/**
 * BrowserVM interface for batch processing
 * Matches frontend/src/lib/view/utils/browserVMProvider.ts
 */
export interface BrowserVMBatchProcessor {
  processBatch(encodedBatch: string, entityProvider: string, hankoData: string, nonce: bigint): Promise<any[]>;
  setBlockTimestamp?: (timestamp: number) => void;
  signSettlement?: (
    initiatorEntityId: string,
    counterpartyEntityId: string,
    diffs: Array<{
      tokenId: number;
      leftDiff: bigint;
      rightDiff: bigint;
      collateralDiff: bigint;
      ondeltaDiff: bigint;
    }>,
    forgiveDebtsInTokenIds?: number[],
    insuranceRegs?: Array<{
      insured: string;
      insurer: string;
      tokenId: number;
      limit: bigint;
      expiresAt: bigint;
    }>
  ) => Promise<string>;
  getEntityProviderAddress?: () => string;
  getDepositoryAddress?: () => string;
  getEntityNonce?: (entityId: string) => Promise<bigint>;
  getChainId?: () => bigint;
}

/**
 * Broadcast batch to Depository contract (ethers or BrowserVM)
 * Reference: 2019src.txt lines 3384-3399
 */
export async function broadcastBatch(
  env: any,
  entityId: string,
  jBatchState: JBatchState,
  jurisdiction: any, // JurisdictionConfig
  browserVM: BrowserVMBatchProcessor | undefined,
  timestamp: number,
  signerId?: string
): Promise<{ success: boolean; txHash?: string; events?: any[]; error?: string }> {
  if (isBatchEmpty(jBatchState.batch)) {
    console.log('ðŸ“¦ jBatch: Empty batch, skipping broadcast');
    return { success: true };
  }

  const batchSize = getBatchSize(jBatchState.batch);
  const b = jBatchState.batch;
  console.log(`ðŸ“¤ BATCH: ${entityId.slice(-4)} | ${batchSize} ops | Râ†’C=${b.reserveToCollateral.length} S=${b.settlements.length} Râ†’R=${b.reserveToReserve.length}`);
  const entityProviderAddress =
    (browserVM as any)?.getEntityProviderAddress?.() ||
    jurisdiction?.entityProviderAddress ||
    '0x0000000000000000000000000000000000000000';
  const depositoryAddress =
    (browserVM as any)?.getDepositoryAddress?.() ||
    jurisdiction?.depositoryAddress ||
    '0x0000000000000000000000000000000000000000';
  const chainId =
    (browserVM as any)?.getChainId?.() ??
    (jurisdiction?.chainId !== undefined ? BigInt(jurisdiction.chainId) : 0n);

  try {
    if (!signerId) {
      throw new Error(`Missing signerId for batch broadcast from ${entityId.slice(-4)}`);
    }

    // BrowserVM path - direct in-browser execution
    if (browserVM) {
      browserVM.setBlockTimestamp?.(timestamp);

      for (const settlement of jBatchState.batch.settlements) {
        const hasChanges = settlement.diffs.length > 0 ||
          settlement.forgiveDebtsInTokenIds.length > 0 ||
          settlement.insuranceRegs.length > 0;

        if (hasChanges) {
          if (entityProviderAddress === '0x0000000000000000000000000000000000000000') {
            console.warn(`âš ï¸ Settlement missing EntityProvider address (required for Hanko verification)`);
          }
          settlement.entityProvider = entityProviderAddress;
          if (!settlement.sig || settlement.sig === '0x') {
            throw new Error(`Settlement ${settlement.leftEntity.slice(-4)}â†”${settlement.rightEntity.slice(-4)} missing hanko signature`);
          }
        } else if (!settlement.sig) {
          settlement.sig = '0x';
        }
      }

      if (depositoryAddress === '0x0000000000000000000000000000000000000000') {
        throw new Error('Missing depository address for batch broadcast');
      }
      if (entityProviderAddress === '0x0000000000000000000000000000000000000000') {
        throw new Error('Missing entity provider address for batch broadcast');
      }
      if (!browserVM.getEntityNonce) {
        throw new Error('BrowserVM missing getEntityNonce for hanko batch signing');
      }
      if (!chainId) {
        throw new Error('Missing chainId for batch hanko signing');
      }

      const encodedBatch = encodeJBatch(jBatchState.batch);
      const normalizedEntityId = normalizeEntityId(entityId);
      const currentNonce = await browserVM.getEntityNonce(normalizedEntityId);
      const nextNonce = currentNonce + 1n;
      const batchHash = computeBatchHankoHash(chainId, depositoryAddress, encodedBatch, nextNonce);

      const { signHashesAsSingleEntity } = await import('./hanko-signing');
      const hankos = await signHashesAsSingleEntity(env, normalizedEntityId, signerId, [batchHash]);
      const hankoData = hankos[0];
      if (!hankoData) {
        throw new Error('Failed to build batch hanko signature');
      }

      const debugSummary = {
        entityId: normalizedEntityId,
        currentNonce: currentNonce.toString(),
        nextNonce: nextNonce.toString(),
        chainId: chainId.toString(),
        depository: depositoryAddress,
        entityProvider: entityProviderAddress,
        hankoBytes: Math.max(hankoData.length - 2, 0) / 2,
        batchSize: getBatchSize(jBatchState.batch),
        r2r: jBatchState.batch.reserveToReserve.length,
        r2c: jBatchState.batch.reserveToCollateral.length,
        settlements: jBatchState.batch.settlements.length,
        disputes: jBatchState.batch.disputeStarts.length,
        finals: jBatchState.batch.disputeFinalizations.length,
      };
      console.log(`ðŸ” BATCH-HANKO: ${safeStringify(debugSummary)}`);
      const preflightIssues = preflightBatchForE2(normalizedEntityId, jBatchState.batch, Math.floor(timestamp / 1000));
      if (preflightIssues.length > 0) {
        throw new Error(`Batch preflight failed: ${preflightIssues.join('; ')}`);
      }

      // Pass batch to contract with hanko authorization
      console.log(`ðŸ“¦ Calling Depository.processBatch() with full batch (${getBatchSize(jBatchState.batch)} ops)...`);
      const events = await browserVM.processBatch(encodedBatch, entityProviderAddress, hankoData, nextNonce);
      console.log(`   âœ… BrowserVM: ${events.length} events`);

      // NOTE: j-events are queued in env.runtimeInput.entityInputs by j-watcher
      // Caller must process them (prepopulate calls processJEvents, browser needs interval)

      // Clear batch after successful broadcast
      jBatchState.batch = createEmptyBatch();
      jBatchState.lastBroadcast = timestamp;
      jBatchState.broadcastCount++;
      jBatchState.failedAttempts = 0;

      return { success: true, events };
    }

    // Ethers path - real blockchain RPC
    const { connectToEthereum } = await import('./evm');
    const { depository, provider } = await connectToEthereum(jurisdiction);

    for (const settlement of jBatchState.batch.settlements) {
      const hasChanges = settlement.diffs.length > 0 ||
        settlement.forgiveDebtsInTokenIds.length > 0 ||
        settlement.insuranceRegs.length > 0;
      if (hasChanges) {
        if (entityProviderAddress === '0x0000000000000000000000000000000000000000') {
          console.warn(`âš ï¸ Settlement missing EntityProvider address (required for Hanko verification)`);
        }
        settlement.entityProvider = entityProviderAddress;
        if (!settlement.sig || settlement.sig === '0x') {
          throw new Error(`Settlement ${settlement.leftEntity.slice(-4)}â†”${settlement.rightEntity.slice(-4)} missing hanko signature`);
        }
      } else if (!settlement.sig) {
        settlement.sig = '0x';
      }
    }

    if (!chainId) {
      const net = await provider.getNetwork();
      if (!net.chainId) {
        throw new Error('Missing chainId for batch hanko signing');
      }
    }
    const resolvedChainId = chainId || BigInt((await provider.getNetwork()).chainId);

    const encodedBatch = encodeJBatch(jBatchState.batch);
    const normalizedEntityId = normalizeEntityId(entityId);
    const entityAddress = ethers.getAddress(`0x${normalizedEntityId.slice(-40)}`);
    const currentNonce = await depository['entityNonces']?.(entityAddress);
    const nextNonce = BigInt(currentNonce ?? 0) + 1n;
    const batchHash = computeBatchHankoHash(resolvedChainId, depositoryAddress, encodedBatch, nextNonce);

    const { signHashesAsSingleEntity } = await import('./hanko-signing');
    const hankos = await signHashesAsSingleEntity(env, entityId, signerId, [batchHash]);
    const hankoData = hankos[0];
    if (!hankoData) {
      throw new Error('Failed to build batch hanko signature');
    }

    // Submit to Depository.processBatch (Hanko)
    const tx = await depository['processBatch']!(encodedBatch, entityProviderAddress, hankoData, nextNonce, {
      gasLimit: 5000000, // High limit for complex batches
    });

    const receipt = await tx.wait();
    console.log(`   âœ… Ethers: block=${receipt.blockNumber} gas=${receipt.gasUsed}`);

    // Clear batch after successful broadcast
    jBatchState.batch = createEmptyBatch();
    jBatchState.lastBroadcast = timestamp;
    jBatchState.broadcastCount++;
    jBatchState.failedAttempts = 0;

    return {
      success: true,
      txHash: receipt.transactionHash,
    };
  } catch (error: unknown) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error(`   âŒ BATCH FAIL: ${entityId.slice(-4)} | ${errorMessage}`);
    if (error instanceof Error && error.stack) {
      console.error(`   âŒ BATCH FAIL STACK: ${error.stack}`);
    }
    jBatchState.failedAttempts++;

    return {
      success: false,
      error: errorMessage,
    };
  }
}

/**
 * Check if batch should be broadcast
 * Triggers: batch full, timeout, or manual flush
 */
export function shouldBroadcastBatch(
  jBatchState: JBatchState,
  currentTimestamp: number
): boolean {
  if (isBatchEmpty(jBatchState.batch)) {
    return false;
  }

  const batchSize = getBatchSize(jBatchState.batch);
  const MAX_BATCH_SIZE = 50; // Max operations per batch
  const BATCH_TIMEOUT_MS = 5000; // Broadcast every 5s even if not full

  // Trigger 1: Batch is full
  if (batchSize >= MAX_BATCH_SIZE) {
    console.log(`ðŸ“¦ jBatch: Full (${batchSize}/${MAX_BATCH_SIZE}) - triggering broadcast`);
    return true;
  }

  // Trigger 2: Timeout since last broadcast
  const timeSinceLastBroadcast = currentTimestamp - jBatchState.lastBroadcast;
  if (timeSinceLastBroadcast >= BATCH_TIMEOUT_MS) {
    console.log(`ðŸ“¦ jBatch: Timeout (${timeSinceLastBroadcast}ms) - triggering broadcast`);
    return true;
  }

  return false;
}


//runtime/account-utils.ts (221 lines)
/**
 * Account utilities for calculating balances and derived states
 * Based on old_src/app/Channel.ts deriveDelta logic
 */

import type { Delta, DerivedDelta } from './types';
import { validateDelta } from './validation-utils';
import { isLeftEntity } from './entity-id-utils';

/**
 * Determine if an entity is the "left" party in a bilateral account (like old_src Channel.ts)
 * @param myEntityId - Current entity ID
 * @param counterpartyEntityId - Other entity ID
 * @returns true if current entity is left (lexicographically smaller)
 */
export function isLeft(myEntityId: string, counterpartyEntityId: string): boolean {
  return isLeftEntity(myEntityId, counterpartyEntityId);
}

// CRITICAL: Default credit is 0 - credit must be explicitly extended via set_credit_limit
const BASE_CREDIT_LIMIT = 0n;

/**
 * Derive account balance information for a specific token
 * @param delta - The delta structure for this token
 * @param isLeft - Whether we are the left party in this account
 * @returns Derived balance information including capacities and credits
 */
export function deriveDelta(delta: Delta, isLeft: boolean): DerivedDelta {
  // VALIDATE AT SOURCE: Financial data must be valid
  validateDelta(delta, 'deriveDelta');

  const nonNegative = (x: bigint): bigint => x < 0n ? 0n : x;

  const totalDelta = delta.ondelta + delta.offdelta;

  const collateral = nonNegative(delta.collateral);

  let ownCreditLimit = delta.leftCreditLimit;
  let peerCreditLimit = delta.rightCreditLimit;

  let inCollateral = totalDelta > 0n ? nonNegative(collateral - totalDelta) : collateral;
  let outCollateral = totalDelta > 0n ? (totalDelta > collateral ? collateral : totalDelta) : 0n;

  // When delta > 0: peer owes us (peer is using OUR credit or we hold their collateral)
  // When delta < 0: we owe peer (we're using PEER's credit or they hold our collateral)

  // inOwnCredit = how much we owe using OUR OWN credit (when delta < 0 beyond collateral)
  let inOwnCredit = nonNegative(-totalDelta);
  if (inOwnCredit > ownCreditLimit) inOwnCredit = ownCreditLimit;

  // outPeerCredit = how much peer owes using OUR credit (when delta > 0 beyond collateral)
  let outPeerCredit = nonNegative(totalDelta - collateral);
  if (outPeerCredit > peerCreditLimit) outPeerCredit = peerCreditLimit;

  // outOwnCredit = remaining OWN credit we can extend
  let outOwnCredit = nonNegative(ownCreditLimit - inOwnCredit);

  // inPeerCredit = remaining credit peer extended to us (simple formula from original)
  let inPeerCredit = nonNegative(peerCreditLimit - outPeerCredit);

  // Track used credit for reporting (not used in capacity calculation)
  const peerCreditUsed = totalDelta < 0n ? nonNegative(-totalDelta - collateral) : 0n;
  const ownCreditUsed = totalDelta > 0n ? nonNegative(totalDelta - collateral) : 0n;

  let inAllowance = delta.rightAllowance;
  let outAllowance = delta.leftAllowance;

  const totalCapacity = collateral + ownCreditLimit + peerCreditLimit;

  // HTLC holds (capacity locked in pending HTLCs)
  const leftHtlcHold = delta.leftHtlcHold || 0n;
  const rightHtlcHold = delta.rightHtlcHold || 0n;

  // Swap holds (capacity locked in pending swap offers)
  const leftSwapHold = delta.leftSwapHold || 0n;
  const rightSwapHold = delta.rightSwapHold || 0n;

  // Total holds = HTLC + Swap
  const leftHold = leftHtlcHold + leftSwapHold;
  const rightHold = rightHtlcHold + rightSwapHold;

  // Original formula: in* components for inCapacity, out* components for outCapacity
  let inCapacity = nonNegative(inOwnCredit + inCollateral + inPeerCredit - inAllowance);
  let outCapacity = nonNegative(outPeerCredit + outCollateral + outOwnCredit - outAllowance);

  // CRITICAL: Deduct holds from capacity (prevents double-spend)
  if (isLeft) {
    outCapacity = nonNegative(outCapacity - leftHold);
    inCapacity = nonNegative(inCapacity - rightHold);
  } else {
    outCapacity = nonNegative(outCapacity - rightHold);
    inCapacity = nonNegative(inCapacity - leftHold);
  }

  if (!isLeft) {
    // Flip for RIGHT entity perspective
    [inCollateral, inAllowance, inCapacity,
     outCollateral, outAllowance, outCapacity] =
    [outCollateral, outAllowance, outCapacity,
     inCollateral, inAllowance, inCapacity];

    [ownCreditLimit, peerCreditLimit] = [peerCreditLimit, ownCreditLimit];
    [outOwnCredit, inOwnCredit, outPeerCredit, inPeerCredit] =
    [inPeerCredit, outPeerCredit, inOwnCredit, outOwnCredit];
  }

  // ASCII visualization
  const totalWidth = Number(totalCapacity);
  const leftCreditWidth = Math.floor((Number(ownCreditLimit) / totalWidth) * 50);
  const collateralWidth = Math.floor((Number(collateral) / totalWidth) * 50);
  const rightCreditWidth = 50 - leftCreditWidth - collateralWidth;
  const deltaPosition = Math.floor(((Number(totalDelta) + Number(ownCreditLimit)) / totalWidth) * 50);

  // ASCII visualization - proper bar with position marker
  // Build the full capacity bar first
  const fullBar =
    '-'.repeat(leftCreditWidth) +
    '='.repeat(collateralWidth) +
    '-'.repeat(rightCreditWidth);

  // Insert position marker at deltaPosition
  const clampedPosition = Math.max(0, Math.min(deltaPosition, fullBar.length));
  const ascii =
    '[' +
    fullBar.substring(0, clampedPosition) +
    '|' +
    fullBar.substring(clampedPosition) +
    ']';

  console.log(`âœ… deriveDelta RETURN: isLeft=${isLeft}, inCap=${inCapacity}, outCap=${outCapacity}, SUM=${inCapacity + outCapacity}`);

  return {
    delta: totalDelta,
    collateral,
    inCollateral,
    outCollateral,
    inOwnCredit,
    outPeerCredit,
    inAllowance,
    outAllowance,
    totalCapacity,
    ownCreditLimit,
    peerCreditLimit,
    inCapacity,
    outCapacity,
    outOwnCredit,
    inPeerCredit,
    peerCreditUsed,  // HYBRID: credit peer lent that we're using
    ownCreditUsed,   // HYBRID: credit we lent that peer is using
    ascii,
  };
}

/**
 * Create a simple delta for demo purposes
 * @param tokenId - Token ID
 * @param collateral - Collateral amount
 * @param delta - Delta amount
 * @returns Delta object with reasonable defaults
 */
export function createDemoDelta(tokenId: number, collateral: bigint = 1000n, delta: bigint = 0n): Delta {
  const creditLimit = getDefaultCreditLimit(tokenId);

  const deltaData = {
    tokenId,
    collateral,
    ondelta: delta,
    offdelta: 0n,
    leftCreditLimit: creditLimit,
    rightCreditLimit: creditLimit,
    leftAllowance: 0n,
    rightAllowance: 0n,
  };

  // VALIDATE AT SOURCE: Guarantee type safety from this point forward
  return validateDelta(deltaData, 'createDemoDelta');
}

/**
 * Get token information for display
 * USDC is primary token (1), ETH is secondary (2)
 */
export const TOKEN_REGISTRY: Record<number, { symbol: string; name: string; decimals: number; color: string }> = {
  1: { symbol: 'USDC', name: 'USD Coin', decimals: 18, color: '#2775ca' },
  2: { symbol: 'WETH', name: 'Wrapped Ether', decimals: 18, color: '#627eea' },
  3: { symbol: 'USDT', name: 'Tether USD', decimals: 18, color: '#26a17b' },
};

export function getTokenInfo(tokenId: number) {
  return TOKEN_REGISTRY[tokenId] || { 
    symbol: `TKN${tokenId}`, 
    name: `Token ${tokenId}`, 
    decimals: 18, 
    color: '#999' 
  };
}

/**
 * Default per-token credit limit scaled to token decimals (matches old channel behavior)
 */
export function getDefaultCreditLimit(tokenId: number): bigint {
  const tokenInfo = getTokenInfo(tokenId);
  const decimals = BigInt(tokenInfo.decimals ?? 18);
  return BASE_CREDIT_LIMIT * 10n ** decimals;
}

/**
 * Format amount for display with proper decimals
 */
// DEPRECATED: Use financial-utils.ts formatTokenAmount instead
// This is kept for backwards compatibility during migration
export { formatTokenAmount } from './financial-utils';

/**
 * Calculate percentage for capacity bar display
 */
// DEPRECATED: Use financial-utils.ts calculatePercentage instead
// This is kept for backwards compatibility during migration
export { calculatePercentage } from './financial-utils';


//runtime/serialization-utils.ts (116 lines)
/**
 * BigInt-safe serialization utilities
 * Handles JSON serialization with BigInt values across the XLN codebase
 */

/**
 * Converts BigInt values to strings for JSON serialization
 * @param key - JSON key
 * @param value - JSON value
 * @returns Serializable value
 */
export function bigIntReplacer(_key: string, value: any): any {
  if (typeof value === 'bigint') {
    return `BigInt(${value.toString()})`;
  }
  // Handle Map objects
  if (value instanceof Map) {
    return Object.fromEntries(value);
  }
  // Handle Set objects
  if (value instanceof Set) {
    return Array.from(value);
  }
  // Handle Buffer objects
  if (value && typeof value === 'object' && value.type === 'Buffer' && Array.isArray(value.data)) {
    return `Buffer(${value.data.length} bytes)`;
  }
  // Handle Functions
  if (typeof value === 'function') {
    return `[Function: ${value.name || 'anonymous'}]`;
  }
  return value;
}

/**
 * BigInt-safe JSON.stringify replacement
 * @param obj - Object to stringify
 * @param space - Formatting space (optional)
 * @returns JSON string
 */
export function safeStringify(obj: any, space?: number): string {
  try {
    return JSON.stringify(obj, bigIntReplacer, space);
  } catch (err) {
    return `[Error stringifying: ${(err as Error).message}]`;
  }
}

/**
 * BigInt-safe console logging for debugging
 * @param message - Log message
 * @param obj - Object to log (optional)
 */
export function safeLog(message: string, obj?: any): void {
  if (obj !== undefined) {
    console.log(message, safeStringify(obj, 2));
  } else {
    console.log(message);
  }
}

/**
 * Parse BigInt strings back to BigInt values
 * @param key - JSON key
 * @param value - JSON value
 * @returns Parsed value with BigInt restored
 */
export function bigIntReviver(_key: string, value: any): any {
  if (typeof value === 'string' && value.startsWith('BigInt(') && value.endsWith(')')) {
    const bigintStr = value.slice(7, -1); // Remove 'BigInt(' and ')'
    return BigInt(bigintStr);
  }
  return value;
}

/**
 * BigInt-safe JSON.parse replacement
 * @param jsonString - JSON string to parse
 * @returns Parsed object with BigInt values restored
 */
export function safeParse(jsonString: string): any {
  try {
    return JSON.parse(jsonString, bigIntReviver);
  } catch (err) {
    throw new Error(`Failed to parse JSON: ${(err as Error).message}`);
  }
}

/**
 * Universal Buffer comparison (works in both Node.js and browser)
 * @param buf1 - First buffer
 * @param buf2 - Second buffer
 * @returns 0 if equal, -1 if buf1 < buf2, 1 if buf1 > buf2
 */
export function bufferCompare(buf1: Buffer, buf2: Buffer): number {
  if (typeof Buffer !== 'undefined' && Buffer.compare) {
    // Node.js environment
    return Buffer.compare(buf1, buf2);
  } else {
    // Browser environment - compare as hex strings
    const hex1 = buf1.toString('hex');
    const hex2 = buf2.toString('hex');
    if (hex1 === hex2) return 0;
    return hex1 < hex2 ? -1 : 1;
  }
}

/**
 * Universal Buffer equality check
 * @param buf1 - First buffer
 * @param buf2 - Second buffer
 * @returns true if buffers are equal
 */
export function buffersEqual(buf1: Buffer, buf2: Buffer): boolean {
  return bufferCompare(buf1, buf2) === 0;
}

//runtime/entity-tx/index.ts (7 lines)
export * from './apply';
export * from './financial';
export * from './handlers/account';
export * from './j-events';
export * from './proposals';
export * from './validation';


//runtime/entity-tx/apply.ts (928 lines)
import { calculateQuorumPower } from '../entity-consensus';
import { isLeftEntity } from '../entity-id-utils';
import { formatEntityId } from '../utils';
import { processProfileUpdate } from '../name-resolution';
import { createOrderbookExtState } from '../orderbook';
import { db } from '../runtime';
import { EntityState, EntityTx, Env, Proposal, Delta, AccountTx, EntityInput, JInput } from '../types';
import { DEBUG, HEAVY_LOGS, log } from '../utils';
import { safeStringify } from '../serialization-utils';
import { buildEntityProfile } from '../gossip-helper';
// import { addToReserves, subtractFromReserves } from './financial'; // Currently unused
import { handleAccountInput, type MempoolOp, type SwapOfferEvent, type SwapCancelEvent } from './handlers/account';
import { handleJEvent } from './j-events';

// Extended return type including pure events from handlers
export interface ApplyEntityTxResult {
  newState: EntityState;
  outputs: EntityInput[];
  jOutputs?: JInput[];
  // Pure events for entity-level orchestration
  mempoolOps?: MempoolOp[];
  swapOffersCreated?: SwapOfferEvent[];
  swapOffersCancelled?: SwapCancelEvent[];
}
import { executeProposal, generateProposalId } from './proposals';
import { validateMessage } from './validation';
import { cloneEntityState, addMessage, canonicalAccountKey, resolveEntityProposerId } from '../state-helpers';
import { submitSettle } from '../evm';
import { logError } from '../logger';
import { FINANCIAL } from '../constants';

export const applyEntityTx = async (env: Env, entityState: EntityState, entityTx: EntityTx): Promise<ApplyEntityTxResult> => {
  if (!entityTx) {
    logError("ENTITY_TX", `âŒ EntityTx is undefined!`);
    return { newState: entityState, outputs: [] };
  }

  try {
    if (entityTx.type === 'chat') {
      const { from, message } = entityTx.data;

      if (!validateMessage(message)) {
        log.error(`âŒ Invalid chat message from ${from}`);
        return { newState: entityState, outputs: [] }; // Return unchanged state
      }

      const currentNonce = entityState.nonces.get(from) || 0;
      const expectedNonce = currentNonce + 1;

      const newEntityState = cloneEntityState(entityState);

      newEntityState.nonces.set(from, expectedNonce);
      addMessage(newEntityState, `${from}: ${message}`);

      return { newState: newEntityState, outputs: [] };
    }

    if (entityTx.type === 'chatMessage') {
      // System-generated messages (e.g., from crontab dispute suggestions)
      const { message } = entityTx.data;
      const newEntityState = cloneEntityState(entityState);

      addMessage(newEntityState, message);

      return { newState: newEntityState, outputs: [] };
    }

    if (entityTx.type === 'propose') {
      const { action, proposer } = entityTx.data;
      const proposalId = generateProposalId(action, proposer, entityState);

      if (DEBUG) console.log(`    ðŸ“ Creating proposal ${proposalId} by ${proposer}: ${action.data.message}`);

      const proposal: Proposal = {
        id: proposalId,
        proposer,
        action,
        // explicitly type votes map to match Proposal.vote value type
        votes: new Map<string, 'yes' | 'no' | 'abstain' | { choice: 'yes' | 'no' | 'abstain'; comment: string }>([
          [proposer, 'yes'],
        ]),
        status: 'pending',
        created: entityState.timestamp,
      };

      const proposerPower = entityState.config.shares[proposer] || BigInt(0);
      const shouldExecuteImmediately = proposerPower >= entityState.config.threshold;

      let newEntityState = cloneEntityState(entityState);

      if (shouldExecuteImmediately) {
        proposal.status = 'executed';
        newEntityState = executeProposal(newEntityState, proposal);
        if (DEBUG)
          console.log(
            `    âš¡ Proposal executed immediately - proposer has ${proposerPower} >= ${entityState.config.threshold} threshold`,
          );
      } else {
        if (DEBUG)
          console.log(
            `    â³ Proposal pending votes - proposer has ${proposerPower} < ${entityState.config.threshold} threshold`,
          );
      }

      newEntityState.proposals.set(proposalId, proposal);
      return { newState: newEntityState, outputs: [] };
    }

    if (entityTx.type === 'vote') {
      console.log(`ðŸ—³ï¸ PROCESSING VOTE: entityTx.data=`, entityTx.data);
      const { proposalId, voter, choice, comment } = entityTx.data;
      const proposal = entityState.proposals.get(proposalId);

      console.log(`ðŸ—³ï¸ Vote lookup: proposalId=${proposalId}, found=${!!proposal}, status=${proposal?.status}`);
      console.log(`ðŸ—³ï¸ Available proposals:`, Array.from(entityState.proposals.keys()));

      if (!proposal || proposal.status !== 'pending') {
        console.log(`    âŒ Vote ignored - proposal ${proposalId.slice(0, 12)}... not found or not pending`);
        return { newState: entityState, outputs: [] };
      }

      console.log(`    ðŸ—³ï¸  Vote by ${voter}: ${choice} on proposal ${proposalId.slice(0, 12)}...`);

      const newEntityState = cloneEntityState(entityState);

      const updatedProposal = {
        ...proposal,
        votes: new Map(proposal.votes),
      };
      // Only create the object variant when comment is provided (comment must be string)
      const voteData: 'yes' | 'no' | 'abstain' | { choice: 'yes' | 'no' | 'abstain'; comment: string } =
        comment !== undefined ? ({ choice, comment } as { choice: 'yes' | 'no' | 'abstain'; comment: string }) : choice;
      updatedProposal.votes.set(voter, voteData);

      const yesVoters = Array.from(updatedProposal.votes.entries())
        .filter(([_voter, voteData]) => {
          const vote = typeof voteData === 'object' ? voteData.choice : voteData;
          return vote === 'yes';
        })
        .map(([voter, _voteData]) => voter);

      const totalYesPower = calculateQuorumPower(entityState.config, yesVoters);

      if (DEBUG) {
        const totalShares = Object.values(entityState.config.shares).reduce((sum, val) => sum + val, BigInt(0));
        const percentage = ((Number(totalYesPower) / Number(entityState.config.threshold)) * 100).toFixed(1);
        console.log(
          `    ðŸ” Proposal votes: ${totalYesPower} / ${totalShares} [${percentage}% threshold${Number(totalYesPower) >= Number(entityState.config.threshold) ? '+' : ''}]`,
        );
      }

      if (totalYesPower >= entityState.config.threshold) {
        updatedProposal.status = 'executed';
        const executedState = executeProposal(newEntityState, updatedProposal);
        executedState.proposals.set(proposalId, updatedProposal);
        return { newState: executedState, outputs: [] };
      }

      newEntityState.proposals.set(proposalId, updatedProposal);
      return { newState: newEntityState, outputs: [] };
    }

    if (entityTx.type === 'profile-update') {
      console.log(`ðŸ·ï¸ Profile update transaction processing - data:`, entityTx.data);

      // Extract profile update data
      const profileData = entityTx.data.profile;
      console.log(`ðŸ·ï¸ Extracted profileData:`, profileData);

      if (profileData && profileData.entityId) {
        console.log(`ðŸ·ï¸ Calling processProfileUpdate for entity ${profileData.entityId}`);
        // Process profile update synchronously to ensure gossip is updated before snapshot
        try {
          await processProfileUpdate(db, profileData.entityId, profileData, profileData.hankoSignature || '', env);
        } catch (error) {
          logError("ENTITY_TX", `âŒ Failed to process profile update for ${profileData.entityId}:`, error);
        }
      } else {
        console.warn(`âš ï¸ Invalid profile-update transaction data:`, entityTx.data);
        console.warn(`âš ï¸ ProfileData missing or invalid:`, profileData);
      }

      return { newState: entityState, outputs: [] };
    }

    if (entityTx.type === 'initOrderbookExt') {
      if (entityState.orderbookExt) {
        return { newState: entityState, outputs: [] };
      }

      const hubProfile = {
        entityId: entityState.entityId,
        name: entityTx.data.name,
        spreadDistribution: entityTx.data.spreadDistribution,
        referenceTokenId: entityTx.data.referenceTokenId,
        minTradeSize: entityTx.data.minTradeSize,
        supportedPairs: [...entityTx.data.supportedPairs],
      };

      const newState = cloneEntityState(entityState);
      newState.orderbookExt = createOrderbookExtState(hubProfile);

      return { newState, outputs: [] };
    }

    if (entityTx.type === 'j_event') {
      // Emit J-event received
      env.emit('JEventReceived', {
        entityId: entityState.entityId,
        eventType: entityTx.data.event.type,
        blockNumber: entityTx.data.blockNumber,
        txHash: entityTx.data.transactionHash,
      });

      const { newState, mempoolOps } = await handleJEvent(entityState, entityTx.data, env);
      return { newState, outputs: [], mempoolOps: mempoolOps || [] };
    }

    if (entityTx.type === 'accountInput') {
      const result = await handleAccountInput(entityState, entityTx.data, env);
      return {
        newState: result.newState,
        outputs: result.outputs,
        mempoolOps: result.mempoolOps,
        swapOffersCreated: result.swapOffersCreated,
        swapOffersCancelled: result.swapOffersCancelled,
      };
    }

    if (entityTx.type === 'openAccount') {
      const targetEntityId = entityTx.data.targetEntityId;
      // Account keyed by counterparty ID (simpler than canonical)
      const counterpartyId = targetEntityId;
      const isLeft = isLeftEntity(entityState.entityId, targetEntityId);

      if (entityState.accounts.has(counterpartyId)) {
        console.log(`ðŸ’³ OPEN-ACCOUNT: Account with ${formatEntityId(counterpartyId)} already exists, skipping duplicate request`);
        return { newState: entityState, outputs: [] };
      }

      console.log(`ðŸ’³ OPEN-ACCOUNT: Opening account with ${counterpartyId} (counterparty: ${counterpartyId.slice(-4)})`);

      // Emit account opening event
      env.emit('AccountOpening', {
        entityId: entityState.entityId,
        counterpartyId: targetEntityId,
      });

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];

      // Add chat message about account opening
      addMessage(newState, `ðŸ’³ Opening account with Entity ${formatEntityId(entityTx.data.targetEntityId)}...`);

      // STEP 1: Create local account machine
      if (!newState.accounts.has(counterpartyId)) {
        console.log(`ðŸ’³ LOCAL-ACCOUNT: Creating local account with Entity ${formatEntityId(counterpartyId)}...`);

        // CONSENSUS FIX: Start with empty deltas - let all delta creation happen through transactions
        // This ensures both sides have identical delta Maps (matches Channel.ts pattern)
        const initialDeltas = new Map<number, Delta>();

        // CANONICAL: Store leftEntity/rightEntity (sorted) for AccountMachine internals
        const leftEntity = isLeft ? entityState.entityId : counterpartyId;
        const rightEntity = isLeft ? counterpartyId : entityState.entityId;

        newState.accounts.set(counterpartyId, {
          leftEntity,
          rightEntity,
          mempool: [],
          currentFrame: {
            height: 0,
            timestamp: env.timestamp,
            jHeight: 0,
            accountTxs: [],
            prevFrameHash: '',
            tokenIds: [],
            deltas: [],
            stateHash: '',
            byLeft: isLeft,
          },
          sentTransitions: 0,
          ackedTransitions: 0,
          deltas: initialDeltas,
          globalCreditLimits: {
            ownLimit: 0n, // Credit starts at 0 - must be explicitly extended via set_credit_limit
            peerLimit: 0n, // Credit starts at 0 - must be explicitly extended via set_credit_limit
          },
          // Frame-based consensus fields
          currentHeight: 0,
          pendingSignatures: [],
          rollbackCount: 0,
          // CHANNEL.TS REFERENCE: Proper message counters (NOT timestamps!)
          sendCounter: 0,    // Like Channel.ts line 131
          receiveCounter: 0, // Like Channel.ts line 132
          // Removed isProposer - use isLeft() function like old_src Channel.ts
          proofHeader: {
            fromEntity: entityState.entityId,  // Perspective-dependent for signing
            toEntity: counterpartyId,
            cooperativeNonce: 0,
            disputeNonce: 0,
          },
          proofBody: { tokenIds: [], deltas: [] },
          // Dispute configuration (default: 20 blocks = 2 * 10)
          disputeConfig: {
            leftDisputeDelay: 2,  // 20 blocks for left entity
            rightDisputeDelay: 2, // 20 blocks for right entity
          },
          frameHistory: [],
          pendingWithdrawals: new Map(),
          requestedRebalance: new Map(),
          locks: new Map(), // HTLC: Initialize empty locks
          swapOffers: new Map(), // Swap: Initialize empty offers
          // Bilateral J-event consensus
          leftJObservations: [],
          rightJObservations: [],
          jEventChain: [],
          lastFinalizedJHeight: 0,
        });
      }

      // STEP 2: Add setup txs ONLY on LEFT side (Channel.ts pattern)
      // Right side waits for left's frame; otherwise it will re-propose add_delta and stall.
      console.log(`ðŸ’³ Preparing account setup for ${formatEntityId(entityTx.data.targetEntityId)} (left=${isLeft})`);

      const localAccount = newState.accounts.get(counterpartyId);
      if (!localAccount) {
        throw new Error(`CRITICAL: Account machine not found after creation`);
      }

      if (isLeft) {
        // Token 1 = USDC
        const usdcTokenId = 1;
        // Add transactions to mempool - will be batched into frame #1 on next tick
        // NOTE: Only add_delta is queued. Credit limits are 0 by default - must be explicitly set
        localAccount.mempool.push({
          type: 'add_delta',
          data: { tokenId: usdcTokenId }
        });

        console.log(`ðŸ“ Queued add_delta to mempool (total: ${localAccount.mempool.length})`);
        console.log(`â° Frame #1 will be auto-proposed on next tick (100ms) via AUTO-PROPOSE`);
        console.log(`   Transactions: [add_delta] - credit limits start at 0, must be explicitly set`);
      } else {
        console.log(`ðŸ§­ Right side: waiting for left's frame (mempool stays empty)`);
      }

      // Add success message to chat
      addMessage(newState, `âœ… Account opening request sent to Entity ${formatEntityId(counterpartyId)}`);

      // CRITICAL: Notify counterparty to create mirror account
      // Without this, Hub won't know about Alice-Hub account when j-events arrive!
      const counterpartySigner = resolveEntityProposerId(env, targetEntityId, 'openAccount');
      outputs.push({
        entityId: targetEntityId,
        signerId: counterpartySigner,
        entityTxs: [{
          type: 'openAccount',
          data: { targetEntityId: entityState.entityId }
        }]
      });
      console.log(`ðŸ“¤ Sent openAccount request to counterparty ${formatEntityId(targetEntityId)} (signer: ${counterpartySigner})`);

      // Broadcast updated profile to gossip layer
      if (env.gossip) {
        // MONOTONIC TIMESTAMP: Ensure timestamp grows
        const existingProfile = env.gossip?.getProfiles?.().find((p: any) => p.entityId === newState.entityId);
        const lastTimestamp = existingProfile?.metadata?.lastUpdated || 0;
        const monotonicTimestamp = Math.max(lastTimestamp + 1, env.timestamp);

        // Preserve existing name if any (don't overwrite with undefined)
        const existingName = existingProfile?.metadata?.name;
        const profile = buildEntityProfile(newState, existingName, monotonicTimestamp);

        console.log(`ðŸ—ï¸ Built profile for ${newState.entityId.slice(-4)}: accounts=${profile.accounts?.length || 0} name=${profile.metadata?.name || 'none'}`);

        if (env.runtimeId) {
          profile.runtimeId = env.runtimeId;
        }
        console.log(`ðŸ“¡ Announcing profile ${newState.entityId.slice(-4)} ts=${monotonicTimestamp} accounts=${profile.accounts?.length || 0}`);
        env.gossip.announce(profile);
      }

      return { newState, outputs };
    }

    if (entityTx.type === 'htlcPayment') {
      const { handleHtlcPayment } = await import('./handlers/htlc-payment');
      return await handleHtlcPayment(entityState, entityTx, env);
    }

    if (entityTx.type === 'processHtlcTimeouts') {
      console.log(`â° PROCESS-HTLC-TIMEOUTS: Processing ${entityTx.data.expiredLocks?.length || 0} expired locks`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];
      const mempoolOps: MempoolOp[] = [];

      // Convert expired locks to htlc_timeout mempoolOps
      for (const { accountId, lockId } of entityTx.data.expiredLocks || []) {
        mempoolOps.push({
          accountId,
          tx: {
            type: 'htlc_timeout',
            data: { lockId }
          }
        });
        console.log(`â°   Queued timeout for lock ${lockId.slice(0,16)}... on account ${accountId.slice(-4)}`);
      }

      return { newState, outputs, mempoolOps };
    }

    if (entityTx.type === 'manualHtlcLock') {
      console.log(`ðŸ”’ MANUAL-HTLC-LOCK: Creating lock without envelope (timeout test)`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];
      const mempoolOps: MempoolOp[] = [];

      const { counterpartyId, lockId, hashlock, timelock, revealBeforeHeight, amount, tokenId } = entityTx.data;

      mempoolOps.push({
        accountId: counterpartyId,
        tx: {
          type: 'htlc_lock',
          data: {
            lockId,
            hashlock,
            timelock,
            revealBeforeHeight,
            amount,
            tokenId
            // NO envelope - for timeout testing
          }
        }
      });

      console.log(`ðŸ”’   Queued htlc_lock for ${counterpartyId.slice(-4)}, lockId=${lockId.slice(0,16)}...`);

      return { newState, outputs, mempoolOps };
    }

    if (entityTx.type === 'directPayment') {
      console.log(`ðŸ’¸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
      console.log(`ðŸ’¸ DIRECT-PAYMENT HANDLER: ${entityState.entityId.slice(-4)} â†’ ${entityTx.data.targetEntityId.slice(-4)}`);
      console.log(`ðŸ’¸ Amount: ${entityTx.data.amount}, TokenId: ${entityTx.data.tokenId}`);
      console.log(`ðŸ’¸ Route: ${entityTx.data.route?.map(r => r.slice(-4)).join('â†’') || 'NONE (will calculate)'}`);
      console.log(`ðŸ’¸ Description: ${entityTx.data.description || 'none'}`);

      // Emit payment initiation event
      env.emit('PaymentInitiated', {
        fromEntity: entityState.entityId,
        toEntity: entityTx.data.targetEntityId,
        tokenId: entityTx.data.tokenId,
        amount: entityTx.data.amount.toString(),
        route: entityTx.data.route,
      });

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];
      const mempoolOps: MempoolOp[] = [];
      console.log(`ðŸ’¸ Initialized: outputs=[], mempoolOps=[]`);

      // Extract payment details
      let { targetEntityId, tokenId, amount, route, description } = entityTx.data;
      if (amount < FINANCIAL.MIN_PAYMENT_AMOUNT || amount > FINANCIAL.MAX_PAYMENT_AMOUNT) {
        logError("ENTITY_TX", `âŒ Payment amount out of bounds: ${amount.toString()} (min ${FINANCIAL.MIN_PAYMENT_AMOUNT.toString()}, max ${FINANCIAL.MAX_PAYMENT_AMOUNT.toString()})`);
        addMessage(newState, `âŒ Payment failed: amount out of bounds`);
        return { newState, outputs: [] };
      }

      // If no route provided, check for direct account or calculate route
      if (!route || route.length === 0) {
        // Check if we have a direct account with target
        // Account keyed by counterparty ID
        if (newState.accounts.has(targetEntityId)) {
          console.log(`ðŸ’¸ Direct account exists with ${formatEntityId(targetEntityId)}`);
          route = [entityState.entityId, targetEntityId];
        } else {
          // Find route through network using gossip
          console.log(`ðŸ’¸ No direct account, finding route to ${formatEntityId(targetEntityId)}`);

          // Try to find a route through the network
          if (env.gossip) {
            const networkGraph = env.gossip.getNetworkGraph();
            const paths = networkGraph.findPaths(entityState.entityId, targetEntityId);

            if (paths.length > 0) {
              // Use the shortest path
              route = paths[0].path;
              console.log(`ðŸ’¸ Found route: ${route.map(e => formatEntityId(e)).join(' â†’ ')}`);
            } else {
              logError("ENTITY_TX", `âŒ No route found to ${formatEntityId(targetEntityId)}`);
              addMessage(newState, `âŒ Payment failed: No route to ${formatEntityId(targetEntityId)}`);
              return { newState, outputs: [] };
            }
          } else {
            logError("ENTITY_TX", `âŒ Cannot find route: Gossip layer not available`);
            addMessage(newState, `âŒ Payment failed: Network routing unavailable`);
            return { newState, outputs: [] };
          }
        }
      }

      // Validate route starts with current entity
      if (route.length < 1 || route[0] !== entityState.entityId) {
        console.error(`âŒ ROUTE VALIDATION FAILED: route.length=${route.length}, route[0]=${route[0]?.slice(-4)}, entityId=${entityState.entityId.slice(-4)}`);
        logError("ENTITY_TX", `âŒ Invalid route: doesn't start with current entity`);
        return { newState: entityState, outputs: [] };
      }

      // Check if we're the final destination (route.length === 1)
      if (route.length === 1 && route[0] === targetEntityId) {
        console.error(`âœ… FINAL DESTINATION: Entity ${entityState.entityId.slice(-4)} is the final recipient`);
        // This is a payment TO us (final hop) - handle as received payment
        // The payment was already applied in the bilateral consensus
        // Just add a message and return
        addMessage(newState, `ðŸ’° Received payment of ${amount} (token ${tokenId})`);
        return { newState, outputs: [] };
      }

      // Determine next hop (for intermediate forwarding)
      const nextHop = route[1];
      if (!nextHop) {
        console.error(`âŒ ROUTE ERROR: No next hop in route=[${route.map(r => r.slice(-4)).join(',')}]`);
        logError("ENTITY_TX", `âŒ Invalid route: no next hop specified in route`);
        return { newState, outputs: [] };
      }

      // Check if we have an account with next hop
      // Account keyed by counterparty ID
      const accountMachine = newState.accounts.get(nextHop);
      if (!accountMachine) {
        logError("ENTITY_TX", `âŒ No account with next hop: ${nextHop}`);
        addMessage(newState, `âŒ Payment failed: No account with ${formatEntityId(nextHop)}`);
        return { newState, outputs: [] };
      }

      // Capacity validation deferred to account-level (bilateral consensus)
      // Entity-level state may be stale before bilateral frames settle

      // Create AccountTx for the payment
      // CRITICAL: ALWAYS include fromEntityId/toEntityId for deterministic consensus
      const accountTx: AccountTx = {
        type: 'direct_payment',
        data: {
          tokenId,
          amount,
          route: route.slice(1), // Remove sender from route (next hop needs to see themselves in route[0])
          description: description || `Payment to ${formatEntityId(targetEntityId)}`,
          fromEntityId: entityState.entityId, // âœ… EXPLICIT direction
          toEntityId: nextHop,                 // âœ… EXPLICIT direction
        },
      };

      // Add to account machine mempool via pure mempoolOps
      if (accountMachine) {
        // Pure: return mempoolOp instead of mutating directly
        mempoolOps.push({ accountId: nextHop, tx: accountTx });
        console.log(`ðŸ’¸ QUEUED TO MEMPOOL: account=${formatEntityId(nextHop)}`);
        console.log(`ðŸ’¸   AccountTx type: ${accountTx.type}`);
        console.log(`ðŸ’¸   Amount: ${accountTx.data.amount}`);
        console.log(`ðŸ’¸   From: ${accountTx.data.fromEntityId.slice(-4)}`);
        console.log(`ðŸ’¸   To: ${accountTx.data.toEntityId.slice(-4)}`);
        console.log(`ðŸ’¸   Route after slice: [${accountTx.data.route.map(r => r.slice(-4)).join(',')}]`);
        console.log(`ðŸ’¸ mempoolOps.length: ${mempoolOps.length}`);

        const isLeft = isLeftEntity(accountMachine.proofHeader.fromEntity, accountMachine.proofHeader.toEntity);
        console.log(`ðŸ’¸ Account state: isLeft=${isLeft}, hasPendingFrame=${!!accountMachine.pendingFrame}`);

        // Message about payment initiation
        addMessage(newState,
          `ðŸ’¸ Sending ${amount} (token ${tokenId}) to ${formatEntityId(targetEntityId)} via ${route.length - 1} hops`
        );

        // The payment is now queued for entity-level orchestration
        // Entity-consensus will apply mempoolOps and add to proposableAccounts
        console.log(`ðŸ’¸ Payment queued for bilateral consensus with ${formatEntityId(nextHop)}`);
        console.log(`ðŸ’¸ Account ${formatEntityId(nextHop)} will be added to proposableAccounts`);

        // Return a trigger output to ensure process() continues
        // This ensures the AUTO-PROPOSE logic runs to process the payment
        const firstValidator = entityState.config.validators[0];
        if (firstValidator) {
          outputs.push({
            entityId: entityState.entityId,
            signerId: firstValidator,
            entityTxs: [] // Empty transaction array - just triggers processing
          });
          console.log(`ðŸ’¸ Added processing trigger: outputs.length=${outputs.length}`);
        }
        console.log(`ðŸ’¸ DIRECT-PAYMENT COMPLETE: mempoolOps=${mempoolOps.length}, outputs=${outputs.length}`);
        console.log(`ðŸ’¸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
      }

      return { newState, outputs, mempoolOps };
    }

    if (entityTx.type === 'deposit_collateral') {
      const { handleDepositCollateral } = await import('./handlers/deposit-collateral');
      return await handleDepositCollateral(entityState, entityTx);
    }

    if (entityTx.type === 'reserve_to_reserve') {
      const { handleReserveToReserve } = await import('./handlers/reserve-to-reserve');
      return await handleReserveToReserve(entityState, entityTx);
    }

    if (entityTx.type === 'j_broadcast') {
      const { handleJBroadcast } = await import('./handlers/j-broadcast');
      const batch = entityState.jBatchState?.batch;
      if (batch) {
        console.log(`ðŸ” APPLY j_broadcast: ${entityState.entityId.slice(-4)} batch r2r=${batch.reserveToReserve.length}, r2c=${batch.reserveToCollateral.length}, settlements=${batch.settlements.length}, starts=${batch.disputeStarts.length}, finals=${batch.disputeFinalizations.length}`);
      } else {
        console.log(`ðŸ” APPLY j_broadcast: ${entityState.entityId.slice(-4)} has no jBatchState`);
      }
      const result = await handleJBroadcast(entityState, entityTx, env);
      // j_broadcast returns jOutputs to queue to J-mempool
      return result;
    }

    if (entityTx.type === 'mintReserves') {
      const { handleMintReserves } = await import('./handlers/mint-reserves');
      return await handleMintReserves(entityState, entityTx);
    }

    if (entityTx.type === 'createSettlement') {
      const { handleCreateSettlement } = await import('./handlers/create-settlement');
      return await handleCreateSettlement(entityState, entityTx);
    }

    if (entityTx.type === 'extendCredit') {
      console.log(`ðŸ’³ EXTEND-CREDIT: ${entityState.entityId.slice(-4)} extending credit to ${entityTx.data.counterpartyEntityId.slice(-4)}`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];
      const mempoolOps: MempoolOp[] = [];
      const { counterpartyEntityId, tokenId, amount } = entityTx.data;

      // Get account machine (use canonical key)
      // Account keyed by counterparty ID
      const accountMachine = newState.accounts.get(counterpartyEntityId);
      if (!accountMachine) {
        console.error(`âŒ No account with ${counterpartyEntityId.slice(-4)} for credit extension`);
        return { newState: entityState, outputs: [] };
      }

      // Determine canonical side - credit limit I'm setting for my COUNTERPARTY to use
      // leftCreditLimit = credit extended by RIGHT entity to LEFT entity
      // rightCreditLimit = credit extended by LEFT entity to RIGHT entity
      const counterpartyIsLeft = counterpartyEntityId < entityState.entityId;
      const side = counterpartyIsLeft ? 'left' : 'right';

      // Create set_credit_limit account transaction
      const accountTx: AccountTx = {
        type: 'set_credit_limit',
        data: {
          tokenId,
          amount,
          side: side as 'left' | 'right',
        },
      };

      // Pure: return mempoolOp instead of mutating directly
      mempoolOps.push({ accountId: counterpartyEntityId, tx: accountTx });
      console.log(`ðŸ’³ Added set_credit_limit to mempoolOps for account with ${counterpartyEntityId.slice(-4)}`);
      console.log(`ðŸ’³ Setting ${side}CreditLimit=${amount} (counterparty is ${side}) for token ${tokenId}`);

      addMessage(newState, `ðŸ’³ Extended credit of ${amount} to ${counterpartyEntityId.slice(-4)}`);

      // Trigger processing (same pattern as directPayment)
      const firstValidator = entityState.config.validators[0];
      if (firstValidator) {
        outputs.push({
          entityId: entityState.entityId,
          signerId: firstValidator,
          entityTxs: [] // Empty - triggers processing
        });
      }

      console.log(`ðŸ’¸ DIRECT-PAYMENT RETURN: outputs.length=${outputs.length}`);

      return { newState, outputs, mempoolOps };
    }

    // === SWAP ENTITY HANDLERS ===
    if (entityTx.type === 'placeSwapOffer') {
      console.log(`ðŸ“Š PLACE-SWAP-OFFER: ${entityState.entityId.slice(-4)} placing offer with ${entityTx.data.counterpartyEntityId.slice(-4)}`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];
      const mempoolOps: MempoolOp[] = [];
      const { counterpartyEntityId, offerId, giveTokenId, giveAmount, wantTokenId, wantAmount, minFillRatio } = entityTx.data;

      // Use canonical key for account lookup
      // Account keyed by counterparty ID
      const accountMachine = newState.accounts.get(counterpartyEntityId);
      if (!accountMachine) {
        console.error(`âŒ No account with ${counterpartyEntityId.slice(-4)} for swap offer`);
        return { newState: entityState, outputs: [] };
      }

      const accountTx: AccountTx = {
        type: 'swap_offer',
        data: { offerId, giveTokenId, giveAmount, wantTokenId, wantAmount, minFillRatio },
      };

      // Pure: return mempoolOp instead of mutating directly
      mempoolOps.push({ accountId: counterpartyEntityId, tx: accountTx });
      console.log(`ðŸ“Š Added swap_offer to mempoolOps for account with ${counterpartyEntityId.slice(-4)}`);

      // AUDIT FIX (CRITICAL-6): Use namespaced key to prevent offerId collisions across accounts
      // Key format: accountId:offerId (same as orderbook uses)
      const swapBookKey = `${counterpartyEntityId}:${offerId}`;
      newState.swapBook.set(swapBookKey, {
        offerId,
        accountId: counterpartyEntityId,
        giveTokenId,
        giveAmount,
        wantTokenId,
        wantAmount,
        minFillRatio: minFillRatio ?? 0,
        createdAt: BigInt(env.timestamp),
      });

      const firstValidator = entityState.config.validators[0];
      if (firstValidator) {
        outputs.push({ entityId: entityState.entityId, signerId: firstValidator, entityTxs: [] });
      }

      return { newState, outputs, mempoolOps };
    }

    if (entityTx.type === 'resolveSwap') {
      console.log(`ðŸ’± RESOLVE-SWAP: ${entityState.entityId.slice(-4)} resolving offer with ${entityTx.data.counterpartyEntityId.slice(-4)}`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];
      const mempoolOps: MempoolOp[] = [];
      const { counterpartyEntityId, offerId, fillRatio, cancelRemainder } = entityTx.data;

      // Use canonical key for account lookup
      // Account keyed by counterparty ID
      const accountMachine = newState.accounts.get(counterpartyEntityId);
      if (!accountMachine) {
        console.error(`âŒ No account with ${counterpartyEntityId.slice(-4)} for swap resolve`);
        return { newState: entityState, outputs: [] };
      }

      const accountTx: AccountTx = {
        type: 'swap_resolve',
        data: { offerId, fillRatio, cancelRemainder },
      };

      // Pure: return mempoolOp instead of mutating directly (keyed by counterparty)
      mempoolOps.push({ accountId: counterpartyEntityId, tx: accountTx });
      console.log(`ðŸ’± Added swap_resolve to mempoolOps for account with ${counterpartyEntityId.slice(-4)}`);

      const firstValidator = entityState.config.validators[0];
      if (firstValidator) {
        outputs.push({ entityId: entityState.entityId, signerId: firstValidator, entityTxs: [] });
      }

      return { newState, outputs, mempoolOps };
    }

    if (entityTx.type === 'fillSwapOffer') {
      // Alias for swap fill/resolve
      console.log(`ðŸ’± FILL-SWAP-OFFER: ${entityState.entityId.slice(-4)} filling offer`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];
      const mempoolOps: MempoolOp[] = [];
      const { offerId, counterpartyId, fillRatio } = entityTx.data;

      const accountMachine = newState.accounts.get(counterpartyId);
      if (!accountMachine) {
        console.error(`âŒ No account with ${counterpartyId.slice(-4)}`);
        return { newState: entityState, outputs: [] };
      }

      // Create swap_resolve AccountTx
      const accountTx: AccountTx = {
        type: 'swap_resolve',
        data: { offerId, fillRatio, cancelRemainder: false },
      };

      mempoolOps.push({ accountId: counterpartyId, tx: accountTx });

      const firstValidator = entityState.config.validators[0];
      if (firstValidator) {
        outputs.push({ entityId: entityState.entityId, signerId: firstValidator, entityTxs: [] });
      }

      return { newState, outputs, mempoolOps };
    }

    if (entityTx.type === 'cancelSwapOffer' || entityTx.type === 'cancelSwap') {
      console.log(`ðŸ“Š CANCEL-SWAP: ${entityState.entityId.slice(-4)} cancelling offer with ${entityTx.data.counterpartyEntityId.slice(-4)}`);

      const newState = cloneEntityState(entityState);
      const outputs: EntityInput[] = [];
      const mempoolOps: MempoolOp[] = [];
      const { counterpartyEntityId, offerId } = entityTx.data;

      // Use canonical key for account lookup
      // Account keyed by counterparty ID
      const accountMachine = newState.accounts.get(counterpartyEntityId);
      if (!accountMachine) {
        console.error(`âŒ No account with ${counterpartyEntityId.slice(-4)} for swap cancel`);
        return { newState: entityState, outputs: [] };
      }

      const accountTx: AccountTx = {
        type: 'swap_cancel',
        data: { offerId },
      };

      // Pure: return mempoolOp instead of mutating directly
      mempoolOps.push({ accountId: counterpartyEntityId, tx: accountTx });
      console.log(`ðŸ“Š Added swap_cancel to mempoolOps for account with ${counterpartyEntityId.slice(-4)}`);

      // AUDIT FIX (CRITICAL-6): Use namespaced key for swapBook delete
      const swapBookKey = `${counterpartyEntityId}:${offerId}`;
      newState.swapBook.delete(swapBookKey);

      const firstValidator = entityState.config.validators[0];
      if (firstValidator) {
        outputs.push({ entityId: entityState.entityId, signerId: firstValidator, entityTxs: [] });
      }

      return { newState, outputs, mempoolOps };
    }

    if (entityTx.type === 'requestWithdrawal') {
      const { handleRequestWithdrawal } = await import('./handlers/request-withdrawal');
      return { newState: handleRequestWithdrawal(entityState, entityTx), outputs: [] };
    }

    if (entityTx.type === 'settleDiffs') {
      console.log(`ðŸ¦ SETTLE-DIFFS: Processing settlement with ${entityTx.data.counterpartyEntityId}`);

      const newState = cloneEntityState(entityState);
      const { counterpartyEntityId, diffs, description, sig } = entityTx.data;

      // Step 1: Validate invariant for all diffs
      for (const diff of diffs) {
        const sum = diff.leftDiff + diff.rightDiff + diff.collateralDiff;
        if (sum !== 0n) {
          logError("ENTITY_TX", `âŒ INVARIANT-VIOLATION: leftDiff + rightDiff + collateralDiff = ${sum} (must be 0)`);
          throw new Error(`Settlement invariant violation: ${sum} !== 0`);
        }
      }

      // Step 2: Validate account exists (use canonical key)
      // Account keyed by counterparty ID
      if (!newState.accounts.has(settleAccountKey)) {
        logError("ENTITY_TX", `âŒ No account exists with ${formatEntityId(counterpartyEntityId)}`);
        throw new Error(`No account with ${counterpartyEntityId}`);
      }

      // Step 3: Determine canonical left/right order
      const isLeft = isLeftEntity(entityState.entityId, counterpartyEntityId);
      const leftEntity = isLeft ? entityState.entityId : counterpartyEntityId;
      const rightEntity = isLeft ? counterpartyEntityId : entityState.entityId;

      console.log(`ðŸ¦ Canonical order: left=${leftEntity.slice(0,10)}..., right=${rightEntity.slice(0,10)}...`);
      console.log(`ðŸ¦ We are: ${isLeft ? 'LEFT' : 'RIGHT'}`);

      // Step 4: Get jurisdiction config
      const jurisdiction = entityState.config.jurisdiction;
      if (!jurisdiction) {
        throw new Error('No jurisdiction configured for this entity');
      }

      // Step 5: Convert diffs to contract format (keep as bigint - ethers handles conversion)
      const contractDiffs = diffs.map(d => ({
        tokenId: d.tokenId,
        leftDiff: d.leftDiff,
        rightDiff: d.rightDiff,
        collateralDiff: d.collateralDiff,
        ondeltaDiff: d.ondeltaDiff || 0n,
      }));

      console.log(`ðŸ¦ Calling submitSettle with diffs:`, safeStringify(contractDiffs, 2));

      // Step 6: Call Depository.settle() - fire and forget (j-watcher handles result)
      if (!sig || sig === '0x') {
        throw new Error(`Settlement ${entityState.entityId.slice(-4)}â†”${counterpartyEntityId.slice(-4)} missing hanko signature`);
      }

      try {
        const result = await submitSettle(jurisdiction, leftEntity, rightEntity, contractDiffs, [], [], sig);
        console.log(`âœ… Settlement transaction sent: ${result.txHash}`);

        // Add message to chat
        addMessage(newState,
          `ðŸ¦ ${description || 'Settlement'} tx: ${result.txHash.slice(0, 10)}... (block ${result.blockNumber})`
        );
      } catch (error) {
        logError("ENTITY_TX", `âŒ Settlement transaction failed:`, error);
        addMessage(newState, `âŒ Settlement failed: ${(error as Error).message}`);
        throw error; // Re-throw to trigger outer catch
      }

      return { newState, outputs: [] };
    }

    // === DISPUTES ===
    if (entityTx.type === 'disputeStart') {
      const { handleDisputeStart } = await import('./handlers/dispute');
      return await handleDisputeStart(entityState, entityTx, env);
    }

    if (entityTx.type === 'disputeFinalize') {
      const { handleDisputeFinalize } = await import('./handlers/dispute');
      return await handleDisputeFinalize(entityState, entityTx, env);
    }

    console.warn(`âš ï¸ Unhandled EntityTx type: ${entityTx.type}`);
    return { newState: entityState, outputs: [], jOutputs: [] };
  } catch (error) {
    log.error(`âŒ Transaction execution error: ${error}`);
    return { newState: entityState, outputs: [], jOutputs: [] }; // Return unchanged state on error
  }
};


//runtime/entity-tx/validation.ts (37 lines)
// Security validation helpers: validateNonce, validateMessage
import { log } from '../utils';

export const validateNonce = (currentNonce: number, expectedNonce: number, from: string): boolean => {
  try {
    if (expectedNonce !== currentNonce + 1) {
      log.error(`âŒ Invalid nonce from ${from}: expected ${currentNonce + 1}, got ${expectedNonce}`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`âŒ Nonce validation error: ${error}`);
    return false;
  }
};

export const validateMessage = (message: string): boolean => {
  try {
    if (typeof message !== 'string') {
      log.error(`âŒ Message must be string, got: ${typeof message}`);
      return false;
    }
    if (message.length > 1000) {
      log.error(`âŒ Message too long: ${message.length} > 1000 chars`);
      return false;
    }
    if (message.length === 0) {
      log.error(`âŒ Empty message not allowed`);
      return false;
    }
    return true;
  } catch (error) {
    log.error(`âŒ Message validation error: ${error}`);
    return false;
  }
};


//runtime/entity-tx/financial.ts (33 lines)
import { AssetBalance } from '../types';

// Financial helpers: formatAssetAmount, addToReserves, subtractFromReserves
// Use unified financial utilities with ethers.js
export { formatAssetAmount } from '../financial-utils';

export const addToReserves = (
  reserves: Map<string, AssetBalance>,
  symbol: string,
  amount: bigint,
  _decimals: number,
  _contractAddress?: string,
): void => {
  const existing = reserves.get(symbol);
  if (existing) {
    existing.amount += amount;
  } else {
    reserves.set(symbol, { amount });
  }
};

export const subtractFromReserves = (reserves: Map<string, AssetBalance>, symbol: string, amount: bigint): boolean => {
  const existing = reserves.get(symbol);
  if (!existing || existing.amount < amount) {
    return false; // Insufficient balance
  }
  existing.amount -= amount;
  if (existing.amount === 0n) {
    reserves.delete(symbol);
  }
  return true;
};


//runtime/entity-tx/proposals.ts (35 lines)
import { EntityState, Proposal, ProposalAction } from '../types';
import { createHash, DEBUG } from '../utils';
import { safeStringify } from '../serialization-utils';

export const generateProposalId = (action: ProposalAction, proposer: string, entityState: EntityState): string => {
  const proposalData = safeStringify({
    type: action.type,
    data: action.data,
    proposer,
    timestamp: entityState.timestamp,
  });

  const hash = createHash('sha256').update(proposalData).digest('hex');
  return `prop_${hash.slice(0, 12)}`;
};

export const executeProposal = (entityState: EntityState, proposal: Proposal): EntityState => {
  if (proposal.action.type === 'collective_message') {
    const message = `[COLLECTIVE] ${proposal.action.data.message}`;
    if (DEBUG) console.log(`    ðŸ›ï¸  Executing collective proposal: "${message}"`);

    const newMessages = [...entityState.messages, message];

    if (newMessages.length > 10) {
      newMessages.shift();
    }

    return {
      ...entityState,
      messages: newMessages,
    };
  }
  return entityState;
};


//runtime/entity-tx/j-events.ts (793 lines)
import { EntityState, Delta, JBlockObservation, JBlockFinalized, JurisdictionEvent, Env } from '../types';
import { DEBUG } from '../utils';
import { cloneEntityState, addMessage, canonicalAccountKey } from '../state-helpers';
import { getTokenInfo, getDefaultCreditLimit } from '../account-utils';
import { isLeftEntity } from '../entity-id-utils';
import { safeStringify } from '../serialization-utils';
import { CANONICAL_J_EVENTS } from '../j-event-watcher';

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * J-EVENT HANDLERS (Single Source of Truth - must match j-event-watcher.ts)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * Canonical J-Events (update entity state):
 * - ReserveUpdated  â†’ entity.reserves[tokenId] = newBalance
 * - AccountSettled  â†’ entity.accounts[counterparty].deltas[tokenId] = { collateral, ondelta }
 *
 * Future J-Events (when added to Solidity):
 * - InsuranceRegistered, InsuranceClaimed, InsuranceExpired
 * - DebtCreated, DebtEnforced
 *
 * Design: One event = One state change. No redundant handlers.
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

/**
 * Jurisdiction event transaction data structure
 * These events come from blockchain watchers observing on-chain activity
 */
export interface JEventEntityTxData {
  from: string;  // Signer ID that observed the event
  event: {
    type: string;  // Event name (e.g., "ReserveUpdated", "AccountSettled")
    data: Record<string, unknown>;  // Event-specific data from blockchain
  };
  events?: Array<{
    type: string;  // Event name (e.g., "ReserveUpdated", "AccountSettled")
    data: Record<string, unknown>;
  }>;
  observedAt: number;  // Timestamp when event was observed (ms)
  blockNumber: number;  // Blockchain block number where event occurred
  blockHash: string;    // Block hash for JBlock consensus
  transactionHash: string;  // Blockchain transaction hash
}

const getTokenSymbol = (tokenId: number): string => {
  return getTokenInfo(tokenId).symbol;
};

const getTokenDecimals = (tokenId: number): number => {
  return getTokenInfo(tokenId).decimals;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// J-EVENT HANDLER: Entry point for jurisdiction (blockchain) events
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// When a signer observes a blockchain event (via j-event-watcher.ts), it submits
// a j_event EntityTx. This handler:
//
// 1. Creates a JBlockObservation from the incoming event
// 2. Adds it to the entity's pending observations
// 3. Attempts to finalize j-blocks (if threshold met)
// 4. Returns updated state
//
// The actual event application happens in applyFinalizedJEvent() ONLY after
// consensus is reached. This prevents a single signer from injecting fake events.
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Handle incoming j-event from a signer.
 *
 * Converts the event to an observation and attempts j-block finalization.
 * Events are only applied to state after threshold agreement.
 *
 * @param entityState - Current entity state
 * @param entityTxData - J-event data from the observing signer
 * @param env - Runtime environment
 * @returns Updated state (may include finalized events if threshold met)
 */
export const handleJEvent = async (entityState: EntityState, entityTxData: JEventEntityTxData, env: Env): Promise<{ newState: EntityState; mempoolOps: Array<{ accountId: string; tx: any }> }> => {
  const { from: signerId, observedAt, blockNumber, blockHash } = entityTxData;
  // j-watcher now sends batched events - use 'events' array, fallback to single 'event'
  const rawEvents = (entityTxData as any).events || [entityTxData.event];

  const entityShort = entityState.entityId.slice(-4);
  console.log(`ðŸ›ï¸ [2/3] E-MACHINE: ${entityShort} â† ${rawEvents.length} events (block ${blockNumber})`);

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Skip already-finalized blocks
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Check if this block height was already finalized (prevents re-applying events)
  const alreadyFinalized = entityState.jBlockChain.some(b => b.jHeight === blockNumber);
  if (alreadyFinalized) {
    console.log(`   â­ï¸ SKIP: block ${blockNumber} already finalized`);
    return { newState: entityState, mempoolOps: [] };
  }

  // Skip blocks at or below lastFinalizedJHeight (monotonic progress only)
  // Note: The == case is already caught by alreadyFinalized check above,
  // but we use <= here for explicit monotonic enforcement
  // TODO: For multi-signer production, add appliedJBlockHashes: Set<string>
  // to track exact block hashes and reject conflicting observations
  if (blockNumber <= entityState.lastFinalizedJHeight) {
    console.log(`   â­ï¸ SKIP: stale block (${blockNumber} <= finalized ${entityState.lastFinalizedJHeight})`);
    return { newState: entityState, mempoolOps: [] };
  }

  // Convert raw events to JurisdictionEvent format
  const jEvents: JurisdictionEvent[] = rawEvents.map((e: any) => ({
    type: e.type as any,
    data: e.data as any,
    blockNumber,
    blockHash,
  }));

  // Clone state and create observation with ALL events from this batch
  let newEntityState = cloneEntityState(entityState);

  const observation: JBlockObservation = {
    signerId,
    jHeight: blockNumber,
    jBlockHash: blockHash,
    events: jEvents,
    observedAt,
  };

  newEntityState.jBlockObservations.push(observation);
  console.log(`   ðŸ“ Observation from ${signerId}: ${jEvents.length} events for block ${blockNumber}`);

  // Try to finalize - with batching, single-signer entities finalize immediately
  // with ALL events from the block (no more race condition)
  const { newState, mempoolOps } = await tryFinalizeJBlocks(newEntityState, entityState.config.threshold, env);
  newEntityState = newState;

  // DEBUG: Dump account mempools after j-event processing
  for (const [cpId, account] of newEntityState.accounts) {
    if (account.mempool.length > 0 || account.leftJObservations.length > 0 || account.rightJObservations.length > 0) {
      console.log(`ðŸ” AFTER-J-EVENT: Account ${cpId.slice(-4)} mempool=${account.mempool.length} txs:`, account.mempool.map((tx: any) => tx.type));
      console.log(`ðŸ” AFTER-J-EVENT: leftJObs=${account.leftJObservations?.length || 0}, rightJObs=${account.rightJObservations?.length || 0}`);
    }
  }

  if (mempoolOps.length > 0) {
    console.log(`   ðŸ“¦ handleJEvent: Returning ${mempoolOps.length} mempoolOps for bilateral consensus`);
  }

  // Return both newState and mempoolOps
  return { newState: newEntityState, mempoolOps };
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// BILATERAL J-EVENT CONSENSUS: 2-of-2 agreement on AccountSettled events
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/**
 * Finalize AccountSettled when BOTH entities agree (2-of-2).
 * Called after receiving j_event_claim from counterparty.
 */
export function tryFinalizeAccountJEvents(account: any, counterpartyId: string, env: any): void {
  // Find matching (jHeight, jBlockHash) in left + right observations
  const leftMap = new Map();
  const rightMap = new Map();

  for (const obs of account.leftJObservations) {
    leftMap.set(`${obs.jHeight}:${obs.jBlockHash}`, obs);
  }
  for (const obs of account.rightJObservations) {
    rightMap.set(`${obs.jHeight}:${obs.jBlockHash}`, obs);
  }

  const matches = Array.from(leftMap.keys()).filter(k => rightMap.has(k));

  if (matches.length === 0) {
    console.log(`   ðŸ” BILATERAL: left=${account.leftJObservations.length}, right=${account.rightJObservations.length}, matches=0`);
    return;
  }

  console.log(`   ðŸ¤ BILATERAL-MATCH: ${matches.length} j-blocks agreed!`);

  for (const key of matches) {
    const leftObs = leftMap.get(key)!;
    const jHeight = leftObs.jHeight;

    // Skip already finalized
    if (account.lastFinalizedJHeight >= jHeight) continue;
    if (account.jEventChain.some((b: any) => b.jHeight === jHeight)) continue;

    console.log(`   âœ… BILATERAL-FINALIZE: jHeight=${jHeight}`);

    // Apply events (from left observation - both should be identical)
    for (const event of leftObs.events) {
      if (event.type === 'AccountSettled') {
        const { tokenId, collateral, ondelta } = event.data;
        const tokenIdNum = Number(tokenId);

        let delta = account.deltas.get(tokenIdNum);
        if (!delta) {
          const defaultCreditLimit = getDefaultCreditLimit(tokenIdNum);
          delta = {
            tokenId: tokenIdNum,
            collateral: 0n,
            ondelta: 0n,
            offdelta: 0n,
            leftCreditLimit: defaultCreditLimit,
            rightCreditLimit: defaultCreditLimit,
            leftAllowance: 0n,
            rightAllowance: 0n,
          };
          account.deltas.set(tokenIdNum, delta);
        }

        const oldColl = delta.collateral;
        delta.collateral = BigInt(collateral);
        delta.ondelta = BigInt(ondelta);
        console.log(`   ðŸ’° BILATERAL-APPLIED for ${counterpartyId.slice(-4)}: coll ${oldColl}â†’${delta.collateral}, ondelta=${delta.ondelta}`);
      }
    }

    // Add to jEventChain (replay prevention) - DETERMINISTIC timestamp
    account.jEventChain.push({ jHeight, jBlockHash: leftObs.jBlockHash, events: leftObs.events, finalizedAt: env.timestamp });
    account.lastFinalizedJHeight = Math.max(account.lastFinalizedJHeight, jHeight);
  }

  // Prune finalized
  const finalizedHeights = new Set(matches.map(k => leftMap.get(k)!.jHeight));
  account.leftJObservations = account.leftJObservations.filter((o: any) => !finalizedHeights.has(o.jHeight));
  account.rightJObservations = account.rightJObservations.filter((o: any) => !finalizedHeights.has(o.jHeight));
  console.log(`   ðŸ§¹ Pruned ${finalizedHeights.size} finalized (left=${account.leftJObservations.length}, right=${account.rightJObservations.length} pending)`);
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// J-BLOCK CONSENSUS: Multi-signer agreement on jurisdiction (blockchain) state
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// WHY: Each entity has multiple signers (board members). When the J-machine
// (blockchain) emits events, each signer independently observes them. We need
// threshold agreement before applying events to entity state - this prevents
// a single compromised signer from injecting fake blockchain events.
//
// HOW IT WORKS:
// 1. Each signer watches the blockchain and submits observations of j-blocks
// 2. Observations are grouped by (blockHeight, blockHash) tuple
// 3. When enough signers agree on the same tuple â†’ block is "finalized"
// 4. Finalized events are applied to entity state
// 5. Old observations are pruned
//
// EXAMPLE: Entity with 3 signers, threshold=2
// - Signer A sees block 100 with hash 0xabc... â†’ adds observation
// - Signer B sees block 100 with hash 0xabc... â†’ adds observation
// - Now 2 signers agree â†’ block 100 finalized, events applied
// - Signer C's late observation is ignored (already finalized)
//
// SINGLE-SIGNER FAST PATH: For entities with threshold=1, blocks finalize
// immediately when the single signer submits an observation.
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Check for j-block finalization and apply finalized events.
 *
 * Groups pending observations by (height, hash), checks threshold,
 * and applies events from blocks that reach consensus.
 *
 * @param state - Entity state with pending jBlockObservations
 * @param threshold - Required number of agreeing signers (from entity config)
 * @param env - Runtime environment for deterministic timestamps
 * @returns Updated state with finalized events applied
 */
async function tryFinalizeJBlocks(
  state: EntityState,
  threshold: bigint,
  env: Env
): Promise<{ newState: EntityState; mempoolOps: Array<{ accountId: string; tx: any }> }> {
  const allMempoolOps: Array<{ accountId: string; tx: any }> = [];

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Step 1: Group observations by (height, hash)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Multiple signers may observe the same block - group them together.
  // Key format: "height:hash" e.g. "100:0xabc123..."
  const observationGroups = new Map<string, JBlockObservation[]>();

  for (const obs of state.jBlockObservations) {
    const key = `${obs.jHeight}:${obs.jBlockHash}`;
    if (!observationGroups.has(key)) {
      observationGroups.set(key, []);
    }
    observationGroups.get(key)!.push(obs);
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Step 2: Check each group for threshold agreement
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const finalizedHeights: number[] = [];
  console.log(`   ðŸ“Š OBSERVATION-GROUPS: ${observationGroups.size} groups, keys=[${Array.from(observationGroups.keys()).join(', ')}]`);

  for (const [_key, observations] of observationGroups) {
    // Count UNIQUE signers (ignore duplicate submissions from same signer)
    const uniqueSigners = new Set(observations.map(o => o.signerId));
    const signerCount = uniqueSigners.size;

    // Does this group meet the threshold?
    if (BigInt(signerCount) >= threshold) {
      const jHeight = observations[0].jHeight;
      const jBlockHash = observations[0].jBlockHash;

      // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      // IDEMPOTENCY CHECK: Skip if this block height was already finalized
      // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      // This can happen if:
      // 1. Multiple observation groups exist for same height (different hashes)
      // 2. A previous iteration of this loop already finalized this height
      // 3. Block was finalized in a previous call (caught at handleJEvent entry)
      console.log(`   ðŸ” CHECK-FINALIZE: jHeight=${jHeight}, jBlockChain.length=${state.jBlockChain.length}, heights=[${state.jBlockChain.map(b => b.jHeight).join(',')}]`);
      const alreadyInChain = state.jBlockChain.some(b => b.jHeight === jHeight);
      if (alreadyInChain) {
        console.log(`   â­ï¸ SKIP-FINALIZE: block ${jHeight} already in jBlockChain`);
        continue;
      }

      console.log(`   âœ… J-BLOCK FINALIZED: height=${jHeight} (${signerCount}/${threshold} signers)`);

      // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      // Step 3: Merge events from all observations
      // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      const events = mergeSignerObservations(observations);

      // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      // Step 4: Create finalized block record - DETERMINISTIC timestamp
      // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      const finalized: JBlockFinalized = {
        jHeight,
        jBlockHash,
        events,
        finalizedAt: env.timestamp, // DETERMINISTIC
        signerCount,
      };

      // CRITICAL: Add to jBlockChain BEFORE applying events
      // This prevents duplicate finalization in subsequent loop iterations
      state.jBlockChain.push(finalized);
      state.lastFinalizedJHeight = jHeight;
      finalizedHeights.push(jHeight);
      console.log(`   âœ… Added block ${jHeight} to jBlockChain (length: ${state.jBlockChain.length})`);

      // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      // Step 5: Apply all events from this finalized block
      // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      console.log(`   ðŸ“¦ Applying ${events.length} events from block ${jHeight}`);
      console.log(`      Event types:`, events.map(e => e.type));
      for (const event of events) {
        console.log(`      ðŸ”§ Applying event: ${event.type}`);
        const { newState, mempoolOps } = await applyFinalizedJEvent(state, event, env);
        state = newState;
        allMempoolOps.push(...mempoolOps);
        // applyFinalizedJEvent clones state - ensure jBlockChain preserved
        if (!state.jBlockChain.some(b => b.jHeight === jHeight)) {
          console.log(`   âš ï¸  CLONE LOST jBlockChain - restoring block ${jHeight}`);
          state.jBlockChain.push(finalized);
          state.lastFinalizedJHeight = jHeight;
        }
      }

      console.log(`   ðŸ“¦ Applied ${events.length} events from j-block ${jHeight}`);
    }
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Step 6: Prune ONLY finalized heights
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Only remove observations for heights that were actually finalized.
  // Keep observations for unfinalized heights (even if lower than highest finalized)
  // to allow out-of-order finalization and detect conflicts.
  if (finalizedHeights.length > 0) {
    const finalizedSet = new Set(finalizedHeights);
    state.jBlockObservations = state.jBlockObservations.filter(
      obs => !finalizedSet.has(obs.jHeight)
    );
    console.log(`   ðŸ§¹ Pruned finalized heights [${finalizedHeights.join(',')}] (${state.jBlockObservations.length} pending)`);
  }

  return { newState: state, mempoolOps: allMempoolOps };
}

/**
 * Merge events from multiple signers' observations of the same j-block.
 *
 * In a healthy network, all signers observe identical events for a given block.
 * This function handles edge cases like:
 * - Duplicate submissions from the same signer
 * - Minor ordering differences between signers
 *
 * @param observations - All observations for a specific (height, hash) tuple
 * @returns Deduplicated list of events from that block
 */
function mergeSignerObservations(observations: JBlockObservation[]): JurisdictionEvent[] {
  // Dedup by (eventType + eventData) - all signers should see same events
  const eventMap = new Map<string, JurisdictionEvent>();

  for (const obs of observations) {
    for (const event of obs.events) {
      // Create unique key from event type and data
    const key = `${event.type}:${safeStringify(event.data)}`;
      if (!eventMap.has(key)) {
        eventMap.set(key, event);
      }
    }
  }

  return Array.from(eventMap.values());
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// J-EVENT APPLICATION: Apply finalized blockchain events to entity state
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// This is called ONLY after j-block consensus is reached. At this point we trust
// the event is legitimate (threshold signers agreed on it).
//
// Each event type maps to a specific state change:
// - ReserveUpdated  â†’ entity.reserves[tokenId] = newBalance
// - AccountSettled  â†’ entity.accounts[cp].deltas[tokenId] = {collateral, ondelta}
// - InsuranceXxx    â†’ entity.insuranceLines (future)
// - DebtXxx         â†’ entity.debts (future)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Apply a single finalized j-event to entity state.
 *
 * Called after j-block consensus - the event is trusted at this point.
 * Maps each event type to the appropriate state mutation.
 *
 * @param entityState - Current entity state
 * @param event - Finalized j-event to apply
 * @returns New state with event applied
 */
async function applyFinalizedJEvent(
  entityState: EntityState,
  event: JurisdictionEvent,
  env: Env
): Promise<{ newState: EntityState; mempoolOps: Array<{ accountId: string; tx: any }> }> {
  console.log(`ðŸ”§ðŸ”§ applyFinalizedJEvent: entityId=${entityState.entityId.slice(-4)}, event.type=${event.type}`);

  const entityShort = entityState.entityId.slice(-4);
  const blockNumber = event.blockNumber ?? 0;
  const transactionHash = event.transactionHash || 'unknown';
  const txHashShort = transactionHash.slice(0, 10) + '...';

  // Clone state for mutation
  const newState = cloneEntityState(entityState);
  const mempoolOps: Array<{ accountId: string; tx: any }> = [];

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CANONICAL J-EVENTS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  if (event.type === 'ReserveUpdated') {
    const { entity, tokenId, newBalance } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);
    const decimals = getTokenDecimals(tokenId as number);
    const balanceDisplay = (Number(newBalance) / (10 ** decimals)).toFixed(4);

    if (entity === entityState.entityId) {
      newState.reserves.set(String(tokenId), BigInt(newBalance as string | number | bigint));
      if (DEBUG) console.log(`âœ… Reserve updated: Token ${tokenId} â†’ ${newBalance}`);
    }

    addMessage(newState, `ðŸ“Š RESERVE: ${tokenSymbol} = ${balanceDisplay} | Block ${blockNumber} | Tx ${txHashShort}`);

  } else if (event.type === 'SecretRevealed') {
    const { hashlock, secret } = event.data;
    const hashlockKey = String(hashlock).toLowerCase();
    const route = newState.htlcRoutes.get(hashlockKey);

    if (!route) {
      console.log(`âš ï¸ HTLC: Secret reveal for unknown hashlock ${hashlockKey.slice(0, 16)}...`);
      return { newState, mempoolOps };
    }

    if (route.secret) {
      console.log(`âœ… HTLC: Secret already stored for hashlock ${hashlockKey.slice(0, 16)}...`);
      addMessage(newState, `ðŸ”“ HTLC reveal observed: ${hashlockKey.slice(0, 10)}... | Block ${blockNumber}`);
      return { newState, mempoolOps };
    }

    route.secret = String(secret);

    if (route.pendingFee) {
      newState.htlcFeesEarned = (newState.htlcFeesEarned || 0n) + route.pendingFee;
      console.log(`ðŸ’° HTLC: Fee earned on on-chain reveal: ${route.pendingFee} (total: ${newState.htlcFeesEarned})`);
      route.pendingFee = undefined;
    }

    if (route.outboundLockId) {
      newState.lockBook.delete(route.outboundLockId);
    }
    if (route.inboundLockId) {
      newState.lockBook.delete(route.inboundLockId);
    }

    if (route.inboundEntity && route.inboundLockId) {
      mempoolOps.push({
        accountId: route.inboundEntity,
        tx: {
          type: 'htlc_reveal',
          data: {
            lockId: route.inboundLockId,
            secret: String(secret),
          }
        }
      });
      console.log(`â¬…ï¸ HTLC: On-chain secret propagated to ${route.inboundEntity.slice(-4)}`);
    } else {
      console.log(`âœ… HTLC: On-chain reveal complete (no inbound hop)`);
    }

    addMessage(newState, `ðŸ”“ HTLC reveal observed: ${hashlockKey.slice(0, 10)}... | Block ${blockNumber}`);

  } else if (event.type === 'AccountSettled') {
    // Universal settlement event (covers R2C, C2R, settle, rebalance)
    const { counterpartyEntityId, tokenId, ownReserve, collateral, ondelta } = event.data;
    const tokenIdNum = Number(tokenId);
    const cpShort = (counterpartyEntityId as string).slice(-4);
    const tokenSymbol = getTokenSymbol(tokenIdNum);
    const decimals = getTokenDecimals(tokenIdNum);

    // Update own reserves (entity-level, unilateral OK)
    if (ownReserve) {
      newState.reserves.set(String(tokenId), BigInt(ownReserve as string | number | bigint));
    }

    // BILATERAL J-EVENT CONSENSUS: Need 2-of-2 agreement before applying to account
    // Use canonical key for account lookup
    // Account keyed by counterparty ID
    const account = newState.accounts.get(counterpartyEntityId as string);
    if (!account) {
      console.warn(`   âš ï¸ No account for ${cpShort}`);
      return newState;
    }

    // Initialize consensus fields
    if (!account.leftJObservations) account.leftJObservations = [];
    if (!account.rightJObservations) account.rightJObservations = [];
    if (!account.jEventChain) account.jEventChain = [];
    if (account.lastFinalizedJHeight === undefined) account.lastFinalizedJHeight = 0;

    const isLeft = isLeftEntity(entityState.entityId, counterpartyEntityId as string);
    const jHeight = event.blockNumber ?? blockNumber;
    const jBlockHash = event.blockHash || '';

    // Store OWN observation
    const obs = { jHeight, jBlockHash, events: [event], observedAt: entityState.timestamp || 0 };
    if (isLeft) {
      account.leftJObservations.push(obs);
      console.log(`   ðŸ“ LEFT obs: jHeight=${jHeight}`);
    } else {
      account.rightJObservations.push(obs);
      console.log(`   ðŸ“ RIGHT obs: jHeight=${jHeight}`);
    }

    // Add j_event_claim via mempoolOps (auto-triggers proposableAccounts + account frame)
    // Account keyed by counterparty ID
    // CRITICAL: Deep-copy event to prevent mutation issues (frame fullDeltaStates added later)
    const eventCopy = JSON.parse(safeStringify(event));
    mempoolOps.push({
      accountId: counterpartyEntityId as string,
      tx: { type: 'j_event_claim', data: { jHeight, jBlockHash, events: [eventCopy], observedAt: obs.observedAt } },
    });
    console.log(`   ðŸ“® j_event_claim â†’ mempoolOps[${mempoolOps.length}] (will auto-propose frame)`);

    const collDisplay = (Number(collateral) / (10 ** decimals)).toFixed(4);
    addMessage(newState, `âš–ï¸ OBSERVED: ${tokenSymbol} ${cpShort} | coll=${collDisplay} | j-block ${blockNumber} (awaiting 2-of-2)`);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // FUTURE J-EVENTS (when added to Solidity - handlers ready)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  } else if (event.type === 'InsuranceRegistered') {
    const { insured, insurer, tokenId, limit, expiresAt } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);
    const decimals = getTokenDecimals(tokenId as number);
    const limitDisplay = (Number(limit) / (10 ** decimals)).toFixed(2);

    if (!newState.insuranceLines) {
      newState.insuranceLines = [];
    }

    if (insured === entityState.entityId) {
      newState.insuranceLines.push({
        insurer: insurer as string,
        tokenId: tokenId as number,
        remaining: BigInt(limit as string | number | bigint),
        expiresAt: BigInt(expiresAt as string | number | bigint),
      });
    }

    addMessage(newState, `ðŸ›¡ï¸ INSURANCE: ${(insurer as string).slice(-8)} covers ${limitDisplay} ${tokenSymbol} | Block ${blockNumber}`);

  } else if (event.type === 'InsuranceClaimed') {
    const { insured, insurer, creditor, tokenId, amount } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);
    const decimals = getTokenDecimals(tokenId as number);
    const amountDisplay = (Number(amount) / (10 ** decimals)).toFixed(4);

    if (insured === entityState.entityId && newState.insuranceLines) {
      const line = newState.insuranceLines.find(
        l => l.insurer === insurer && l.tokenId === tokenId
      );
      if (line) {
        line.remaining -= BigInt(amount as string | number | bigint);
      }
    }

    addMessage(newState, `ðŸ’¸ INSURANCE CLAIMED: ${amountDisplay} ${tokenSymbol} paid to ${(creditor as string).slice(-8)} | Block ${blockNumber}`);

  } else if (event.type === 'InsuranceExpired') {
    const { insured, insurer, tokenId } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);

    addMessage(newState, `â° INSURANCE EXPIRED: ${(insurer as string).slice(-8)} â†’ ${(insured as string).slice(-8)} ${tokenSymbol} | Block ${blockNumber}`);

  } else if (event.type === 'DebtCreated') {
    const { debtor, creditor, tokenId, amount, debtIndex } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);
    const decimals = getTokenDecimals(tokenId as number);
    const amountDisplay = (Number(amount) / (10 ** decimals)).toFixed(4);

    if (!newState.debts) {
      newState.debts = [];
    }

    if (debtor === entityState.entityId) {
      newState.debts.push({
        creditor: creditor as string,
        tokenId: tokenId as number,
        amount: BigInt(amount as string | number | bigint),
        index: debtIndex as number,
      });
    }

    addMessage(newState, `ðŸ”´ DEBT: ${(debtor as string).slice(-8)} owes ${amountDisplay} ${tokenSymbol} to ${(creditor as string).slice(-8)} | Block ${blockNumber}`);

  } else if (event.type === 'DebtEnforced') {
    const { debtor, creditor, tokenId, amountPaid, remainingAmount, newDebtIndex } = event.data;
    const tokenSymbol = getTokenSymbol(tokenId as number);
    const decimals = getTokenDecimals(tokenId as number);
    const paidDisplay = (Number(amountPaid) / (10 ** decimals)).toFixed(4);

    if (debtor === entityState.entityId && newState.debts) {
      const debt = newState.debts.find(
        d => d.creditor === creditor && d.tokenId === tokenId
      );
      if (debt) {
        debt.amount = BigInt(remainingAmount as string | number | bigint);
        debt.index = newDebtIndex as number;
      }
    }

    addMessage(newState, `âœ… DEBT PAID: ${paidDisplay} ${tokenSymbol} to ${(creditor as string).slice(-8)} | Block ${blockNumber}`);

  } else if (event.type === 'DisputeStarted') {
    console.log(`ðŸ” DISPUTE-EVENT HANDLER: entityId=${newState.entityId.slice(-4)}`);

    // Dispute started on-chain - store dispute state from event
    const { sender, counterentity, disputeNonce, proofbodyHash } = event.data;
    const normalizeId = (id: string) => String(id).toLowerCase();
    const senderStr = normalizeId(sender as string);
    const counterentityStr = normalizeId(counterentity as string);
    const entityIdNorm = normalizeId(newState.entityId);

    // Find which account this affects (we are either sender or counterentity)
    const candidateCounterpartyId = senderStr === entityIdNorm ? counterentityStr : senderStr;
    let counterpartyId = candidateCounterpartyId;
    let account = newState.accounts.get(counterpartyId);
    if (!account) {
      for (const [key, value] of newState.accounts.entries()) {
        if (normalizeId(key) === candidateCounterpartyId) {
          counterpartyId = key;
          account = value;
          break;
        }
      }
    }

    if (account) {
      // Query on-chain for timeout
      const browserVM = env.browserVM || (await import('../evm')).getBrowserVMInstance();
      if (!browserVM) {
        console.warn(`âš ï¸ DisputeStarted: No browserVM to query timeout`);
        return { newState, mempoolOps };
      }

      const accountInfo = await browserVM.getAccountInfo(newState.entityId, counterpartyId);

      const weAreStarter = senderStr === entityIdNorm;
      const hasCounterpartySig = Boolean(account.counterpartyDisputeProofHanko);
      let initialCooperativeNonce = account.proofHeader.cooperativeNonce;
      let nonceSource = 'proofHeader';
      const mappedNonce = account.disputeProofNoncesByHash?.[String(proofbodyHash)];
      if (mappedNonce !== undefined) {
        initialCooperativeNonce = mappedNonce;
        nonceSource = 'hashMap';
      } else if (weAreStarter) {
        if (account.counterpartyDisputeProofCooperativeNonce !== undefined) {
          initialCooperativeNonce = account.counterpartyDisputeProofCooperativeNonce;
          nonceSource = 'counterpartySig';
        } else if (hasCounterpartySig && account.ackedTransitions > 0) {
          initialCooperativeNonce = account.ackedTransitions - 1;
          nonceSource = 'ackedTransitions-1';
        }
      } else {
        if (account.currentDisputeProofCooperativeNonce !== undefined) {
          initialCooperativeNonce = account.currentDisputeProofCooperativeNonce;
          nonceSource = 'currentSig';
        } else if (account.ackedTransitions > 0) {
          initialCooperativeNonce = account.ackedTransitions - 1;
          nonceSource = 'ackedTransitions-1';
        }
      }
      console.log(`   DEBUG DisputeStarted: starter=${weAreStarter}, source=${nonceSource}, ackedTransitions=${account.ackedTransitions}, proofHeader.cooperativeNonce=${account.proofHeader.cooperativeNonce}, initialCooperativeNonce=${initialCooperativeNonce}`);

      // Store dispute state from event + on-chain (source of truth)
      account.activeDispute = {
        startedByLeft: senderStr < counterentityStr,
        initialProofbodyHash: String(proofbodyHash),  // From event (committed on-chain)
        initialDisputeNonce: Number(disputeNonce),
        disputeTimeout: Number(accountInfo.disputeTimeout),  // From on-chain
        initialCooperativeNonce,  // Nonce PASSED to disputeStart (for hash match)
        onChainCooperativeNonce: Number(accountInfo.cooperativeNonce),  // May differ
        initialArguments: event.data.initialArguments || '0x',
      };

      // ASSERTION: Our local proof hash should match on-chain committed hash
      const { buildAccountProofBody } = await import('../proof-builder');
      const localProof = buildAccountProofBody(account);
      if (localProof.proofBodyHash !== account.activeDispute.initialProofbodyHash) {
        console.error(`âŒ CONSENSUS DIVERGENCE: Local proofBodyHash != on-chain`);
        console.error(`   Local: ${localProof.proofBodyHash}`);
        console.error(`   On-chain: ${account.activeDispute.initialProofbodyHash}`);
        console.error(`   This means bilateral state diverged - CRITICAL BUG!`);
        // Continue but log for audit
      } else {
        console.log(`âœ… Proof hash verified: local matches on-chain`);
      }

      addMessage(newState, `âš”ï¸ DISPUTE ${weAreStarter ? 'STARTED' : 'vs us'} with ${counterpartyId.slice(-4)}, timeout: block ${account.activeDispute.disputeTimeout}`);
      console.log(`âš”ï¸ activeDispute stored: hash=${account.activeDispute.initialProofbodyHash.slice(0,10)}..., timeout=${account.activeDispute.disputeTimeout}`);
    } else {
      console.warn(`âš ï¸ DisputeStarted: account ${candidateCounterpartyId.slice(-4)} not found for entity ${entityIdNorm.slice(-4)}`);
    }

  } else if (event.type === 'DisputeFinalized') {
    console.log(`ðŸ” DISPUTE-FINALIZED HANDLER: entityId=${newState.entityId.slice(-4)}`);

    const { sender, counterentity, initialDisputeNonce, initialProofbodyHash } = event.data;
    const normalizeId = (id: string) => String(id).toLowerCase();
    const senderStr = normalizeId(sender as string);
    const counterentityStr = normalizeId(counterentity as string);
    const entityIdNorm = normalizeId(newState.entityId);

    const candidateCounterpartyId = senderStr === entityIdNorm ? counterentityStr : senderStr;
    let counterpartyId = candidateCounterpartyId;
    let account = newState.accounts.get(counterpartyId);
    if (!account) {
      for (const [key, value] of newState.accounts.entries()) {
        if (normalizeId(key) === candidateCounterpartyId) {
          counterpartyId = key;
          account = value;
          break;
        }
      }
    }

    if (account) {
      if (account.activeDispute) {
        account.activeDispute = undefined;
        addMessage(newState, `âœ… DISPUTE FINALIZED with ${counterpartyId.slice(-4)} (nonce ${Number(initialDisputeNonce)})`);
        console.log(`âœ… activeDispute cleared for ${counterpartyId.slice(-4)} (proof=${String(initialProofbodyHash).slice(0, 10)}...)`);
      } else {
        console.warn(`âš ï¸ DisputeFinalized: No activeDispute for ${counterpartyId.slice(-4)}`);
      }
    } else {
      console.warn(`âš ï¸ DisputeFinalized: account ${candidateCounterpartyId.slice(-4)} not found for entity ${entityIdNorm.slice(-4)}`);
    }

  } else {
    // Unknown event - log but don't fail
    addMessage(newState, `âš ï¸ Unknown j-event: ${event.type} | Block ${blockNumber}`);
    console.warn(`âš ï¸ Unknown j-event type: ${event.type}. Canonical events: ${CANONICAL_J_EVENTS.join(', ')}`);
  }

  return { newState, mempoolOps };
}


//runtime/entity-tx/handlers/account.ts (872 lines)
import { AccountInput, AccountTx, EntityState, Env, EntityInput, EntityTx } from '../../types';
import { handleAccountInput as processAccountInput } from '../../account-consensus';
import { cloneEntityState, addMessage, addMessages, canonicalAccountKey, getAccountPerspective, emitScopedEvents, resolveEntityProposerId } from '../../state-helpers';
import { applyCommand, createBook, canonicalPair, deriveSide, type BookState, type OrderbookExtState } from '../../orderbook';
import { HTLC } from '../../constants';
import { formatEntityId, HEAVY_LOGS } from '../../utils';
import { isLeftEntity } from '../../entity-id-utils';
import { batchAddRevealSecret, initJBatch } from '../../j-batch';
import { getDeltaTransformerAddress } from '../../proof-builder';

// === PURE EVENT TYPES ===
// Events returned by handlers, applied by entity orchestrator

export interface MempoolOp {
  accountId: string;
  tx: AccountTx;
}

export interface SwapOfferEvent {
  offerId: string;
  makerIsLeft: boolean;     // Simple boolean (account-level context)
  fromEntity: string;       // Account pair (left entity)
  toEntity: string;         // Account pair (right entity)
  accountId?: string;       // Added by entity handler (Hub's Map key for this account)
  giveTokenId: number;
  giveAmount: bigint;
  wantTokenId: number;
  wantAmount: bigint;
  minFillRatio: number;
}

export interface SwapCancelEvent {
  offerId: string;
  accountId: string;
}

export interface MatchResult {
  mempoolOps: MempoolOp[];       // swap_resolve txs to push
  bookUpdates: {                 // orderbook state mutations
    pairId: string;
    book: BookState;
  }[];
}

export interface AccountHandlerResult {
  newState: EntityState;
  outputs: EntityInput[];
  // Pure events for entity-level orchestration:
  mempoolOps: MempoolOp[];
  swapOffersCreated: SwapOfferEvent[];
  swapOffersCancelled: SwapCancelEvent[];
}

export async function handleAccountInput(state: EntityState, input: AccountInput, env: Env): Promise<AccountHandlerResult> {
  console.log(`ðŸš€ APPLY accountInput: ${input.fromEntityId.slice(-4)} â†’ ${input.toEntityId.slice(-4)}`);
  console.log(`ðŸš€ APPLY accountInput details: height=${input.height}, hasNewFrame=${!!input.newAccountFrame}, hasPrevHanko=${!!input.prevHanko}, counter=${input.counter}`);

  // CRITICAL: Don't clone here - state already cloned at entity level (applyEntityTx)
  // Cloning here causes ackedTransitions updates to be lost between sequential messages
  const newState: EntityState = state;  // Use state directly
  const outputs: EntityInput[] = [];

  // Collect events for entity-level orchestration (pure - no direct mempool mutation)
  const mempoolOps: MempoolOp[] = [];
  const allSwapOffersCreated: SwapOfferEvent[] = [];
  const allSwapOffersCancelled: SwapCancelEvent[] = [];

  // Get or create account machine (KEY: counterparty ID for simpler lookups)
  // AccountMachine still uses canonical left/right internally
  const counterpartyId = input.fromEntityId;
  let accountMachine = newState.accounts.get(counterpartyId);
  let isNewAccount = false;

  if (!accountMachine) {
    isNewAccount = true;
    console.log(`ðŸ’³ Creating new account machine for ${counterpartyId.slice(-4)} (counterparty: ${counterpartyId.slice(-4)})`);

    // CONSENSUS FIX: Start with empty deltas (Channel.ts pattern)
    const initialDeltas = new Map();

    // CANONICAL: Sort entities (left < right) for AccountMachine internals (like Channel.ts)
    const leftEntity = isLeftEntity(state.entityId, counterpartyId) ? state.entityId : counterpartyId;
    const rightEntity = isLeftEntity(state.entityId, counterpartyId) ? counterpartyId : state.entityId;

    accountMachine = {
      leftEntity,
      rightEntity,
      mempool: [],
      currentFrame: {
        height: 0,
        timestamp: env.timestamp,
        jHeight: 0,
        accountTxs: [],
        prevFrameHash: '',
        tokenIds: [],
        deltas: [],
        stateHash: '',
        byLeft: state.entityId === leftEntity, // Am I left entity?
      },
      sentTransitions: 0,
      ackedTransitions: 0,
      deltas: initialDeltas,
      globalCreditLimits: {
        ownLimit: 0n, // Credit starts at 0 - must be explicitly extended
        peerLimit: 0n, // Credit starts at 0 - must be explicitly extended
      },
      currentHeight: 0,
      pendingSignatures: [],
      rollbackCount: 0,
      sendCounter: 0,    // Channel.ts message counter
      receiveCounter: 0,
      proofHeader: {
        fromEntity: state.entityId,
        toEntity: counterpartyId,
        cooperativeNonce: 0,
        disputeNonce: 0,
      },
      proofBody: {
        tokenIds: [],
        deltas: [],
      },
      frameHistory: [],
      pendingWithdrawals: new Map(),
      requestedRebalance: new Map(), // Phase 2: Câ†’R withdrawal tracking
      locks: new Map(), // HTLC: Empty locks map
      swapOffers: new Map(), // Swap: Empty offers map
      // Bilateral J-event consensus
      leftJObservations: [],
      rightJObservations: [],
      jEventChain: [],
      lastFinalizedJHeight: 0,
    };

    // Store with counterparty ID as key (simpler than canonical)
    newState.accounts.set(counterpartyId, accountMachine);
    console.log(`âœ… Account created with counterparty key: ${counterpartyId.slice(-4)}`);
  }

  // FINTECH-SAFETY: Ensure accountMachine exists
  if (!accountMachine) {
    throw new Error(`CRITICAL: AccountMachine creation failed for ${input.fromEntityId}`);
  }

  // NOTE: Credit limits start at 0 - no auto-credit on account opening
  // Credit must be explicitly extended via set_credit_limit transaction

  // CHANNEL.TS PATTERN: Process frame-level consensus ONLY
  if (input.height || input.newAccountFrame) {
    console.log(`ðŸ¤ Processing frame from ${input.fromEntityId.slice(-4)}, accountMachine.pendingFrame=${accountMachine.pendingFrame ? `h${accountMachine.pendingFrame.height}` : 'none'}`);

    const result = await processAccountInput(env, accountMachine, input);

    if (result.success) {
      addMessages(newState, result.events);
      emitScopedEvents(
        env,
        'account',
        `E/A/${newState.entityId.slice(-4)}:${counterpartyId.slice(-4)}/consensus`,
        result.events,
        {
          entityId: newState.entityId,
          counterpartyId,
          frameHeight: input.newAccountFrame?.height ?? input.height,
          counter: input.counter,
          hasNewFrame: Boolean(input.newAccountFrame),
        },
        newState.entityId,
      );

      // === HTLC LOCK PROCESSING: Check if we need to forward ===
      // CRITICAL: Only process NEW locks (prevent replay on re-processing same frame)
      // Check if this is a NEW frame (just committed) by comparing heights
      const justCommittedFrame = input.newAccountFrame;
      const isNewFrame = Boolean(justCommittedFrame && justCommittedFrame.height > (accountMachine.currentHeight - 1));

      if (isNewFrame && justCommittedFrame?.accountTxs) {
        if (HEAVY_LOGS) console.log(`ðŸ” HTLC-CHECK: isNewFrame=${isNewFrame}, inputHeight=${justCommittedFrame.height}, currentHeight=${accountMachine.currentHeight}`);
        if (HEAVY_LOGS) console.log(`ðŸ” HTLC-CHECK: accountMachine.locks.size=${accountMachine.locks.size}`);
        if (HEAVY_LOGS) console.log(`ðŸ” FRAME-TXS: ${justCommittedFrame.accountTxs.length} txs in frame:`, justCommittedFrame.accountTxs.map(tx => tx.type));
        for (const accountTx of justCommittedFrame.accountTxs) {
          if (HEAVY_LOGS) console.log(`ðŸ” HTLC-CHECK: Checking committed tx type=${accountTx.type}`);

          // === J-EVENT BILATERAL CONSENSUS ===
          if (accountTx.type === 'j_event_claim') {
            const { jHeight, jBlockHash, events, observedAt } = accountTx.data;
            console.log(`ðŸ“¥ j_event_claim: Counterparty claims jHeight=${jHeight}`);

            // Determine which side counterparty is
            const { iAmLeft: weAreLeft, counterparty } = getAccountPerspective(accountMachine, newState.entityId);
            const theyAreLeft = !weAreLeft;

            const obs = { jHeight, jBlockHash, events, observedAt };

            // Store THEIR observation in appropriate array
            if (theyAreLeft) {
              accountMachine.leftJObservations.push(obs);
              console.log(`   ðŸ“ Stored LEFT obs from counterparty (${accountMachine.leftJObservations.length} total)`);
            } else {
              accountMachine.rightJObservations.push(obs);
              console.log(`   ðŸ“ Stored RIGHT obs from counterparty (${accountMachine.rightJObservations.length} total)`);
            }

            // Try finalize now that we have counterparty's observation
            const { tryFinalizeAccountJEvents } = await import('../j-events');
            tryFinalizeAccountJEvents(accountMachine, counterparty, env);

            continue; // Move to next tx
          }

          if (accountTx.type === 'swap_resolve' || accountTx.type === 'swap_cancel') {
            const key = `${counterpartyId}:${accountTx.data.offerId}`;
            if (newState.pendingSwapFillRatios?.delete(key)) {
              console.log(`ðŸ“‰ Cleared pending fillRatio for ${key.slice(-12)}`);
            }
          }

          if (accountTx.type === 'htlc_lock') {
            if (HEAVY_LOGS) console.log(`ðŸ” HTLC-CHECK: Found htlc_lock in committed frame!`);
            const lock = accountMachine.locks.get(accountTx.data.lockId);
            if (HEAVY_LOGS) console.log(`ðŸ” HTLC-CHECK: lock found? ${!!lock}`);
            if (!lock) {
              console.log(`âŒ HTLC-CHECK: Lock not in accountMachine.locks (lockId=${accountTx.data.lockId.slice(0,16)}...)`);
              continue;
            }

            // Check envelope (onion routing)
            if (!lock.envelope) {
              console.log(`â­ï¸ HTLC: No envelope, skipping forwarding`);
              continue;
            }

            let envelope = lock.envelope;
            console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
            console.log(`ðŸ§… ENVELOPE RECEIVED at ${newState.entityId.slice(-4)}`);
            console.log(`ðŸ§… LockId: ${lock.lockId.slice(0,16)}...`);
            console.log(`ðŸ§… Hashlock: ${lock.hashlock.slice(0,16)}...`);
            console.log(`ðŸ§… Amount: ${lock.amount}`);
            console.log(`ðŸ§… Envelope type: ${typeof envelope}`);
            console.log(`ðŸ§… OUTER envelope: finalRecipient=${envelope.finalRecipient}, nextHop=${envelope.nextHop?.slice(-4)}`);
            console.log(`ðŸ§… OUTER envelope structure: ${JSON.stringify(envelope, null, 2).slice(0, 300)}...`);

            // CRITICAL: For onion routing, envelope can be:
            // 1. A string (encrypted payload for THIS hop - decrypt it directly)
            // 2. An object with innerEnvelope (THIS hop's plaintext instructions with encrypted payload for NEXT hop)

            // Case 1: Envelope is a string (encrypted FOR us)
            if (typeof envelope === 'string') {
              console.log(`ðŸ”“ Envelope is encrypted string - decrypting for us...`);
              try {
                let envelopeData = envelope;

                // Decrypt if crypto keys are configured
                if (newState.cryptoPrivateKey) {
                  const { NobleCryptoProvider } = await import('../../crypto-noble');
                  const crypto = new NobleCryptoProvider();
                  envelopeData = await crypto.decrypt(envelope, newState.cryptoPrivateKey);
                  console.log(`ðŸ”“ Decryption successful`);
                }

                // Unwrap decrypted envelope
                const { unwrapEnvelope } = await import('../../htlc-envelope-types');
                envelope = unwrapEnvelope(envelopeData);
                console.log(`ðŸ”“ Unwrapped envelope: finalRecipient=${envelope.finalRecipient}, nextHop=${envelope.nextHop?.slice(-4)}`);
                console.log(`ðŸ”“ Decrypted envelope structure: ${JSON.stringify(envelope, null, 2).slice(0, 300)}...`);
              } catch (e) {
                console.log(`âŒ HTLC-GATE: ENVELOPE_DECRYPT_FAIL - ${e instanceof Error ? e.message : String(e)} [lockId=${lock.lockId.slice(0,16)}]`);
                console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
                continue;
              }
            }
            // Case 2: Envelope has innerEnvelope (plaintext wrapper)
            else if (envelope.innerEnvelope && !envelope.finalRecipient) {
              console.log(`ðŸ”“ Decrypting innerEnvelope to get routing instructions...`);
              try {
                let envelopeData = envelope.innerEnvelope;

                // Decrypt if crypto keys are configured
                if (newState.cryptoPrivateKey) {
                  const { NobleCryptoProvider } = await import('../../crypto-noble');
                  const crypto = new NobleCryptoProvider();
                  envelopeData = await crypto.decrypt(envelope.innerEnvelope, newState.cryptoPrivateKey);
                  console.log(`ðŸ”“ Decryption successful`);
                }

                // Unwrap decrypted envelope - THIS is our actual routing instruction
                const { unwrapEnvelope } = await import('../../htlc-envelope-types');
                envelope = unwrapEnvelope(envelopeData);
                console.log(`ðŸ”“ Unwrapped envelope: finalRecipient=${envelope.finalRecipient}, nextHop=${envelope.nextHop?.slice(-4)}`);
                console.log(`ðŸ”“ Decrypted envelope structure: ${JSON.stringify(envelope, null, 2).slice(0, 300)}...`);
              } catch (e) {
                console.log(`âŒ HTLC-GATE: ENVELOPE_DECRYPT_FAIL - ${e instanceof Error ? e.message : String(e)} [lockId=${lock.lockId.slice(0,16)}]`);
                console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
                continue;
              }
            }

            // Validate envelope structure (safety check)
            const { validateEnvelope } = await import('../../htlc-envelope-types');
            try {
              validateEnvelope(envelope);
              console.log(`ðŸ§… Envelope validation: PASSED`);
            } catch (e) {
              console.log(`âŒ HTLC: Invalid envelope structure: ${e instanceof Error ? e.message : String(e)}`);
              console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
              continue;
            }

            // CRITICAL: Verify envelope matches HTLC lock (prevent replay/manipulation)
            // This is "verify-after-decrypt" pattern - simpler than AAD
            // The envelope MUST match the lock that carries it
            if (lock.amount.toString() !== accountTx.data.amount.toString()) {
              console.log(`âŒ HTLC: Envelope amount mismatch: lock=${lock.amount}, tx=${accountTx.data.amount}`);
              console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
              continue;
            }
            if (lock.tokenId !== accountTx.data.tokenId) {
              console.log(`âŒ HTLC: Envelope tokenId mismatch: lock=${lock.tokenId}, tx=${accountTx.data.tokenId}`);
              console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
              continue;
            }
            if (lock.hashlock !== accountTx.data.hashlock) {
              console.log(`âŒ HTLC: Envelope hashlock mismatch: lock=${lock.hashlock.slice(0,16)}..., tx=${accountTx.data.hashlock.slice(0,16)}...`);
              console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
              continue;
            }
            console.log(`âœ… HTLC: Envelope verified - matches lock parameters (amount, tokenId, hashlock)`);

            // For intermediary hops, verify nextHop is a valid entity
            if (envelope.nextHop && !envelope.finalRecipient) {
              // Check if we have an account with nextHop (can forward)
              const hasNextHopAccount = newState.accounts.has(envelope.nextHop);
              if (!hasNextHopAccount) {
                console.log(`âŒ HTLC: Cannot forward - no account with nextHop ${envelope.nextHop.slice(-4)}`);
                console.log(`âŒ HTLC: Available accounts: [${Array.from(newState.accounts.keys()).map(k => k.slice(-4)).join(', ')}]`);
                console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
                continue;
              }
              console.log(`âœ… HTLC: NextHop ${envelope.nextHop.slice(-4)} validated - account exists`);
            }

            // Are we the final recipient?
            if (envelope.finalRecipient) {
              console.log(`ðŸŽ¯ HTLC-ROUTING: WE ARE FINAL RECIPIENT!`);
              // Final recipient - reveal immediately
              if (envelope.secret) {
                mempoolOps.push({
                  accountId: input.fromEntityId,
                  tx: {
                    type: 'htlc_reveal',
                    data: {
                      lockId: lock.lockId,
                      secret: envelope.secret
                    }
                  }
                });
                console.log(`ðŸŽ¯ HTLC: Final recipient, revealing secret=${envelope.secret.slice(0,16)}...`);
                console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
              } else {
                console.log(`âŒ HTLC: Final recipient envelope missing secret!`);
                console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
              }
            } else if (envelope.nextHop) {
              // Intermediary - forward to next hop
              const nextHop = envelope.nextHop;
              console.log(`âž¡ï¸ HTLC-ROUTING: INTERMEDIARY HOP`);
              console.log(`âž¡ï¸ Forwarding to: ${nextHop.slice(-4)}`);

              // Register route for backward propagation
              const inboundEntity = newState.entityId === accountMachine.leftEntity
                ? accountMachine.rightEntity
                : accountMachine.leftEntity;

              console.log(`âž¡ï¸ Registering route: ${inboundEntity.slice(-4)} â†’ ${newState.entityId.slice(-4)} â†’ ${nextHop.slice(-4)}`);

              // Create route object (will add pendingFee later)
              const htlcRoute = {
                hashlock: lock.hashlock,
                inboundEntity,
                inboundLockId: lock.lockId,
                outboundEntity: nextHop,
                outboundLockId: `${lock.lockId}-fwd`,
                createdTimestamp: env.timestamp
              };
              newState.htlcRoutes.set(lock.hashlock, htlcRoute);

              const nextAccount = newState.accounts.get(nextHop);

              if (nextAccount) {
                // Calculate forwarded amounts/timelocks with safety checks
                const { calculateHtlcFee, calculateHtlcFeeAmount } = await import('../../htlc-utils');

                let forwardAmount: bigint;
                let feeAmount: bigint;

                try {
                  forwardAmount = calculateHtlcFee(lock.amount);
                  feeAmount = calculateHtlcFeeAmount(lock.amount);
                } catch (e) {
                  console.log(`âŒ HTLC: Fee calculation failed for amount ${lock.amount}: ${e instanceof Error ? e.message : String(e)}`);
                  console.log(`   Cannot forward - amount too small`);
                  continue;
                }

                // Store pending fee (only accrue on successful reveal, not on forward)
                htlcRoute.pendingFee = feeAmount;

                // Get inner envelope for next hop (already decrypted above)
                // The envelope variable now contains OUR decrypted instructions
                // envelope.innerEnvelope is the NEXT hop's encrypted payload
                const innerEnvelope = envelope.innerEnvelope;
                console.log(`ðŸ“¦ Inner envelope for next hop: ${innerEnvelope ? 'present' : 'missing'}`);

                // Calculate forwarded timelock/height with safety checks
                const forwardTimelock = lock.timelock - BigInt(HTLC.MIN_TIMELOCK_DELTA_MS); // Per-hop timelock delta
                const forwardHeight = lock.revealBeforeHeight - 1;

                // Validate forwarded lock is still valid (with instrumentation)
                const currentJHeight = newState.lastFinalizedJHeight || 0;

                // Timelock validation: forward must have breathing room (1s safety margin for processing delays)
                const SAFETY_MARGIN_MS = 1000;
                if (forwardTimelock < BigInt(env.timestamp) + BigInt(SAFETY_MARGIN_MS)) {
                  console.log(`âŒ HTLC-GATE: TIMELOCK_TOO_TIGHT - forward=${forwardTimelock}, current+margin=${BigInt(env.timestamp) + BigInt(SAFETY_MARGIN_MS)} [lockId=${lock.lockId.slice(0,16)}]`);
                  continue;
                }

                if (forwardHeight <= currentJHeight) {
                  console.log(`âŒ HTLC-GATE: HEIGHT_EXPIRED - forward=${forwardHeight}, current=${currentJHeight}, lock=${lock.revealBeforeHeight} [lockId=${lock.lockId.slice(0,16)}]`);
                  continue;
                }

                // Forward HTLC with reduced timelock/height and inner envelope
                console.log(`âž¡ï¸ HTLC-FORWARD: Creating outbound lock`);
                console.log(`âž¡ï¸ Outbound lockId: ${lock.lockId}-fwd`);
                console.log(`âž¡ï¸ Amount: ${lock.amount} â†’ ${forwardAmount} (fee=${feeAmount})`);
                console.log(`âž¡ï¸ Timelock: ${lock.timelock} â†’ ${forwardTimelock}`);
                console.log(`âž¡ï¸ Height: ${lock.revealBeforeHeight} â†’ ${forwardHeight}`);
                console.log(`âž¡ï¸ Inner envelope: ${innerEnvelope ? JSON.stringify(innerEnvelope, null, 2).slice(0, 200) : 'NONE'}...`);

                mempoolOps.push({
                  accountId: nextHop,
                  tx: {
                    type: 'htlc_lock',
                    data: {
                      lockId: `${lock.lockId}-fwd`,
                      hashlock: lock.hashlock,
                      timelock: forwardTimelock,
                      revealBeforeHeight: forwardHeight,
                      amount: forwardAmount,
                      tokenId: lock.tokenId,
                      envelope: innerEnvelope  // Next hop's envelope
                    }
                  }
                });
                console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);

                console.log(`âž¡ï¸ HTLC: Forwarding to ${nextHop.slice(-4)}, amount ${forwardAmount} (fee ${feeAmount})`);
              } else {
                console.log(`âŒ HTLC: No account found for nextHop ${nextHop.slice(-4)}`);
              }
            }
          }
        }
      }

      // CRITICAL: Process multi-hop forwarding (consume pendingForward)
      // Skip if env.skipPendingForward (for AHB demo frame separation)
      // AUTO-PROPOSE deferred to Frame 13 when flag cleared
      if (accountMachine.pendingForward && !env.skipPendingForward) {
        const forward = accountMachine.pendingForward;
        console.log(`ðŸ’¸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
        console.log(`ðŸ’¸ PROCESSING PENDING-FORWARD at ${state.entityId.slice(-4)}`);
        console.log(`ðŸ’¸ Amount: ${forward.amount}, TokenId: ${forward.tokenId}`);
        console.log(`ðŸ’¸ Route: [${forward.route.map(r => r.slice(-4)).join(',')}]`);
        console.log(`ðŸ’¸ Description: ${forward.description || 'none'}`);

        const nextHop = forward.route.length > 1 ? forward.route[1] : null;

        if (nextHop) {
          console.log(`ðŸ’¸ Next hop: ${nextHop.slice(-4)}`);
          const nextHopAccountKey = nextHop; // counterparty ID is key
          const nextHopAccount = newState.accounts.get(nextHopAccountKey);
          if (nextHopAccount) {
            // Forward full amount (no fees for simplicity)
            const forwardAmount = forward.amount;

            console.log(`ðŸ’¸ FORWARDING TO NEXT HOP`);
            console.log(`ðŸ’¸   Creating direct_payment AccountTx`);
            console.log(`ðŸ’¸   Amount: ${forwardAmount}`);
            console.log(`ðŸ’¸   From: ${state.entityId.slice(-4)}`);
            console.log(`ðŸ’¸   To: ${nextHop.slice(-4)}`);
            console.log(`ðŸ’¸   Route: [${forward.route.slice(1).map(r => r.slice(-4)).join(',')}]`);

            mempoolOps.push({
              accountId: nextHopAccountKey, // CRITICAL: Use canonical key, not entity ID!
              tx: {
                type: 'direct_payment',
                data: {
                  tokenId: forward.tokenId,
                  amount: forwardAmount,
                  route: forward.route.slice(1),
                  description: forward.description || 'Forwarded payment',
                  fromEntityId: state.entityId,
                  toEntityId: nextHop,
                }
              }
            });

            console.log(`ðŸ’¸ FORWARD QUEUED: mempoolOps.length=${mempoolOps.length}`);
            console.log(`ðŸ’¸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
          } else {
            console.log(`âŒ No account found for next hop ${nextHop.slice(-4)}`);
            console.log(`ðŸ’¸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
          }
        } else {
          console.log(`âŒ No next hop in forward route`);
          console.log(`ðŸ’¸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
        }

        delete accountMachine.pendingForward;
      }

      // === HTLC TIMEOUT CLEANUP (MEDIUM-7) ===
      // Check if any timeouts happened - clean up htlcRoutes
      const timedOutHashlocks = result.timedOutHashlocks || [];
      for (const timedOutHashlock of timedOutHashlocks) {
        console.log(`â° HTLC-TIMEOUT: Cleaning up route for hashlock ${timedOutHashlock.slice(0,16)}...`);
        const route = newState.htlcRoutes.get(timedOutHashlock);
        if (route) {
          // Clear pending fee (won't be earned)
          if (route.pendingFee) {
            console.log(`   Clearing pending fee: ${route.pendingFee} (not earned due to timeout)`);
          }

          // Remove from htlcRoutes (prevent state leak)
          newState.htlcRoutes.delete(timedOutHashlock);
          console.log(`   âœ… Route cleaned up`);
        }
      }

      // === HTLC SECRET PROPAGATION ===
      // Check if any reveals happened in this frame
      const revealedSecrets = result.revealedSecrets || [];
      if (HEAVY_LOGS) console.log(`ðŸ” HTLC-SECRET-CHECK: ${revealedSecrets.length} secrets revealed in frame`);

      if (revealedSecrets.length > 0) {
        if (!newState.jBatchState) {
          newState.jBatchState = initJBatch();
        }
        const transformerAddress = getDeltaTransformerAddress();
        if (transformerAddress === '0x0000000000000000000000000000000000000000') {
          console.warn('âš ï¸ HTLC: DeltaTransformer address not set - skipping on-chain reveal');
        } else {
          for (const { secret } of revealedSecrets) {
            batchAddRevealSecret(newState.jBatchState, transformerAddress, secret);
          }
        }
      }

      for (const { secret, hashlock } of revealedSecrets) {
        if (HEAVY_LOGS) console.log(`ðŸ” HTLC-SECRET: Processing revealed secret for hash ${hashlock.slice(0,16)}...`);
        const route = newState.htlcRoutes.get(hashlock);
        if (route) {
          // Store secret
          route.secret = secret;

          // Accrue fees on successful reveal (not on forward)
          if (route.pendingFee) {
            newState.htlcFeesEarned = (newState.htlcFeesEarned || 0n) + route.pendingFee;
            console.log(`ðŸ’° HTLC: Fee earned on reveal: ${route.pendingFee} (total: ${newState.htlcFeesEarned})`);
            route.pendingFee = undefined; // Clear pending
          }

          // Remove from lockBook (E-Machine aggregated view) - payment settled
          if (route.outboundLockId) {
            newState.lockBook.delete(route.outboundLockId);
          }
          if (route.inboundLockId) {
            newState.lockBook.delete(route.inboundLockId);
          }

          // Propagate backward to sender (2024 hashlockMap pattern)
          if (route.inboundEntity && route.inboundLockId) {
            mempoolOps.push({
              accountId: route.inboundEntity,
              tx: {
                type: 'htlc_reveal',
                data: {
                  lockId: route.inboundLockId,
                  secret
                }
              }
            });
            console.log(`â¬…ï¸ HTLC: Propagating secret to ${route.inboundEntity.slice(-4)}`);
          } else {
            console.log(`âœ… HTLC: Payment complete (we initiated)`);
          }
        } else {
          console.log(`âš ï¸ HTLC: No route found for hashlock ${hashlock.slice(0,16)}...`);
        }
      }

      // === COLLECT SWAP EVENTS (deferred to entity-level orchestration) ===
      const swapOffersCreated = result.swapOffersCreated || [];
      if (swapOffersCreated.length > 0) {
        console.log(`ðŸ“Š SWAP-EVENTS: Collected ${swapOffersCreated.length} swap offers for entity-level matching`);
        allSwapOffersCreated.push(...swapOffersCreated);
      }

      const swapOffersCancelled = result.swapOffersCancelled || [];
      if (swapOffersCancelled.length > 0) {
        console.log(`ðŸ“Š SWAP-EVENTS: Collected ${swapOffersCancelled.length} swap cancels`);
        allSwapOffersCancelled.push(...swapOffersCancelled);
        // Update E-Machine swapBook immediately (this is entity state, not mempool)
        // AUDIT FIX (CRITICAL-6): Use namespaced key for swapBook delete
        for (const { offerId, accountId } of swapOffersCancelled) {
          const swapBookKey = `${accountId}:${offerId}`;
          newState.swapBook.delete(swapBookKey);
        }
      }

      // Send response (ACK + optional new frame)
      if (result.response) {
        console.log(`ðŸ“¤ Sending response to ${result.response.toEntityId.slice(-4)}`);

        // Get target proposer
        // IMPORTANT: Send only to PROPOSER - bilateral consensus between entity proposers
        // Multi-validator entities sync account state via entity-level consensus (not bilateral broadcast)
        const targetProposerId = resolveEntityProposerId(
          env,
          result.response!.toEntityId,
          'accountInput.response'
        );

        outputs.push({
          entityId: result.response.toEntityId,
          signerId: targetProposerId,
          entityTxs: [{
            type: 'accountInput',
            data: result.response
          }]
        });

        console.log(`âœ… ACK-RESPONSE queued: ${state.entityId.slice(-4)} â†’ ${result.response.toEntityId.slice(-4)}, height=${result.response.height}, hasPrevHanko=${!!result.response.prevHanko}, counter=${result.response.counter}`);
      }
    } else {
      console.error(`âŒ Frame consensus failed: ${result.error}`);
      addMessage(newState, `âŒ ${result.error}`);
    }
  } else {
    // NO individual accountTx handling! Channel.ts sends frames ONLY
    console.error(`âŒ Received AccountInput without frames - invalid!`);
    addMessage(newState, `âŒ Invalid AccountInput from ${input.fromEntityId.slice(-4)}`);
  }

  return {
    newState,
    outputs,
    mempoolOps,
    swapOffersCreated: allSwapOffersCreated,
    swapOffersCancelled: allSwapOffersCancelled
  };
}

/**
 * Process swap offers through hub's orderbook (PURE - returns events, no mutations)
 * Called at entity level after aggregating all swap events
 */
export function processOrderbookSwaps(
  hubState: EntityState,
  swapOffers: SwapOfferEvent[]
): MatchResult {
  const mempoolOps: MempoolOp[] = [];
  const bookUpdates: { pairId: string; book: BookState }[] = [];
  const ext = hubState.orderbookExt as OrderbookExtState | undefined;
  if (!ext) return { mempoolOps, bookUpdates };

  // AUDIT FIX (CRITICAL-5): Cache book updates within batch to avoid stale snapshots
  // Without this, same-tick offers don't see each other's fills
  const bookCache = new Map<string, BookState>();

  for (const offer of swapOffers) {
    // Use accountId enriched by entity handler (already has correct counterparty ID)
    const accountId = offer.accountId!;
    console.log(`ðŸ“Š ORDERBOOK-PROCESS: offerId=${offer.offerId}, accountId=${accountId.slice(-8)}`);

    const { pairId } = canonicalPair(offer.giveTokenId, offer.wantTokenId);
    const bookKey = pairId;

    const side = deriveSide(offer.giveTokenId, offer.wantTokenId);
    // LOT_SCALE = 10^12: Orderbook works in lots for uint32 efficiency
    // For 18-decimal tokens: 1 lot = 10^12 wei = 0.000001 tokens
    // This allows up to ~4.2M lots per order (uint32 max), sufficient for most trades
    // NOTE (MEDIUM-1): Amounts below LOT_SCALE will be truncated to 0 lots and rejected
    // This is acceptable: sub-$0.001 orders at typical ETH prices are uneconomical anyway
    const LOT_SCALE = 10n ** 12n;
    const MAX_LOTS = 0xFFFFFFFFn;

    let priceTicks: bigint;
    let qtyLots: bigint;

    if (side === 1) {
      priceTicks = (offer.wantAmount * 100n) / offer.giveAmount;
      qtyLots = offer.giveAmount / LOT_SCALE;
    } else {
      priceTicks = (offer.giveAmount * 100n) / offer.wantAmount;
      qtyLots = offer.wantAmount / LOT_SCALE;
    }

    if (qtyLots === 0n || qtyLots > MAX_LOTS || priceTicks <= 0n || priceTicks > MAX_LOTS) {
      console.warn(`ðŸ“Š ORDERBOOK REJECT: Invalid order (qty=${qtyLots}, price=${priceTicks}), offerId=${offer.offerId}`);
      continue;
    }

    // AUDIT FIX (CRITICAL-5): Use cached book if available, otherwise load from ext.books
    let book = bookCache.get(bookKey) || ext.books.get(bookKey);
    if (!book) {
      const BOOK_LEVELS = 100;
      const PRICE_TICK = 1000;
      const center = Number(priceTicks);
      const halfRange = PRICE_TICK * Math.floor(BOOK_LEVELS / 2);
      const pmin = Math.max(1, center - halfRange);
      const pmax = pmin + PRICE_TICK * (BOOK_LEVELS - 1);

      book = createBook({
        tick: PRICE_TICK,
        pmin,
        pmax,
        maxOrders: 10000,
        stpPolicy: 0,
      });
    }

    const makerId = offer.makerIsLeft ? offer.fromEntity : offer.toEntity;
    const namespacedOrderId = `${accountId}:${offer.offerId}`;
    console.log(`ðŸ“Š ORDERBOOK ADD: maker=${formatEntityId(makerId)}, orderId=${namespacedOrderId.slice(-20)}, side=${side}, price=${priceTicks}, qty=${qtyLots}`);

    const result = applyCommand(book, {
      kind: 0,
      ownerId: makerId,
      orderId: namespacedOrderId,
      side,
      tif: 0,
      postOnly: false,
      priceTicks: Number(priceTicks),
      qtyLots: Number(qtyLots),
      minFillRatio: offer.minFillRatio ?? 0,
    });

    book = result.state;
    // AUDIT FIX (CRITICAL-5): Cache updated book for next offer in same batch
    bookCache.set(bookKey, book);
    bookUpdates.push({ pairId: bookKey, book });

    // Process trade events
    const fillsPerOrder = new Map<string, { filledLots: number; originalLots: number }>();

    for (const event of result.events) {
      if (event.type === 'TRADE') {
        const extractOfferId = (namespacedId: string) => {
          const lastColon = namespacedId.lastIndexOf(':');
          return lastColon >= 0 ? namespacedId.slice(lastColon + 1) : namespacedId;
        };

        const makerEntry = fillsPerOrder.get(event.makerOrderId);
        if (!makerEntry) {
          fillsPerOrder.set(event.makerOrderId, { filledLots: event.qty, originalLots: event.makerQtyBefore });
        } else {
          makerEntry.filledLots += event.qty;
        }

        const takerEntry = fillsPerOrder.get(event.takerOrderId);
        if (!takerEntry) {
          fillsPerOrder.set(event.takerOrderId, { filledLots: event.qty, originalLots: event.takerQtyTotal });
        } else {
          takerEntry.filledLots += event.qty;
        }

        console.log(`ðŸ“Š ORDERBOOK TRADE: ${extractOfferId(event.makerOrderId)} â†” ${extractOfferId(event.takerOrderId)} @ ${event.price}, qty=${event.qty}`);
      }
    }

    // Emit swap_resolve for each filled order
    const MAX_FILL_RATIO = 65535;

    for (const [namespacedOrderId, { filledLots, originalLots }] of fillsPerOrder) {
      // Parse namespacedOrderId format: "counterpartyId:offerId"
      // counterpartyId is the Map key used to store the account
      const lastColon = namespacedOrderId.lastIndexOf(':');
      if (lastColon === -1) continue;
      const offerId = namespacedOrderId.slice(lastColon + 1);
      const accountId = namespacedOrderId.slice(0, lastColon);

      // Verify account exists in hub's state
      if (HEAVY_LOGS) console.log(`ðŸ” ORDERBOOK-LOOKUP: Looking for accountId="${accountId}"`);
      if (HEAVY_LOGS) console.log(`ðŸ” ORDERBOOK-LOOKUP: Hub accounts:`, Array.from(hubState.accounts.keys()));
      if (HEAVY_LOGS) console.log(`ðŸ” ORDERBOOK-LOOKUP: Match found:`, hubState.accounts.has(accountId));
      if (!hubState.accounts.has(accountId)) {
        console.warn(`âš ï¸ ORDERBOOK: Account not found for swap_resolve, skipping`);
        console.warn(`   Looking for: "${accountId}"`);
        console.warn(`   Hub has: ${Array.from(hubState.accounts.keys()).map(k => `"${k}"`).join(', ')}`);
        continue;
      }
      console.log(`âœ… ORDERBOOK-LOOKUP: Found account for ${accountId.slice(-8)}, generating swap_resolve`);

      const filledBig = BigInt(filledLots);
      const originalBig = BigInt(originalLots);
      const fillRatio = originalBig > 0n
        ? Number((filledBig * BigInt(MAX_FILL_RATIO)) / originalBig)
        : 0;

      const orderStillInBook = book.orderIdToIdx.has(namespacedOrderId) &&
        book.orderActive[book.orderIdToIdx.get(namespacedOrderId)!];

      mempoolOps.push({
        accountId,
        tx: {
          type: 'swap_resolve',
          data: {
            offerId,
            fillRatio: Math.min(fillRatio, MAX_FILL_RATIO),
            cancelRemainder: !orderStillInBook,
          }
        }
      });
      console.log(`ðŸ“¤ ORDERBOOK: Queued swap_resolve for ${offerId.slice(-8)}, fill=${(fillRatio/MAX_FILL_RATIO*100).toFixed(1)}%, cancel=${!orderStillInBook}`);
    }
  }

  return { mempoolOps, bookUpdates };
}

/**
 * Process swap cancels through hub's orderbook
 */
export function processOrderbookCancels(
  hubState: EntityState,
  cancels: SwapCancelEvent[]
): { pairId: string; book: BookState }[] {
  const bookUpdates: { pairId: string; book: BookState }[] = [];
  const ext = hubState.orderbookExt as OrderbookExtState | undefined;
  if (!ext) return bookUpdates;

  for (const { offerId, accountId } of cancels) {
    const namespacedOrderId = `${accountId}:${offerId}`;

    for (const [bookKey, book] of ext.books) {
      const orderIdx = book.orderIdToIdx.get(namespacedOrderId);
      if (orderIdx !== undefined && book.orderActive[orderIdx]) {
        const ownerId = book.owners[book.orderOwnerIdx[orderIdx]];

        const result = applyCommand(book, {
          kind: 1,
          ownerId,
          orderId: namespacedOrderId,
          side: 0,
          tif: 0,
          postOnly: false,
          priceTicks: 0,
          qtyLots: 0,
        });

        bookUpdates.push({ pairId: bookKey, book: result.state });
        console.log(`ðŸ“Š ORDERBOOK: Cancelled order ${offerId.slice(-8)}`);
        break;
      }
    }
  }

  return bookUpdates;
}


//runtime/entity-tx/handlers/deposit-collateral.ts (74 lines)
/**
 * Deposit Collateral Handler
 *
 * Entity moves own reserve â†’ account collateral (unilateral on-chain action)
 * Reference: 2019src.txt lines 233-239 (reserveToChannel batchAdd)
 * Reference: Depository.sol reserveToCollateral() (line 1035)
 *
 * Flow:
 * 1. Entity validates sufficient reserve
 * 2. Add Râ†’C operation to jBatch
 * 3. Wait for jBatch crontab to broadcast
 * 4. On-chain event triggers bilateral account state update
 */

import type { EntityState, EntityTx, EntityInput } from '../../types';
import { cloneEntityState, addMessage, canonicalAccountKey } from '../../state-helpers';

export async function handleDepositCollateral(
  entityState: EntityState,
  entityTx: Extract<EntityTx, { type: 'deposit_collateral' }>
): Promise<{ newState: EntityState; outputs: EntityInput[]; jOutputs?: any[] }> {
  const { counterpartyId, tokenId, amount } = entityTx.data;
  const newState = cloneEntityState(entityState);
  const outputs: EntityInput[] = [];

  // Validate: Do we have enough reserve?
  const currentReserve = entityState.reserves.get(String(tokenId)) || 0n;
  if (currentReserve < amount) {
    addMessage(newState,
      `âŒ Insufficient reserve for collateral deposit: have ${currentReserve}, need ${amount} token ${tokenId}`
    );
    return { newState, outputs };
  }

  // Validate: Does account exist?
  // Account keyed by counterparty ID
  if (!entityState.accounts.has(counterpartyId)) {
    addMessage(newState,
      `âŒ Cannot deposit collateral: no account with ${counterpartyId.slice(-4)}`
    );
    return { newState, outputs };
  }

  // CRITICAL: Do NOT update state here - wait for SettlementProcessed event from j-watcher
  // This is consensus-critical: both entities must update based on the on-chain event

  // Initialize jBatch on first use
  if (!newState.jBatchState) {
    const { initJBatch } = await import('../../j-batch');
    newState.jBatchState = initJBatch();
  }

  // Add to jBatch for on-chain submission
  const { batchAddReserveToCollateral } = await import('../../j-batch');
  batchAddReserveToCollateral(
    newState.jBatchState,
    entityState.entityId,
    counterpartyId,
    tokenId,
    amount
  );

  addMessage(newState,
    `ðŸ“¦ Queued Râ†’C: ${amount} token ${tokenId} to account with ${counterpartyId.slice(-4)} (use j_broadcast to commit)`
  );

  console.log(`âœ… deposit_collateral: Added to jBatch for ${entityState.entityId.slice(-4)}`);
  console.log(`   Counterparty: ${counterpartyId.slice(-4)}`);
  console.log(`   Token: ${tokenId}, Amount: ${amount}`);
  console.log(`   âš ï¸  Remember to send j_broadcast tx to commit batch to J-Machine`);

  return { newState, outputs };
}


//runtime/entity-tx/handlers/htlc-payment.ts (238 lines)
/**
 * HTLC Payment Handler (Entity-level)
 * Creates conditional payment with hashlock, routes through network
 *
 * Pattern: Exactly like directPayment but creates htlc_lock instead of direct_payment
 * Reference: entity-tx/apply.ts:302-437 (directPayment handler)
 */

import { EntityState, EntityInput, AccountTx, Env } from '../../types';
import { cloneEntityState, canonicalAccountKey } from '../../state-helpers';
import { generateHashlock, generateLockId, calculateHopTimelock, calculateHopRevealHeight, hashHtlcSecret } from '../../htlc-utils';
import { HTLC } from '../../constants';

const formatEntityId = (id: string) => id.slice(-4);
const addMessage = (state: EntityState, message: string) => state.messages.push(message);
const logError = (context: string, message: string) => console.error(`[${context}] ${message}`);

export async function handleHtlcPayment(
  entityState: EntityState,
  entityTx: Extract<any, { type: 'htlcPayment' }>,
  env: Env
): Promise<{ newState: EntityState; outputs: EntityInput[]; mempoolOps?: Array<{ accountId: string; tx: any }> }> {
  console.log(`ðŸ”’ HTLC-PAYMENT HANDLER: ${entityState.entityId.slice(-4)} â†’ ${entityTx.data.targetEntityId.slice(-4)}`);
  console.log(`   Amount: ${entityTx.data.amount}, Route: ${entityTx.data.route?.map((r: string) => r.slice(-4)).join('â†’') || 'none'}`);

  // Emit HTLC initiation event
  env.emit('HtlcPaymentInitiated', {
    fromEntity: entityState.entityId,
    toEntity: entityTx.data.targetEntityId,
    tokenId: entityTx.data.tokenId,
    amount: entityTx.data.amount.toString(),
    route: entityTx.data.route,
  });

  const newState = cloneEntityState(entityState);
  const outputs: EntityInput[] = [];
  const mempoolOps: Array<{ accountId: string; tx: any }> = [];

  // Extract payment details
  let { targetEntityId, tokenId, amount, route, description, secret, hashlock } = entityTx.data;

  // Generate or validate secret/hashlock
  if (!secret && !hashlock) {
    const generated = generateHashlock();
    secret = generated.secret;
    hashlock = generated.hashlock;
    console.log(`ðŸ”’ Generated secret: ${secret.slice(0,16)}..., hash: ${hashlock.slice(0,16)}...`);
  } else if (secret && !hashlock) {
    try {
      hashlock = hashHtlcSecret(secret);
      console.log(`ðŸ”’ Derived hashlock from provided secret: ${hashlock.slice(0,16)}...`);
    } catch (error) {
      logError("HTLC_PAYMENT", `âŒ Invalid secret format: ${error instanceof Error ? error.message : String(error)}`);
      addMessage(newState, `âŒ HTLC payment failed: invalid secret`);
      return { newState, outputs: [], mempoolOps: [] };
    }
  } else if (!secret && hashlock) {
    logError("HTLC_PAYMENT", `âŒ Provided hashlock without secret`);
    addMessage(newState, `âŒ HTLC payment failed: missing secret`);
    return { newState, outputs: [], mempoolOps: [] };
  } else if (secret && hashlock) {
    try {
      const computed = hashHtlcSecret(secret);
      if (computed !== hashlock) {
        logError("HTLC_PAYMENT", `âŒ Secret/hashlock mismatch: computed ${computed.slice(0,16)}..., expected ${hashlock.slice(0,16)}...`);
        addMessage(newState, `âŒ HTLC payment failed: secret/hash mismatch`);
        return { newState, outputs: [], mempoolOps: [] };
      }
    } catch (error) {
      logError("HTLC_PAYMENT", `âŒ Invalid secret format: ${error instanceof Error ? error.message : String(error)}`);
      addMessage(newState, `âŒ HTLC payment failed: invalid secret`);
      return { newState, outputs: [], mempoolOps: [] };
    }
  }

  // If no route provided, check for direct account or calculate route
  if (!route || route.length === 0) {
    // Account keyed by counterparty ID (no canonical helper needed)
    if (newState.accounts.has(targetEntityId)) {
      console.log(`ðŸ”’ Direct account exists with ${formatEntityId(targetEntityId)}`);
      route = [entityState.entityId, targetEntityId];
    } else {
      // Find route through network using gossip
      if (env.gossip) {
        const networkGraph = env.gossip.getNetworkGraph();
        const paths = await networkGraph.findPaths(entityState.entityId, targetEntityId, amount, tokenId);

        if (paths.length > 0) {
          route = paths[0].path;
          console.log(`ðŸ”’ Found route: ${route.map((e: string) => formatEntityId(e)).join(' â†’ ')}`);
        } else {
          logError("HTLC_PAYMENT", `âŒ No route found to ${formatEntityId(targetEntityId)}`);
          addMessage(newState, `âŒ HTLC payment failed: No route to ${formatEntityId(targetEntityId)}`);
          return { newState, outputs: [], mempoolOps: [] };
        }
      } else {
        logError("HTLC_PAYMENT", `âŒ Cannot find route: Gossip layer not available`);
        addMessage(newState, `âŒ HTLC payment failed: Network routing unavailable`);
        return { newState, outputs: [], mempoolOps: [] };
      }
    }
  }

  // Validate route starts with current entity
  if (route.length < 1 || route[0] !== entityState.entityId) {
    logError("HTLC_PAYMENT", `âŒ Invalid route: doesn't start with current entity`);
    return { newState: entityState, outputs: [] };
  }

  // Check if we're the final destination
  if (route.length === 1 && route[0] === targetEntityId) {
    addMessage(newState, `ðŸ’° Received HTLC payment of ${amount} (token ${tokenId})`);
    return { newState, outputs: [] };
  }

  // Determine next hop
  const nextHop = route[1];
  if (!nextHop) {
    logError("HTLC_PAYMENT", `âŒ Invalid route: no next hop`);
    return { newState, outputs: [] };
  }

  // Check if we have an account with next hop
  // Accounts keyed by counterparty ID (simpler than canonical)
  if (!newState.accounts.has(nextHop)) {
    logError("HTLC_PAYMENT", `âŒ No account with next hop: ${nextHop.slice(-4)}`);
    addMessage(newState, `âŒ HTLC payment failed: No account with ${formatEntityId(nextHop)}`);
    return { newState, outputs: [] };
  }

  // Calculate timelocks and reveal heights (Alice gets most time)
  const totalHops = route.length - 1; // Minus sender
  const hopIndex = 0; // We're always hop 0 (sender) in this handler
  const minExpiryMs = totalHops * HTLC.MIN_TIMELOCK_DELTA_MS + HTLC.MIN_FORWARD_TIMELOCK_MS;
  // Use much longer expiry for test scenarios (100+ frames Ã— 100ms = 10s+ elapsed)
  const expiryMs = Math.max(120_000, minExpiryMs);
  const baseTimelock = BigInt(env.timestamp + expiryMs);
  // Add safety buffer for long-running test scenarios (prevent immediate expiry)
  const baseHeight = (newState.lastFinalizedJHeight || 0) + 50;

  const timelock = calculateHopTimelock(baseTimelock, hopIndex, totalHops);
  const revealBeforeHeight = calculateHopRevealHeight(baseHeight, hopIndex, totalHops);

  // Generate deterministic lockId
  const lockId = generateLockId(hashlock, newState.height, 0, env.timestamp);

  // Store routing info (like 2024 hashlockMap)
  newState.htlcRoutes.set(hashlock, {
    hashlock,
    outboundEntity: nextHop,
    outboundLockId: lockId,
    createdTimestamp: env.timestamp
  });

  // Create encrypted onion envelope (privacy-preserving routing)
  const { createOnionEnvelopes } = await import('../../htlc-envelope-types');
  let envelope;
  try {
    // Gather public keys from route entities (for encryption)
    const entityPubKeys = new Map<string, string>();
    for (const entityId of route) {
      // Find entity replica in env
      const replica = Array.from(env.eReplicas.entries()).find(([key]) => key.startsWith(entityId + ':'));
      if (replica && replica[1].state.cryptoPublicKey) {
        entityPubKeys.set(entityId, replica[1].state.cryptoPublicKey);
      }
    }

    // Create envelope with encryption if keys available
    const { NobleCryptoProvider } = await import('../../crypto-noble');
    const crypto = entityPubKeys.size === route.length ? new NobleCryptoProvider() : undefined;

    envelope = await createOnionEnvelopes(route, secret, entityPubKeys, crypto);
    console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
    console.log(`ðŸ§… ENVELOPE CREATED at ${formatEntityId(entityState.entityId)}`);
    console.log(`ðŸ§… Route: ${route.map(r => formatEntityId(r)).join(' â†’ ')}`);
    console.log(`ðŸ§… Encryption: ${crypto ? 'ENCRYPTED' : 'CLEARTEXT'}`);
    console.log(`ðŸ§… Secret: ${secret.slice(0,16)}...`);
    console.log(`ðŸ§… Hashlock: ${hashlock.slice(0,16)}...`);
    console.log(`ðŸ§… Envelope structure: ${JSON.stringify(envelope, null, 2).slice(0, 300)}...`);
    console.log(`ðŸ§… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
  } catch (e) {
    logError("HTLC_PAYMENT", `âŒ Envelope creation failed: ${e instanceof Error ? e.message : String(e)}`);
    addMessage(newState, `âŒ HTLC payment failed: Invalid route`);
    return { newState, outputs: [], mempoolOps: [] };
  }

  // Create htlc_lock AccountTx
  const accountTx: AccountTx = {
    type: 'htlc_lock',
    data: {
      lockId,
      hashlock,
      timelock,
      revealBeforeHeight,
      amount,
      tokenId,
      envelope  // Onion envelope (cleartext JSON in Phase 2)
    },
  };

  // Queue mempool operation (entity-consensus will apply + mark account proposable)
  const accountMachine = newState.accounts.get(nextHop);
  if (accountMachine) {
    mempoolOps.push({ accountId: nextHop, tx: accountTx });
    console.log(`ðŸ”’ Queued HTLC lock for mempool (account ${formatEntityId(nextHop)})`);
    console.log(`ðŸ”’ Lock ID: ${lockId.slice(0,16)}..., expires block ${revealBeforeHeight}`);

    // Add to lockBook (E-Machine aggregated view)
    newState.lockBook.set(lockId, {
      lockId,
      accountId: nextHop, // Use counterparty ID as key (simpler than canonical)
      tokenId,
      amount,
      hashlock,
      timelock,
      direction: 'outgoing',
      createdAt: BigInt(env.timestamp),
    });

    addMessage(newState,
      `ðŸ”’ HTLC: Locking ${amount} (token ${tokenId}) to ${formatEntityId(targetEntityId)} via ${route.length - 1} hops`
    );

    // Trigger processing
    const firstValidator = entityState.config.validators[0];
    if (firstValidator) {
      outputs.push({
        entityId: entityState.entityId,
        signerId: firstValidator,
        entityTxs: []
      });
    }
  }

  return { newState, outputs, mempoolOps };
}


//runtime/entity-tx/handlers/create-settlement.ts (62 lines)
/**
 * Create Settlement Handler
 *
 * Adds settlement to entity's jBatch (via proper E-layer flow)
 * Used for: Rebalancing, cooperative closes, dispute resolutions
 *
 * Flow:
 * 1. Entity creates createSettlement EntityTx
 * 2. Handler calls batchAddSettlement (adds to jBatch)
 * 3. Entity sends j_broadcast
 * 4. Settlement executes via J-processor
 */

import type { EntityState, EntityTx, EntityInput } from '../../types';
import { cloneEntityState, addMessage } from '../../state-helpers';
import { initJBatch, batchAddSettlement } from '../../j-batch';
import { isLeftEntity } from '../../entity-id-utils';

export async function handleCreateSettlement(
  entityState: EntityState,
  entityTx: Extract<EntityTx, { type: 'createSettlement' }>
): Promise<{ newState: EntityState; outputs: EntityInput[]; jOutputs?: any[] }> {
  const { counterpartyEntityId, diffs, sig } = entityTx.data;
  const newState = cloneEntityState(entityState);
  const outputs: EntityInput[] = [];

  console.log(`âš–ï¸ createSettlement: ${entityState.entityId.slice(-4)} â†’ ${counterpartyEntityId.slice(-4)}`);
  console.log(`   Diffs: ${diffs.length} operations`);

  // Initialize jBatch on first use
  if (!newState.jBatchState) {
    newState.jBatchState = initJBatch();
  }

  // Determine canonical left/right order
  const isLeft = isLeftEntity(entityState.entityId, counterpartyEntityId);
  const leftEntity = isLeft ? entityState.entityId : counterpartyEntityId;
  const rightEntity = isLeft ? counterpartyEntityId : entityState.entityId;

  if (!sig || sig === '0x') {
    throw new Error(`Settlement ${entityState.entityId.slice(-4)}â†”${counterpartyEntityId.slice(-4)} missing hanko signature`);
  }

  // Add settlement to jBatch
  batchAddSettlement(
    newState.jBatchState,
    leftEntity,
    rightEntity,
    diffs,
    [],
    [],
    sig
  );

  console.log(`âœ… createSettlement: Added to jBatch for ${entityState.entityId.slice(-4)}`);
  console.log(`   Settlement: ${leftEntity.slice(-4)} â†” ${rightEntity.slice(-4)}`);

  addMessage(newState, `âš–ï¸ Settlement created (${diffs.length} diffs) - use jBroadcast to commit`);

  return { newState, outputs };
}


//runtime/entity-tx/handlers/mint-reserves.ts (55 lines)
/**
 * Mint Reserves Handler
 *
 * SAME FLOW AS R2R: adds mint operation to jBatch, broadcasts via j_broadcast
 * Pattern: E-machine tx accumulates ops â†’ jBroadcast tx commits batch â†’ J-machine executes
 *
 * Flow:
 * 1. Entity validates (optional)
 * 2. Add mint operation to jBatch
 * 3. User sends j_broadcast
 * 4. J-machine executes â†’ BrowserVM mints
 * 5. J-events route back
 */

import type { EntityState, EntityTx, EntityInput } from '../../types';
import { cloneEntityState, addMessage } from '../../state-helpers';
import { initJBatch } from '../../j-batch';

export async function handleMintReserves(
  entityState: EntityState,
  entityTx: Extract<EntityTx, { type: 'mintReserves' }>
): Promise<{ newState: EntityState; outputs: EntityInput[]; jOutputs?: any[] }> {
  const { tokenId, amount } = entityTx.data;
  const newState = cloneEntityState(entityState);
  const outputs: EntityInput[] = [];

  console.log(`ðŸ’° mintReserves: ${entityState.entityId.slice(-4)} adding ${amount} token ${tokenId} to jBatch`);

  // Initialize jBatch on first use
  if (!newState.jBatchState) {
    newState.jBatchState = initJBatch();
  }

  // Add mint to jBatch (same pattern as R2R)
  // Note: JBatch.reserveToReserve uses "receivingEntity" field name
  const mintOp = {
    receivingEntity: entityState.entityId,
    tokenId,
    amount,
  };

  console.log(`ðŸ“¦ jBatch: Adding mint:`, mintOp);
  newState.jBatchState.batch.reserveToReserve.push(mintOp);
  console.log(`ðŸ“¦ jBatch: After push, array length: ${newState.jBatchState.batch.reserveToReserve.length}`);

  addMessage(newState,
    `ðŸ“¦ Queued Mint: ${amount} token ${tokenId} (use jBroadcast to commit)`
  );

  console.log(`âœ… mintReserves: Added to jBatch for ${entityState.entityId.slice(-4)}`);
  console.log(`   Token: ${tokenId}, Amount: ${amount}`);

  return { newState, outputs };
}


//runtime/account-tx/index.ts (10 lines)
/**
 * Account Transaction Module Exports
 * Modular organization matching entity-tx pattern
 */

export { processAccountTx } from './apply';
export { handleAddDelta } from './handlers/add-delta';
export { handleSetCreditLimit } from './handlers/set-credit-limit';
export { handleDirectPayment } from './handlers/direct-payment';


//runtime/account-tx/apply.ts (215 lines)
/**
 * Account Transaction Dispatcher
 * Routes AccountTx to appropriate handlers (like entity-tx/apply.ts pattern)
 */

import { AccountMachine, AccountTx } from '../types';
import { getAccountPerspective } from '../state-helpers';
import { handleAddDelta } from './handlers/add-delta';
import { handleSetCreditLimit } from './handlers/set-credit-limit';
import { handleDirectPayment } from './handlers/direct-payment';
import { handleReserveToCollateral } from './handlers/reserve-to-collateral';
import { handleRequestWithdrawal } from './handlers/request-withdrawal';
import { handleApproveWithdrawal } from './handlers/approve-withdrawal';
import { handleRequestRebalance } from './handlers/request-rebalance';
import { handleJSync } from './handlers/j-sync';
import { handleHtlcLock } from './handlers/htlc-lock';
import { handleHtlcReveal } from './handlers/htlc-reveal';
import { handleHtlcTimeout } from './handlers/htlc-timeout';
import { handleSwapOffer } from './handlers/swap-offer';
import { handleSwapResolve } from './handlers/swap-resolve';
import { handleSwapCancel } from './handlers/swap-cancel';

/**
 * Process single AccountTx through bilateral consensus
 * @param accountMachine - The account machine state
 * @param accountTx - The transaction to process
 * @param isOurFrame - Whether we're processing our own frame (vs counterparty's)
 * @param currentTimestamp - Current timestamp (for HTLC timelock validation)
 * @param currentHeight - Current J-block height (for HTLC revealBeforeHeight validation)
 * @returns Result with success, events, and optional error (may include secret/hashlock for HTLC routing)
 */
export async function processAccountTx(
  accountMachine: AccountMachine,
  accountTx: AccountTx,
  isOurFrame: boolean = true,
  currentTimestamp: number = 0,
  currentHeight: number = 0,
  isValidation: boolean = false
): Promise<{
  success: boolean;
  events: string[];
  error?: string;
  secret?: string;
  hashlock?: string;
  timedOutHashlock?: string;
  swapOfferCreated?: {
    offerId: string;
    makerIsLeft: boolean;
    fromEntity: string;
    toEntity: string;
    giveTokenId: number;
    giveAmount: bigint;
    wantTokenId: number;
    wantAmount: bigint;
    minFillRatio: number;
  };
  swapOfferCancelled?: { offerId: string; accountId: string; makerId?: string };
}> {
  // Derive counterparty from canonical left/right using proofHeader's fromEntity as "me"
  const myEntityId = accountMachine.proofHeader.fromEntity;
  const { counterparty } = getAccountPerspective(accountMachine, myEntityId);
  console.log(`ðŸ”„ Processing ${accountTx.type} for ${counterparty.slice(-4)} (ourFrame: ${isOurFrame})`);

  // Route to appropriate handler based on transaction type
  switch (accountTx.type) {
    case 'add_delta':
      return handleAddDelta(accountMachine, accountTx, isOurFrame);

    case 'set_credit_limit':
      return handleSetCreditLimit(accountMachine, accountTx, isOurFrame);

    case 'direct_payment':
      return handleDirectPayment(accountMachine, accountTx, isOurFrame);

    case 'account_payment':
      // Legacy type - not used in new implementation
      console.warn(`âš ï¸ account_payment type is deprecated`);
      return { success: true, events: [] };

    case 'account_settle':
      // Blockchain settlement - handled separately in entity-tx/handlers/account.ts
      console.log(`ðŸ’° account_settle processed externally`);
      return { success: true, events: [`âš–ï¸ Settlement processed`] };

    case 'reserve_to_collateral':
      return handleReserveToCollateral(accountMachine, accountTx as Extract<AccountTx, { type: 'reserve_to_collateral' }>);

    case 'request_withdrawal':
      return handleRequestWithdrawal(accountMachine, accountTx as Extract<AccountTx, { type: 'request_withdrawal' }>, isOurFrame);

    case 'approve_withdrawal':
      return handleApproveWithdrawal(accountMachine, accountTx as Extract<AccountTx, { type: 'approve_withdrawal' }>);

    case 'request_rebalance':
      return handleRequestRebalance(accountMachine, accountTx as Extract<AccountTx, { type: 'request_rebalance' }>);

    case 'j_sync':
      return handleJSync(accountMachine, accountTx as Extract<AccountTx, { type: 'j_sync' }>, isOurFrame);

    case 'j_event_claim': {
      // Bilateral J-event consensus: Store observation with correct left/right attribution
      const { jHeight, jBlockHash, events, observedAt } = accountTx.data;
      console.log(`ðŸ“¥ j_event_claim: jHeight=${jHeight}, hash=${jBlockHash.slice(0,10)}, isOurFrame=${isOurFrame}`);

      // Initialize consensus fields if missing
      if (!accountMachine.leftJObservations) accountMachine.leftJObservations = [];
      if (!accountMachine.rightJObservations) accountMachine.rightJObservations = [];
      if (!accountMachine.jEventChain) accountMachine.jEventChain = [];
      if (accountMachine.lastFinalizedJHeight === undefined) accountMachine.lastFinalizedJHeight = 0;

      // AUTH: Determine whose observation this is (2024 Transition.ts pattern)
      // isOurFrame = are WE the frame proposer? (like block.isLeft === channel.isLeft in 2024)
      const { iAmLeft, counterparty: cpId } = getAccountPerspective(accountMachine, myEntityId);

      // If isOurFrame=true: this is OUR claim (store in our side)
      // If isOurFrame=false: this is THEIR claim (store in their side)
      const claimIsFromLeft = isOurFrame ? iAmLeft : !iAmLeft;

      console.log(`   ðŸ” AUTH: iAmLeft=${iAmLeft}, isOurFrame=${isOurFrame}, claimIsFromLeft=${claimIsFromLeft}`);

      const obs = { jHeight, jBlockHash, events, observedAt };

      // Store observation with correct left/right attribution
      if (claimIsFromLeft) {
        accountMachine.leftJObservations.push(obs);
        console.log(`   ðŸ“ Stored LEFT obs (${accountMachine.leftJObservations.length} total)`);
      } else {
        accountMachine.rightJObservations.push(obs);
        console.log(`   ðŸ“ Stored RIGHT obs (${accountMachine.rightJObservations.length} total)`);
      }

      // CRITICAL: Only finalize during COMMIT (on real accountMachine), not VALIDATION (on clone)
      // Validation happens on clonedMachine which gets discarded - finalization would be lost!
      if (!isValidation) {
        const { tryFinalizeAccountJEvents } = await import('../entity-tx/j-events');
        tryFinalizeAccountJEvents(accountMachine, cpId, { timestamp: currentTimestamp });

        // DEBUG: Check if bilateral finalization persisted
        const delta = accountMachine.deltas.get(1); // USDC token
        console.log(`ðŸ” AFTER-BILATERAL-FINALIZE (isValidation=${isValidation}): collateral=${delta?.collateral || 0n}`);
      } else {
        console.log(`â­ï¸ SKIP-BILATERAL-FINALIZE: On validation clone, will finalize during commit`);
      }

      return { success: true, events: [`ðŸ“¥ J-event claim processed`] };
    }

    // === HTLC HANDLERS ===
    case 'htlc_lock':
      return await handleHtlcLock(
        accountMachine,
        accountTx as Extract<AccountTx, { type: 'htlc_lock' }>,
        isOurFrame,
        currentTimestamp,
        currentHeight,
        isValidation
      );

    case 'htlc_reveal':
      return await handleHtlcReveal(
        accountMachine,
        accountTx as Extract<AccountTx, { type: 'htlc_reveal' }>,
        isOurFrame,
        currentHeight,
        currentTimestamp
      );

    case 'htlc_timeout':
      return await handleHtlcTimeout(
        accountMachine,
        accountTx as Extract<AccountTx, { type: 'htlc_timeout' }>,
        isOurFrame,
        currentHeight,
        currentTimestamp
      );

    // === SWAP HANDLERS ===
    case 'swap_offer':
      return await handleSwapOffer(
        accountMachine,
        accountTx as Extract<AccountTx, { type: 'swap_offer' }>,
        isOurFrame,
        currentHeight,
        isValidation
      );

    case 'swap_resolve':
      return await handleSwapResolve(
        accountMachine,
        accountTx as Extract<AccountTx, { type: 'swap_resolve' }>,
        isOurFrame,
        currentHeight,
        isValidation
      );

    case 'swap_cancel':
      return await handleSwapCancel(
        accountMachine,
        accountTx as Extract<AccountTx, { type: 'swap_cancel' }>,
        isOurFrame,
        currentHeight,
        isValidation
      );

    case 'account_frame':
      // This should never be called - frames are handled by frame-level consensus
      console.error(`âŒ FATAL: account_frame should not be in accountTxs array!`);
      return { success: false, error: 'account_frame is not a transaction type', events: [] };

    default:
      // Type-safe error handling for unknown AccountTx types
      return { success: false, error: `Unknown accountTx type`, events: [] };
  }
}


//runtime/account-tx/handlers/add-delta.ts (42 lines)
/**
 * Add Delta Handler
 * Creates a new token delta with zero balances (Channel.ts AddDelta pattern)
 */

import { AccountMachine, AccountTx } from '../../types';
import { getAccountPerspective } from '../../state-helpers';

export function handleAddDelta(
  accountMachine: AccountMachine,
  accountTx: Extract<AccountTx, { type: 'add_delta' }>,
  _isOurFrame: boolean = true
): { success: boolean; events: string[]; error?: string } {
  const { tokenId } = accountTx.data;
  const events: string[] = [];

  // Check if delta already exists
  if (accountMachine.deltas.has(tokenId)) {
    console.warn(`âš ï¸ Delta for token ${tokenId} already exists, skipping add_delta`);
    return { success: true, events }; // Idempotent - not an error
  }

  // Create new delta with zero balances (matches Channel.ts AddDelta pattern)
  const newDelta = {
    tokenId,
    collateral: 0n,
    ondelta: 0n,
    offdelta: 0n,
    leftCreditLimit: 0n,
    rightCreditLimit: 0n,
    leftAllowance: 0n,
    rightAllowance: 0n,
  };

  accountMachine.deltas.set(tokenId, newDelta);
  const { counterparty } = getAccountPerspective(accountMachine, accountMachine.proofHeader.fromEntity);
  console.log(`âœ… Added delta for token ${tokenId} to account with ${counterparty.slice(-4)}`);

  events.push(`âž• Added token ${tokenId} to account`);
  return { success: true, events };
}


//runtime/routing/graph.ts (117 lines)
/**
 * Network Graph Structure for Payment Routing
 * Builds from gossip profiles to create routing graph
 */

import type { Profile } from '../gossip';

export interface ChannelEdge {
  from: string;
  to: string;
  tokenId: number;
  capacity: bigint;
  baseFee: bigint; // Base fee in smallest unit
  feePPM: number; // Fee rate in parts per million
  disabled: boolean;
}

export interface NetworkGraph {
  nodes: Set<string>; // Entity IDs
  edges: Map<string, ChannelEdge[]>; // from -> edges[]

  // Quick lookup for channel capacities
  channelCapacities: Map<string, {
    outbound: bigint;
    inbound: bigint;
  }>;
}

/**
 * Build network graph from gossip profiles
 */
export function buildNetworkGraph(
  profiles: Map<string, Profile>,
  tokenId: number
): NetworkGraph {
  const nodes = new Set<string>();
  const edges = new Map<string, ChannelEdge[]>();
  const channelCapacities = new Map<string, {
    outbound: bigint;
    inbound: bigint;
  }>();

  // Add all entities as nodes
  for (const profile of profiles.values()) {
    nodes.add(profile.entityId);
  }

  // Build edges from account relationships
  for (const profile of profiles.values()) {
    const fromEntity = profile.entityId;
    const fromEdges: ChannelEdge[] = [];

    if (profile.accounts) {
      for (const account of profile.accounts) {
        const toEntity = account.counterpartyId;

        // Only add if counterparty exists in network
        if (!nodes.has(toEntity)) continue;

        // Get capacities for this token
        const tokenCapacity = account.tokenCapacities.get(tokenId);
        if (!tokenCapacity || tokenCapacity.outCapacity === 0n) continue;

        // Get fee configuration from profile with explicit validation
        const metadata = profile.metadata;
        if (!metadata) {
          console.warn(`ðŸš¨ ROUTING-SAFETY: Entity ${fromEntity} has no metadata, using safe defaults`);
        }
        const baseFee = metadata?.baseFee ?? 0n; // Explicit null/undefined check
        const feePPM = metadata?.routingFeePPM ?? 100; // Explicit default: 100 PPM (0.01%)

        // Create edge
        const edge: ChannelEdge = {
          from: fromEntity,
          to: toEntity,
          tokenId,
          capacity: tokenCapacity.outCapacity,
          baseFee,
          feePPM,
          disabled: false,
        };

        fromEdges.push(edge);

        // Store channel capacities
        const channelKey = `${fromEntity}:${toEntity}:${tokenId}`;
        channelCapacities.set(channelKey, {
          outbound: tokenCapacity.outCapacity,
          inbound: tokenCapacity.inCapacity,
        });
      }
    }

    if (fromEdges.length > 0) {
      edges.set(fromEntity, fromEdges);
    }
  }

  return {
    nodes,
    edges,
    channelCapacities,
  };
}

/**
 * Get edge between two nodes
 */
export function getEdge(
  graph: NetworkGraph,
  from: string,
  to: string,
  tokenId: number
): ChannelEdge | undefined {
  const edges = graph.edges.get(from) ?? [];  // Explicit undefined handling
  return edges.find(e => e.to === to && e.tokenId === tokenId);
}

//runtime/routing/pathfinding.ts (227 lines)
/**
 * Dijkstra Pathfinding Implementation for Payment Routing
 * Finds optimal payment routes through the network
 */

import type { NetworkGraph, ChannelEdge } from './graph';
import { getEdge } from './graph';

export interface PaymentRoute {
  path: string[]; // Array of entity IDs from source to target
  hops: Array<{
    from: string;
    to: string;
    fee: bigint;
    feePPM: number;
  }>;
  totalFee: bigint;
  totalAmount: bigint; // Amount including fees
  probability: number; // Success probability estimate (0-1)
}

/**
 * Priority queue entry for Dijkstra
 */
interface QueueEntry {
  cost: bigint;
  node: string;
  path: string[];
  totalFee: bigint;
}

export class PathFinder {
  constructor(private graph: NetworkGraph) {}

  /**
   * Find payment routes using modified Dijkstra algorithm
   * Returns up to maxRoutes sorted by total fees
   */
  findRoutes(
    source: string,
    target: string,
    amount: bigint,
    tokenId: number,
    maxRoutes: number = 100
  ): PaymentRoute[] {
    if (source === target) return [];
    if (!this.graph.nodes.has(source) || !this.graph.nodes.has(target)) return [];

    const routes: PaymentRoute[] = [];
    const visited = new Map<string, Set<string>>(); // node -> set of previous nodes

    // Priority queue: [cost, node, path, totalFee]
    const queue: QueueEntry[] = [{
      cost: 0n,
      node: source,
      path: [source],
      totalFee: 0n,
    }];

    while (queue.length > 0 && routes.length < maxRoutes) {
      // Sort by cost (simple priority queue)
      queue.sort((a, b) => {
        if (a.cost < b.cost) return -1;
        if (a.cost > b.cost) return 1;
        return 0;
      });

      const current = queue.shift()!;

      // Check if we've visited this node from this previous node
      const prevNode = current.path[current.path.length - 2] || 'START';
      const visitedFrom = visited.get(current.node) || new Set();
      if (visitedFrom.has(prevNode)) continue;
      visitedFrom.add(prevNode);
      visited.set(current.node, visitedFrom);

      // Found target - build route
      if (current.node === target) {
        const route = this.buildRoute(current.path, amount, tokenId);
        if (route) {
          routes.push(route);
        }
        continue;
      }

      // Explore neighbors
      const edges = this.graph.edges.get(current.node) ?? []; // Explicit undefined handling
      for (const edge of edges) {
        // Skip if wrong token or disabled
        if (edge.tokenId !== tokenId || edge.disabled) continue;

        // Skip if already in path (no loops)
        if (current.path.includes(edge.to)) continue;

        // Calculate required amount at this hop (working backwards)
        const requiredAmount = this.calculateRequiredAmount(
          amount,
          [...current.path, edge.to],
          target,
          tokenId
        );

        // Skip if insufficient capacity
        if (requiredAmount > edge.capacity) continue;

        // Calculate fee for this edge
        const edgeFee = this.calculateFee(edge, requiredAmount);
        const newTotalFee = current.totalFee + edgeFee;

        // Add to queue with updated cost
        queue.push({
          cost: newTotalFee, // Use total fee as cost
          node: edge.to,
          path: [...current.path, edge.to],
          totalFee: newTotalFee,
        });
      }
    }

    // Sort routes by total fee
    return routes.sort((a, b) => {
      if (a.totalFee < b.totalFee) return -1;
      if (a.totalFee > b.totalFee) return 1;
      return 0;
    });
  }

  /**
   * Calculate fee for an edge
   */
  private calculateFee(edge: ChannelEdge, amount: bigint): bigint {
    // Fee = baseFee + (amount * feePPM / 1,000,000)
    const proportionalFee = (amount * BigInt(edge.feePPM)) / 1_000_000n;
    return edge.baseFee + proportionalFee;
  }

  /**
   * Calculate required amount at each hop (working backwards from target)
   */
  private calculateRequiredAmount(
    finalAmount: bigint,
    path: string[],
    target: string,
    tokenId: number
  ): bigint {
    let amount = finalAmount;

    // Work backwards from target to source
    for (let i = path.length - 1; i > 0; i--) {
      if (path[i] === target) continue; // Skip target node

      const edge = getEdge(this.graph, path[i - 1]!, path[i]!, tokenId);
      if (edge) {
        // Add fee that this hop will charge
        amount = amount + this.calculateFee(edge, amount);
      }
    }

    return amount;
  }

  /**
   * Build complete route details from path
   */
  private buildRoute(
    path: string[],
    amount: bigint,
    tokenId: number
  ): PaymentRoute | null {
    if (path.length < 2) return null;

    const hops: PaymentRoute['hops'] = [];
    let totalFee = 0n;
    let currentAmount = amount;

    // Build hops forward, calculating fees
    for (let i = 0; i < path.length - 1; i++) {
      const edge = getEdge(this.graph, path[i]!, path[i + 1]!, tokenId);
      if (!edge) return null;

      const fee = this.calculateFee(edge, currentAmount);
      hops.push({
        from: path[i]!,
        to: path[i + 1]!,
        fee,
        feePPM: edge.feePPM,
      });

      totalFee += fee;
      currentAmount += fee; // Next hop needs more to cover this fee
    }

    // Calculate success probability
    const probability = this.calculateProbability(path, amount, tokenId);

    return {
      path,
      hops,
      totalFee,
      totalAmount: amount + totalFee,
      probability,
    };
  }

  /**
   * Calculate success probability based on channel utilization
   */
  private calculateProbability(
    path: string[],
    amount: bigint,
    tokenId: number
  ): number {
    let probability = 1.0;

    for (let i = 0; i < path.length - 1; i++) {
      const edge = getEdge(this.graph, path[i]!, path[i + 1]!, tokenId);
      if (edge && edge.capacity > 0n) {
        const utilization = Number(amount) / Number(edge.capacity);
        // Higher utilization = lower success probability
        // Using exponential decay: e^(-2 * utilization)
        probability *= Math.exp(-2 * utilization);
      }
    }

    return Math.max(0.01, Math.min(1.0, probability));
  }
}

//runtime/account-crypto.ts (397 lines)
/**
 * Real cryptographic signatures for account consensus
 * Uses secp256k1 (Ethereum standard) with HMAC-derived keys from BrainVault seed
 */

import * as secp256k1 from '@noble/secp256k1';
import { hmac } from '@noble/hashes/hmac.js';
import { sha256 } from '@noble/hashes/sha2.js';
import { concatBytes } from '@noble/hashes/utils.js';
import { keccak256 } from 'ethers';

// Configure @noble/secp256k1 HMAC (required for signing)
// Always install a sync HMAC implementation (Node/Bun fast path, browser fallback).
const installHmacSync = () => {
  if (secp256k1.utils.hmacSha256Sync) return;
  const isBrowser =
    typeof window !== 'undefined' &&
    typeof window.document !== 'undefined';
  const isNodeLike =
    !isBrowser &&
    (typeof (globalThis as any).Bun !== 'undefined' ||
      (typeof process !== 'undefined' && !!process.versions?.node));
  try {
    if (isNodeLike && typeof require !== 'undefined') {
      const crypto = require('crypto');
      if (crypto && typeof crypto.createHmac === 'function') {
        secp256k1.utils.hmacSha256Sync = (key: Uint8Array, ...messages: Uint8Array[]) => {
          const hmac = crypto.createHmac('sha256', Buffer.from(key));
          for (const msg of messages) hmac.update(Buffer.from(msg));
          return new Uint8Array(hmac.digest());
        };
        return;
      }
    }
  } catch (e) {
    console.warn('Failed to configure secp256k1 HMAC via crypto:', e);
  }
  secp256k1.utils.hmacSha256Sync = (key: Uint8Array, ...messages: Uint8Array[]) => {
    return hmac(sha256, key, concatBytes(...messages));
  };
};
installHmacSync();
// Browser: deriveSignerKeySync uses noble hashes (no async required)

// Global key cache (signerId â†’ private/public key)
// Populated by runtime when BrainVault seed is provided
const signerKeys = new Map<string, Uint8Array>();
const signerPublicKeys = new Map<string, Uint8Array>();
const signerAddresses = new Map<string, string>();
const externalPublicKeys = new Map<string, Uint8Array>();
let runtimeSeedBytes: Uint8Array | null = null;
let runtimeSeedLocked = false;
const textEncoder = new TextEncoder();

const toSeedBytes = (seed: Uint8Array | string): Uint8Array =>
  typeof seed === 'string' ? textEncoder.encode(seed) : seed;

/**
 * Derive signer private key from BrainVault master seed
 * Formula: privateKey = HMAC-SHA256(masterSeed, signerId)
 * Browser-compatible (pure JS HMAC) and Node-compatible
 */
export async function deriveSignerKey(masterSeed: Uint8Array, signerId: string): Promise<Uint8Array> {
  return deriveSignerKeySync(masterSeed, signerId);
}

export function deriveSignerKeySync(masterSeed: Uint8Array, signerId: string): Uint8Array {
  const message = textEncoder.encode(signerId);
  return hmac(sha256, masterSeed, message);
}

export function setRuntimeSeed(seed: Uint8Array | string | null): void {
  if (runtimeSeedLocked) {
    console.warn('âš ï¸ Runtime seed update ignored (crypto lock enabled)');
    return;
  }
  runtimeSeedBytes = seed ? toSeedBytes(seed) : null;
  signerKeys.clear();
  signerPublicKeys.clear();
  signerAddresses.clear();
  externalPublicKeys.clear();
}

export function lockRuntimeSeedUpdates(locked: boolean): void {
  runtimeSeedLocked = locked;
}

const getOrDeriveKey = (envSeed: Uint8Array, signerId: string): Uint8Array => {
  console.log(`ðŸ” getOrDeriveKey: signerId=${signerId.slice(-4)}`);
  const cached = signerKeys.get(signerId);
  if (cached) {
    console.log(`âœ… Found cached key for ${signerId.slice(-4)}`);
    return cached;
  }
  console.log(`âš ï¸ No cached key for ${signerId.slice(-4)}, deriving from env.runtimeSeed...`);

  // PURE: ONLY use env seed, NEVER fall back to global
  if (!envSeed) {
    throw new Error(`CRYPTO_DETERMINISM_VIOLATION: getOrDeriveKey called without env.runtimeSeed for signer ${signerId}`);
  }
  console.log(`âœ… Deriving key from env seed (${envSeed.length} bytes)`);
  const derived = deriveSignerKeySync(envSeed, signerId);
  registerSignerKey(signerId, derived);
  console.log(`âœ… Derived and registered key for ${signerId.slice(-4)}`);
  return derived;
};

/**
 * Get cached signer private key (no derivation, cache-only)
 * Used by components like BrowserVM that don't have env access
 */
export function getCachedSignerPrivateKey(signerId: string): Uint8Array | null {
  return signerKeys.get(signerId) || null;
}

/**
 * Get cached signer public key (no derivation, cache-only)
 * Used by components that don't have env access
 */
export function getCachedSignerPublicKey(signerId: string): Uint8Array | null {
  const external = externalPublicKeys.get(signerId);
  if (external) return external;
  const cached = signerPublicKeys.get(signerId);
  if (cached) return cached;
  // Try deriving from cached private key
  const privateKey = signerKeys.get(signerId);
  if (!privateKey) return null;
  const publicKey = secp256k1.getPublicKey(privateKey);
  signerPublicKeys.set(signerId, publicKey);
  return publicKey;
}

/**
 * Get cached signer address (no derivation, cache-only)
 * Used by components that don't have env access
 */
export function getCachedSignerAddress(signerId: string): string | null {
  const cached = signerAddresses.get(signerId);
  if (cached) return cached;
  // Try deriving from cached private key
  const privateKey = signerKeys.get(signerId);
  if (!privateKey) return null;
  const address = privateKeyToAddress(privateKey);
  signerAddresses.set(signerId, address);
  return address;
}

// Export for hanko-signing.ts
export function getSignerPrivateKey(env: any, signerId: string): Uint8Array {
  if (!env?.runtimeSeed) {
    throw new Error(`CRYPTO_DETERMINISM_VIOLATION: getSignerPrivateKey called without env.runtimeSeed for signer ${signerId}`);
  }
  const seed = textEncoder.encode(env.runtimeSeed);
  return getOrDeriveKey(seed, signerId);
}

export function getSignerPublicKey(env: any, signerId: string): Uint8Array | null {
  const external = externalPublicKeys.get(signerId);
  if (external) return external;
  const cached = signerPublicKeys.get(signerId);
  if (cached) return cached;

  // Try cached private key first
  const cachedPrivateKey = signerKeys.get(signerId);
  if (cachedPrivateKey) {
    const publicKey = secp256k1.getPublicKey(cachedPrivateKey);
    signerPublicKeys.set(signerId, publicKey);
    return publicKey;
  }

  // Derive from env if available
  if (!env?.runtimeSeed) {
    return null;
  }
  const seed = textEncoder.encode(env.runtimeSeed);
  const privateKey = getOrDeriveKey(seed, signerId);
  const publicKey = secp256k1.getPublicKey(privateKey);
  signerPublicKeys.set(signerId, publicKey);
  return publicKey;
}

const privateKeyToAddress = (privateKey: Uint8Array): string => {
  const publicKey = secp256k1.getPublicKey(privateKey, false); // uncompressed 65 bytes
  const hash = keccak256(publicKey.slice(1));
  return `0x${hash.slice(-40)}`.toLowerCase();
};

export function deriveSignerAddressSync(seed: Uint8Array | string, signerId: string): string {
  const seedBytes = toSeedBytes(seed);
  const privateKey = deriveSignerKeySync(seedBytes, signerId);
  return privateKeyToAddress(privateKey);
}

export function getSignerAddress(env: any, signerId: string): string | null {
  const cached = signerAddresses.get(signerId);
  if (cached) return cached;

  // Try cached private key first
  const cachedPrivateKey = signerKeys.get(signerId);
  if (cachedPrivateKey) {
    const address = privateKeyToAddress(cachedPrivateKey);
    signerAddresses.set(signerId, address);
    return address;
  }

  // Derive from env if available
  if (!env?.runtimeSeed) {
    return null;
  }
  const seed = textEncoder.encode(env.runtimeSeed);
  const privateKey = getOrDeriveKey(seed, signerId);
  const address = privateKeyToAddress(privateKey);
  signerAddresses.set(signerId, address);
  return address;
}

/**
 * Register signer keys derived from a deterministic seed
 * Formula: privateKey = HMAC-SHA256(seed, signerId)
 */
export async function registerSeededKeys(
  seed: Uint8Array | string,
  signerIds: string[]
): Promise<void> {
  const seedBytes = toSeedBytes(seed);
  setRuntimeSeed(seedBytes);

  for (const signerId of signerIds) {
    const privateKey = await deriveSignerKey(seedBytes, signerId);
    registerSignerKey(signerId, privateKey);
  }

  console.log(`ðŸ”‘ Registered ${signerIds.length} keys from seed`);
}

/**
 * Register signer keys (called when BrainVault unlocked)
 */
export function registerSignerKey(signerId: string, privateKey: Uint8Array): void {
  signerKeys.set(signerId, privateKey);
  signerPublicKeys.set(signerId, secp256k1.getPublicKey(privateKey));
  signerAddresses.set(signerId, privateKeyToAddress(privateKey));
}

export function registerSignerPublicKey(signerId: string, publicKey: Uint8Array | string): void {
  console.log(`ðŸ“ registerSignerPublicKey: signerId=${signerId.slice(-4)}, publicKey type=${typeof publicKey}`);
  if (signerKeys.has(signerId)) {
    console.log(`âš ï¸ signerId ${signerId.slice(-4)} already has private key, skipping public key registration`);
    return;
  }
  const bytes =
    typeof publicKey === 'string'
      ? Uint8Array.from(Buffer.from(publicKey.replace(/^0x/, ''), 'hex'))
      : publicKey;
  console.log(`ðŸ“ Public key bytes: ${bytes.length}`);
  externalPublicKeys.set(signerId, bytes);
  signerPublicKeys.delete(signerId);
  console.log(`âœ… Registered external public key for ${signerId.slice(-4)}, total: ${externalPublicKeys.size}`);
}

/**
 * Register test keys for scenarios (deterministic test keys from signerId)
 * Used in CLI scenarios when BrainVault not available
 */
export async function registerTestKeys(signerIds: string[]): Promise<void> {
  const testMasterSeed = new Uint8Array(32);
  testMasterSeed.fill(42); // Deterministic test seed
  setRuntimeSeed(testMasterSeed);

  // Use registerSeededKeys but suppress its log (we log our own below)
  const seedBytes = testMasterSeed;
  for (const signerId of signerIds) {
    const privateKey = await deriveSignerKey(seedBytes, signerId);
    registerSignerKey(signerId, privateKey);
  }
  console.log(`ðŸ”‘ Registered ${signerIds.length} test keys (deterministic from signerId)`);
}

/**
 * Clear all registered keys (for testing isolation)
 */
export function clearSignerKeys(): void {
  signerKeys.clear();
  signerPublicKeys.clear();
  externalPublicKeys.clear();
}

/**
 * Sign account frame using secp256k1
 * Returns: 65-byte signature (r + s + recovery)
 */
export function signAccountFrame(
  env: any,
  signerId: string,
  frameHash: string
): string {
  if (!env?.runtimeSeed) {
    throw new Error(`CRYPTO_DETERMINISM_VIOLATION: signAccountFrame called without env.runtimeSeed for signer ${signerId}`);
  }
  const seed = textEncoder.encode(env.runtimeSeed);

  console.log(`ðŸ”‘ signAccountFrame CALLED: signerId=${signerId.slice(-4)}, frameHash=${frameHash.slice(0, 10)}, source=env`);
  console.log(`ðŸ”‘ Available signerKeys:`, Array.from(signerKeys.keys()).map(k => k.slice(-4)));
  console.log(`ðŸ”‘ Available signerPublicKeys:`, Array.from(signerPublicKeys.keys()).map(k => k.slice(-4)));

  const messageHash = keccak256(Buffer.from(frameHash.replace('0x', ''), 'hex'));
  const signature = signDigest(seed, signerId, messageHash);
  console.log(`âœï¸ Signed frame ${frameHash.slice(0, 10)} by ${signerId.slice(-4)}: ${signature.slice(0, 20)}...`);
  return signature;
}

export function signDigest(seed: Uint8Array, signerId: string, digestHex: string): string {
  installHmacSync();

  const privateKey = getOrDeriveKey(seed, signerId);

  const messageBytes = Buffer.from(digestHex.replace('0x', ''), 'hex');
  const [signature, recovery] = secp256k1.signSync(messageBytes, privateKey, { recovered: true, der: false });
  const sigHex = Buffer.from(signature).toString('hex') + recovery.toString(16).padStart(2, '0');
  return `0x${sigHex}`;
}

/**
 * Verify account signature using secp256k1
 */
export function verifyAccountSignature(
  env: any,
  signerId: string,
  frameHash: string,
  signature: string
): boolean {
  // Real signature verification
  console.log(`ðŸ” VERIFY: signerId=${signerId.slice(-4)}, frameHash=${frameHash.slice(0, 10)}, sig=${signature.slice(0, 20)}...`);
  const publicKey = getSignerPublicKey(env, signerId);
  if (!publicKey) {
    console.warn(`âš ï¸ Cannot verify - no public key for signerId=${signerId.slice(-4)}`);
    console.warn(`âš ï¸ Available keys:`, Array.from(signerPublicKeys.keys()).map(k => k.slice(-4)));
    console.warn(`âš ï¸ Available external keys:`, Array.from(externalPublicKeys.keys()).map(k => k.slice(-4)));
    return false;
  }
  console.log(`âœ… Found public key for ${signerId.slice(-4)} (${publicKey.length} bytes)`);

  try {
    // Extract compact signature (64 bytes) from hex
    const sigHex = signature.replace('0x', '');
    const sigBytes = Buffer.from(sigHex.slice(0, 128), 'hex'); // First 64 bytes (r + s)

    // Hash the frame hash
    const messageHash = keccak256(Buffer.from(frameHash.replace('0x', ''), 'hex'));
    const messageBytes = Buffer.from(messageHash.replace('0x', ''), 'hex');

    // Verify signature using @noble/secp256k1
    const isValid = secp256k1.verify(sigBytes, messageBytes, publicKey);

    if (isValid) {
      console.log(`âœ… Valid signature from ${signerId.slice(-4)} for frame ${frameHash.slice(0, 10)}`);
    } else {
      console.log(`âŒ Invalid signature from ${signerId.slice(-4)} for frame ${frameHash.slice(0, 10)}`);
    }

    return isValid;
  } catch (error) {
    console.error(`âŒ Signature verification error for ${signerId.slice(-4)}:`, error);
    return false;
  }
}

/**
 * Validate multiple signatures for account frame
 */
export function validateAccountSignatures(
  env: any,
  frameHash: string,
  signatures: string[],
  expectedSigners: string[]
): { valid: boolean; validSigners: string[] } {
  const validSigners: string[] = [];
  const remaining = new Set(expectedSigners);

  for (const signature of signatures) {
    for (const signer of Array.from(remaining)) {
      const isValid = verifyAccountSignature(env, signer, frameHash, signature);
      if (isValid) {
        validSigners.push(signer);
        remaining.delete(signer);
        break;
      }
    }
  }

  const allValid = validSigners.length === expectedSigners.length;

  console.log(`ðŸ” Signature validation: ${validSigners.length}/${expectedSigners.length} valid (${allValid ? 'PASS' : 'FAIL'})`);

  return { valid: allValid, validSigners };
}


//runtime/state-helpers.ts (675 lines)
/**
 * XLN State Management Helpers
 * Utilities for entity replica cloning, snapshots, and state persistence
 */

import { encode } from './snapshot-coder';
import type { EntityInput, EntityReplica, EntityState, Env, EnvSnapshot, RuntimeInput, AccountMachine, JReplica, LogCategory, BrowserVMState } from './types';
import type { Profile } from './gossip';
import { DEBUG } from './utils';
import { validateEntityState } from './validation-utils';
import { safeStringify, safeParse } from './serialization-utils';
import { isLeftEntity } from './entity-id-utils';

// Message size limit for snapshot efficiency
const MESSAGE_LIMIT = 10;

/**
 * CANONICAL ACCOUNT KEY: Bilateral accounts stored in sorted form (left < right)
 * Pattern from Channel.ts - ensures both entities reference SAME account object
 */
export function canonicalAccountKey(entity1: string, entity2: string): string {
  return isLeftEntity(entity1, entity2) ? `${entity1}:${entity2}` : `${entity2}:${entity1}`;
}

/**
 * Get account perspective: Am I left or right? Derive from/to for current operation.
 */
export function getAccountPerspective(account: AccountMachine, myEntityId: string): {
  iAmLeft: boolean;
  from: string;
  to: string;
  counterparty: string;
} {
  const iAmLeft = myEntityId === account.leftEntity;
  return {
    iAmLeft,
    from: iAmLeft ? account.leftEntity : account.rightEntity,
    to: iAmLeft ? account.rightEntity : account.leftEntity,
    counterparty: iAmLeft ? account.rightEntity : account.leftEntity,
  };
}

/**
 * Add message to EntityState with automatic size limiting
 * Prevents unbounded message array growth that causes snapshot bloat
 */
export function addMessage(state: EntityState, message: string): void {
  state.messages.push(message);
  if (state.messages.length > MESSAGE_LIMIT) {
    state.messages.shift(); // Remove oldest message
  }
}

/**
 * Add multiple messages with size limiting
 */
export function addMessages(state: EntityState, messages: string[]): void {
  for (const msg of messages) {
    addMessage(state, msg);
  }
}

/**
 * Emit structured events with a scoped path for time-travel debugging.
 * This keeps per-frame logs queryable without bloating state.messages.
 */
export function emitScopedEvents(
  env: Env,
  category: LogCategory,
  scope: string,
  messages: string[],
  data: Record<string, unknown> = {},
  entityId?: string,
): void {
  if (!messages || messages.length === 0) return;

  const payload = { path: scope, ...data };
  for (const message of messages) {
    env.info(category, message, payload, entityId);
  }
}

/**
 * Resolve the proposer signerId for a given entity.
 * Prefers local proposer replica, then local config validators[0], then gossip board[0].
 * Throws if no signer can be resolved (fail early).
 */
export function resolveEntityProposerId(env: Env, entityId: string, context: string): string {
  let fallback: string | null = null;

  for (const replica of env.eReplicas.values()) {
    if (replica.entityId !== entityId) continue;
    if (replica.isProposer) return replica.signerId;
    if (!fallback) {
      fallback = replica.state.config.validators[0] || replica.signerId;
    }
  }

  if (env.gossip?.getProfiles) {
    const profile = (env.gossip.getProfiles() as Profile[]).find(p => p.entityId === entityId);
    const board = profile?.metadata?.board;
    if (Array.isArray(board) && board.length > 0) {
      return board[0];
    }
    if (board && !Array.isArray(board) && Array.isArray(board.validators) && board.validators.length > 0) {
      const first = board.validators[0];
      if (first?.signerId) return first.signerId;
      if (first?.signer) return first.signer;
    }
  }

  if (fallback) return fallback;

  throw new Error(`SIGNER_RESOLUTION_FAILED: ${context} entityId=${entityId}`);
}

// === CLONING UTILITIES ===
export const cloneMap = <K, V>(map: Map<K, V>) => new Map(map);
export const cloneArray = <T>(arr: T[]) => [...arr];

/**
 * Creates a safe deep clone of entity state with guaranteed jBlock preservation
 * This prevents the jBlock corruption bugs that occur with manual state spreading
 */
export function cloneEntityState(entityState: EntityState, forSnapshot: boolean = false): EntityState {
  // Use structuredClone for deep cloning with fallback
  try {
    const cloned = structuredClone(entityState);

    // CRITICAL: Validate entityId was preserved correctly
    if (!cloned.entityId || cloned.entityId !== entityState.entityId) {
      cloned.entityId = entityState.entityId; // Force preserve entityId
    }

    // CRITICAL: Validate lastFinalizedJHeight was preserved correctly
    if (typeof cloned.lastFinalizedJHeight !== 'number') {
      console.error(`ðŸ’¥ CLONE-CORRUPTION: structuredClone corrupted lastFinalizedJHeight!`);
      console.error(`ðŸ’¥   Original: ${entityState.lastFinalizedJHeight} (${typeof entityState.lastFinalizedJHeight})`);
      console.error(`ðŸ’¥   Cloned: ${cloned.lastFinalizedJHeight} (${typeof cloned.lastFinalizedJHeight})`);
      cloned.lastFinalizedJHeight = entityState.lastFinalizedJHeight ?? 0; // Force fix
    }

    // For snapshots, remove clonedForValidation from all accounts to avoid cycles
    if (forSnapshot) {
      for (const account of cloned.accounts.values()) {
        delete (account as any).clonedForValidation;
      }
    }

    // VALIDATE AT SOURCE: Guarantee type safety from this point forward
    return validateEntityState(cloned, 'cloneEntityState.structuredClone');
  } catch (error) {
    // structuredClone warning removed - browser limitation, not actionable
    const manual = manualCloneEntityState(entityState, forSnapshot);

    // VALIDATE AT SOURCE: Guarantee type safety from manual clone path too
    return validateEntityState(manual, 'cloneEntityState.manual');
  }
}

/**
 * Manual entity state cloning with explicit jBlock preservation
 * Fallback for environments that don't support structuredClone
 */
function manualCloneEntityState(entityState: EntityState, forSnapshot: boolean = false): EntityState {
  return {
    ...entityState,
    entityId: entityState.entityId, // CRITICAL: Explicitly preserve entityId
    nonces: cloneMap(entityState.nonces),
    messages: cloneArray(entityState.messages),
    proposals: new Map(
      Array.from(entityState.proposals.entries()).map(([id, proposal]) => [
        id,
        { ...proposal, votes: cloneMap(proposal.votes) },
      ]),
    ),
    reserves: cloneMap(entityState.reserves),
    accounts: new Map(
      Array.from(entityState.accounts.entries()).map(([id, account]) => [
        id,
        cloneAccountMachine(account, forSnapshot), // forSnapshot excludes clonedForValidation
      ]),
    ),
    deferredAccountProposals: cloneMap(entityState.deferredAccountProposals || new Map()),
    accountInputQueue: cloneArray(entityState.accountInputQueue || []),
    // JBlock consensus state
    lastFinalizedJHeight: entityState.lastFinalizedJHeight ?? 0,
    jBlockObservations: cloneArray(entityState.jBlockObservations || []),
    jBlockChain: cloneArray(entityState.jBlockChain || []),
    // HTLC routing table (deep clone)
    htlcRoutes: new Map(
      Array.from((entityState.htlcRoutes || new Map()).entries()).map(([hashlock, route]) => [
        hashlock,
        { ...route } // Clone route object
      ])
    ),
    htlcFeesEarned: entityState.htlcFeesEarned || 0n,
    // Orderbook extension (hub-only, contains TypedArrays)
    // Must manually clone since structuredClone failed (we're in fallback path)
    ...(entityState.orderbookExt && { orderbookExt: cloneOrderbookExt(entityState.orderbookExt) }),
    // Aggregated books (E-Machine view of A-Machine positions)
    swapBook: new Map(
      Array.from((entityState.swapBook || new Map()).entries()).map(([id, entry]) => [
        id,
        { ...entry }
      ])
    ),
    lockBook: new Map(
      Array.from((entityState.lockBook || new Map()).entries()).map(([id, entry]) => [
        id,
        { ...entry }
      ])
    ),
    pendingSwapFillRatios: new Map(
      Array.from((entityState.pendingSwapFillRatios || new Map()).entries())
    ),
  };
}

/**
 * Manually clone OrderbookExtState for environments without structuredClone
 * TypedArrays must be explicitly copied via their constructors
 */
function cloneOrderbookExt(ext: EntityState['orderbookExt']): EntityState['orderbookExt'] {
  if (!ext) return undefined;

  const clonedBooks = new Map<string, any>();
  for (const [key, book] of ext.books) {
    clonedBooks.set(key, cloneBookState(book));
  }

  // Clone referrals Map
  const clonedReferrals = new Map<string, any>();
  if (ext.referrals) {
    for (const [key, referral] of ext.referrals) {
      clonedReferrals.set(key, { ...referral });
    }
  }

  // Clone hubProfile with nested arrays
  const clonedHubProfile = ext.hubProfile ? {
    ...ext.hubProfile,
    supportedPairs: ext.hubProfile.supportedPairs ? [...ext.hubProfile.supportedPairs] : [],
  } : undefined;

  return {
    books: clonedBooks,
    referrals: clonedReferrals,
    hubProfile: clonedHubProfile,
  };
}

/**
 * Clone a BookState with TypedArrays properly copied
 */
function cloneBookState(book: any): any {
  return {
    ...book,
    // Clone TypedArrays via slice() which creates new underlying ArrayBuffer
    orderPriceIdx: book.orderPriceIdx?.slice?.() ?? book.orderPriceIdx,
    orderQtyLots: book.orderQtyLots?.slice?.() ?? book.orderQtyLots,
    orderOwnerIdx: book.orderOwnerIdx?.slice?.() ?? book.orderOwnerIdx,
    orderSide: book.orderSide?.slice?.() ?? book.orderSide,
    orderPrev: book.orderPrev?.slice?.() ?? book.orderPrev,
    orderNext: book.orderNext?.slice?.() ?? book.orderNext,
    orderActive: book.orderActive?.slice?.() ?? book.orderActive,
    levelHeadBid: book.levelHeadBid?.slice?.() ?? book.levelHeadBid,
    levelTailBid: book.levelTailBid?.slice?.() ?? book.levelTailBid,
    levelHeadAsk: book.levelHeadAsk?.slice?.() ?? book.levelHeadAsk,
    levelTailAsk: book.levelTailAsk?.slice?.() ?? book.levelTailAsk,
    bitmapBid: book.bitmapBid?.slice?.() ?? book.bitmapBid,
    bitmapAsk: book.bitmapAsk?.slice?.() ?? book.bitmapAsk,
    // Clone mutable reference types
    owners: [...(book.owners || [])],
    orderIds: [...(book.orderIds || [])],
    orderIdToIdx: new Map(book.orderIdToIdx || []),
    ownerToIdx: new Map(book.ownerToIdx || []),
  };
}

/**
 * Deep clone entity replica with all nested state properly cloned
 * Uses cloneEntityState as the entry point for state cloning
 */
export const cloneEntityReplica = (replica: EntityReplica, forSnapshot: boolean = false): EntityReplica => {
  return {
    entityId: replica.entityId,
    signerId: replica.signerId,
    state: cloneEntityState(replica.state, forSnapshot), // forSnapshot excludes clonedForValidation
    mempool: cloneArray(replica.mempool),
    ...(replica.proposal && {
      proposal: {
        height: replica.proposal.height,
        txs: cloneArray(replica.proposal.txs),
        hash: replica.proposal.hash,
        newState: replica.proposal.newState,
        signatures: cloneMap(replica.proposal.signatures),
      }
    }),
    ...(replica.lockedFrame && {
      lockedFrame: {
        height: replica.lockedFrame.height,
        txs: cloneArray(replica.lockedFrame.txs),
        hash: replica.lockedFrame.hash,
        newState: replica.lockedFrame.newState,
        signatures: cloneMap(replica.lockedFrame.signatures),
      }
    }),
    isProposer: replica.isProposer,
    ...(replica.sentTransitions !== undefined && { sentTransitions: replica.sentTransitions }),
    ...(replica.position && { position: { ...replica.position } }),
  };
};

export const captureSnapshot = async (
  env: Env,
  envHistory: EnvSnapshot[],
  db: any,
  runtimeInput: RuntimeInput,
  runtimeOutputs: EntityInput[],
  description: string,
): Promise<void> => {
  // Snapshots ALWAYS happen - they're essential for time-travel debugging
  // Use env.frameDisplayMs to hint how long to display important frames

  // Solvency check if set (from scenarios)
  if (env.extra?.expectedSolvency !== undefined) {
    const { checkSolvency } = await import('./scenarios/solvency-check');
    checkSolvency(env, env.extra.expectedSolvency, `Frame ${envHistory.length}`);
  }

  const gossipProfiles = env.gossip?.getProfiles
    ? env.gossip.getProfiles().map((profile: Profile) => {
        try {
          // structuredClone keeps nested data without mutating live gossip state
          return structuredClone(profile);
        } catch (error) {
          try {
            return safeParse(safeStringify(profile));
          } catch {
            return profile;
          }
        }
      })
    : [];

  // Capture fresh stateRoot from BrowserVM for time-travel (if available)
  let freshStateRoot: Uint8Array | null = null;
  let browserVMState: BrowserVMState | null = null;
  if (env.jReplicas) {
    try {
      const { getBrowserVMInstance } = await import('./evm');
      const browserVM = getBrowserVMInstance(env);
      if (browserVM?.captureStateRoot) {
        freshStateRoot = await browserVM.captureStateRoot();
        // Update live jReplicas so next snapshot has correct base
        for (const [, jReplica] of env.jReplicas.entries()) {
          jReplica.stateRoot = freshStateRoot;
        }
      }
      if (browserVM?.serializeState) {
        browserVMState = await browserVM.serializeState();
      }
    } catch {
      // Silent fail - stateRoot capture is optional
    }
  }

  // Clone jReplicas (J-layer state) + SYNC reserves/collaterals from eReplicas for time travel
  const jReplicas: JReplica[] = env.jReplicas
    ? Array.from(env.jReplicas.values()).map(jr => {
        // Sync reserves from eReplicas into JReplica snapshot
        const reserves = new Map<string, Map<number, bigint>>();
        const registeredEntities = new Map<string, { name: string; quorum: string[]; threshold: number }>();
        // Collaterals: channelKey â†’ tokenId â†’ { collateral, ondelta }
        const collaterals = new Map<string, Map<number, { collateral: bigint; ondelta: bigint }>>();

        // Aggregate reserves and collaterals from all entity replicas
        for (const [key, replica] of env.eReplicas.entries()) {
          const entityId = key.split(':')[0];
          if (replica.state?.reserves) {
            const tokenMap = new Map<number, bigint>();
            // Handle both Map and plain object
            if (replica.state.reserves instanceof Map) {
              replica.state.reserves.forEach((amount: bigint, tokenId: string) => {
                tokenMap.set(Number(tokenId), amount);
              });
            } else {
              for (const [tokenId, amount] of Object.entries(replica.state.reserves as Record<string, bigint>)) {
                tokenMap.set(Number(tokenId), BigInt(amount));
              }
            }
            if (tokenMap.size > 0) {
              reserves.set(entityId, tokenMap);
            }
          }

          // Extract collaterals from bilateral accounts (only for LEFT entity to avoid duplicates)
          if (replica.state?.accounts) {
            for (const [counterpartyId, account] of replica.state.accounts.entries()) {
              // Only capture from LEFT entity (smaller ID) to avoid duplicates
              if (isLeftEntity(entityId, counterpartyId) && account.deltas) {
                // Create channel key: LEFT-RIGHT (canonical ordering)
                const channelKey = `${entityId.slice(-4)}-${counterpartyId.slice(-4)}`;
                const tokenMap = new Map<number, { collateral: bigint; ondelta: bigint }>();

                for (const [tokenId, delta] of account.deltas.entries()) {
                  if (delta.collateral > 0n || delta.ondelta !== 0n) {
                    tokenMap.set(Number(tokenId), {
                      collateral: delta.collateral,
                      ondelta: delta.ondelta,
                    });
                  }
                }

                if (tokenMap.size > 0) {
                  collaterals.set(channelKey, tokenMap);
                }
              }
            }
          }

          // Add entity to registeredEntities
          if (!registeredEntities.has(entityId)) {
            registeredEntities.set(entityId, {
              name: replica.name || `E${entityId.slice(-4)}`,
              quorum: replica.quorum || [],
              threshold: replica.threshold || 1,
            });
          }
        }

        return {
          name: jr.name,
          blockNumber: jr.blockNumber,
          stateRoot: freshStateRoot ? new Uint8Array(freshStateRoot) : new Uint8Array(jr.stateRoot),
          mempool: [...jr.mempool],
          blockDelayMs: jr.blockDelayMs || 300,
          lastBlockTimestamp: jr.lastBlockTimestamp || 0,
          position: { ...jr.position },
          contracts: jr.contracts ? { ...jr.contracts } : undefined,
          reserves,
          collaterals,  // Collateral state from bilateral accounts
          registeredEntities,
        };
      })
    : [];

  // Capture and reset frame logs
  const frameLogs = env.frameLogs ? [...env.frameLogs] : [];
  if (frameLogs.length > 0) {
    console.log(`ðŸ“‹ Capturing ${frameLogs.length} frame events into snapshot`);
  }
  if (env.frameLogs) {
    env.frameLogs = [];
  }

  const snapshot: EnvSnapshot = {
    height: env.height,
    timestamp: env.timestamp,
    ...(env.runtimeSeed ? { runtimeSeed: env.runtimeSeed } : {}),
    ...(env.runtimeId ? { runtimeId: env.runtimeId } : {}),
    eReplicas: new Map(Array.from(env.eReplicas.entries()).map(([key, replica]) => [key, cloneEntityReplica(replica, true)])), // forSnapshot=true excludes clonedForValidation
    jReplicas,
    ...(browserVMState ? { browserVMState } : {}),
    runtimeInput: {
      runtimeTxs: [...runtimeInput.runtimeTxs],
      entityInputs: runtimeInput.entityInputs.map(input => ({
        entityId: input.entityId,
        signerId: input.signerId,
        ...(input.entityTxs && { entityTxs: [...input.entityTxs] }),
        ...(input.precommits && { precommits: new Map(input.precommits) }),
        ...(input.proposedFrame && { proposedFrame: input.proposedFrame }),
      })),
    },
    runtimeOutputs: runtimeOutputs.map(output => ({
      entityId: output.entityId,
      signerId: output.signerId,
      ...(output.entityTxs && { entityTxs: [...output.entityTxs] }),
      ...(output.precommits && { precommits: new Map(output.precommits) }),
      ...(output.proposedFrame && { proposedFrame: output.proposedFrame }),
    })),
    description: env.extra?.description || description,
    gossip: { profiles: gossipProfiles },
    logs: frameLogs,
    ...(env.frameDisplayMs && { displayMs: env.frameDisplayMs }),
    ...(env.extra?.subtitle && { subtitle: { ...env.extra.subtitle } }),
  };

  // Clear consumed extras
  env.frameDisplayMs = undefined;
  env.extra = undefined;

  envHistory.push(snapshot);

  // --- SNAPSHOT SIZE MONITORING ---
  const snapshotBuffer = encode(snapshot);
  const snapshotSize = snapshotBuffer.length;
  const sizeMB = (snapshotSize / 1024 / 1024).toFixed(2);

  // Alert if snapshot exceeds 1MB threshold
  if (snapshotSize > 1_000_000) {
    console.warn(`ðŸ“¦ LARGE SNAPSHOT: ${sizeMB}MB at height ${snapshot.height}`);
    console.warn(`   E-Replicas: ${snapshot.eReplicas.size}, J-Replicas: ${snapshot.jReplicas.length}`);

    // Log per-entity diagnostics
    for (const [key, replica] of snapshot.eReplicas) {
      const msgCount = replica.state.messages?.length || 0;
      const accountCount = replica.state.accounts?.size || 0;
      if (msgCount > 20 || accountCount > 10) {
        console.warn(`   ${key.slice(0,25)}...: ${msgCount} msgs, ${accountCount} accounts`);
      }
    }
  }

  // --- PERSISTENCE WITH BATCH OPERATIONS ---
  // Try to save, but gracefully handle IndexedDB unavailable (incognito mode, etc)
  try {
    const batch = db.batch();
    batch.put(Buffer.from(`snapshot:${snapshot.height}`), snapshotBuffer);
    batch.put(Buffer.from('latest_height'), Buffer.from(snapshot.height.toString()));
    batch.write();
  } catch (error) {
    // Silent fail - IndexedDB unavailable (incognito) or full - continue anyway
  }

  if (DEBUG) {
    console.log(`ðŸ“¸ Snapshot ${snapshot.height}: ${sizeMB}MB - "${description}" (total: ${envHistory.length})`);
    if (runtimeInput.runtimeTxs.length > 0) {
      console.log(`    ðŸ–¥ï¸  RuntimeTxs: ${runtimeInput.runtimeTxs.length}`);
      runtimeInput.runtimeTxs.forEach((tx, i) => {
        console.log(
          `      ${i + 1}. ${tx.type} ${tx.entityId}:${tx.signerId} (${tx.data.isProposer ? 'proposer' : 'validator'})`,
        );
      });
    }
    if (runtimeInput.entityInputs.length > 0) {
      console.log(`    ðŸ“¨ EntityInputs: ${runtimeInput.entityInputs.length}`);
      runtimeInput.entityInputs.forEach((input, i) => {
        const parts = [];
        if (input.entityTxs?.length) parts.push(`${input.entityTxs.length} txs`);
        if (input.precommits?.size) parts.push(`${input.precommits.size} precommits`);
        if (input.proposedFrame) parts.push(`frame: ${input.proposedFrame.hash.slice(0, 10)}...`);
        console.log(`      ${i + 1}. ${input.entityId}:${input.signerId} (${parts.join(', ') || 'empty'})`);
      });
    }
  }
};

// === ACCOUNT MACHINE HELPERS ===

/**
 * Clone AccountMachine for validation (replaces dryRun pattern)
 */
export function cloneAccountMachine(account: AccountMachine, forSnapshot: boolean = false): AccountMachine {
  // For snapshots, exclude clonedForValidation to avoid cycles
  if (forSnapshot) {
    const { clonedForValidation, ...accountWithoutCloned } = account as any;
    try {
      return structuredClone(accountWithoutCloned) as AccountMachine;
    } catch {
      return manualCloneAccountMachine(account, true);
    }
  }

  // Normal clone - preserve clonedForValidation for consensus
  try {
    const cloned = structuredClone(account);
    return cloned;
  } catch (error) {
    console.log(`âš ï¸ structuredClone failed, using manual clone`);
    return manualCloneAccountMachine(account, false);
  }
}

/**
 * Manual AccountMachine cloning
 */
function manualCloneAccountMachine(account: AccountMachine, skipClonedForValidation: boolean = false): AccountMachine {
  const result: AccountMachine = {
    leftEntity: account.leftEntity,
    rightEntity: account.rightEntity,
    mempool: [...account.mempool],
    currentFrame: {
      ...account.currentFrame,
      tokenIds: [...account.currentFrame.tokenIds],
      deltas: [...account.currentFrame.deltas],
    },
    sentTransitions: account.sentTransitions,
    ackedTransitions: account.ackedTransitions,
    deltas: new Map(Array.from(account.deltas.entries()).map(([key, delta]) => [key, { ...delta }])),
    globalCreditLimits: { ...account.globalCreditLimits },
    currentHeight: account.currentHeight,
    pendingSignatures: [...account.pendingSignatures],
    rollbackCount: account.rollbackCount,
    sendCounter: account.sendCounter,
    receiveCounter: account.receiveCounter,
    frameHistory: [...account.frameHistory], // Clone frame history array
    proofHeader: { ...account.proofHeader },
    proofBody: {
      ...account.proofBody,
      tokenIds: [...account.proofBody.tokenIds],
      deltas: [...account.proofBody.deltas],
    },
    disputeConfig: { ...account.disputeConfig }, // Dispute delay configuration
    pendingWithdrawals: new Map(account.pendingWithdrawals), // Phase 2: Clone withdrawal tracking
    requestedRebalance: new Map(account.requestedRebalance), // Phase 3: Clone rebalance hints
  };

  // Add optional properties if they exist
  if (account.pendingFrame) {
    result.pendingFrame = {
      ...account.pendingFrame,
      accountTxs: [...account.pendingFrame.accountTxs],
      tokenIds: [...account.pendingFrame.tokenIds],
      deltas: [...account.pendingFrame.deltas]
    };
  }

  if (account.clonedForValidation && !skipClonedForValidation) {
    result.clonedForValidation = manualCloneAccountMachine(account.clonedForValidation, true);
  }

  if (account.hankoSignature) {
    result.hankoSignature = account.hankoSignature;
  }
  if (account.currentDisputeProofHanko) {
    result.currentDisputeProofHanko = account.currentDisputeProofHanko;
  }
  if (account.currentDisputeProofCooperativeNonce !== undefined) {
    result.currentDisputeProofCooperativeNonce = account.currentDisputeProofCooperativeNonce;
  }
  if (account.currentDisputeProofBodyHash) {
    result.currentDisputeProofBodyHash = account.currentDisputeProofBodyHash;
  }
  if (account.counterpartyDisputeProofHanko) {
    result.counterpartyDisputeProofHanko = account.counterpartyDisputeProofHanko;
  }
  if (account.counterpartyDisputeProofCooperativeNonce !== undefined) {
    result.counterpartyDisputeProofCooperativeNonce = account.counterpartyDisputeProofCooperativeNonce;
  }
  if (account.counterpartyDisputeProofBodyHash) {
    result.counterpartyDisputeProofBodyHash = account.counterpartyDisputeProofBodyHash;
  }
  if (account.disputeProofNoncesByHash) {
    result.disputeProofNoncesByHash = { ...account.disputeProofNoncesByHash };
  }
  if (account.disputeProofBodiesByHash) {
    result.disputeProofBodiesByHash = { ...account.disputeProofBodiesByHash };
  }

  // ABI-encoded proofBody for on-chain disputes
  if (account.abiProofBody) {
    result.abiProofBody = { ...account.abiProofBody };
  }

  // HTLC state (deep clone locks Map)
  result.locks = new Map(
    Array.from(account.locks.entries()).map(([lockId, lock]) => [
      lockId,
      { ...lock } // Clone lock object
    ])
  );

  // Swap state (deep clone swapOffers Map)
  result.swapOffers = new Map(
    Array.from((account.swapOffers || new Map()).entries()).map(([offerId, offer]) => [
      offerId,
      { ...offer } // Clone offer object
    ])
  );

  return result;
}


//runtime/snapshot-coder.ts (316 lines)
/**
 * Unified encoder/decoder for snapshots with configurable JSON/msgpack methods.
 * Set USE_MSGPACK = true for msgpack with integrity hashing, false for simple JSON.
 */

// Configuration flag - change this to test different encoders
const USE_MSGPACK = false;

// JSON encoder imports and setup - cycle-safe
const createSafeJsonReplacer = () => {
  const seen = new WeakSet();
  return (key: string, value: any) => {
    // Skip fields that may contain cycles (ethers providers, validation state)
    if (key === 'clonedForValidation' || key === 'jurisdiction' || key === 'provider' || key === 'ethersProvider') {
      return undefined;
    }
    // Handle Maps BEFORE cycle detection (Map entries need processing)
    if (value instanceof Map) {
      const entries = Array.from(value.entries());
      return { _dataType: 'Map', value: entries };
    }
    // Handle BigInts
    if (typeof value === 'bigint') {
      return { _dataType: 'BigInt', value: value.toString() };
    }
    // Cycle detection for objects (skip arrays - they're rarely the cause of true cycles)
    if (value !== null && typeof value === 'object' && !Array.isArray(value)) {
      if (seen.has(value)) {
        return undefined; // Silent skip
      }
      seen.add(value);
    }
    return value;
  };
};

/**
 * Remove cycles from an object by replacing cyclic references with undefined
 */
const removeCycles = (obj: any, seen = new WeakSet()): any => {
  if (obj === null || typeof obj !== 'object') {
    return obj;
  }

  // Handle BigInt
  if (typeof obj === 'bigint') {
    return { _dataType: 'BigInt', value: obj.toString() };
  }

  // Skip known problematic keys
  if (obj.clonedForValidation !== undefined) {
    const { clonedForValidation, ...rest } = obj;
    return removeCycles(rest, seen);
  }
  if (obj.jurisdiction !== undefined) {
    const { jurisdiction, ...rest } = obj;
    return removeCycles(rest, seen);
  }
  if (obj.provider !== undefined) {
    const { provider, ...rest } = obj;
    return removeCycles(rest, seen);
  }

  // Check for cycles
  if (seen.has(obj)) {
    return undefined;
  }
  seen.add(obj);

  // Handle Map
  if (obj instanceof Map) {
    const entries = Array.from(obj.entries()).map(([k, v]) => [
      removeCycles(k, seen),
      removeCycles(v, seen)
    ]);
    return { _dataType: 'Map', value: entries };
  }

  // Handle Array
  if (Array.isArray(obj)) {
    return obj.map(item => removeCycles(item, seen));
  }

  // Handle plain object
  const result: any = {};
  for (const key of Object.keys(obj)) {
    if (key === 'clonedForValidation' || key === 'jurisdiction' || key === 'provider' || key === 'ethersProvider') {
      continue;
    }
    result[key] = removeCycles(obj[key], seen);
  }
  return result;
};

const jsonReviver = (_key: string, value: any) => {
  if (typeof value === 'object' && value !== null) {
    if (value._dataType === 'Map') return new Map(value.value);
    if (value._dataType === 'BigInt') return BigInt(value.value);
  }
  return value;
};

// Msgpack encoder setup - lazy initialization to avoid browser issues
let packr: any = null;
let sha256: any = null;

// Lazy initialization function for msgpack
const initMsgpack = async () => {
  if (packr) return packr; // Already initialized

  try {
    const { Packr } = await import('msgpackr');
    const { createHash } = await import('./utils.js');

    sha256 = (data: Buffer): Buffer => createHash('sha256').update(data).digest();

    packr = new Packr({
      structures: [[BigInt, (value: bigint) => value.toString(), (str: string) => BigInt(str)]],
    });

    return packr;
  } catch (error) {
    console.warn('Failed to load msgpack dependencies:', error);
    throw error;
  }
};

/**
 * Recursively traverses an object and converts any Map instances into
 * arrays of [key, value] pairs, sorted by key. This is essential for
 * ensuring that serialization is deterministic.
 */
function deterministicDeepSort(obj: any): any {
  if (obj instanceof Map) {
    const entries = Array.from(obj.entries());
    // Sort entries by key to ensure deterministic output.
    entries.sort((a, b) => (a[0] < b[0] ? -1 : 1));
    // Recursively process values in case they contain Maps.
    return entries.map(([k, v]) => [k, deterministicDeepSort(v)]);
  }
  if (Array.isArray(obj)) {
    return obj.map(deterministicDeepSort);
  }
  if (typeof obj === 'object' && obj !== null) {
    const newObj: { [key: string]: any } = {};
    const sortedKeys = Object.keys(obj).sort();
    for (const key of sortedKeys) {
      newObj[key] = deterministicDeepSort(obj[key]);
    }
    return newObj;
  }
  return obj;
}

/**
 * Reconstructs Map objects from the key-sorted arrays created by deterministicDeepSort.
 * This is the reverse operation used during deserialization.
 */
function reconstructMaps(obj: any): any {
  if (Array.isArray(obj)) {
    // Check if it's a key-value pair array that should be a Map
    const isMapArray = obj.every(item => Array.isArray(item) && item.length === 2);
    if (isMapArray) {
      return new Map(obj.map(([k, v]) => [k, reconstructMaps(v)]));
    }
    return obj.map(reconstructMaps);
  }
  if (typeof obj === 'object' && obj !== null) {
    const newObj: { [key: string]: any } = {};
    for (const key in obj) {
      newObj[key] = reconstructMaps(obj[key]);
    }
    return newObj;
  }
  return obj;
}

// Define the structure of the persisted tuple for msgpack format
type SnapshotTuple = [
  number, // height
  any, // serverInput
  Buffer, // hashOfSerializedReplicas
  any, // deterministically sorted replicas
];

/**
 * Encodes data using the configured method (JSON or msgpack)
 */
export const encode = (data: any): Buffer => {
  // ENCODE validation removed - too verbose
  // Auto-fix jBlock corruption if needed (supports both old and new naming)
  const replicasMap = data?.eReplicas || data?.replicas;
  if (replicasMap) {
    for (const [replicaKey, replica] of replicasMap.entries()) {
      if (replica && replica.state && typeof replica.state.lastFinalizedJHeight !== 'number') {
        console.error(`ðŸ’¥ CRITICAL: Invalid jBlock for ${replicaKey.slice(0,20)}... - auto-fixing to 0`);
        replica.state.lastFinalizedJHeight = 0;
      }
    }
  }

  if (USE_MSGPACK) {
    // For msgpack mode, we need to use async initialization
    // This should not happen in current config (USE_MSGPACK = false)
    throw new Error('Msgpack mode requires async initialization - use encodeAsync instead');
  } else {
    // Simple JSON encoding with cycle-safe pre-processing
    const safeCopy = removeCycles(data);
    return Buffer.from(JSON.stringify(safeCopy, createSafeJsonReplacer()));
  }
};

/**
 * Decodes data using the configured method (JSON or msgpack)
 */
export const decode = (buffer: Buffer): any => {
  if (USE_MSGPACK) {
    // For msgpack mode, we need to use async initialization
    // This should not happen in current config (USE_MSGPACK = false)
    throw new Error('Msgpack mode requires async initialization - use decodeAsync instead');
  } else {
    // Simple JSON decoding
    const decoded = JSON.parse(buffer.toString(), jsonReviver);

    // CRITICAL: Validate financial state integrity after deserialization
    // Supports both old naming (replicas) and new naming (eReplicas)
    const decodedReplicas = decoded?.eReplicas || decoded?.replicas;
    if (decodedReplicas) {
      for (const [replicaKey, replica] of decodedReplicas.entries()) {
        if (replica && replica.state) {
          const jBlock = replica.state.lastFinalizedJHeight;
          if (typeof jBlock !== 'number') {
            // IMPORTANT: Don't reset to 0 - this causes re-processing of ALL events!
            // If jBlock is missing, use the snapshot height as a safe fallback
            const fallbackJBlock = Number(decoded.height) || 0;
            console.warn(`âš ï¸ jBlock missing for replica ${replicaKey}, using height ${fallbackJBlock} as fallback`);
            replica.state.lastFinalizedJHeight = fallbackJBlock;
          }
        }
      }
    }

    return decoded;
  }
};

/**
 * Async version for msgpack encoding
 */
export const encodeAsync = async (data: any): Promise<Buffer> => {
  if (USE_MSGPACK) {
    const packrInstance = await initMsgpack();

    // Msgpack encoding with integrity hashing
    const sortedReplicas = deterministicDeepSort(data.eReplicas || data.replicas || new Map());
    const serializedReplicas = packrInstance.pack(sortedReplicas);
    const hashOfReplicas = sha256(serializedReplicas);

    const snapshotTuple: SnapshotTuple = [
      data.height || 0,
      deterministicDeepSort(data.serverInput || {}),
      hashOfReplicas,
      sortedReplicas,
    ];

    return packrInstance.pack(snapshotTuple);
  } else {
    // Fallback to sync JSON encoding
    return encode(data);
  }
};

/**
 * Async version for msgpack decoding
 */
export const decodeAsync = async (buffer: Buffer): Promise<any> => {
  if (USE_MSGPACK) {
    const packrInstance = await initMsgpack();

    // Msgpack decoding with integrity verification
    const decodedTuple = packrInstance.unpack(buffer) as SnapshotTuple;

    if (!Array.isArray(decodedTuple) || decodedTuple.length !== 4) {
      throw new Error('Invalid snapshot format: Expected a 4-element tuple.');
    }

    const [height, serverInput, hashOfReplicas, sortedReplicas] = decodedTuple;

    // Security/Integrity Check: Verify the hash of the replicas.
    const serializedReplicas = packrInstance.pack(sortedReplicas);
    const calculatedHash = sha256(serializedReplicas);
    // Browser-compatible buffer comparison
    if (hashOfReplicas.toString('hex') !== calculatedHash.toString('hex')) {
      throw new Error('State integrity check failed: Replica hash does not match.');
    }

    // Reconstruct the original object, converting sorted arrays back to Maps.
    const replicas = reconstructMaps(sortedReplicas);

    return {
      height,
      serverInput: reconstructMaps(serverInput),
      replicas,
      // Add timestamp for compatibility
      timestamp: 0,
      // Note: gossip layer will be re-created by runtime on restore
    };
  } else {
    // Fallback to sync JSON decoding
    return decode(buffer);
  }
};

// Export the configuration flag for external use/testing
export { USE_MSGPACK };


//runtime/evm.ts (961 lines)
/**
 * XLN EVM Integration
 * Handles blockchain interactions, jurisdictions, and smart contract operations
 */

import { ethers } from 'ethers';
import { loadJurisdictions } from './jurisdiction-loader';
import { encodeJBatch, computeBatchHankoHash, type JBatch } from './j-batch';

import { detectEntityType, encodeBoard, extractNumberFromEntityId, hashBoard } from './entity-factory';
import { normalizeEntityId } from './entity-id-utils';
import { safeStringify } from './serialization-utils';
import type { ConsensusConfig, JurisdictionConfig } from './types';
import { DEBUG, isBrowser } from './utils';
import { logError } from './logger';
import { BrowserVMEthersProvider } from './browservm-ethers-provider';
import type { BrowserVMInstance } from './xln-api';

// Global logger for UI-accessible error logging (set by frontend)
declare global {
  interface Window {
    xlnErrorLog?: (message: string, source: string, details?: unknown) => void;
  }
}

const uiLog = (message: string, details?: unknown) => {
  console.log(message, details);
  if (isBrowser && window.xlnErrorLog) {
    window.xlnErrorLog(message, 'EVM', details);
  }
};

const uiError = (message: string, details?: unknown) => {
  logError("BLOCKCHAIN", message, details);
  if (isBrowser && window.xlnErrorLog) {
    window.xlnErrorLog(message, 'EVM-ERROR', details);
  }
};

// === ETHEREUM INTEGRATION ===

// Load contract configuration directly in jurisdiction generation
export const ENTITY_PROVIDER_ABI = [
  'function registerNumberedEntity(bytes32 boardHash) external returns (uint256 entityNumber)',
  'function registerNumberedEntitiesBatch(bytes32[] calldata boardHashes) external returns (uint256[] memory entityNumbers)',
  'function assignName(string memory name, uint256 entityNumber) external',
  'function transferName(string memory name, uint256 newEntityNumber) external',
  'function entities(bytes32 entityId) external view returns (tuple(uint256 boardHash, uint8 status, uint256 activationTime))',
  'function nameToNumber(string memory name) external view returns (uint256)',
  'function numberToName(uint256 entityNumber) external view returns (string memory)',
  'function nextNumber() external view returns (uint256)',
  // Governance functions (governance is auto-setup on entity registration)
  'function getTokenIds(uint256 entityNumber) external pure returns (uint256 controlTokenId, uint256 dividendTokenId)',
  'function getGovernanceInfo(uint256 entityNumber) external view returns (uint256 controlTokenId, uint256 dividendTokenId, uint256 controlSupply, uint256 dividendSupply, bool hasActiveProposal, bytes32 articlesHash)',
  'function balanceOf(address account, uint256 id) external view returns (uint256)',
  'function safeTransferFrom(address from, address to, uint256 id, uint256 amount, bytes data) external',
  // Events
  'event EntityRegistered(bytes32 indexed entityId, uint256 indexed entityNumber, bytes32 boardHash)',
  'event NameAssigned(string indexed name, uint256 indexed entityNumber)',
  'event NameTransferred(string indexed name, uint256 indexed oldEntityNumber, uint256 indexed newEntityNumber)',
  'event GovernanceEnabled(bytes32 indexed entityId, uint256 controlTokenId, uint256 dividendTokenId)',
];

export const DEPOSITORY_ABI = [
  'function mintToReserve(bytes32 entity, uint256 tokenId, uint256 amount) external',
  'function debugFundReserves(bytes32 entity, uint256 tokenId, uint256 amount) external',
  'function debugBulkFundEntities() external',
  'function reserveToReserve(bytes32 fromEntity, bytes32 toEntity, uint256 tokenId, uint256 amount) external returns (bool)',
  'function processBatch(bytes encodedBatch, address entityProvider, bytes hankoData, uint256 nonce) external returns (bool)',
  'function unsafeProcessBatch(bytes32 entity, tuple(tuple(uint256 tokenId, uint256 amount)[] flashloans, tuple(bytes32 receivingEntity, uint256 tokenId, uint256 amount)[] reserveToReserve, tuple(uint256 tokenId, bytes32 receivingEntity, tuple(bytes32 entity, uint256 amount)[] pairs)[] reserveToCollateral, tuple(bytes32 leftEntity, bytes32 rightEntity, tuple(uint256 tokenId, int256 leftDiff, int256 rightDiff, int256 collateralDiff, int256 ondeltaDiff)[] diffs, uint256[] forgiveDebtsInTokenIds, tuple(bytes32 insured, bytes32 insurer, uint256 tokenId, uint256 limit, uint64 expiresAt)[] insuranceRegs, bytes sig, address entityProvider, bytes hankoData, uint256 nonce)[] settlements, tuple(bytes32 counterentity, uint256 cooperativeNonce, uint256 disputeNonce, bytes32 proofbodyHash, bytes sig, bytes initialArguments)[] disputeStarts, tuple(bytes32 counterentity, uint256 initialCooperativeNonce, uint256 finalCooperativeNonce, uint256 initialDisputeNonce, uint256 finalDisputeNonce, bytes32 initialProofbodyHash, tuple(int256[] offdeltas, uint256[] tokenIds, tuple(address transformerAddress, bytes encodedBatch, tuple(uint256 deltaIndex, uint256 rightAllowance, uint256 leftAllowance)[] allowances)[] transformers) finalProofbody, bytes finalArguments, bytes initialArguments, bytes sig, bool startedByLeft, uint256 disputeUntilBlock, bool cooperative)[] disputeFinalizations, tuple(bytes32 entity, bytes32 packedToken, uint256 internalTokenId, uint256 amount)[] externalTokenToReserve, tuple(bytes32 receivingEntity, uint256 tokenId, uint256 amount)[] reserveToExternalToken, tuple(address transformer, bytes32 secret)[] revealSecrets, uint256 hub_id) batch) external returns (bool)',
  'function entityNonces(address) view returns (uint256)',
  'function prefundAccount(bytes32 fundingEntity, bytes32 counterpartyEntity, uint256 tokenId, uint256 amount) external returns (bool)',
  'function settle(bytes32 leftEntity, bytes32 rightEntity, tuple(uint256 tokenId, int256 leftDiff, int256 rightDiff, int256 collateralDiff, int256 ondeltaDiff)[] diffs, uint256[] forgiveDebtsInTokenIds, tuple(bytes32 insured, bytes32 insurer, uint256 tokenId, uint256 limit, uint64 expiresAt)[] insuranceRegs, bytes sig) external returns (bool)',
  'function _reserves(bytes32 entity, uint256 tokenId) external view returns (uint256)',
  // Insurance view functions
  'function getInsuranceLines(bytes32 insured) external view returns (tuple(bytes32 insurer, uint256 tokenId, uint256 remaining, uint64 expiresAt)[])',
  'function getInsuranceLinesCount(bytes32 insured) external view returns (uint256)',
  'function getAvailableInsurance(bytes32 insured, uint256 tokenId) external view returns (uint256)',
  // Canonical J-Events (must match CANONICAL_J_EVENTS in j-event-watcher.ts)
  'event ReserveUpdated(bytes32 indexed entity, uint256 indexed tokenId, uint256 newBalance)',
  'event SecretRevealed(bytes32 indexed hashlock, bytes32 indexed revealer, bytes32 secret)',
  'event DisputeStarted(bytes32 indexed sender, bytes32 indexed counterentity, uint256 indexed disputeNonce, bytes32 proofbodyHash, bytes initialArguments)',
  'event DisputeFinalized(bytes32 indexed sender, bytes32 indexed counterentity, uint256 indexed initialDisputeNonce, bytes32 initialProofbodyHash, bytes32 finalProofbodyHash)',
  // Note: AccountSettled is emitted via DELEGATECALL from Account.sol - parsed directly from logs
  // Insurance events
  'event InsuranceRegistered(bytes32 indexed insured, bytes32 indexed insurer, uint256 indexed tokenId, uint256 limit, uint64 expiresAt)',
  'event InsuranceClaimed(bytes32 indexed insured, bytes32 indexed insurer, bytes32 indexed creditor, uint256 tokenId, uint256 amount)',
  'event InsuranceExpired(bytes32 indexed insured, bytes32 indexed insurer, uint256 indexed tokenId, uint256 index)',
  // Debt events
  'event DebtCreated(bytes32 indexed debtor, bytes32 indexed creditor, uint256 indexed tokenId, uint256 amount, uint256 debtIndex)',
  'event DebtEnforced(bytes32 indexed debtor, bytes32 indexed creditor, uint256 indexed tokenId, uint256 amountPaid, uint256 remainingAmount, uint256 newDebtIndex)',
];

export const connectToEthereum = async (jurisdiction: JurisdictionConfig) => {
  // Declare outside try block for error logging
  let rpcUrl = jurisdiction.address;
  let entityProviderAddress = jurisdiction.entityProviderAddress;
  let depositoryAddress = jurisdiction.depositoryAddress;

  try {
    // FINTECH-SAFETY: Validate jurisdiction structure before using

    // Support legacy format with explicit validation
    if (!rpcUrl && 'rpc' in jurisdiction) {
      console.warn('ðŸš¨ JURISDICTION-LEGACY: Using deprecated rpc field, should be address');
    }
    if (!entityProviderAddress && 'contracts' in jurisdiction) {
      console.warn('ðŸš¨ JURISDICTION-LEGACY: Using deprecated contracts.entityProvider field');
    }

    if (!rpcUrl) {
      throw new Error('Jurisdiction missing RPC URL (address or rpc property)');
    }
    if (!entityProviderAddress || !depositoryAddress) {
      throw new Error('Jurisdiction missing contract addresses (entityProvider and depository)');
    }

    uiLog(`ðŸ”Œ CONNECTING: jurisdiction=${jurisdiction.name}, rpcUrl=${rpcUrl}`);
    if (isBrowser) {
      uiLog(`   Page Origin: ${window.location.origin}`);
      uiLog(`   Page Protocol: ${window.location.protocol}`);
      uiLog(`   Page Host: ${window.location.hostname}:${window.location.port}`);

      // Handle relative URLs (like /rpc/ethereum) by providing base
      const fullRpcUrl = new URL(rpcUrl, window.location.origin);
      uiLog(`   RPC URL: ${fullRpcUrl.href}`);
      const corsIssue = window.location.origin !== fullRpcUrl.origin;
      uiLog(`   CORS issue? ${corsIssue ? 'YES - Different origins!' : 'No (using proxy)'}`, { corsIssue });
      uiLog(`   User Agent: ${navigator.userAgent}`);
    }
    uiLog(`   Contracts: EP=${entityProviderAddress.slice(0,10)}, DEP=${depositoryAddress.slice(0,10)}`);

    // Resolve relative URLs to full URLs for ethers.js
    let resolvedRpcUrl = rpcUrl;
    if (isBrowser && rpcUrl.startsWith('/')) {
      resolvedRpcUrl = new URL(rpcUrl, window.location.origin).href;
      uiLog(`   Resolved RPC: ${resolvedRpcUrl}`);
    }

    // Connect to specified RPC node (or use BrowserVM provider)
    let provider: ethers.Provider;
    const isBrowserVM = resolvedRpcUrl.startsWith('browservm://');

    if (isBrowserVM) {
      // Use BrowserVM provider (lazy-init if needed)
      // NOTE: This path is for legacy code. New code should use env.browserVM
      if (!BROWSER_VM_INSTANCE) {
        const { BrowserEVM } = await import('./evms/browser-evm');
        const evm = new BrowserEVM();
        await evm.init();
        // Store in global singleton (backward compat - no env available here)
        BROWSER_VM_INSTANCE = evm.getProvider();
        // Update jurisdictions with this VM's addresses
        const depositoryAddress = evm.getDepositoryAddress();
        const entityProviderAddress = evm.getEntityProviderAddress();
        DEFAULT_JURISDICTIONS = new Map();
        DEFAULT_JURISDICTIONS.set('arrakis', {
          name: 'Arrakis',
          chainId: 1337,
          address: 'browservm://',
          entityProviderAddress,
          depositoryAddress,
        });
        console.log('âœ… Legacy BrowserVM jurisdiction active (global singleton)');
      }
      if (!BROWSER_VM_INSTANCE) {
        throw new Error('BrowserVM instance not set - failed to initialize BrowserVM');
      }
      if (BROWSER_VM_INSTANCE?.getEntityProviderAddress && (!entityProviderAddress || entityProviderAddress === '0x0000000000000000000000000000000000000000')) {
        entityProviderAddress = BROWSER_VM_INSTANCE.getEntityProviderAddress();
      }
      if (BROWSER_VM_INSTANCE?.getDepositoryAddress && (!depositoryAddress || depositoryAddress === '0x0000000000000000000000000000000000000000')) {
        depositoryAddress = BROWSER_VM_INSTANCE.getDepositoryAddress();
      }
      uiLog(`ðŸ§ª Using BrowserVM ethers provider`);
      provider = new BrowserVMEthersProvider(BROWSER_VM_INSTANCE);
    } else {
      // Use standard JSON-RPC provider
      provider = new ethers.JsonRpcProvider(resolvedRpcUrl);
    }

    uiLog(`âœ… Provider created`);

    // Use Hardhat account #0 private key (browser-compatible, no getSigner)
    // This is the publicly known Hardhat test key, safe for demo
    const privateKey = '0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80';
    const signer = new ethers.Wallet(privateKey, provider);
    const signerAddress = await signer.getAddress();
    uiLog(`âœ… Signer created: ${signerAddress}`);

    // Test connection (skip for BrowserVM to avoid circular dependency issues)
    if (!isBrowserVM) {
      try {
        const network = await provider.getNetwork();
        uiLog(`âœ… Network connected: chainId=${network.chainId}`);
      } catch (netError) {
        uiError(`âŒ NETWORK-CONNECT-FAILED`, {
          rpcUrl,
          errorCode: (netError as any)?.code,
          errorMessage: (netError as any)?.message,
          errorStack: (netError as any)?.stack
        });
        throw netError;
      }
    } else {
      uiLog(`âœ… BrowserVM connection established (chainId=1337)`);
    }

    // Create contract instances
    const entityProvider = new ethers.Contract(entityProviderAddress, ENTITY_PROVIDER_ABI, signer);
    const depository = new ethers.Contract(depositoryAddress, DEPOSITORY_ABI, signer);
    uiLog(`âœ… Contracts created for ${jurisdiction.name}`);

    return { provider, signer, entityProvider, depository };
  } catch (error) {
    uiError(`âŒ CONNECT-FAILED: ${jurisdiction.name}`, {
      rpcUrl,
      errorType: (error as any)?.constructor?.name,
      errorCode: (error as any)?.code,
      errorReason: (error as any)?.reason,
      errorMessage: (error as any)?.message,
      errorStack: (error as any)?.stack
    });
    throw error;
  }
};

// Debug function to fund entity reserves for testing
export const debugFundReserves = async (jurisdiction: JurisdictionConfig, entityId: string, tokenId: number, amount: string) => {
  try {
    console.log(`ðŸ’° DEBUG: Funding entity ${entityId.slice(0, 10)} with ${amount} of token ${tokenId}...`);
    
    const { depository } = await connectToEthereum(jurisdiction);
    
    // Fund the entity's reserves for testing
    const tx = await depository['debugFundReserves']!(entityId, tokenId, amount);
    console.log(`ðŸ“¡ Debug funding transaction: ${tx.hash}`);
    
    const receipt = await tx.wait();
    console.log(`âœ… Debug funding confirmed in block ${receipt.blockNumber}`);
    
    // Check new balance
    const newBalance = await depository['_reserves']!(entityId, tokenId);
    console.log(`ðŸ’° Entity ${entityId.slice(0, 10)} now has ${newBalance.toString()} of token ${tokenId}`);
    
    return { transaction: tx, receipt, newBalance };
  } catch (error) {
    logError("BLOCKCHAIN", `âŒ Failed to fund reserves:`, error);
    throw error;
  }
};

/**
 * Fund entity with multiple assets and emit ReserveUpdated events
 */
export const fundEntityReserves = async (entityId: string, assets: Array<{ tokenId: number; amount: string; symbol: string }>) => {
  console.log(`ðŸ’° Funding entity ${entityId.slice(0, 10)}... with ${assets.length} assets`);
  
  for (const asset of assets) {
    console.log(`  ðŸ’³ Adding ${asset.symbol}: ${asset.amount} (token ${asset.tokenId})`);
    // TODO: Implement fundReserves function or use debugFundReserves
    console.log(`  - Funding ${entityId.slice(0, 10)} with ${asset.amount} of token ${asset.tokenId}`);
  }
  
  console.log(`âœ… Entity ${entityId.slice(0, 10)}... funded with all assets`);
};

// Submit real processBatch transaction to jurisdiction
export const submitPrefundAccount = async (jurisdiction: JurisdictionConfig, entityId: string, counterpartyEntityId: string, tokenId: number, amount: string) => {
  try {
    console.log(`ðŸ’° Prefunding account between ${entityId.slice(0, 10)}... and ${counterpartyEntityId.slice(0, 10)}...`);
    console.log(`ðŸ” TOKEN: ${tokenId}, AMOUNT: ${amount}`);
    
    const { depository, provider } = await connectToEthereum(jurisdiction);
    console.log(`ðŸ” CONTRACT ADDRESS: ${depository.target}`);
    
    // Check if contract exists
    const code = await provider.getCode(depository.target);
    if (code === '0x') {
      throw new Error('Contract not deployed at this address');
    }
    
    // Check entity has sufficient reserves
    const currentBalance = await depository['_reserves']!(entityId, tokenId);
    console.log(`ðŸ” Current balance: ${currentBalance.toString()}`);
    console.log(`ðŸ” Requested amount: ${amount}`);
    
    if (currentBalance < BigInt(amount)) {
      throw new Error(`Insufficient reserves: have ${currentBalance.toString()}, need ${amount}`);
    }
    
    // Call prefundAccount function
    console.log(`ðŸ“ž Calling prefundAccount(${counterpartyEntityId}, ${tokenId}, ${amount})`);
    const tx = await depository['prefundAccount']!(counterpartyEntityId, tokenId, amount);
    console.log(`â³ Transaction sent: ${tx.hash}`);
    
    // Wait for confirmation
    const receipt = await tx.wait();
    console.log(`âœ… Prefunding confirmed in block ${receipt.blockNumber}`);
    
    return {
      hash: tx.hash,
      receipt: receipt
    };
    
  } catch (error) {
    logError("BLOCKCHAIN", `âŒ Failed to prefund account:`, error);
    throw error;
  }
};

export const submitProcessBatch = async (
  env: any,
  jurisdiction: JurisdictionConfig,
  entityId: string,
  batch: JBatch | any,
  signerId?: string
) => {
  try {
    if (!signerId) {
      throw new Error(`submitProcessBatch Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ signerId Ð´Ð»Ñ ${entityId.slice(0, 10)}`);
    }

    console.log(`ðŸ’¸ Submitting processBatch (Hanko) to ${jurisdiction.name} as entity ${entityId.slice(0, 10)}...`);
    const { depository, provider } = await connectToEthereum(jurisdiction);

    const entityProviderAddress = jurisdiction.entityProviderAddress;
    if (!entityProviderAddress || entityProviderAddress === '0x0000000000000000000000000000000000000000') {
      throw new Error('Jurisdiction missing entityProviderAddress');
    }

    const encodedBatch = encodeJBatch(batch);
    const net = await provider.getNetwork();
    const chainId = BigInt(net.chainId);
    const normalizedEntityId = normalizeEntityId(entityId);
    const entityAddress = ethers.getAddress(`0x${normalizedEntityId.slice(-40)}`);
    const currentNonce = await depository['entityNonces']?.(entityAddress);
    const nextNonce = BigInt(currentNonce ?? 0) + 1n;
    const batchHash = computeBatchHankoHash(chainId, String(depository.target), encodedBatch, nextNonce);

    const { signHashesAsSingleEntity } = await import('./hanko-signing');
    const hankos = await signHashesAsSingleEntity(env, entityId, signerId, [batchHash]);
    const hankoData = hankos[0];
    if (!hankoData) {
      throw new Error('Failed to build batch hanko signature');
    }

    const tx = await depository['processBatch']!(encodedBatch, entityProviderAddress, hankoData, nextNonce);
    console.log(`ðŸ“¡ Transaction submitted: ${tx.hash}`);
    const receipt = await tx.wait();
    console.log(`âœ… Transaction confirmed in block ${receipt.blockNumber}`);

    return { transaction: tx, receipt };
  } catch (error) {
    logError("BLOCKCHAIN", `âŒ Failed to submit processBatch to ${jurisdiction.name}:`, error);
    throw error;
  }
};

// Note: setupGovernance is no longer needed - governance is automatically created on entity registration

export const registerNumberedEntityOnChain = async (
  config: ConsensusConfig,
  name: string,
): Promise<{ txHash: string; entityNumber: number }> => {
  if (!config.jurisdiction) {
    throw new Error('Jurisdiction required for on-chain registration');
  }

  try {
    const { entityProvider } = await connectToEthereum(config.jurisdiction);

    const encodedBoard = encodeBoard(config);
    const boardHash = hashBoard(encodedBoard);

    if (DEBUG) console.log(`ðŸ›ï¸ Registering numbered entity "${name}" on chain`);
    if (DEBUG) console.log(`   Jurisdiction: ${config.jurisdiction.name}`);
    if (DEBUG) console.log(`   EntityProvider: ${config.jurisdiction.entityProviderAddress}`);
    if (DEBUG) console.log(`   Board Hash: ${boardHash}`);

    // Test connection by calling nextNumber()
    try {
      const nextNumber = await entityProvider['nextNumber']!();
      if (DEBUG) console.log(`   ðŸ“Š Next entity number will be: ${nextNumber}`);
    } catch (error) {
      throw new Error(`Failed to call nextNumber(): ${error}`);
    }

    // Call the smart contract
    const tx = await entityProvider['registerNumberedEntity']!(boardHash);
    if (DEBUG) console.log(`   ðŸ“¤ Transaction sent: ${tx.hash}`);

    // Wait for confirmation
    const receipt = await tx.wait();
    if (DEBUG) console.log(`   âœ… Transaction confirmed in block ${receipt.blockNumber}`);

    // Check if transaction reverted
    if (receipt.status === 0) {
      throw new Error(`Transaction reverted! Hash: ${tx.hash}`);
    }

    // Debug: log all events in receipt
    if (DEBUG) {
      console.log(`   ðŸ“‹ Receipt logs count: ${receipt.logs.length}`);
      receipt.logs.forEach((log: ethers.Log, i: number) => {
        try {
          const parsed = entityProvider.interface.parseLog(log);
          console.log(`   ðŸ“ Log ${i}: ${parsed?.name} - ${safeStringify(parsed?.args)}`);
        } catch {
          console.log(`   ðŸ“ Log ${i}: Unable to parse log - ${log.topics?.[0]}`);
        }
      });
    }

    // Extract entity number from event logs
    const event = receipt.logs.find((log: ethers.Log) => {
      try {
        const parsed = entityProvider.interface.parseLog(log);
        return parsed?.name === 'EntityRegistered';
      } catch {
        return false;
      }
    });

    if (!event) {
      throw new Error('EntityRegistered event not found in transaction logs');
    }

    const parsedEvent = entityProvider.interface.parseLog(event);
    // const _entityId = parsedEvent?.args[0]; // Entity ID for debugging (unused)
    const entityNumber = Number(parsedEvent?.args[1]);

    if (DEBUG) console.log(`âœ… Numbered entity registered!`);
    if (DEBUG) console.log(`   TX: ${tx.hash}`);
    if (DEBUG) console.log(`   Entity Number: ${entityNumber}`);

    return { txHash: tx.hash, entityNumber };
  } catch (error) {
    logError("BLOCKCHAIN", 'âŒ Blockchain registration failed:', error);
    throw error;
  }
};

/**
 * Batch register multiple numbered entities in ONE transaction
 * Massive speedup for scenario imports (1000 entities in 1 tx vs 1000 txs)
 */
export const registerNumberedEntitiesBatchOnChain = async (
  configs: ConsensusConfig[],
  jurisdiction: JurisdictionConfig,
): Promise<{ txHash: string; entityNumbers: number[] }> => {
  try {
    // Encode all board hashes
    const boardHashes = configs.map(config => {
      const encodedBoard = encodeBoard(config);
      return hashBoard(encodedBoard);
    });

    console.log(`ðŸ›ï¸ Batch registering ${configs.length} entities in ONE transaction...`);

    // BrowserVM: Use direct call to avoid circular dependencies
    if (jurisdiction.address.startsWith('browservm://')) {
      if (!BROWSER_VM_INSTANCE) {
        throw new Error('BrowserVM instance not set');
      }
      return await BROWSER_VM_INSTANCE.registerNumberedEntitiesBatch(boardHashes);
    }

    // Standard blockchain: Use ethers.js
    const { entityProvider } = await connectToEthereum(jurisdiction);

    // Call batch registration function
    const tx = await entityProvider['registerNumberedEntitiesBatch']!(boardHashes);
    console.log(`ðŸ“¤ Batch tx sent: ${tx.hash}`);

    // Wait for confirmation (ONE block for ALL entities!)
    const receipt = await tx.wait();
    console.log(`âœ… Batch confirmed in block ${receipt.blockNumber}`);

    if (receipt.status === 0) {
      throw new Error(`Batch registration reverted! Hash: ${tx.hash}`);
    }

    // Extract all entity numbers from events
    const entityNumbers: number[] = [];
    receipt.logs.forEach((log: ethers.Log) => {
      try {
        const parsed = entityProvider.interface.parseLog(log);
        if (parsed?.name === 'EntityRegistered') {
          entityNumbers.push(Number(parsed.args[1]));
        }
      } catch {
        // Skip unparseable logs
      }
    });

    console.log(`âœ… Registered ${entityNumbers.length} entities: ${entityNumbers[0]}-${entityNumbers[entityNumbers.length - 1]}`);

    return { txHash: tx.hash, entityNumbers };
  } catch (error) {
    logError("BLOCKCHAIN", 'âŒ Batch registration failed:', error);
    throw error;
  }
};

export const assignNameOnChain = async (
  name: string,
  entityNumber: number,
  jurisdiction: JurisdictionConfig,
): Promise<{ txHash: string }> => {
  try {
    const { entityProvider } = await connectToEthereum(jurisdiction);

    if (DEBUG) console.log(`ðŸ·ï¸  Assigning name "${name}" to entity #${entityNumber}`);

    // Call the smart contract (admin only)
    const tx = await entityProvider['assignName']!(name, entityNumber);
    if (DEBUG) console.log(`   ðŸ“¤ Transaction sent: ${tx.hash}`);

    // Wait for confirmation
    const receipt = await tx.wait();
    if (DEBUG) console.log(`   âœ… Transaction confirmed in block ${receipt.blockNumber}`);

    // Check if transaction reverted
    if (receipt.status === 0) {
      throw new Error(`Transaction reverted! Hash: ${tx.hash}`);
    }

    if (DEBUG) console.log(`âœ… Name assigned successfully!`);
    if (DEBUG) console.log(`   TX: ${tx.hash}`);

    return { txHash: tx.hash };
  } catch (error) {
    logError("BLOCKCHAIN", 'âŒ Name assignment failed:', error);
    throw error;
  }
};

export const getEntityInfoFromChain = async (
  entityId: string,
  jurisdiction: JurisdictionConfig,
): Promise<{ exists: boolean; entityNumber?: number; name?: string }> => {
  try {
    const { entityProvider } = await connectToEthereum(jurisdiction);

    // Try to get entity info
    const entityInfo = await entityProvider['entities']!(entityId);

    if (entityInfo.status === 0) {
      return { exists: false };
    }

    // For numbered entities, get the number and name
    const entityType = detectEntityType(entityId);
    let entityNumber: number | undefined;
    let name: string | undefined;

    if (entityType === 'numbered') {
      const extractedNumber = extractNumberFromEntityId(entityId);
      if (extractedNumber !== null) {
        entityNumber = extractedNumber;
        try {
          const retrievedName = await entityProvider['numberToName']!(entityNumber);
          name = retrievedName || undefined;
        } catch {
          // No name assigned
        }
      }
    }

    return {
      exists: true,
      ...(entityNumber !== undefined ? { entityNumber } : {}),
      ...(name !== undefined ? { name } : {})
    };
  } catch (error) {
    logError("BLOCKCHAIN", 'âŒ Failed to get entity info from chain:', error);
    return { exists: false };
  }
};

export const getNextEntityNumber = async (jurisdiction: JurisdictionConfig): Promise<number> => {
  try {
    if (!jurisdiction) {
      throw new Error('Jurisdiction parameter is required');
    }

    // Support both direct property and nested under contracts with type safety
    let entityProviderAddress = jurisdiction.entityProviderAddress;

    if (!entityProviderAddress && 'contracts' in jurisdiction) {
      const jurisdictionWithContracts = jurisdiction as Record<string, unknown> & { contracts?: { entityProvider?: string } };
      const contractAddress = jurisdictionWithContracts.contracts?.entityProvider;
      if (contractAddress) {
        entityProviderAddress = contractAddress;
      }
    }

    if (!jurisdiction.name || !entityProviderAddress) {
      throw new Error('Jurisdiction object is missing required properties (name, entityProvider address)');
    }

    const { entityProvider } = await connectToEthereum(jurisdiction);

    if (DEBUG)
      console.log(`ðŸ” Fetching next entity number from ${entityProviderAddress} (${jurisdiction.name})`);

    const nextNumber = await entityProvider['nextNumber']!();
    const result = Number(nextNumber);

    if (DEBUG) console.log(`ðŸ”¢ Next entity number: ${result}`);
    return result;
  } catch (error) {
    logError("BLOCKCHAIN", 'âŒ Failed to get next entity number:', error);
    throw error;
  }
};

export const transferNameBetweenEntities = async (
  name: string,
  fromNumber: number,
  toNumber: number,
  _jurisdiction: JurisdictionConfig,
): Promise<string> => {
  if (DEBUG) console.log(`ðŸ”„ Transferring name "${name}" from #${fromNumber} to #${toNumber}`);

  // TODO: Implement real blockchain name transfer
  throw new Error('Name transfer not implemented - requires blockchain integration');
};

// === JURISDICTION MANAGEMENT ===

// Load contract configuration and generate jurisdictions
export const generateJurisdictions = async (): Promise<Map<string, JurisdictionConfig>> => {

  const jurisdictions = new Map<string, JurisdictionConfig>();

  try {
    let config: any; // Complex type - loadJurisdictions returns different shapes in different contexts

    if (!isBrowser && typeof process !== 'undefined') {
      // Node.js environment - use centralized loader
      console.log('ðŸ” JURISDICTION SOURCE: Using centralized jurisdiction-loader');
      config = loadJurisdictions();
      console.log('ðŸ” JURISDICTION DEBUG: Loaded config with contracts:', config.jurisdictions?.ethereum?.contracts);
      console.log('âœ… Loaded jurisdictions from centralized loader (cached)');
    } else {
      // Browser environment - fetch from runtime with timeout (prevents indefinite hang in BrowserVM mode)
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 3000); // 3 second timeout

      try {
        const response = await fetch('./jurisdictions.json', { signal: controller.signal });
        clearTimeout(timeoutId);
        if (!response.ok) {
          throw new Error(`Failed to fetch jurisdictions.json: ${response.status} ${response.statusText}`);
        }
        config = await response.json();
        console.log('ðŸ” JURISDICTION DEBUG: Browser loaded config with contracts:', config.jurisdictions?.ethereum?.contracts);
        console.log('âœ… Loaded jurisdictions from runtime');
      } catch (fetchError: any) {
        clearTimeout(timeoutId);
        if (fetchError.name === 'AbortError') {
          console.log('â±ï¸ jurisdictions.json fetch timed out - using BrowserVM mode (no external blockchain)');
        } else {
          console.log('âš ï¸ jurisdictions.json not found - using BrowserVM mode (no external blockchain)');
        }
        // Return empty map for BrowserVM mode - scenarios handle their own fallback
        return jurisdictions;
      }
    }

    const jurisdictionData = config.jurisdictions;

    // Build jurisdictions from loaded config with type safety
    for (const [key, data] of Object.entries(jurisdictionData)) {
      // Validate structure before using
      if (!data || typeof data !== 'object') {
        console.warn(`ðŸš¨ Invalid jurisdiction data for ${key}:`, data);
        continue;
      }
      const jData = data as Record<string, any>;

      // CRITICAL: Check for RPC override (for Oculus Quest compatibility)
      let rpcUrl = jData['rpc'];

      // Detect Oculus Browser (blocks custom ports on HTTPS - security restriction)
      const isOculusBrowser = isBrowser && /OculusBrowser|Quest/i.test(navigator.userAgent);

      const rpcOverride = isBrowser ? localStorage.getItem('xln_rpc_override') : null;

      uiLog(`ðŸ” RPC-TRANSFORM-START: key=${key}, rpc=${rpcUrl}`, {
        isOculusBrowser,
        override: rpcOverride,
        userAgent: isBrowser ? navigator.userAgent : 'N/A'
      });

      // Oculus Browser fix: Force direct port without +10000 offset
      if (isOculusBrowser && !rpcOverride && rpcUrl.startsWith(':')) {
        const port = parseInt(rpcUrl.slice(1));
        rpcUrl = `${window.location.protocol}//${window.location.hostname}:${port}`;
        uiLog(`ðŸŽ® OCULUS FIX: Using direct port ${port} â†’ ${rpcUrl}`);
      }

      if (rpcOverride && rpcOverride !== '') {
        // User-specified RPC override
        if (rpcOverride.startsWith('/')) {
          // Path-based proxy (e.g., /rpc or /rpc/ethereum)
          // If single jurisdiction, use path directly. If multiple, append jurisdiction name.
          const jurisdictionCount = Object.keys(config.jurisdictions).length;
          const path = jurisdictionCount === 1
            ? rpcOverride  // Single jurisdiction: use /rpc directly
            : (rpcOverride.endsWith('/') ? rpcOverride + jData['name'].toLowerCase() : `${rpcOverride}/${jData['name'].toLowerCase()}`);
          rpcUrl = `${window.location.origin}${path}`;
          uiLog(`ðŸ”§ RPC URL (override): ${jData['rpc']} â†’ ${rpcUrl} (path proxy, ${jurisdictionCount} jurisdictions)`);
        } else if (rpcOverride.startsWith(':')) {
          // Port-based (e.g., :8545 or :18545)
          rpcUrl = `${window.location.protocol}//${window.location.hostname}${rpcOverride}`;
          uiLog(`ðŸ”§ RPC URL (override): ${jData['rpc']} â†’ ${rpcUrl} (custom port)`);
        } else {
          // Full URL override
          rpcUrl = rpcOverride;
          uiLog(`ðŸ”§ RPC URL (override): ${jData['rpc']} â†’ ${rpcUrl} (full URL)`);
        }
      } else if (isBrowser && rpcUrl.startsWith('/')) {
        // Path-based proxy (e.g., /rpc/arrakis) - use same origin
        rpcUrl = `${window.location.origin}${rpcUrl}`;
        uiLog(`ðŸ”§ RPC-TRANSFORM-PROXY: ${jData['rpc']} â†’ ${rpcUrl}`, {
          origin: window.location.origin,
          proxyPath: jData['rpc']
        });
      } else if (isBrowser && rpcUrl.startsWith(':')) {
        // Port-based (legacy): production uses port + 10000 (nginx proxy)
        const port = parseInt(rpcUrl.slice(1));
        const isLocalhost = window.location.hostname.match(/localhost|127\.0\.0\.1/);
        const actualPort = isLocalhost ? port : port + 10000;
        rpcUrl = `${window.location.protocol}//${window.location.hostname}:${actualPort}`;
        uiLog(`ðŸ”§ RPC-TRANSFORM-DEFAULT: ${jData['rpc']} â†’ ${rpcUrl}`, {
          hostname: window.location.hostname,
          isLocalhost: !!isLocalhost,
          port,
          actualPort,
          portOffset: isLocalhost ? 0 : 10000
        });
      } else if (!isBrowser && rpcUrl.startsWith(':')) {
        // Node.js: Default to localhost
        rpcUrl = `http://localhost${rpcUrl}`;
      }

      uiLog(`ðŸ“ FINAL-RPC-URL: ${key} â†’ ${rpcUrl}`, {
        entityProvider: jData['contracts']['entityProvider'],
        depository: jData['contracts']['depository']
      });

      jurisdictions.set(key, {
        address: rpcUrl,
        name: jData['name'],
        entityProviderAddress: jData['contracts']['entityProvider'],
        depositoryAddress: jData['contracts']['depository'],
        chainId: jData['chainId'],
      });
    }
  } catch (error) {
    logError("BLOCKCHAIN", 'âŒ Failed to load jurisdictions:', error);
  }

  return jurisdictions;
};

export let DEFAULT_JURISDICTIONS: Map<string, JurisdictionConfig> | null = null;

export const getJurisdictions = async (): Promise<Map<string, JurisdictionConfig>> => {
  // In browser, cache the result to avoid multiple fetches
  if (isBrowser && DEFAULT_JURISDICTIONS !== null) {
    console.log('ðŸ” JURISDICTIONS: Using cached browser data');
    return DEFAULT_JURISDICTIONS;
  }

  // Generate/fetch jurisdictions
  DEFAULT_JURISDICTIONS = await generateJurisdictions();
  return DEFAULT_JURISDICTIONS!;
};

export const getAvailableJurisdictions = async (): Promise<JurisdictionConfig[]> => {
  const jurisdictions = await getJurisdictions();
  return Array.from(jurisdictions.values());
};

// DEPRECATED: Use env.browserVM instead of global singleton
let BROWSER_VM_INSTANCE: any = null;

/**
 * Set BrowserVM jurisdiction (for isolated /view environments)
 * @param env - Runtime environment to store BrowserVM instance
 * @param depositoryAddress - Depository contract address
 * @param browserVMInstance - Optional pre-initialized BrowserVM instance
 */
export const setBrowserVMJurisdiction = (env: any, depositoryAddress: string, browserVMInstance?: any) => {
  console.log('[BrowserVM] Setting jurisdiction override:', { depositoryAddress, hasBrowserVM: !!browserVMInstance });

  const rawBrowserVM = browserVMInstance?.browserVM ?? browserVMInstance;
  const resolvedBrowserVM = rawBrowserVM?.getProvider ? rawBrowserVM.getProvider() : rawBrowserVM;

  // Store browserVM instance in env (isolated per-runtime)
  if (resolvedBrowserVM && env) {
    env.browserVM = resolvedBrowserVM;
    console.log('[BrowserVM] Stored browserVM instance in env (isolated)');
  }

  // BACKWARD COMPAT: Also store in global for legacy code
  if (resolvedBrowserVM) {
    BROWSER_VM_INSTANCE = resolvedBrowserVM;
  }

  const resolveEntityProvider = () => {
    if (resolvedBrowserVM?.getEntityProviderAddress) return resolvedBrowserVM.getEntityProviderAddress();
    if (env?.browserVM?.getEntityProviderAddress) return env.browserVM.getEntityProviderAddress();
    if (BROWSER_VM_INSTANCE?.getEntityProviderAddress) return BROWSER_VM_INSTANCE.getEntityProviderAddress();
    return '0x0000000000000000000000000000000000000000';
  };

  const entityProviderAddress = resolveEntityProvider();
  if (!entityProviderAddress || entityProviderAddress === '0x0000000000000000000000000000000000000000') {
    console.warn('[BrowserVM] EntityProvider address missing - numbered entities will fail until EP is deployed.');
  }

  DEFAULT_JURISDICTIONS = new Map();
  DEFAULT_JURISDICTIONS.set('arrakis', {
    name: 'Arrakis',
    chainId: 1337,
    address: 'browservm://', // BrowserVM uses in-memory EVM, no real RPC
    entityProviderAddress,
    depositoryAddress,
  });

  console.log('âœ… BrowserVM jurisdiction active - numbered entities will register here');
};

export const getJurisdictionByAddress = async (address: string): Promise<JurisdictionConfig | undefined> => {
  const jurisdictions = await getJurisdictions();
  return jurisdictions.get(address);
};

/**
 * Get BrowserVM instance (for demos that need direct BrowserVM access)
 * Prefers env.browserVM (isolated), falls back to global singleton (legacy)
 */
export const getBrowserVMInstance = (env?: any): BrowserVMInstance | null => {
  if (env?.browserVM) {
    return env.browserVM;
  }
  // BACKWARD COMPAT: Fall back to global singleton
  return BROWSER_VM_INSTANCE;
};

// Settlement diff structure matching contract
export interface SettlementDiff {
  tokenId: number;
  leftDiff: bigint;
  rightDiff: bigint;
  collateralDiff: bigint;
  ondeltaDiff?: bigint; // Optional in some contexts
}

export const submitSettle = async (
  jurisdiction: JurisdictionConfig,
  leftEntity: string,
  rightEntity: string,
  diffs: SettlementDiff[],
  forgiveDebtsInTokenIds: number[] = [],
  insuranceRegs: Array<{ insured: string; insurer: string; tokenId: number; limit: bigint; expiresAt: bigint }> = [],
  sig?: string
) => {
  try {
    console.log(`âš–ï¸ Submitting settle transaction between ${leftEntity.slice(0, 10)}... and ${rightEntity.slice(0, 10)}...`);
    console.log(`ðŸ” DIFFS:`, diffs.map(d => ({
      ...d,
      leftDiff: d.leftDiff.toString(),
      rightDiff: d.rightDiff.toString(),
      collateralDiff: d.collateralDiff.toString()
    })));

    const hasChanges = diffs.length > 0 || forgiveDebtsInTokenIds.length > 0 || insuranceRegs.length > 0;
    if (hasChanges && (!sig || sig === '0x')) {
      throw new Error('Settlement signature required for settle');
    }
    const finalSig = sig || '0x';

    const { depository, provider } = await connectToEthereum(jurisdiction);
    console.log(`ðŸ” CONTRACT ADDRESS: ${depository.target}`);

    // Check if contract exists
    const code = await provider.getCode(depository.target);
    if (code === '0x') {
      throw new Error('Contract not deployed at this address');
    }

    // Call settle function
    console.log(`ðŸ“¤ Calling settle function...`);
    const tx = await depository['settle']!(
      leftEntity,
      rightEntity,
      diffs,
      forgiveDebtsInTokenIds,
      insuranceRegs,
      finalSig
    );
    console.log(`ðŸ’« Transaction sent: ${tx.hash}`);

    // Wait for confirmation
    const receipt = await tx.wait();
    console.log(`âœ… Settlement confirmed in block ${receipt.blockNumber}`);

    if (receipt.status === 0) {
      throw new Error(`Settlement transaction reverted! Hash: ${tx.hash}`);
    }

    console.log(`ðŸŽ‰ Settlement successful! Both entities should receive SettlementProcessed events`);
    return { txHash: tx.hash, blockNumber: receipt.blockNumber };

  } catch (error) {
    logError("BLOCKCHAIN", 'âŒ Settlement failed:', error);
    throw error;
  }
};

export const submitReserveToReserve = async (jurisdiction: JurisdictionConfig, fromEntity: string, toEntity: string, tokenId: number, amount: string) => {
  try {
    console.log(`ðŸ’¸ DIRECT R2R: ${fromEntity.slice(0,10)} â†’ ${toEntity.slice(0,10)}, token ${tokenId}, amount ${amount}`);

    const { depository, provider } = await connectToEthereum(jurisdiction);
    console.log(`ðŸ” CONTRACT ADDRESS: ${depository.target}`);

    // Check if contract exists
    const code = await provider.getCode(depository.target);
    if (code === '0x') {
      throw new Error('Contract not deployed at this address');
    }

    // Call direct reserveToReserve function
    console.log(`ðŸ“¤ Calling reserveToReserve(${fromEntity}, ${toEntity}, ${tokenId}, ${amount})...`);
    const tx = await depository['reserveToReserve']!(fromEntity, toEntity, tokenId, amount);
    console.log(`ðŸ’« Transaction sent: ${tx.hash}`);

    // Wait for confirmation
    const receipt = await tx.wait();
    console.log(`âœ… R2R confirmed in block ${receipt.blockNumber}`);

    if (receipt.status === 0) {
      throw new Error(`R2R transaction reverted! Hash: ${tx.hash}`);
    }

    console.log(`ðŸŽ‰ Direct R2R successful!`);
    return { txHash: tx.hash, blockNumber: receipt.blockNumber };

  } catch (error) {
    logError("BLOCKCHAIN", 'âŒ Direct R2R failed:', error);
    throw error;
  }
};


//docs/emc2.md (33 lines)
Î”

âˆ’Lâ‚— â‰¤ Î” â‰¤ C + Láµ£
xln.finance
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Reserve-Credit Programmable Enforceable 
Layer2 Netting-Account Network  
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FCUAN Full-Credit Unprovable Account Network
100% of modern finance: Banking, SWIFT, Visa, any CEX etc (âˆ’5000 BCE)
no collateral, no proof = trust-based, censorable, Diamond-Dybvig runs
[âˆ’âˆ’âˆ’.**Î”âˆ’]  C = 0, Î” âˆˆ [âˆ’Lâ‚—, +Láµ£]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FRPAP Full-Reserve Provable Account Primitives
Layer2 channels: BTC Lightning (2015), ETH Raiden (2017), ADA Hydra (2020) etc
no credit = unusable inbound capacity wall, capital inefficiency
[.==Î”=]  Lâ‚—=Láµ£=0, Î” âˆˆ [0, +C]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
xln (RCPAN) âŠƒ { FCUAN, FRPAP }
Î” âˆˆ [âˆ’Lâ‚—, C + Láµ£]
Scalable Secure Simple

âˆž unicast O(1) scalability, Coasian ->0% fees

first-ever cryptographically enforced debt + collateral
account proofs with guaranteed L1 dispute resolution
always local state without erasure coding/DAC/DAS-trust
sovereign exits, no rollup DA-risk by design 

EVM-first multi-jurisdiction omni-Layer2
flexible credit-collateral security model
banking-like UX


//docs/12_invariant.md (80 lines)
# 1.2 RCPAN Invariant 

[pairing: Pye Corner Audio - The Simplest Equation](https://www.youtube.com/watch?v=Vp0a8tdzJmk) (but yes, technically it's inequality)


The core creditâ€“collateral mechanism can be grasped in three minutes. Accounts are bilateral relationships between entities. 

For centuries, the world has run on FCUAN (full-credit, unprovable account networksâ€”i.e., traditional banking credit rails): bilateral, uncollateralized limits between end-users (â€œspokesâ€) and banks/brokers (â€œhubsâ€). Any CEX (e.g., Binance, Coinbase) is also FCUAN. 

FCUAN scales phenomenally but offers weak user security. Any spoke can be censored, and assets seized at any moment. Hubs can default, even without malice (Diamondâ€“Dybvigâ€“style hub runs). 

Deposit insurance is typically small relative to broad money (â‰ª M2), which systematically externalizes tail risk and invites moral hazard.

Two entities start a financial relationship (per-asset Î” balances). Their xln wallets compare their hex IDs; the lower becomes L (left), the other R (right). Imagine an x-axis where:

. is zero (0)
Î” delta is the signed balance (saldo) between counterparties
[ ] are invariant boundariesâ€”how far Î” can move given mutual credit and shared collateral

Clean slate (all zeros):

(L)eft entity   [.Î”]   (R)ight entity

Either party can extend a credit limit to the other:
- unused, uncollateralized credit line (credit)
* used credit

Example (leftCreditLimit = 3, rightCreditLimit = 3):

[---.Î”---]

Payments pull Î” toward the payerâ€™s side (away from the receiver) while the receiverâ€™s allocation increases.
L pays 2 to R â†’ Î” = âˆ’2:

[-Î”**.---]

R pays back 3 â†’ Î” = +1:

[---.*âˆ†--]

This is what 99.99% of the world economy runs on. Today, every bank, broker, CEX, and payment intermediary is pure FCUAN.

A different approach, FRPAP (full-reserve, provable account primitives), often called â€œpayment/state channels,â€ was popularized by the 2017 Lightning Network paper. FRPAP/Payment channels are full-reserve bilateral accounts with proofsâ€”not a network architecture.

Every full-reserve design (e.g., Raiden on Ethereum, Hydra on Cardano) inherits the inbound-capacity constraintâ€”an architectural limit, not an implementation bug. Itâ€™s more precise to treat this as a family of three account primitivesâ€”proofs, collateral, and delta transformersâ€”rather than a scalable network.

In diagrams:
= collateral (fully escrowed). Think of it as a dedicated 2-of-2 escrow with cryptographic guarantees.

We draw collateral to the right of zero. R posts 3 units of collateral:

[.Î”===]

R pays 2 (Î” moves right):

[.==Î”=]

xln is the first RCPAN (Reserve-Credit, Provable Account Network): credit where it scales, collateral where it securesâ€”a principled hybrid of FCUAN and FRPAP.

FCUAN invariant:
âˆ’leftCreditLimit â‰¤ Î” â‰¤ rightCreditLimit
[---.---]

FRPAP invariant:
0 â‰¤ Î” â‰¤ collateral
[.===]

RCPAN (xln) superset invariant:
âˆ’leftCreditLimit â‰¤ Î” â‰¤ collateral + rightCreditLimit
[---.===---]

xln can mimic both: ignore collateral functionality and it works like banking with enforceable proofs; ignore credit lines and it works like Lightning/full-reserve payment-channel networks. 

Using both is where the real synergy emerges. RCPAN is literally how banks already think about credit, just formalized.

Practical consequences: no inbound liquidity wall and no unbounded hub riskâ€”losses are link-capped; throughput scales with links, not global broadcasts.

Follow for news, analysis, and a verification-first roadmap (proof sketch, benchmarks, economic spec, security playbook). xln is layer-2 done right.

ðŸ”— https://github.com/xlnfinance/xln

//docs/jea.md (134 lines)
ðŸ›ï¸ JEA: Jurisdiction-Entity-Account Model

â€œJEA is not just a technical pattern â€” itâ€™s a legal operating system for programmable institutions.â€

The JEA architecture underpins XLNâ€™s modular trust and execution model. It separates concerns cleanly across three layers:
	â€¢	Jurisdictions: Public, often on-chain arbitration and registry zones
	â€¢	Entities: Sovereign programmable machines (like DAOs or firms)
	â€¢	Accounts (Channels): Bilateral trust relationships or financial instruments

This document outlines the JEA structure in detail, its purpose, flow, and how it replaces traditional consensus-heavy architectures.

â¸»

âš–ï¸ 1. Jurisdiction: Public Arbitration Layer

A Jurisdiction is a public smart contract or observable registry that acts as:
	â€¢	Dispute settlement ground
	â€¢	Reserve registry
	â€¢	Oracle of record for shared events

Key Concepts
	â€¢	Jurisdiction is opt-in: Entities choose when to interact
	â€¢	Jurisdiction has no access to internal state
	â€¢	Jurisdiction observes receipts: Signed proofs of action

Contracts
	â€¢	EntityProvider.sol â€” stores quorum hash (Merkle root of signer structure)
	â€¢	Depository.sol â€” stores reserve/collateral data
	â€¢	Custom registries â€” e.g., insurance claims, auctions, licenses

Use Cases

Case	Jurisdiction Role
Reserve deposit	Holds tokens, emits event
Credit collateralization	Verifies locked assets and releases collateral
Token mint claim	Accepts signed receipt from Entity and emits asset

â€œJurisdictions are like courts that accept signed, notarized paperwork â€” but never interfere in private life unless called.â€

â¸»

ðŸ›ï¸ 2. Entity: Sovereign Organization

An Entity is a self-contained state-time machine with its own quorum, storage, and block history.

Key Properties
	â€¢	Maintains internal logic via deterministic actions
	â€¢	Requires quorum threshold for any state change
	â€¢	Can spawn accounts, tokens, and internal machines
	â€¢	Interacts with Jurisdiction via signed receipts

On Jurisdiction Access
	â€¢	Entity creates a Proposal to mint/reserve/interact externally
	â€¢	Once quorum signs and the state commits, the signed receipt is emitted
	â€¢	Receipt may be submitted to Jurisdiction by any party (watchers)

Security Guarantees
	â€¢	Jurisdiction verifies Merkle proof of quorum hash
	â€¢	Jurisdiction does not need to replay Entity logic â€” trust is cryptographic

â€œAn Entity is like a company with its own bylaws and board. The state doesnâ€™t care what happens inside â€” until you file a public claim.â€

â¸»

ðŸ’³ 3. Account: Channels and Financial Instruments

Accounts represent:
	â€¢	Channels (credit lines, bilateral payments)
	â€¢	Subcontracts (vesting, options, loans)
	â€¢	Internal balances or positions

Structure
	â€¢	Always nested inside an Entity
	â€¢	Follows AccountProof â†’ Subcontract model
	â€¢	Each has its own logic, deltas, and Merkle proof

Execution
	â€¢	Account emits proof of state change (e.g. balance update)
	â€¢	Entity collects and commits proof into its block
	â€¢	Optionally, Jurisdiction may act on this (e.g. insurance trigger)

â€œAccounts are the atoms. Entities are the molecules. Jurisdiction is the surrounding legal atmosphere.â€

â¸»

ðŸ” Flow Summary: Bottom-Up

1. Account: emits change (e.g., collateral unlocked)
2. Entity: signs and commits block containing proof
3. Jurisdiction: optionally accepts receipt, verifies hash chain


â¸»

ðŸ›¡ Why JEA Is Superior

Feature	Traditional Stack	JEA Architecture
Shared State	Global / Bottleneck	Local / Modular
Dispute Resolution	Forks / Governance	Receipt + Quorum
Composability	High coupling	Strong separation
State Integrity	L1-dependent	Self-contained with proofs
Credit / Receivability	Impossible	Native via Accounts

â€œRollups try to be courts, states, and wallets all at once. JEA says: split the roles, keep the contracts clean, and let each layer focus on what itâ€™s best at.â€

â¸»

ðŸ§¬ Design Ethos
	â€¢	Modularity over Monolith: Each layer is clean, testable, swappable
	â€¢	Paper trail over gossip: All actions leave verifiable receipts
	â€¢	State sufficiency: If your Entity vanishes, your counterparty still has proof
	â€¢	Quorum â‰  Token ownership: Governance and execution are separate vectors

â¸»

ðŸ§­ Future Directions
	â€¢	Jurisdictions as regulated custodians
	â€¢	Inter-Jurisdiction arbitration via Entity-controlled registries
	â€¢	Reputation-weighted quorum systems
	â€¢	Federated DAOs across multiple Entities

â¸»

ðŸ“Œ In Practice
	â€¢	EntityProvider.sol: sets Merkle hash of quorum
	â€¢	Depository.sol: verifies and tracks reserves
	â€¢	Entity: commits actions, emits receipts
	â€¢	Account: executes financial logic, tracks deltas

â¸»

JEA is to blockchain what OSI was to networking â€” a layered abstraction that makes sovereign computation composable, trustable, and legible.

â€œYou donâ€™t need one chain to rule them all. You just need a structure where trust can be scoped, verified, and proven.â€

//docs/11_Jurisdiction_Machine.md (43 lines)
# 1.1 Jurisdiction Machine / J-machine

## 1.1.1 TradFi J-machine

Imagine, the year is 2008. Blockchains/cryptocurrencies/DLT never existed. Forget about DAOs, BFT and payment channels, lets focus exclusively on the traditional financial world (TradFi). We are going to apply Occam's Razor and Duck Typing principle to each component of TradFi, to remove the legacy fluff and extract the essence.

Let's start with our fundamental primitive: a replicated state machine.

What is a state machine? It's an abstract concept from Automata theory. A state machine is a system that moves between defined states based on inputs â€” each tx (transaction) changes behavior predictably. Itâ€™s how you turn chaos into logic.

Say, you have `{Alice: 10, Bob: 5}`. Tx `alice-bob pay 2` would turn it into `{Alice: 8, Bob: 7}`

TradFi can be expressed as a myriad of interconnected state machines. At first glance it seems that every country has their own unique financial system with different acronyms and legal quirks. But after a closer look, we immediately see a pattern: there always is a root sovereign settlement court state machine that rules all state machines beneath it: the Jurisdiction State Machine.

For historical reasons, tradfi J-machines are fragmented:

* the oldest component â€“ Central Bank, where **the currency (fiat) token** is minted in a form of debt to commercial banks.
* the second component, Real Time Gross Settlement (RTGS) appeared later with advances in computers and networking. It allows commercial banks to move high value instantly (real time) without trusting each other with netting accounts (ACH). Technically, an account in Fedwire is an account in Fed. Therefore RTGS === Central Bank.
* the third is central securities depository. That's where other **tokens are minted and stored**. 
* plus multiple land registries where non-fungible tokens such as land and apartments are assigned to entities

This fragmentation brings nothing but pain and reconcillation hell. 

Storing fiat token in one ledger and security tokens in another is like keeping count of bananas in one spreadsheat and using a whole another book for other fruits. The benefits are marginal, the downsides are glorious. 

Applying Occam's Razor, we suggest from now on to conceptually treat all fragmented tradfi central banks/RTGS/depositories as a unified J-machine. 

## 1.1.2 TradFi Entity Machine

Beneath the J-machine there always is a second layer graph-like hub & spoke network, where:
* **spokes** are end users, merchants, companies, non-profits, institutions
* **hubs** commercial banks, brokers

We generalize all layer2 actors bounded to specific J-machine as E-machines. Think of it as your personal state machine that stores your financial history and relationships with others. Each E-machine can interact with J-machine (the broadcast layer) and with other entities through A-machines (unicast account layer).







Namely, in TradFi we superset {RTGS, Central Banks and Central Securities Depositaries} as a single-signer J-machine. Likewise, we claim "blockchains" or "cryptocurrencies" should have never existed as buzzwords: it's a multi-signer J-machine.
 

//docs/PriorArt.md (62 lines)
# Prior Art

Xln is built on shoulders of giants.

## Bitcoin

Satoshi Nakamoto is genius for creating the replicated state machine (RSM) movement. For making people even ask and wonder why do we keep our entire net-worth in hands of unprovable custodial state machines. 

## Ethereum

Vitalik Buterin is genius for inventing Turing-complete programmable RSM: EVM (Ethereum Virtual Machine). EVM is our reference adapter Jurisdiction machine in J-REA stack. Its yellowpaper alone changed the course of human history forever. 
Unfortunatelly, we believe his & EF team narrative about plasma, rollups, DAC/DAS are not an endgame. It feels like a costly detour and dead-end research trap. **All broadcast O(n) designs are fundamentally bottlenecked in scalability and mathematically flawed with data availability paradox.**

Their goals are noble: trustless exitable layer2. But their means are mathematically handicapped. Broadcast-J-shared-state just cannot have planetary scale. Neither directly (big blockers) nor through blob-checkpointing surrogates. There is nothing you can do about it. 

The unicast bilateral state approach completely side-steps this problem.

No amount of DAC/DAS/erasure coding assumption cascades can solve that. **Those are very intellectually interesting problems to work on, but they are perpetuum mobile in a nutshell.**


Ethereum: 15 TPS global
XLN on Ethereum: Millions of TPS bilateral (O(1) per entity pair)

Solana: 3000 TPS global  
XLN on Solana: Still millions of TPS bilateral

Conclusion: Base layer TPS is IRRELEVANT for XLN.


## Lightning Network



## Ronald Coase

##  Douglas Diamond, Philip H. Dybvig, Ben Bernanke





We are turn existing RSM into J-REA two-layered stack. 
Banking: "Trust us with your money"
XLN: "Same UX, but you can exit anytime with cryptographic proof"

Binance: "We're totally not fractional reserve"
XLN: "Here's the on-chain collateral, verify yourself"

SWIFT: "$30 fee, 3 days"
XLN: "$0.00001 fee, 3 seconds"
```

## Against Rollups
```
Rollups: "We'll decentralize the sequencer somedayâ„¢"
XLN: "No sequencer needed"

Rollups: "Trust our data availability committee"
XLN: "Your counterparty IS your data availability"

Rollups: "Pay $0.10 per tx for blob space"
XLN: "Pay $0 until you need to rebalance (rare)"
